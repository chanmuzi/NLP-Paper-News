{
  "version": 1,
  "last_updated": "2025-10-28T12:58:31.524004",
  "total_items": 1482,
  "items": [
    {
      "id": "NVIDIA,-MIT,-HKUST-longlive-real-time-interactive-long-video-generation",
      "date": "2025-10-W01",
      "year": "2025",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "NVIDIA, MIT, HKUST",
      "title": "LongLive: Real-time Interactive Long Video Generation",
      "url": "https://arxiv.org/abs/2509.22622",
      "bullets": [
        {
          "text": "KV-recache mechanism: new prompts을 통해 cached states를 refresh",
          "level": 1
        },
        {
          "text": "short window attention paired with a frame-level attention sink",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Anthropic-introducing-claude-sonnet-45",
      "date": "2025-10-W01",
      "year": "2025",
      "month": "10",
      "week": "1",
      "type": "dev",
      "org": "Anthropic",
      "title": "Introducing Claude Sonnet 4.5",
      "url": "https://www.anthropic.com/news/claude-sonnet-4-5",
      "bullets": [
        {
          "text": "30시간 넘게 처리해야 하는 코딩 태스크도 수행 가능하다고 설명",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-vibe-working-introducing-agent-mode-and-office-agent-in-microsoft-365-copilot",
      "date": "2025-10-W01",
      "year": "2025",
      "month": "10",
      "week": "1",
      "type": "dev",
      "org": "Microsoft",
      "title": "Vibe working: Introducing Agent Mode and Office Agent in Microsoft 365 Copilot",
      "url": "https://www.microsoft.com/en-us/microsoft-365/blog/2025/09/29/vibe-working-introducing-agent-mode-and-office-agent-in-microsoft-365-copilot/",
      "bullets": [
        {
          "text": "[SpreadsheetBench](https://spreadsheetbench.github.io/)에서 SoTA",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Ai2-asta-datavoyager-data-driven-discovery-and-analysis",
      "date": "2025-10-W01",
      "year": "2025",
      "month": "10",
      "week": "1",
      "type": "dev",
      "org": "Ai2",
      "title": "Asta DataVoyager: Data-driven discovery and analysis",
      "url": "https://allenai.org/blog/asta-datavoyager",
      "bullets": [
        {
          "text": "spreadsheet, csv와 같은 structured data에서 explainable answer 반환 (복사 가능한 코드, 시각적 자료 등과 함께)",
          "level": 1
        },
        {
          "text": "on-premise, private cloud에서 데이터 관리 (보안)",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "OpenAI-sora-2-is-here",
      "date": "2025-10-W01",
      "year": "2025",
      "month": "10",
      "week": "1",
      "type": "dev",
      "org": "OpenAI",
      "title": "Sora 2 is here",
      "url": "https://openai.com/index/sora-2/",
      "bullets": [
        {
          "text": "physics-aware, synchronized audio, controllability 등 특징",
          "level": 1
        },
        {
          "text": "5-10s output, 워터마크",
          "level": 1
        },
        {
          "text": "invite-only launch in U.S. & Canada",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "NUS-mcpmark-a-benchmark-for-stress-testing-realistic-and-comprehensive-mcp-use",
      "date": "2025-10-W01",
      "year": "2025",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "NUS",
      "title": "MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP Use",
      "url": "https://arxiv.org/abs/2509.24002",
      "bullets": [
        {
          "text": "richer & diverse interactions 필요. CRUD operations 포함.",
          "level": 1
        },
        {
          "text": "gpt-5-medium이 52.56% pass@1, 33.86% pass^4로 현재 기준 최고 성능",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Thinking-Machines-announcing-tinker",
      "date": "2025-10-W01",
      "year": "2025",
      "month": "10",
      "week": "1",
      "type": "dev",
      "org": "Thinking Machines",
      "title": "Announcing Tinker",
      "url": "https://thinkingmachines.ai/blog/announcing-tinker/",
      "bullets": [
        {
          "text": "Llama-3.x ~ Qwen3 시리즈 모델 대상으로 학습 가능. 중간 체크포인트도 다운로드 가능",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Google-ai-as-a-research-partner-advancing-theoretical-computer-science-with-alphaevolve",
      "date": "2025-10-W01",
      "year": "2025",
      "month": "10",
      "week": "1",
      "type": "dev",
      "org": "Google",
      "title": "AI as a research partner: Advancing theoretical computer science with AlphaEvolve",
      "url": "https://research.google/blog/ai-as-a-research-partner-advancing-theoretical-computer-science-with-alphaevolve/",
      "bullets": [
        {
          "text": "LLM을 통해 기존 연구 자료 요약, 새로운 이론과 관련된 연구 계획, 이를 위한 증거(proofs) 단계를 밟게 될텐데, 특히 proof 확보에 AlphaEvolve를 활용할 수 있을 것이라 설명",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "NUS,-Oxford,-Stanford-gem-a-gym-for-agentic-llms",
      "date": "2025-10-W01",
      "year": "2025",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "NUS, Oxford, Stanford",
      "title": "GEM: A Gym for Agentic LLMs",
      "url": "https://arxiv.org/abs/2510.01051",
      "bullets": [
        {
          "text": "기존 OpenAI-Gym이 제공하던 것들을 그대로 지원 - asynchronous vectorized execution for high throughput & flexible wrappers for easy extensibility",
          "level": 1
        },
        {
          "text": "추가로, robust integrated tools & single-file example scripts with five popular RL training frameworks 지원",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Imperial-College-London-fine-tuning-with-rag-for-improving-llm-learning-of-new-skills",
      "date": "2025-10-W01",
      "year": "2025",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "Imperial College London",
      "title": "Fine-tuning with RAG for Improving LLM Learning of New Skills",
      "url": "https://arxiv.org/abs/2510.01375",
      "bullets": [
        {
          "text": "(1) agent failures로부터 compact & reusable hints 추출",
          "level": 1
        },
        {
          "text": "(2) 이 hints를 episode start 시점에 one-shot retrieval에 사용하여 improved teacher trajectories 생성",
          "level": 1
        },
        {
          "text": "(3) hint strings를 제거하여 student 모델을 학습함으로써 memorization 대신 internalization 유도",
          "level": 1
        },
        {
          "text": "household tasks를 다루는 ALFWorld, online shopping tasks를 다루는 WebShop 벤치마크에서 뛰어난 성능 달성",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Meta,-Johns-Hopkins-the-era-of-real-world-human-interaction-rl-from-user-conversations",
      "date": "2025-10-W01",
      "year": "2025",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "Meta, Johns Hopkins",
      "title": "The Era of Real-World Human Interaction: RL from User Conversations",
      "url": "https://arxiv.org/abs/2509.25137",
      "bullets": [
        {
          "text": "RLHI with User-Guided Rewrites: unsatisfactory model outputs를 유저의 natural-language follow-up response 기반으로 수정",
          "level": 1
        },
        {
          "text": "RLHI with User-Based Rewards: 유저의 long-term interaction history로 conditioned된 reward 모델을 통해 학습",
          "level": 1
        },
        {
          "text": "WildChat 데이터를 두 방식으로 학습한 모델이 personalization & instruction-following 관점에서 baseline outperform",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "DeepSeek-AI-deepseek-v32-exp",
      "date": "2025-10-W01",
      "year": "2025",
      "month": "10",
      "week": "1",
      "type": "dev",
      "org": "DeepSeek AI",
      "title": "DeepSeek-V3.2-Exp",
      "url": "https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/tree/main",
      "bullets": [
        {
          "text": "본 Sparse Attention은 long-context scenarios를 위해 설계된 디자인",
          "level": 2
        },
        {
          "text": "HuggingFace의 inference를 이용한 demo 시연 가능",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-openai-devday-2025",
      "date": "2025-10-W02",
      "year": "2025",
      "month": "10",
      "week": "2",
      "type": "dev",
      "org": "OpenAI",
      "title": "OpenAI DevDay 2025",
      "url": "https://openai.com/devday/",
      "bullets": [
        {
          "text": "AgentKit: Agent Builder, ChatKit, Evals (타사 모델 평가 지원), RFT, Guardrail 등",
          "level": 1
        },
        {
          "text": "Models & API update: GPT-5 Pro (API), Sora 2 (API), gpt-realtime-mini, gpt-image-1-mini",
          "level": 1
        },
        {
          "text": "Codex 일반 제공: Slack 연동, Codex SDK, 관리자 기능",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal",
        "agent"
      ]
    },
    {
      "id": "Maryland-uncertainty-aware-answer-selection-for-improved-reasoning-in-multi-llm-systems",
      "date": "2025-10-W02",
      "year": "2025",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Maryland",
      "title": "Uncertainty-Aware Answer Selection for Improved Reasoning in Multi-LLM Systems",
      "url": "https://arxiv.org/abs/2510.02377",
      "bullets": [
        {
          "text": "정확히는 모델들의 internal knowledge & confidence를 활용",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Anthropic,-Oxford-eliciting-secret-knowledge-from-language-models",
      "date": "2025-10-W02",
      "year": "2025",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Anthropic, Oxford",
      "title": "Eliciting Secret Knowledge from Language Models",
      "url": "https://arxiv.org/abs/2510.01070",
      "bullets": [
        {
          "text": "3개 model families로 black-box & white-box 스타일 둘 다 연구",
          "level": 1
        },
        {
          "text": "가장 퍼포먼스가 좋았던 것은 black-box 스타일 중 하나인 prefill attacks: LLM이 predefinex prefix가 주어졌을 때 completion 하면서 secret reveal",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Oxford,-Apple-the-data-quality-illusion-rethinking-classifier-based-quality-filtering-for-llm-pretraining",
      "date": "2025-10-W02",
      "year": "2025",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Oxford, Apple",
      "title": "The Data-Quality Illusion: Rethinking Classifier-Based Quality Filtering for LLM Pretraining",
      "url": "https://arxiv.org/abs/2510.00866",
      "bullets": [
        {
          "text": "각 document에 quality score를 부여",
          "level": 2
        },
        {
          "text": "CQF가 downstream task 퍼포먼스는 향상시키지만, 반드시 high-quality dataset modeling으로 이어지는 것은 아니라고 지적",
          "level": 1
        },
        {
          "text": "왜냐하면 CQF가 high-qaulity dataset 또한 filtering 하는 경우가 있기 때문",
          "level": 2
        },
        {
          "text": "CQF 기반으로 학습한 모델 vs. random token permutations 기반으로 학습한 모델",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Google-meet-jules-tools-a-command-line-companion-for-googles-async-coding-agent",
      "date": "2025-10-W02",
      "year": "2025",
      "month": "10",
      "week": "2",
      "type": "dev",
      "org": "Google",
      "title": "Meet Jules Tools: A Command Line Companion for Google’s Async Coding Agent",
      "url": "https://developers.googleblog.com/en/meet-jules-tools-a-command-line-companion-for-googles-async-coding-agent/",
      "bullets": [
        {
          "text": "과거 수정 내역과 개발자의 preferences를 기억하는 context awareness",
          "level": 1
        },
        {
          "text": "dashboard-style tasks view를 terminal에서 지원",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "CMU-llm-microscope-what-model-internals-reveal-about-answer-correctness-and-context-utilization",
      "date": "2025-10-W02",
      "year": "2025",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "CMU",
      "title": "LLM Microscope: What Model Internals Reveal About Answer Correctness and Context Utilization",
      "url": "https://arxiv.org/abs/2510.04013",
      "bullets": [
        {
          "text": "retrieved context가 모델 답변에 필요할지에 대한 internal signal이 존재하는지 탐구",
          "level": 1
        },
        {
          "text": "correct, incorrect, irrelevant context로 비교 실험",
          "level": 2
        },
        {
          "text": "intermediate layer activations에 대해 trained simple classifier를 사용하는 것만으로도 첫 번째 토큰의 activation을 분석하여 75% 정확도를 달성함",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta,-NYU-a-single-character-can-make-or-break-your-llm-evals",
      "date": "2025-10-W02",
      "year": "2025",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Meta, NYU",
      "title": "A Single Character can Make or Break Your LLM Evals",
      "url": "https://arxiv.org/abs/2510.05152",
      "bullets": [
        {
          "text": "comma? new line? semi-colon?, …",
          "level": 2
        },
        {
          "text": "Llama, Qwen, Gemma model family로 비교실험한 결과 the choice of delimiter가 MMLU에 대한 성능을 +- 23%까지 영향을 줬다고 설명",
          "level": 1
        },
        {
          "text": "심지어 topics, models families 구분 없이 존재하는 현상이며 scale에 따른 개선도 없다고 함",
          "level": 1
        },
        {
          "text": "attentino head scores를 분석하여, good-performing delimiters가 입력의 핵심 토큰에 attention 할 수 있도록 돕는다는 것을 확인",
          "level": 1
        },
        {
          "text": "또한 LLM의 robustness to the choice of delimiter를 강화하는 방법론 탐구",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-introducing-the-gemini-25-computer-use-model",
      "date": "2025-10-W02",
      "year": "2025",
      "month": "10",
      "week": "2",
      "type": "dev",
      "org": "Google",
      "title": "Introducing the Gemini 2.5 Computer Use model",
      "url": "https://blog.google/technology/google-deepmind/gemini-computer-use-model/",
      "bullets": [
        {
          "text": "Gemini 2.5 Pro의 visual understanding & reasoning capability 기반으로 specialized",
          "level": 2
        },
        {
          "text": "web & mobile control benchmarks에서 다른 모델들 outperform with lower latency",
          "level": 1
        },
        {
          "text": "Google AI Studio & Vertext AI 등에서 access 가능",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Google-speech-to-retrieval-s2r-a-new-approach-to-voice-search",
      "date": "2025-10-W02",
      "year": "2025",
      "month": "10",
      "week": "2",
      "type": "dev",
      "org": "Google",
      "title": "Speech-to-Retrieval (S2R): A new approach to voice search",
      "url": "https://research.google/blog/speech-to-retrieval-s2r-a-new-approach-to-voice-search/",
      "bullets": [
        {
          "text": "Simple Voice Questions (SVQ) dataset open-sourcing: 17개 언어, 27개 지역 대상으로 수집된 short audio questions. S2R 평가에 사용됨",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Samsung-less-is-more-recursive-reasoning-with-tiny-networks",
      "date": "2025-10-W02",
      "year": "2025",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Samsung",
      "title": "Less is More: Recursive Reasoning with Tiny Networks",
      "url": "https://arxiv.org/abs/2510.04871",
      "bullets": [
        {
          "text": "27M parameters trained on small data (~1000 examples)",
          "level": 2
        },
        {
          "text": "Tiny Recursive Model (TRM): 더 간단한 recursive reasoning approach로, HRM보다 뛰어난 일반화 성능을 지녔다고 설명",
          "level": 1
        },
        {
          "text": "only 2 layers. 7M parameters",
          "level": 2
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Figure-introducing-figure-03",
      "date": "2025-10-W02",
      "year": "2025",
      "month": "10",
      "week": "2",
      "type": "dev",
      "org": "Figure",
      "title": "Introducing Figure 03",
      "url": "https://www.figure.ai/news/introducing-figure-03",
      "bullets": [
        {
          "text": "each fingertip은 high-fidelity tactile sensor를 통해 real-time perception & reasoning을 가능토록 함",
          "level": 1
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Tsinghua-cache-to-cache-direct-semantic-communication-between-large-language-models",
      "date": "2025-10-W02",
      "year": "2025",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Tsinghua",
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language Models",
      "url": "https://arxiv.org/abs/2510.03215",
      "bullets": [
        {
          "text": "이를 통해 KV-Cache가 inter-model communication의 effective medium이라고 주장",
          "level": 1
        },
        {
          "text": "Cache-to-Cache (C2C): LLMs 간의 direct semantic communication을 위한 새로운 paradigm",
          "level": 1
        },
        {
          "text": "neural network를 사용하여 source model’s KV-cache를 project & fuse with that of target model",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta-agent-learning-via-early-experience",
      "date": "2025-10-W02",
      "year": "2025",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Meta",
      "title": "Agent Learning via Early Experience",
      "url": "https://arxiv.org/abs/2510.08558",
      "bullets": [
        {
          "text": "현재는 expert data로 fine-tuning하고 있으나 이는 scale-up 할 수 없는 원인이 됨",
          "level": 2
        },
        {
          "text": "early experience: agent’s own actions로 생성된 interaction data로 future states는 reward signals 없이 supervision으로 serve",
          "level": 1
        },
        {
          "text": "→ Implicit world modeling, Self-refelction",
          "level": 2
        }
      ],
      "tags": [
        "multimodal",
        "agent"
      ]
    },
    {
      "id": "Anthropic-a-small-number-of-samples-can-poison-llms-of-any-size",
      "date": "2025-10-W03",
      "year": "2025",
      "month": "10",
      "week": "3",
      "type": "dev",
      "org": "Anthropic",
      "title": "A small number of samples can poison LLMs of any size",
      "url": "https://www.anthropic.com/research/small-samples-poison",
      "bullets": [
        {
          "text": "모델 사이즈에 비례하여 더 많은 데이터를 학습하게 되므로 이를 attack 하기 위해서는 training data의 비율을 조정해야 한다는 것이 관념이었으나 “고정된” 개수의 documents로 attack이 가능하다고 주장하는 것임",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Stanford-agentic-context-engineering-evolving-contexts-for-self-improving-language-models",
      "date": "2025-10-W03",
      "year": "2025",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "Stanford",
      "title": "Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models",
      "url": "https://www.arxiv.org/abs/2510.04618",
      "bullets": [
        {
          "text": "agent, domain-specific benchmark에서 ACE가 context를 offline & online 둘 다 잘 optimize 한다는 실험 결과",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "KAIST-kormo-korean-open-reasoning-model-for-everyone",
      "date": "2025-10-W03",
      "year": "2025",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "KAIST",
      "title": "KORMo: Korean Open Reasoning Model for Everyone",
      "url": "https://arxiv.org/abs/2510.09426",
      "bullets": [
        {
          "text": "(1) synthetic data로 model collapse 없이 pre-training 가능",
          "level": 1
        },
        {
          "text": "synthetic data-driven fully open models (FOMs)",
          "level": 2
        },
        {
          "text": "(2) bilingual instruction tuning으로 near-native reasoning & coherence 달성 가능",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Adrej-Karpathy-nanochat",
      "date": "2025-10-W03",
      "year": "2025",
      "month": "10",
      "week": "3",
      "type": "dev",
      "org": "Adrej Karpathy",
      "title": "Nanochat",
      "url": "https://github.com/karpathy/nanochat",
      "bullets": [
        {
          "text": "학습 및 추론 돌리는데 $100 정도 비용",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "MS-introducing-mai-image-1-debuting-in-the-top-10-on-lmarena",
      "date": "2025-10-W03",
      "year": "2025",
      "month": "10",
      "week": "3",
      "type": "dev",
      "org": "MS",
      "title": "Introducing MAI-Image-1, debuting in the top 10 on LMArena",
      "url": "https://microsoft.ai/news/introducing-mai-image-1-debuting-in-the-top-10-on-lmarena/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Princeton-skill-targeted-adaptive-training",
      "date": "2025-10-W03",
      "year": "2025",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "Princeton",
      "title": "Skill-Targeted Adaptive Training",
      "url": "https://arxiv.org/abs/2510.10023",
      "bullets": [
        {
          "text": "teacher는 task dataset을 사용해서 list of skills를 만들고, 각 스킬에 필요한 data point에 labeling",
          "level": 1
        },
        {
          "text": "student’s answers를 monitoring하여 Missing-Skill-Profile를 생성",
          "level": 1
        },
        {
          "text": "STAT-Sel: 이에 따라 training examples를 adaptively reweights",
          "level": 2
        },
        {
          "text": "STAT-Syn: missing skills를 포함하는 additional examples를 synthesize",
          "level": 2
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "NYU-diffusion-transformers-with-representation-autoencoders",
      "date": "2025-10-W03",
      "year": "2025",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "NYU",
      "title": "Diffusion Transformers with Representation Autoencoders",
      "url": "https://arxiv.org/abs/2510.11690",
      "bullets": [
        {
          "text": "high-quality reconstructions & semnatically rich latent spaces 제공",
          "level": 2
        }
      ],
      "tags": []
    },
    {
      "id": "Alibaba-qwen3-vl",
      "date": "2025-10-W03",
      "year": "2025",
      "month": "10",
      "week": "3",
      "type": "dev",
      "org": "Alibaba",
      "title": "Qwen3-VL",
      "url": "https://huggingface.co/collections/Qwen/qwen3-vl-68d2a7c1b8a8afce4ebd2dbe",
      "bullets": [
        {
          "text": "FP8 deployment 가능",
          "level": 1
        },
        {
          "text": "일부 벤치마크에서 Gemini 2.5 Flash-Lite & GPT-5 Nano 능가",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Shanghai-Jiao-Tong-ai-for-service-proactive-assistance-with-ai-glasses",
      "date": "2025-10-W03",
      "year": "2025",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "Shanghai Jiao Tong",
      "title": "AI for Service: Proactive Assistance with AI Glasses",
      "url": "https://arxiv.org/abs/2510.14359",
      "bullets": [
        {
          "text": "Alpha-Service: 두 가지 challenges를 address (using AI Glasses)",
          "level": 1
        },
        {
          "text": "Know When to intervene by detecting service opportunities",
          "level": 2
        },
        {
          "text": "Know How to provide both generalized & personalized services",
          "level": 2
        },
        {
          "text": "5개의 key components",
          "level": 1
        },
        {
          "text": "Input Unit, CPU, Arithmetic Logic Unit, Memory unit, Output Uni",
          "level": 2
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Anthropic-introducing-claude-haiku-45",
      "date": "2025-10-W03",
      "year": "2025",
      "month": "10",
      "week": "3",
      "type": "dev",
      "org": "Anthropic",
      "title": "Introducing Claude Haiku 4.5",
      "url": "https://www.anthropic.com/news/claude-haiku-4-5",
      "bullets": [
        {
          "text": "Sonnet 모델과 유사한 아키텍쳐를 따르고 있으나 speed & cost efficiency를 최적화하는 것에 집중",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Alibaba-meet-your-ai-memory",
      "date": "2025-10-W03",
      "year": "2025",
      "month": "10",
      "week": "3",
      "type": "dev",
      "org": "Alibaba",
      "title": "Meet Your AI Memory",
      "url": "https://x.com/Alibaba_Qwen/status/1978466605249204512",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-the-art-of-scaling-reinforcement-learning-compute-for-llms",
      "date": "2025-10-W03",
      "year": "2025",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "Meta",
      "title": "The Art of Scaling Reinforcement Learning Compute for LLMs",
      "url": "https://arxiv.org/abs/2510.13786",
      "bullets": [
        {
          "text": "→ ScaleRL 제시: 100,000 GPU hours까지 scale-up 가능한 best-practice recipe라는 점을 입증",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Stanford-verbalized-sampling-how-to-mitigate-mode-collapse-and-unlock-llm-diversity",
      "date": "2025-10-W03",
      "year": "2025",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "Stanford",
      "title": "Verbalized Sampling: How to Mitigate Mode Collapse and Unlock LLM Diversity",
      "url": "https://arxiv.org/abs/2510.01171",
      "bullets": [
        {
          "text": "Verbalized Sampling (VS): model collapse를 피할 수 있는 training-free prompting strategy",
          "level": 1
        },
        {
          "text": "responses에 대한 probability distribution을 모델이 스스로 verbalize 하는 것만으로도 creative writing, dialogue simulation, open-ended QA 등 태스크에서 답변 다양성 크게 증가 (factual accuracy 감소 없이)",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Together,-Stanford-reasonif-large-reasoning-models-fail-to-follow-instructions-during-reasoning",
      "date": "2025-10-W04",
      "year": "2025",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "Together, Stanford",
      "title": "ReasonIF: Large Reasoning Models Fail to Follow Instructions During Reasoning",
      "url": "https://arxiv.org/abs/2510.15211",
      "bullets": [
        {
          "text": "ReasonIF: reasoning instruction following 능력을 평가하는 벤치마크 도입",
          "level": 1
        },
        {
          "text": "multilingual reasoning, formatting 등 6개의 카테고리로 구분",
          "level": 2
        },
        {
          "text": "현존하는 open-source LRMs는 최대 0.25점을 기록하는 수준임",
          "level": 1
        },
        {
          "text": "합성데이터를 이용한 multi-turn reasoning & Reasoning Instruction Finetuning (RIF) 강조",
          "level": 1
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Nanjing,-ETH-a-theoretical-study-on-bridging-internal-probability-and-self-consistency-for-llm-reasoning",
      "date": "2025-10-W04",
      "year": "2025",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "Nanjing, ETH",
      "title": "A Theoretical Study on Bridging Internal Probability and Self-Consistency for LLM Reasoning",
      "url": "https://arxiv.org/abs/2510.15444",
      "bullets": [
        {
          "text": "self-consistency는 high estimation error, perplexity는 modeling error 라는 한계점 지적",
          "level": 1
        },
        {
          "text": "이를 해결하기 위해 RPC 제안: Perplexity Consistency & Reasoning Pruning을 이용하는 hybrid method",
          "level": 1
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "PaddlePaddle-paddleocr-vl-boosting-multilingual-document-parsing-via-a-09b-ultra-compact-vision-language-model",
      "date": "2025-10-W04",
      "year": "2025",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "PaddlePaddle",
      "title": "PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model",
      "url": "https://arxiv.org/abs/2510.14528",
      "bullets": [
        {
          "text": "109개 언어를 지원하며 다양한 elements 인식 가능 (text, table, formula, chart 등)",
          "level": 1
        },
        {
          "text": "page-level parsing & element-level recognition에서 SoTA",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Google-grounding-with-google-maps-now-available-in-the-gemini-api",
      "date": "2025-10-W04",
      "year": "2025",
      "month": "10",
      "week": "4",
      "type": "dev",
      "org": "Google",
      "title": "Grounding with Google Maps: Now available in the Gemini API",
      "url": "https://blog.google/technology/developers/grounding-google-maps-gemini-api/",
      "bullets": [
        {
          "text": "$25 / 1,000 location-enhanced prompts",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "HuggingFace-huggingchat",
      "date": "2025-10-W04",
      "year": "2025",
      "month": "10",
      "week": "4",
      "type": "dev",
      "org": "HuggingFace",
      "title": "HuggingChat",
      "url": "https://huggingface.co/chat/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Anthropic-claude-code-on-the-web",
      "date": "2025-10-W04",
      "year": "2025",
      "month": "10",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "Claude Code on the web",
      "url": "https://www.anthropic.com/news/claude-code-on-the-web",
      "bullets": [
        {
          "text": "터미널 접속 없이 웹에서 처리하는 기능이 codex와 동일",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-introducing-chatgpt-atlas",
      "date": "2025-10-W04",
      "year": "2025",
      "month": "10",
      "week": "4",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing ChatGPT Atlas",
      "url": "https://openai.com/index/introducing-chatgpt-atlas",
      "bullets": [
        {
          "text": "이용 시작부터 7일 간 promotion. 더 많은 호출 가능. 현재는 mac os만 지원",
          "level": 1
        },
        {
          "text": "새로운 탭 화면이 검색창 같은데 ChatGPT 메인 화면이어서 대화 이력도 확인 가능",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Spike-Studio-automatic-prompt-generation-via-adaptive-selection-of-prompting-techniques",
      "date": "2025-10-W04",
      "year": "2025",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "Spike Studio",
      "title": "Automatic Prompt Generation via Adaptive Selection of Prompting Techniques",
      "url": "https://arxiv.org/abs/2510.18162",
      "bullets": [
        {
          "text": "다양한 tasks 간의 semantic similarity를 기반으로 knowledge base를 constructs",
          "level": 1
        },
        {
          "text": "유저가 task descriptions를 입력하면 system이 가장 관련성 높은 task cluster로 assign",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Google-google-ai-studio",
      "date": "2025-10-W04",
      "year": "2025",
      "month": "10",
      "week": "4",
      "type": "dev",
      "org": "Google",
      "title": "Google AI Studio",
      "url": "https://aistudio.google.com/apps",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Zhejiang,-NUS-lightmem-lightweight-and-efficient-memory-augmented-generation",
      "date": "2025-10-W04",
      "year": "2025",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "Zhejiang, NUS",
      "title": "LightMem: Lightweight and Efficient Memory-Augmented Generation",
      "url": "https://arxiv.org/abs/2510.18866",
      "bullets": [
        {
          "text": "(1) cognition-inspired sensory memory가 lightweight compression을 통해 무관한 데이터를 filter & 주제에 따라 그룹화",
          "level": 2
        },
        {
          "text": "(2) topic-aware short-term memory가 이런 topic-based groups를 consolidate",
          "level": 2
        },
        {
          "text": "(3) long-term memory가 이러한 정보를 활용",
          "level": 2
        }
      ],
      "tags": []
    },
    {
      "id": "JHU,-PKU,-Princeton,-MIT,-Harvard-world-in-world-world-models-in-a-closed-loop-world",
      "date": "2025-10-W04",
      "year": "2025",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "JHU, PKU, Princeton, MIT, Harvard",
      "title": "World-in-World: World Models in a Closed-Loop World",
      "url": "https://arxiv.org/abs/2510.18135",
      "bullets": [
        {
          "text": "World-in-World: real agent-environment를 반영하는 closed-loop에서 WM를 벤치마크하는 open platform",
          "level": 1
        },
        {
          "text": "다양한 WMs를 평가하는 4개의 closed-loop environments를 curate",
          "level": 2
        },
        {
          "text": "또한 embodied setting에서 WM에 대한 data scaling law를 제안",
          "level": 1
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "HKUST,-NYU-diffadapt-difficulty-adaptive-reasoning-for-token-efficient-llm-inference",
      "date": "2025-10-W04",
      "year": "2025",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "HKUST, NYU",
      "title": "DiffAdapt: Difficulty-Adaptive Reasoning for Token-Efficient LLM Inference",
      "url": "https://arxiv.org/abs/2510.19669",
      "bullets": [
        {
          "text": "reasoning traces의 토큰 확률의 entropy 계산 → U-shaped entropy pattern 발견",
          "level": 1
        },
        {
          "text": "쉬운 문제에 대해서도 높은 entropy를 갖고 있음 (정확한 답변임에도 불구하고)",
          "level": 2
        },
        {
          "text": "DiffAdapt: 각 question의 난이도와 reasoning trace entropy를 근거로 Easy/Normal/Hard 추론 전략을 선택하는 프레임워크",
          "level": 1
        },
        {
          "text": "각 전략마다 prompt, temperature, maximum token length 정해져 있음",
          "level": 2
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Tsinghua,-GIT-adaspec-selective-knowledge-distillation-for-efficient-speculative-decoders",
      "date": "2025-10-W04",
      "year": "2025",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "Tsinghua, GIT",
      "title": "AdaSPEC: Selective Knowledge Distillation for Efficient Speculative Decoders",
      "url": "https://arxiv.org/abs/2510.19779",
      "bullets": [
        {
          "text": "AdaSPEC: KD process에 selective token filtering을 통합한 방법론 제시",
          "level": 1
        },
        {
          "text": "reference model을 사용하여 difficult-to-fit tokens를 filtering → simpler tokens에 대해 better align",
          "level": 2
        }
      ],
      "tags": []
    },
    {
      "id": "DeepSeek-AI-deepseek-ocr-contexts-optical-compression",
      "date": "2025-10-W04",
      "year": "2025",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "DeepSeek AI",
      "title": "DeepSeek-OCR: Contexts Optical Compression",
      "url": "https://arxiv.org/abs/2510.18234v1",
      "bullets": [
        {
          "text": "DeepEncoder & DeepSeek3B-MoE-A570M decoder",
          "level": 1
        },
        {
          "text": "텍스트 토큰이 vison 토큰의 10배보다 적게 유지되는 경우 OCR 정확도는 97% 수준 (압축률이 10배 미만이면)",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Sheffield-can-confidence-estimates-decide-when-chain-of-thought-is-necessary-for-llms",
      "date": "2025-10-W05",
      "year": "2025",
      "month": "10",
      "week": "5",
      "type": "paper",
      "org": "Sheffield",
      "title": "Can Confidence Estimates Decide When Chain-of-thought is Necessary for Llms?",
      "url": "https://arxiv.org/abs/2510.21007",
      "bullets": [
        {
          "text": "4개의 방법론으로 비교 실험해본 결과 특정한 방법론이 특정한 데이터셋에 대해 무조건 좋다고 결론 내리기는 어렵다고 함",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Meta,-Berkeley-continual-learning-via-sparse-memory-finetuning",
      "date": "2025-10-W05",
      "year": "2025",
      "month": "10",
      "week": "5",
      "type": "paper",
      "org": "Meta, Berkeley",
      "title": "Continual Learning via Sparse Memory Finetuning",
      "url": "https://arxiv.org/abs/2510.15103",
      "bullets": [
        {
          "text": "사전 학습에 사용되었던 데이터보다 새로운 데이터에 대해 높은 activation 값을 갖는 memory slots만 사용",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Harvard-University,-Cambridge-lexical-hints-of-accuracy-in-llm-reasoning-chains",
      "date": "2025-09-W01",
      "year": "2025",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "Harvard University, Cambridge",
      "title": "Lexical Hints of Accuracy in LLM Reasoning Chains",
      "url": "https://arxiv.org/abs/2508.15842",
      "bullets": [
        {
          "text": "(1) CoT length (2) intra-CoT sentiment volatility (3) lexicographic hints",
          "level": 1
        },
        {
          "text": "Humanity's Last Exam (HLE), Omni-MATH 대상으로 DeepSeek-R1 & Claude 3.7 Sonnet 테스트",
          "level": 0
        },
        {
          "text": "guess, stuck, hard와 같은 어휘들이 uncertainty의 강한 지표로 확인되었고, sentiment는 보조 지표 정도로 활용 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Ai2-asta-accelerating-science-through-trustworthy-agentic-ai",
      "date": "2025-09-W01",
      "year": "2025",
      "month": "9",
      "week": "1",
      "type": "dev",
      "org": "Ai2",
      "title": "Asta: Accelerating science through trustworthy agentic AI",
      "url": "https://allenai.org/blog/asta",
      "bullets": [
        {
          "text": "scientific AI의 지평을 넓히고 투명성을 증진하기 위한 [AstaBench](https://allenai.org/asta/bench)",
          "level": 0
        },
        {
          "text": "Asta resources: scientific AI agents를 build, test, refine 하기 위한 a set of softwoare components",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Microsoft-mai-voice-1-mai-1-preview",
      "date": "2025-09-W01",
      "year": "2025",
      "month": "9",
      "week": "1",
      "type": "dev",
      "org": "Microsoft",
      "title": "MAI-Voice-1, MAI-1-preview",
      "url": "https://microsoft.ai/news/two-new-in-house-models",
      "bullets": [
        {
          "text": "MAI-Voice-1",
          "level": 0
        },
        {
          "text": "single GPU에서 구동 가능하며 일 초 내에 일 분 길이의 오디오 생성 가능",
          "level": 1
        },
        {
          "text": "single- / multi- speaker 시나리오에서 expressive, natural speech 지원",
          "level": 1
        },
        {
          "text": "MAI-1-preview",
          "level": 0
        },
        {
          "text": "15,000 H100 hours로 pre- / post- trained MoE text 모델",
          "level": 1
        },
        {
          "text": "instruction following & everyday query responses에 집중했다고 밝힘",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Apple-fastvlm-efficient-vision-encoding-for-vision-language-models",
      "date": "2025-09-W01",
      "year": "2025",
      "month": "9",
      "week": "1",
      "type": "dev",
      "org": "Apple",
      "title": "FastVLM: Efficient Vision Encoding for Vision Language Models",
      "url": "https://machinelearning.apple.com/research/fast-vision-language-models",
      "bullets": [
        {
          "text": "추론 코드, 모델 체크포인트, iOS/macOS demo는 깃허브 [링크](https://github.com/apple/ml-fastvlm/)에서 확인 가능",
          "level": 0
        },
        {
          "text": "허깅페이스 데모 [링크](https://link.alphasignal.ai/CPaC4b)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-stop-vibe-testing-your-llms-its-time-for-real-evals",
      "date": "2025-09-W01",
      "year": "2025",
      "month": "9",
      "week": "1",
      "type": "dev",
      "org": "Google",
      "title": "Stop “vibe testing” your LLMs. It's time for real evals.",
      "url": "https://developers.googleblog.com/en/streamline-llm-evaluation-with-stax",
      "bullets": [
        {
          "text": "한 번의 평가로 다양한 조합의 성능을 확인",
          "level": 0
        },
        {
          "text": "The complete toolkit for AI evaluation",
          "level": 0
        },
        {
          "text": "현재는 미국에서만 사용 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Tencent-hunyuan-mt",
      "date": "2025-09-W01",
      "year": "2025",
      "month": "9",
      "week": "1",
      "type": "dev",
      "org": "Tencent",
      "title": "Hunyuan-MT",
      "url": "https://github.com/Tencent-Hunyuan/Hunyuan-MT",
      "bullets": [
        {
          "text": "중국의 5개 소수 민족 언어를 포함한 33개 언어 커버",
          "level": 0
        },
        {
          "text": "pretrain → CPT → SFT → translation rl → ensemble rl ([technical report](https://github.com/Tencent-Hunyuan/Hunyuan-MT/blob/main/Hunyuan_MT_Technical_Report.pdf) 참고 가능)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-welcome-embeddinggemma-googles-new-efficient-embedding-model",
      "date": "2025-09-W01",
      "year": "2025",
      "month": "9",
      "week": "1",
      "type": "dev",
      "org": "Google",
      "title": "Welcome EmbeddingGemma, Google's new efficient embedding model",
      "url": "https://huggingface.co/blog/embeddinggemma",
      "bullets": [
        {
          "text": "308M 사이즈 & 2K context window, 100개 이상 언어 지원",
          "level": 0
        },
        {
          "text": "Gemma3 모델을 backbone으로 삼고 있으나, bi-directional attention으로 modified",
          "level": 0
        },
        {
          "text": "Matroyshka Representation Learning (MRL)로 학습되어 768 차원의 ouput을 512, 256, 128 차원으로 truncate 할 수 있음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-vibevoice-a-frontier-open-source-text-to-speech-model",
      "date": "2025-09-W01",
      "year": "2025",
      "month": "9",
      "week": "1",
      "type": "dev",
      "org": "Microsoft",
      "title": "VibeVoice: A Frontier Open-Source Text-to-Speech Model",
      "url": "https://microsoft.github.io/VibeVoice",
      "bullets": [
        {
          "text": "speaker consistency, natural turn-taking 등의 문제를 크게 해결",
          "level": 0
        },
        {
          "text": "ultra-low frame rate of 7.5Hz에서 operating 하는 continuous speech tokenizers 사용",
          "level": 0
        },
        {
          "text": "Context-Aware Expression 데모가 있어서 들어봤는데 엄~청 자연스럽지는 않은 느낌",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Oxford,-Shanghai-AI,-NUS,-UCL,-…-the-landscape-of-agentic-reinforcement-learning-for-llms-a-survey",
      "date": "2025-09-W01",
      "year": "2025",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "Oxford, Shanghai AI, NUS, UCL, …",
      "title": "The Landscape of Agentic Reinforcement Learning for LLMs: A Survey",
      "url": "https://arxiv.org/abs/2509.02547",
      "bullets": [
        {
          "text": "두 가지 taxonomy로 구분",
          "level": 0
        },
        {
          "text": "planning, tool use, memory 등을 포함하는 core agentic capabilities",
          "level": 1
        },
        {
          "text": "다양한 태스크 도메인에 대한 applications",
          "level": 1
        },
        {
          "text": "reinforcement learning이 agents의 능력을 기존의 static, heuristic modules에서 adaptive, robust agentic behavior로 transform",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "OpenAI-why-language-models-hallucinate",
      "date": "2025-09-W01",
      "year": "2025",
      "month": "9",
      "week": "1",
      "type": "dev",
      "org": "OpenAI",
      "title": "Why language models hallucinate",
      "url": "https://openai.com/index/why-language-models-hallucinate/",
      "bullets": [
        {
          "text": "modern training pipeline에서 hallucinations의 통계적 원인을 분석",
          "level": 0
        },
        {
          "text": "이진 분류의 오류에 기인한다고 설명",
          "level": 1
        },
        {
          "text": "incorrect statements가 facts와 구별되지 않는다면, PLM은 natural statistical pressures를 기반으로 hallucinate 한다고 설명",
          "level": 1
        },
        {
          "text": "또한 good test-takers로 optimized 되는 LM 특성상 불확실할 때 추측하는 것이 test performance가 높은 것으로 평가받게 되는 문제점을 지적",
          "level": 0
        },
        {
          "text": "불확실한 응답을 penalizing하는 “전염병(epidemic)”은 misaligned scoring of exisiting benchmarks를 수정하는 방향으로 고쳐져야 한다고 주장",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Manchester-drivel-ology-challenging-llms-with-interpreting-nonsense-with-depth",
      "date": "2025-09-W01",
      "year": "2025",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "Manchester",
      "title": "Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth",
      "url": "https://arxiv.org/abs/2509.03867",
      "bullets": [
        {
          "text": "겉으로 봤을 땐 non-sense이지만 contextual inference, moral reasoning, emotional interpretation을 통해 implicit meaning을 encoding 해야됨",
          "level": 0
        },
        {
          "text": "현존 LLM들은 아직까지 Drivelological text를 온전히 이해하지 못한다고 설명",
          "level": 0
        },
        {
          "text": "English, Mandarin, Spanish, French, Japanese, Korean 등 언어에 대해 1,200여 개 데이터를 meticulously curate",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Meta,-NUS,-Rice-refrag-rethinking-rag-based-decoding",
      "date": "2025-09-W01",
      "year": "2025",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "Meta, NUS, Rice",
      "title": "REFRAG: Rethinking RAG based Decoding",
      "url": "https://arxiv.org/abs/2509.01092",
      "bullets": [
        {
          "text": "긴 입력을 처리하면서 발생하는 knowledge enrichment & system efficiency 간 trade-off",
          "level": 1
        },
        {
          "text": "검색된 텍스트의 대부분은 query와 상관없음",
          "level": 1
        },
        {
          "text": "RAG context에서 decoding 할 때 대부분의 연산은 불필요하며, 제거하더라도 전체 성능에 크게 영향주지 않는다고 주장",
          "level": 0
        },
        {
          "text": "REFRAG 제안: RAG application에서 latency를 개선하기 위한 compress, sense, expand 할 수 있는 decoding framework (attention sparsity structure)",
          "level": 0
        },
        {
          "text": "perplexity를 높이지 않으면서 TTFT를 30.85x 상승 & LLM의 context size를 16x 상승",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "ByteDance-ui-tars-2-technical-report-advancing-gui-agent-with-multi-turn-reinforcement-learning",
      "date": "2025-09-W01",
      "year": "2025",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "ByteDance",
      "title": "UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning",
      "url": "https://arxiv.org/abs/2509.02544",
      "bullets": [
        {
          "text": "GUI 에이전트가 단순한 조작을 넘어 복잡한 환경에도 적응할 수 있음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Stanford-machinelearninglm-continued-pretraining-language-models-on-millions-of-synthetic-tabular-prediction-tasks-scales-in-context-ml",
      "date": "2025-09-W01",
      "year": "2025",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "Stanford",
      "title": "MachineLearningLM: Continued Pretraining Language Models on Millions of Synthetic Tabular Prediction Tasks Scales In-Context ML",
      "url": "https://arxiv.org/abs/2509.06806",
      "bullets": [
        {
          "text": "millions of structural causal models (SCMs) 로부터 ML tasks를 합성하여 1,024 shot 생성",
          "level": 0
        },
        {
          "text": "random-forest teacher로 시작하여 tree-based decision strategies를 LLM에 distill",
          "level": 0
        },
        {
          "text": "모든 tasks는 token-efficient prompt로 serialized",
          "level": 0
        },
        {
          "text": "GPT-5-mini 모델보다도 Qwen-2.5-7B-Instruct를 tuning한 모델의 성능이 좋았다고 설명하면서 이를 many-shot scaling law라고 표현함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "NVIDIA-universal-deep-research-bring-your-own-model-and-strategy",
      "date": "2025-09-W02",
      "year": "2025",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "NVIDIA",
      "title": "Universal Deep Research: Bring Your Own Model and Strategy",
      "url": "https://arxiv.org/abs/2509.00244",
      "bullets": [
        {
          "text": "UDR: 어떤 언어 모델이든 사용할 수 있고, 유저가 스스로 deep research strategies를 추가적인 학습 없이도 custom 할 수 있도록 돕는 generalist agentic system",
          "level": 0
        },
        {
          "text": "Phase 1: skipped steps and drift를 줄이기 위한 strategy compiles → Phase 2: executes synchronous tool calls & yield-based notifications",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Emory-Univ.-improving-factuality-in-llms-via-inference-time-knowledge-graph-construction",
      "date": "2025-09-W02",
      "year": "2025",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "Emory Univ.",
      "title": "Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction",
      "url": "https://arxiv.org/abs/2509.03540",
      "bullets": [
        {
          "text": "knowledge graphs를 dynamically constructs & expands 하는 framework 제안",
          "level": 0
        },
        {
          "text": "question으로부터 seed KG를 추출하고, 이를 바탕으로 LLM’s latent knowledge를 이용하여 iterative expansion 수행",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Arizona,-Michigan-can-multiple-responses-from-an-llm-reveal-the-sources-of-its-uncertainty",
      "date": "2025-09-W02",
      "year": "2025",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "Arizona, Michigan",
      "title": "Can Multiple Responses from an LLM Reveal the Sources of Its Uncertainty?",
      "url": "https://arxiv.org/abs/2509.04464",
      "bullets": [
        {
          "text": "한 LLM이 여러 개의 응답을 생성하고, 다른 LLM(auxiliary)이 disagreement patterns을 분석하도록 지시",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Univ.-of-Bamberg-are-humans-as-brittle-as-large-language-models",
      "date": "2025-09-W02",
      "year": "2025",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "Univ. of Bamberg",
      "title": "Are Humans as Brittle as Large Language Models?",
      "url": "https://arxiv.org/abs/2509.07869",
      "bullets": [
        {
          "text": "이에 따라 human annotators도 instruction changes에 유사한 sensitivity를 보이는지 확인하고자 함",
          "level": 0
        },
        {
          "text": "실험 결과에 따르면 human annotators & LLMs 모두 특정한 prompt 수정 유형에 대해 불안정(brittlenss)한 특성을 보임",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "ByteDance,-HKUST,-Peking,-Tsinghua-reverse-engineered-reasoning-for-open-ended-generation",
      "date": "2025-09-W02",
      "year": "2025",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "ByteDance, HKUST, Peking, Tsinghua",
      "title": "Reverse-Engineered Reasoning for Open-Ended Generation",
      "url": "https://arxiv.org/abs/2509.06160",
      "bullets": [
        {
          "text": "REverse-Engineered Reasoning (REER): trial-and-error | imitation을 통해 reasoning process forwards를 building 하는 것 대신 known good solutions로부터 backwards works",
          "level": 0
        },
        {
          "text": "DeepWriting-20K: 20,000 deep reasoning trajectories 데이터를 오픈소스화",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Meta-Superintelligence,-UC-Berkeley-language-self-play-for-data-free-training",
      "date": "2025-09-W02",
      "year": "2025",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "Meta Superintelligence, UC Berkeley",
      "title": "Language Self-Play For Data-Free Training",
      "url": "https://arxiv.org/abs/2509.07414v1",
      "bullets": [
        {
          "text": "추가적인 데이터 없이 모델 성능을 개할 수 있는 강화학습 방식 제안",
          "level": 0
        },
        {
          "text": "Language Self-Play (LSP): 모델이 스스로 play하면서 stronger policies 형성",
          "level": 0
        },
        {
          "text": "Llama-3.2-3B-Instruct 모델로 실험한 결과 제시",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "HKUSK,-MiniMax,-Waterloo-webexplorer-explore-and-evolve-for-training-long-horizon-web-agents",
      "date": "2025-09-W02",
      "year": "2025",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "HKUSK, MiniMax, Waterloo",
      "title": "WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents",
      "url": "https://arxiv.org/abs/2509.06501",
      "bullets": [
        {
          "text": "WebExplorer: model-based exploration & iterative, long-to-short query evolution 데이터 생성 방법론",
          "level": 0
        },
        {
          "text": "WebExplorer-8B: 128K, 100 tool calling turns",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "HKUST,-Jilin-Univ.,-CUHK-implicit-reasoning-in-large-language-models-a-comprehensive-survey",
      "date": "2025-09-W02",
      "year": "2025",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "HKUST, Jilin Univ., CUHK",
      "title": "Implicit Reasoning in Large Language Models: A Comprehensive Survey",
      "url": "https://arxiv.org/abs/2509.02350",
      "bullets": [
        {
          "text": "representational forms → computational strategies",
          "level": 0
        },
        {
          "text": "how & where internal computation unfolds: latent optimization, signal-guided control, layer-recurrent execution",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Anthropic-claude-can-now-create-and-edit-files",
      "date": "2025-09-W02",
      "year": "2025",
      "month": "9",
      "week": "2",
      "type": "dev",
      "org": "Anthropic",
      "title": "Claude can now create and edit files",
      "url": "https://www.anthropic.com/news/create-files",
      "bullets": [
        {
          "text": "raw data를 input으로 주면 이를 분석한 결과 및 통계적 분석, 시각화 자료, 인사이트 등을 반환",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "ByteDance-seedream-40",
      "date": "2025-09-W02",
      "year": "2025",
      "month": "9",
      "week": "2",
      "type": "dev",
      "org": "ByteDance",
      "title": "Seedream 4.0",
      "url": "https://seed.bytedance.com/en/seedream4_0",
      "bullets": [
        {
          "text": "batch input & output, prompt-based editing, versatile styles, knowledge-driven generation 등을 특징으로 삼음",
          "level": 0
        },
        {
          "text": "모델 성능은 MagicBench 기준으로 평가하여 공개 (Text-to-Image, Single-Image Editing)",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Zurich,-Gothenburg-large-language-model-hacking-quantifying-the-hidden-risks-of-using-llms-for-text-annotation",
      "date": "2025-09-W02",
      "year": "2025",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "Zurich, Gothenburg",
      "title": "Large Language Model Hacking: Quantifying the Hidden Risks of Using LLMs for Text Annotation",
      "url": "https://arxiv.org/abs/2509.08825",
      "bullets": [
        {
          "text": "21편의 사회과학 연구에서 나온 37개 data annotation 태스크를 18개 LLM으로 재현",
          "level": 0
        },
        {
          "text": "13M개의 LLM labels 생성 & 2,361개의 realistic hypotheses 검증 → SOTA 모델도 1/3 오류, 소형 모델은 1/2 오류",
          "level": 0
        },
        {
          "text": "결국 false positive (1종 오류) 발생을 줄이기 위해서는 human annotation이 중요하다는 결론",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Alibaba-qwen3-next-towards-ultimate-training-inference-efficiency",
      "date": "2025-09-W02",
      "year": "2025",
      "month": "9",
      "week": "2",
      "type": "dev",
      "org": "Alibaba",
      "title": "Qwen3-Next: Towards Ultimate Training & Inference Efficiency",
      "url": "https://qwen.ai/blog?id=4074cca80393150c248e508aa62983f9cb7d27cd&from=research.latest-advancements-list",
      "bullets": [
        {
          "text": "Qwen3-Next-80B-A3B-Base: dense Qwen3-32B에 에 준하는 성능. 32K context window를 지원하는데 10배 높은 throughput 달성",
          "level": 0
        },
        {
          "text": "Qwen3-Next-80B-A3B-Instruct, Thinking 두 모델도 공개. 256K context window",
          "level": 0
        },
        {
          "text": "포스트 내에 아키텍쳐에 대한 자세한 설명 포함되어 있음",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Apple-openvision-2-a-family-of-generative-pretrained-visual-encoders-for-multimodal-learning",
      "date": "2025-09-W02",
      "year": "2025",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "Apple",
      "title": "OpenVision 2: A Family of Generative Pretrained Visual Encoders for Multimodal Learning",
      "url": "https://arxiv.org/abs/2509.01644",
      "bullets": [
        {
          "text": "text encoder를 제외 → contrastive loss는 오직 순수하게 generative training signal만 측정함",
          "level": 0
        },
        {
          "text": "OpenVision 2",
          "level": 1
        },
        {
          "text": "training time & memory consumption을 크게 줄이면서도 기존 모델 성능 유지",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "Salesforce-sfr-deepresearch-towards-effective-reinforcement-learning-for-autonomously-reasoning-single-agents",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Salesforce",
      "title": "SFR-DeepResearch: Towards Effective Reinforcement Learning for Autonomously Reasoning Single Agents",
      "url": "https://arxiv.org/abs/2509.06283",
      "bullets": [
        {
          "text": "reasoning-optimized models에 대한 continual reinforcement learning을 제안하여 reasoning ability를 보존하면서도 agentic skills를 강화하고자 함",
          "level": 0
        },
        {
          "text": "Length-normalized RL Objective, Trajectory Filtering, Partial Rollouts 등",
          "level": 1
        }
      ],
      "tags": [
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "Individual-si-fact-mitigating-knowledge-conflict-via-self-improving-faithfulness-aware-contrastive-tuning",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Individual",
      "title": "SI-FACT: Mitigating Knowledge Conflict via Self-Improving Faithfulness-Aware Contrastive Tuning",
      "url": "https://arxiv.org/abs/2509.10208",
      "bullets": [
        {
          "text": "Self-Improving Faithfulness-Aware Contrastive Tuning: self-instruct mechanism을 이용하여 base LLM이 자동적으로 고품질의 structured contrastive learning data를 생성하도록 만듦 (positive & negative samples)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HKUST-vla-adapter-an-effective-paradigm-for-tiny-scale-vision-language-action-model",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "HKUST",
      "title": "VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model",
      "url": "https://arxiv.org/abs/2509.09372",
      "bullets": [
        {
          "text": "VLA-Adapter를 제시하여 large-scale VLMs & extensive pre-training에 대한 의존 낮춤",
          "level": 0
        },
        {
          "text": "lightweight Policy module with Bridge Attention 제시: action space 내에 optimal condition을 자율적으로 injects",
          "level": 0
        },
        {
          "text": "robotic data pre-training 없이, 단 0.5B parameter backbone으로 높은 퍼포먼스 달성",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Princeton-self-interpretability-llms-can-describe-complex-internal-processes-that-drive-their-decisions-and-improve-with-training",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Princeton",
      "title": "Self-Interpretability: LLMs Can Describe Complex Internal Processes that Drive Their Decisions, and Improve with Training",
      "url": "https://www.arxiv.org/abs/2505.17120",
      "bullets": [
        {
          "text": "(1) 현존 LLMs는 특정 종류의 의사 결정에 대한 internal process를 정확하게 기술할 수 있는 능력이 있음",
          "level": 1
        },
        {
          "text": "(2) 이러한 능력은 학습을 통해 강화하는 것도 가능",
          "level": 1
        },
        {
          "text": "(3) 학습된 능력은 어느정도 일반화 가능",
          "level": 1
        },
        {
          "text": "GPT-4o, GPT-4o-mini 두 모델을 fine-tuning하여 실험한 결과를 제시",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-DeepMind,-Toronto-virtual-agent-economies",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Google DeepMind, Toronto",
      "title": "Virtual Agent Economies",
      "url": "https://arxiv.org/abs/2509.10147?asuniq=92d42c3f",
      "bullets": [
        {
          "text": "mission economies를 도입하여 agents들이 공동의 목표를 달성할 수 있도록 함으로써 trust & safety 가 더 잘 보장되는 환경을 조성할 수 있었다고 설명",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "OpenAI-introducing-upgrades-to-codex",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing upgrades to Codex",
      "url": "https://openai.com/index/introducing-upgrades-to-codex",
      "bullets": [
        {
          "text": "Code review, Dynamic reasoning (task 난이도에 따라), Tool use 등의 핵심 features",
          "level": 0
        },
        {
          "text": "CLI, IDE extension, Cloud 등 다양한 환경에서 지원",
          "level": 0
        },
        {
          "text": "깃허브 코드 리뷰 자동화 [가이드](https://developers.openai.com/codex/cloud/code-review) by OpenAI",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "Meta-mobilellm-r1",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "dev",
      "org": "Meta",
      "title": "MobileLLM-R1",
      "url": "https://huggingface.co/facebook/MobileLLM-R1-950M",
      "bullets": [
        {
          "text": "1B도 되지 않는 사이즈의 모델 family로 Qwen3 0.6B를 능가하는 성능을 보여준다고 함",
          "level": 0
        },
        {
          "text": "사전학습에는 2T, 총 5T 토큰 정도 학습했다고 밝힘",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Berkeley,-Washington-reconstruction-alignment-improves-unified-multimodal-models",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Berkeley, Washington",
      "title": "Reconstruction Alignment Improves Unified Multimodal Models",
      "url": "https://arxiv.org/abs/2509.07295",
      "bullets": [
        {
          "text": "Reconstruction Alignment (RecA): visual understanding encoder embeddings를 dense ‘text prompts’로 이용하여 captions 없이도 보다 풍부한 supervision을 제공하는 post-training method",
          "level": 0
        },
        {
          "text": "visual understanding embeddings를 조건으로 input image를 reconstruct 하는 self-supervised reconstruction loss 근거로 학습",
          "level": 0
        },
        {
          "text": "autoregressive, masked-autoregressive, diffusion-based 등 어떤 형태에도 적용 가능하면서도 뛰어난 성능을 보여줌",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "Google-vaultgemma-the-worlds-most-capable-differentially-private-llm",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "dev",
      "org": "Google",
      "title": "VaultGemma: The world's most capable differentially private LLM",
      "url": "https://research.google/blog/vaultgemma-the-worlds-most-capable-differentially-private-llm",
      "bullets": [
        {
          "text": "DP: 학습 시 노이즈를 추가하여 학습 데이터가 모델로부터 추출되는 것을 방지하는 mathematical framework (민감 정보 보호)",
          "level": 1
        },
        {
          "text": "모델 성능을 저해하지 않으면서도 privacy를 지킬 수 있도록 하는 새로운 scaling law 제시",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Nanjing,-Shanghai-AI-the-llm-already-knows-estimating-llm-perceived-question-difficulty-via-hidden-representations",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Nanjing, Shanghai AI",
      "title": "The LLM Already Knows: Estimating LLM-Perceived Question Difficulty via Hidden Representations",
      "url": "https://arxiv.org/abs/2509.12886",
      "bullets": [
        {
          "text": "target LLM에 의해 생성되는 hidden representations만을 이용하여 난이도를 추정하는 방식을 제안",
          "level": 0
        },
        {
          "text": "token-level generation process를 Markov chain으로 모델링하고, value function을 정의하여 hidden state 기반으로 output quality를 추정",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-powering-ai-commerce-with-the-new-agent-payments-protocol-ap2",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "dev",
      "org": "Google",
      "title": "Powering AI commerce with the new Agent Payments Protocol (AP2)",
      "url": "https://cloud.google.com/blog/products/ai-machine-learning/announcing-agents-to-payments-ap2-protocol?hl=en",
      "bullets": [
        {
          "text": "매 단계는 로그로 남아서 안전성과 신뢰성을 높임",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Alibaba-tongyi-deepresearch-a-new-era-of-open-source-ai-researchers",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "dev",
      "org": "Alibaba",
      "title": "Tongyi DeepResearch: A New Era of Open-Source AI Researchers",
      "url": "https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/",
      "bullets": [
        {
          "text": "prompt engineering 없이 ReAct 방식으로 inference",
          "level": 0
        },
        {
          "text": "30B 사이즈 모델로 OpenAI DeepResearch 급 성능 달성",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Peking-early-stopping-chain-of-thoughts-in-large-language-models",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Peking",
      "title": "Early Stopping Chain-of-thoughts in Large Language Models",
      "url": "https://arxiv.org/abs/2509.14004",
      "bullets": [
        {
          "text": "각 reasoning step마다 LLM이 현재 시점의 최종 답변을 생성토록 하고 이를 step answer로 명명",
          "level": 0
        },
        {
          "text": "이 step answer가 연속적으로 동일한 답변이 나온 횟수를 answer convergence의 지표로 해석",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Algoverse-frit-using-causal-importance-to-improve-chain-of-thought-faithfulness",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Algoverse",
      "title": "FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness",
      "url": "https://arxiv.org/abs/2509.13334",
      "bullets": [
        {
          "text": "FRIT: 모델이 systematically corrupted examples로부터 causally consistent reasoning을 생성하는 방법을 배울 수 있도록 돕는 학습 scalable alignment",
          "level": 0
        },
        {
          "text": "reasoning 매 step에 대해 합성 데이터를 생성하여 faithful/unfaithful pairs 구축하고 DPO 학습",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Thinking-Machines-Lab-defeating-nondeterminism-in-llm-inference",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "dev",
      "org": "Thinking Machines Lab",
      "title": "Defeating Nondeterminism in LLM Inference",
      "url": "https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/",
      "bullets": [
        {
          "text": "batch size 변동, normalization, multiplication, attention 등의 연산이 항상 동일한 결과를 반환할 수 있도록 함",
          "level": 0
        },
        {
          "text": "대신 실험에서 1,000개 시퀀스를 처리하는데 26초가 걸리던 것이 42초가 걸리는 정도의 trade off 발생 (62% slow down)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-is-in-context-learning-learning",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Microsoft",
      "title": "Is In-Context Learning Learning?",
      "url": "https://arxiv.org/abs/2509.10414",
      "bullets": [
        {
          "text": "오히려 모델은 prior knowledge & given exemplars 에 의존한다고 설명",
          "level": 0
        },
        {
          "text": "autoregression’s ad-hoc encoding is not a robust mechanism 그리고 제한된 all-purpose generalisabilty 제안",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-detecting-and-reducing-scheming-in-ai-models",
      "date": "2025-09-W03",
      "year": "2025",
      "month": "9",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "Detecting and reducing scheming in AI models",
      "url": "https://openai.com/index/detecting-and-reducing-scheming-in-ai-models",
      "bullets": [
        {
          "text": "모델이 평가 상황을 탐지하면 scheming behavior를 바꾼다는 연구 결과",
          "level": 1
        },
        {
          "text": "reinforcement learning & targeted anti-scheming objectives를 적용하여 situational awareness를 높이고 scheming을 줄일 수 있음",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Shanghai-AI-scalecua-scaling-open-source-computer-use-agents-with-cross-platform-data",
      "date": "2025-09-W04",
      "year": "2025",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Shanghai AI",
      "title": "ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data",
      "url": "https://arxiv.org/abs/2509.15221",
      "bullets": [
        {
          "text": "ScaleCUA: 6개의 운영체제와 3개의 task domains에 대한 large-scale 오픈소스 dataset",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Tsinghua,-Northeastern-deepdive-advancing-deep-search-agents-with-knowledge-graphs-and-multi-turn-rl",
      "date": "2025-09-W04",
      "year": "2025",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Tsinghua, Northeastern",
      "title": "DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL",
      "url": "https://arxiv.org/abs/2509.10446",
      "bullets": [
        {
          "text": "end-to-end multi-turn RL을 적용하여 LLMs의 long-horizon reasoning with deep search 능력 향상 도모",
          "level": 1
        },
        {
          "text": "DeepDive-32B: BrowseComp에서 WebSailor, DeepSeek-R1-Browse 등을 outperform",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Zayed-University-k2-think-a-parameter-efficient-reasoning-system",
      "date": "2025-09-W04",
      "year": "2025",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Zayed University",
      "title": "K2-Think: A Parameter-Efficient Reasoning System",
      "url": "https://arxiv.org/abs/2509.07604",
      "bullets": [
        {
          "text": "Long CoT SFT, RLVR, Agentic planning prior to reasoning, Test-time Scaling, Speculative Decoding, Inference-optimized Hardware",
          "level": 1
        },
        {
          "text": "다른 reasoning 모델과 마찬가지로 수학, 과학, 코딩 영역에 특화되어 있다고 설명",
          "level": 1
        },
        {
          "text": "각 요청마다 초당 2천 토큰씩 처리할 수 있는 서빙 환경으로 오픈소스 모델 이용 가능 ([허깅페이스 링크](https://huggingface.co/LLM360/K2-Think), [Chat UI 링크](https://www.k2think.ai/guest))",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "Apple-atoken-a-unified-tokenizer-for-vision",
      "date": "2025-09-W04",
      "year": "2025",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Apple",
      "title": "AToken: A Unified Tokenizer for Vision",
      "url": "https://arxiv.org/abs/2509.14476?_bhlid=83047d32ee2c3b1328d35b28356e5dee4f18b61d",
      "bullets": [
        {
          "text": "perceptual & Gram matrix losses를 결합한 adversarial-free training objective 제시",
          "level": 1
        },
        {
          "text": "curriculum training 방식을 택하여 single images에서부터 videos, 3D 처리할 수 있도록 학습",
          "level": 1
        },
        {
          "text": "continuous & discrete latent tokens 둘 다 처리 가능하다는 특징",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "Cornell,-CMU-predicting-language-models-success-at-zero-shot-probabilistic-prediction",
      "date": "2025-09-W04",
      "year": "2025",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Cornell, CMU",
      "title": "Predicting Language Models' Success at Zero-Shot Probabilistic Prediction",
      "url": "https://arxiv.org/abs/2509.15356",
      "bullets": [
        {
          "text": "LLM이 base prediction task를 잘 수행할 때, 이것의 individual-level의 예측 능력은 훨씬 강해진다고 설명",
          "level": 1
        },
        {
          "text": "이를 토대로 LLM의 성능을 task level에서 측정할 수 있는 metric을 제시하여 LLM이 잘하는 태스크와 그렇지 않은 것을 구분할 수 있도록 함",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "xAI-grok-4-fast",
      "date": "2025-09-W04",
      "year": "2025",
      "month": "9",
      "week": "4",
      "type": "dev",
      "org": "xAI",
      "title": "Grok 4 Fast",
      "url": "https://x.ai/news/grok-4-fast",
      "bullets": [
        {
          "text": "web & X search, 2M context window, reasoning & non-reasoning",
          "level": 1
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Microsoft,-Tsinghua-rpg-a-repository-planning-graph-for-unified-and-scalable-codebase-generation",
      "date": "2025-09-W04",
      "year": "2025",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Microsoft, Tsinghua",
      "title": "RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation",
      "url": "https://arxiv.org/abs/2509.16198",
      "bullets": [
        {
          "text": "Repository Planning Graph (RPG): 파일 구조, data flows, functions 등을 한 개의 graph 내에 encoding",
          "level": 1
        },
        {
          "text": "ZeroRepo: scratch부터 repo를 생성하는 graph-driven framework",
          "level": 1
        },
        {
          "text": "proposal-level planning, implemetation-level refinement, graph-guided code generation 순서로 실행",
          "level": 2
        },
        {
          "text": "RepoCraft: 현실 세계의 1,052개 태스크를 아우르는 6개의 프로젝트 벤치마크",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "School-of-AI-a-state-update-prompting-strategy-for-efficient-and-robust-multi-turn-dialogue",
      "date": "2025-09-W04",
      "year": "2025",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "School of AI",
      "title": "A State-Update Prompting Strategy for Efficient and Robust Multi-turn Dialogue",
      "url": "https://arxiv.org/abs/2509.17766",
      "bullets": [
        {
          "text": "State Reconstruction & History Remind 할 수 있는 prompt engineering method 소개",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "ASI-limi-less-is-more-for-agency",
      "date": "2025-09-W04",
      "year": "2025",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "ASI",
      "title": "LIMI: Less is More for Agency",
      "url": "https://arxiv.org/abs/2509.17567",
      "bullets": [
        {
          "text": "78개의 training samples만으로 학습한 모델이 다른 SoTA급 모델들의 퍼포먼스를 상회",
          "level": 1
        },
        {
          "text": "즉, 데이터 양치기가 좋은 agentic intelligence를 만드는데 도움이 되지 않는다는 것",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Alibaba-qwen3-omni-natively-omni-modal-foundation-models",
      "date": "2025-09-W04",
      "year": "2025",
      "month": "9",
      "week": "4",
      "type": "dev",
      "org": "Alibaba",
      "title": "Qwen3-Omni: Natively Omni-Modal Foundation Models!",
      "url": "https://qwen.ai/blog?id=fdfbaf2907a36b7659a470c77fb135e381302028&from=research.research-list",
      "bullets": [
        {
          "text": "36개 벤치마크 중 32개 SoTA, 119개 텍스트 언어 & 19개 speech 언어 처리, 30분 길이의 audio input 처리 가능",
          "level": 1
        },
        {
          "text": "Thinker-Talker: Thinker는 텍스트를 생성하고 Talker는 speech를 실시간 stream",
          "level": 1
        },
        {
          "text": "20M+ hours 학습한 AuT encoder, MoE, Joint pretraining 등의 특징",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "DeepSeek-AI-deepseek-v31-terminus",
      "date": "2025-09-W04",
      "year": "2025",
      "month": "9",
      "week": "4",
      "type": "dev",
      "org": "DeepSeek AI",
      "title": "DeepSeek-V3.1-Terminus",
      "url": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Terminus",
      "bullets": [
        {
          "text": "최근 업데이트를 통해 language consistency 이슈도 해결",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Figma-connect-figma-to-top-mcp-clients",
      "date": "2025-09-W04",
      "year": "2025",
      "month": "9",
      "week": "4",
      "type": "dev",
      "org": "Figma",
      "title": "Connect Figma to top MCP clients",
      "url": "https://www.figma.com/mcp-catalog/",
      "bullets": [
        {
          "text": "VS Code, Cursor, Claude Code 등 다양한 서비스들에서 MCP 서버 연동 가능",
          "level": 1
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Michigan-benchmarking-and-improving-llm-robustness-for-personalized-generation",
      "date": "2025-09-W04",
      "year": "2025",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Michigan",
      "title": "Benchmarking and Improving LLM Robustness for Personalized Generation",
      "url": "https://arxiv.org/abs/2509.19358",
      "bullets": [
        {
          "text": "robust LLM: factually accurate & align with user preferences",
          "level": 1
        },
        {
          "text": "PERG: PREGData를 이용한 모델의 preference 평가 프레임워크",
          "level": 1
        },
        {
          "text": "Pref-Aligner: 모델의 robustness를 크게 향상시켜주는 two-stage approach",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-Chrome-chrome-devtools-mcp-for-your-ai-agent",
      "date": "2025-09-W04",
      "year": "2025",
      "month": "9",
      "week": "4",
      "type": "dev",
      "org": "Google Chrome",
      "title": "Chrome DevTools (MCP) for your AI agent",
      "url": "https://developer.chrome.com/blog/chrome-devtools-mcp?hl=en",
      "bullets": [
        {
          "text": "디버깅, 성능 추적 및 네트워크 분석 등을 위한 26개의 built-in tools",
          "level": 1
        },
        {
          "text": "Claude, Cursor, Copilot, Gemini CLI 등을 통해 사용 가능",
          "level": 1
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Meta-cwm-an-open-weights-llm-for-research-on-code-generation-with-world-models",
      "date": "2025-09-W04",
      "year": "2025",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Meta",
      "title": "CWM: An Open-Weights LLM for Research on Code Generation with World Models",
      "url": "https://ai.meta.com/research/publications/cwm-an-open-weights-llm-for-research-on-code-generation-with-world-models/",
      "bullets": [
        {
          "text": "Python interpreter & agentic Docker environments로부터 observation-action trajectories를 대량으로 mid-train",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "OpenAI-introducing-study-mode",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing study mode",
      "url": "https://openai.com/index/chatgpt-study-mode",
      "bullets": [
        {
          "text": "티어에 상관 없이 모든 유저들이 이용할 수 있는 기능으로 제공",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-microsoft-edge-your-ai-powered-browser",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "dev",
      "org": "Microsoft",
      "title": "Microsoft Edge Your AI-powered browser",
      "url": "https://www.microsoft.com/en-us/edge/ai-powered/copilot-mode?form=MG0AWI&cs=2199494592",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Tecent-hunyuanworld-10-generating-immersive-explorable-and-interactive-3d-worlds-from-words-or-pixels",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "paper",
      "org": "Tecent",
      "title": "HunyuanWorld 1.0: Generating Immersive, Explorable, and Interactive 3D Worlds from Words or Pixels",
      "url": "https://arxiv.org/abs/2507.21809",
      "bullets": [
        {
          "text": "기존 video/3D 기반 방식의 단점 보완 → panoramic image 기반 360° world proxy 활용",
          "level": 0
        },
        {
          "text": "세 가지 특징. 1) 360° immersive experiences 2) mesh export capabilities 3) disentangled object representations",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Leiden-Univ.-how-does-chain-of-thought-think-mechanistic-interpretability-of-chain-of-thought-reasoning-with-sparse-autoencoding",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "paper",
      "org": "Leiden Univ.",
      "title": "How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding",
      "url": "https://arxiv.org/abs/2507.22928",
      "bullets": [
        {
          "text": "sparse autoencoder를 activation patching과 결합하여 CoT 결과로부터 monosemantic features 추출",
          "level": 0
        },
        {
          "text": "CoT가 확실히 더 높은 activation sparsity, feature interpretability score를 달성",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "CUHK-screencoder-advancing-visual-to-code-generation-for-front-end-automation-via-modular-multimodal-agents",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "paper",
      "org": "CUHK",
      "title": "ScreenCoder: Advancing Visual-to-Code Generation for Front-End Automation via Modular Multimodal Agents",
      "url": "https://arxiv.org/abs/2507.22827",
      "bullets": [
        {
          "text": "grounding, planning, generation, 세 단계로 구성되어 있음",
          "level": 0
        },
        {
          "text": "vision language model을 사용하여 UI components를 탐지 및 라벨링",
          "level": 1
        },
        {
          "text": "front-end priors 기반의 hierarchical layout 구성",
          "level": 1
        },
        {
          "text": "adaptive prompt-based synthesis를 통한 HTML, CSS 코드 생성",
          "level": 1
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Alibaba-qwen3-coder-flash",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "dev",
      "org": "Alibaba",
      "title": "Qwen3 Coder Flash",
      "url": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "bullets": [
        {
          "text": "128 experts, 8 activated per inference, with 3.8B active parameters",
          "level": 0
        },
        {
          "text": "256K native context window, expandabel to 1M tokens using YaRN",
          "level": 0
        },
        {
          "text": "최근 공개한 Qwen3 Coder 모델의 경량화 버전으로 이해할 수 있음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-gemini-25-deep-think",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "dev",
      "org": "Google",
      "title": "Gemini 2.5 Deep Think",
      "url": "https://blog.google/products/gemini/gemini-2-5-deep-think",
      "bullets": [
        {
          "text": "복잡한 문제를 작은 단위로 쪼개는 interative development and design",
          "level": 0
        },
        {
          "text": "algorithmic development and code, scientific and mathematical discovery 등에 특화되어 있다고 설명",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-phi-ground-tech-report-advancing-perception-in-gui-grounding",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "paper",
      "org": "Microsoft",
      "title": "Phi-Ground Tech Report: Advancing Perception in GUI Grounding",
      "url": "https://arxiv.org/abs/2507.23779",
      "bullets": [
        {
          "text": "Phi-Ground mode family: 10B 이하의 agent 중에서 SoTA를 달성한 모델 공개",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "ByteDance-seed-prover-deep-and-broad-reasoning-for-automated-theorem-proving",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "paper",
      "org": "ByteDance",
      "title": "Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving",
      "url": "https://arxiv.org/abs/2507.23726",
      "bullets": [
        {
          "text": "deep & broad reasoning을 가능토록 하는 3개의 test-time inference strategies",
          "level": 0
        },
        {
          "text": "geometry reasoning engine Seed-Geometry 도입",
          "level": 0
        },
        {
          "text": "IMO 2025의 6개 문제 중 5개를 완벽하게 prove",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Kaggle-introducing-kaggle-game-arena",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "dev",
      "org": "Kaggle",
      "title": "Introducing Kaggle Game Arena",
      "url": "https://www.kaggle.com/blog/introducing-game-arena",
      "bullets": [
        {
          "text": "o3, Gemini 2.5 Pro, Claude Opus 4, Grok 4 와 같은 frontier 모델들이 동작할 수 있는 game environments, harnesses, visualizers 등을 제공",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Anthropic-persona-vectors-monitoring-and-controlling-character-traits-in-language-models",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "dev",
      "org": "Anthropic",
      "title": "Persona vectors: Monitoring and controlling character traits in language models",
      "url": "https://www.anthropic.com/research/persona-vectors",
      "bullets": [
        {
          "text": "이를 파악함으로써 모델의 undesirable 특성들을 억제할수도 있고, 학습 데이터를 조정할수도 있음",
          "level": 0
        },
        {
          "text": "Qwen 2.5-7B-Instruct, Llama-3.1-8B-Instruct 두 open-source 모델로 평가",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-open-models-by-openai",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "dev",
      "org": "OpenAI",
      "title": "Open models by OpenAI",
      "url": "https://openai.com/open-models/",
      "bullets": [
        {
          "text": "Apache 2.0 라이센스. Safety에 대해서도 각별히 신경을 썼다고 함",
          "level": 0
        },
        {
          "text": "Designed for agentic tasks, Deeply customizable, Full chain-of-thought 등의 특징",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "CUHK,-Shanghai-AI-beyond-fixed-variable-length-denoising-for-diffusion-large-language-models",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "paper",
      "org": "CUHK, Shanghai AI",
      "title": "Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models",
      "url": "https://arxiv.org/abs/2508.00819",
      "bullets": [
        {
          "text": "모델이 내부적으로(internal) 주어진 문제에 대한 적절한 답변 길이와 관련된 signals를 포함하고 있다고 설명",
          "level": 0
        },
        {
          "text": "이러한 latent signals를 이용한 DAEDAL 제안: Dynamic Adaptive length Expansion for Diffusion lArge Language models (알파벳 조합 너무 억지..)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Alibaba-qwen-image-technical-report",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "paper",
      "org": "Alibaba",
      "title": "Qwen-Image Technical Report",
      "url": "https://arxiv.org/abs/2508.02324",
      "bullets": [
        {
          "text": "non-text-to-rendering으로 시작해 점점 더 복잡한 텍스트 입력을 받는 curriculum learning approach 적용",
          "level": 0
        },
        {
          "text": "text-to-image (T2I), text-image-to-image (TI2I), image-to-image (I2I) reconstruction을 위해 dual encoding 방식 사용 (Qwen2.5-VL & VAE)",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Google-DeepMind-genie-3-a-new-frontier-for-world-models",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "Genie 3: A new frontier for world models",
      "url": "https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models",
      "bullets": [
        {
          "text": "초당 24프레임, 720p 해상도의 few-minute consistency (Genie 2는 10-20s, Veo는 8s 수준)",
          "level": 0
        },
        {
          "text": "데모 영상 수준 퀄리티 아주 뛰어난 편",
          "level": 1
        },
        {
          "text": "promptable world events: 다양한 종류의 text-based interaction 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-gpt-5-is-here",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "dev",
      "org": "OpenAI",
      "title": "GPT-5 is here",
      "url": "https://openai.com/gpt-5/",
      "bullets": [
        {
          "text": "coding 능력이 크게 향상되어 타 frontier 모델들 수준으로 올라왔다고 보고 (실사용 후기에 따르면 그정도는 아닌 듯함)",
          "level": 0
        },
        {
          "text": "o3-pro처럼 더 오래 생각하는 test-time scaling 방식이 적용된 GPT-5 pro 모델",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "ByteDance,-Tsinghua-seed-diffusion-a-large-scale-diffusion-language-model-with-high-speed-inference",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "paper",
      "org": "ByteDance, Tsinghua",
      "title": "Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference",
      "url": "https://arxiv.org/abs/2508.02193",
      "bullets": [
        {
          "text": "non-sequential, parallel generation 덕분에 엄청나게 빠른 추론 속도: 2,146 tokens/s over H20 GPU",
          "level": 0
        },
        {
          "text": "코드 벤치마크에서 속도-성능의 파레토 라인을 push",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-guided-learning-in-gemini-from-answers-to-understanding",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "dev",
      "org": "Google",
      "title": "Guided Learning in Gemini: From answers to understanding",
      "url": "https://blog.google/outreach-initiatives/education/guided-learning",
      "bullets": [
        {
          "text": "특정 주제에 대해 deep dive 할 수 있도록 probing & open-ended questions encourage",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "VeriGUI-Team-verigui-verifiable-long-chain-gui-dataset",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "paper",
      "org": "VeriGUI Team",
      "title": "VeriGUI: Verifiable Long-Chain GUI Dataset",
      "url": "https://arxiv.org/abs/2508.04026",
      "bullets": [
        {
          "text": "realistic computer environments 대응을 위한 학습 및 평가 데이터셋",
          "level": 0
        },
        {
          "text": "(1) long-chain complexity (2) subtask-level verifiability 강조",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Arizona-State-Univ.-is-chain-of-thought-reasoning-of-llms-a-mirage-a-data-distribution-lens",
      "date": "2025-08-W01",
      "year": "2025",
      "month": "8",
      "week": "1",
      "type": "paper",
      "org": "Arizona State Univ.",
      "title": "Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens",
      "url": "https://arxiv.org/abs/2508.01191",
      "bullets": [],
      "tags": []
    },
    {
      "id": "OPPO-AI-efficient-agents-building-effective-agents-while-reducing-cost",
      "date": "2025-08-W02",
      "year": "2025",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "OPPO AI",
      "title": "Efficient Agents: Building Effective Agents While Reducing Cost",
      "url": "https://arxiv.org/abs/2508.02694",
      "bullets": [
        {
          "text": "test-time scaling (예를 들어 best-of-N) 방식은 성능 향상 대비 비용 상승률이 너무 높다는 한계를 분석",
          "level": 0
        },
        {
          "text": "같은 관점에서 web browsing은 최소화되어야 한다고 주장",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Rutgers-Univ.-reagan-node-as-agent-reasoning-graph-agentic-network",
      "date": "2025-08-W02",
      "year": "2025",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "Rutgers Univ.",
      "title": "ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network",
      "url": "https://arxiv.org/abs/2508.00429",
      "bullets": [
        {
          "text": "Retrieval-augmented Graphic Agentic Network: 그래프의 각 노드를 autonomous & individual decision making 가능하도록 설정",
          "level": 0
        },
        {
          "text": "각 노드가 곧 agent로 Memory, Planning, Action, Tool Use 가능",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Cursor-cursor-cli",
      "date": "2025-08-W02",
      "year": "2025",
      "month": "8",
      "week": "2",
      "type": "dev",
      "org": "Cursor",
      "title": "Cursor CLI",
      "url": "https://cursor.com/cli",
      "bullets": [
        {
          "text": "다른 서비스들과 크게 다른 점은 없어 보임",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-langextract",
      "date": "2025-08-W02",
      "year": "2025",
      "month": "8",
      "week": "2",
      "type": "dev",
      "org": "Google",
      "title": "LangExtract",
      "url": "https://github.com/google/langextract",
      "bullets": [
        {
          "text": "시각화 기능도 잘 지원되고 Ollma를 이용하면 로컬 모델로도 돌릴 수 있음",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-introducing-ai-sheets-a-tool-to-work-with-datasets-using-open-ai-models",
      "date": "2025-08-W02",
      "year": "2025",
      "month": "8",
      "week": "2",
      "type": "dev",
      "org": "HuggingFace",
      "title": "Introducing AI Sheets: a tool to work with datasets using open AI models!",
      "url": "https://huggingface.co/blog/aisheets",
      "bullets": [
        {
          "text": "LLM을 이용하여 합성 데이터 등을 생성 후 최종 데이터셋을 csv 형태로 반환할 수 있음",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Zhipu-AI,-Tsinghua-glm-45-agentic-reasoning-and-coding-arc-foundation-models",
      "date": "2025-08-W02",
      "year": "2025",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "Zhipu AI, Tsinghua",
      "title": "GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models",
      "url": "https://arxiv.org/abs/2508.06471",
      "bullets": [
        {
          "text": "thinking & direct response 동시 지원하는 hybrid reasoning method",
          "level": 0
        },
        {
          "text": "23T 토큰에 대해 학습",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Meta-tribe-trimodal-brain-encoder-for-whole-brain-fmri-response-prediction",
      "date": "2025-08-W02",
      "year": "2025",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "Meta",
      "title": "TRIBE: TRImodal Brain Encoder for whole-brain fMRI response prediction",
      "url": "https://arxiv.org/abs/2507.22229",
      "bullets": [
        {
          "text": "frozen pretrained model을 사용하여 audio, video, dialogue로부터 feature 추출",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "ByteDance-widesearch-benchmarking-agentic-broad-info-seeking",
      "date": "2025-08-W02",
      "year": "2025",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "ByteDance",
      "title": "WideSearch: Benchmarking Agentic Broad Info-Seeking",
      "url": "https://arxiv.org/abs/2508.07999",
      "bullets": [
        {
          "text": "large-scale atomic information을 필요로 하는 질문들이며 각 내용이 객관적으로 증명되어야 하는 까다로운 문제들임",
          "level": 0
        },
        {
          "text": "대규모 & 반복적인 정보 검색을 잘하는 LLM-based agent를 만드는 것이 목표",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Gaoling-School,-Baidu,-CMU-reasonrank-empowering-passage-ranking-with-strong-reasoning-ability",
      "date": "2025-08-W02",
      "year": "2025",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "Gaoling School, Baidu, CMU",
      "title": "ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability",
      "url": "https://arxiv.org/abs/2508.07050",
      "bullets": [
        {
          "text": "automated reasoning-intesnvie training data synthesis framework 제안. self-consistency data filtering mechanism이 적용되어 데이터 퀄리티를 보장",
          "level": 0
        },
        {
          "text": "cold-start SFT → RL for ruther ranking ability enhancement",
          "level": 0
        },
        {
          "text": "강화학습 단계에서 listwise ranking을 위해 multi-view ranking reward를 설계했는데, 이는 기존의 ranking metric-based reward보다 효과적이라고 설명함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Apple-your-llm-knows-the-future-uncovering-its-multi-token-prediction-potential",
      "date": "2025-08-W02",
      "year": "2025",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "Apple",
      "title": "Your LLM Knows the Future: Uncovering Its Multi-Token Prediction Potential",
      "url": "https://arxiv.org/abs/2507.11851",
      "bullets": [
        {
          "text": "common prefix로부터 multi token precition, 이를 이용하여 coherent sequence를 생성하는 모듈",
          "level": 0
        },
        {
          "text": "gated LoRA formulation: 기존 모델의 functionality 유지",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Ai2,-Washington-molmoact-action-reasoning-models-that-can-reason-in-space",
      "date": "2025-08-W02",
      "year": "2025",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "Ai2, Washington",
      "title": "MolmoAct: Action Reasoning Models that can Reason in Space",
      "url": "https://arxiv.org/abs/2508.07917",
      "bullets": [
        {
          "text": "MolmoAct 모델은 observations & instructions를 depth-aware perception tokens로 encode → mid-level spatial plans 생성 → precise low-level actions 예측 (7B 사이즈)",
          "level": 0
        },
        {
          "text": "MolmoAct Datset: mid-training robot dataset 공개. 10,000개의 고품질 robot trajectories",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Hebrew-story2board-a-training-free-approach-for-expressive-storyboard-generation",
      "date": "2025-08-W02",
      "year": "2025",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "Hebrew",
      "title": "Story2Board: A Training-Free Approach for Expressive Storyboard Generation",
      "url": "https://arxiv.org/abs/2508.09983",
      "bullets": [
        {
          "text": "기존에는 subject identity에만 집중한 것을 한계로 지적하고, spatial composition, background evolution, narrative pacing 등에 집중했다고 설명",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "NVIDIA-nvidia-releases-3-million-sample-dataset-for-ocr-visual-question-answering-and-captioning-tasks",
      "date": "2025-08-W02",
      "year": "2025",
      "month": "8",
      "week": "2",
      "type": "dev",
      "org": "NVIDIA",
      "title": "NVIDIA Releases 3 Million Sample Dataset for OCR, Visual Question Answering, and Captioning Tasks",
      "url": "https://huggingface.co/blog/nvidia/nvidia-vlm-dataset-v1",
      "bullets": [
        {
          "text": "OCR, VQA, captioning 등에 집중된 데이터셋이며, 최근 Llama 3.1 Nemotron Nano VL 8B V1 을 학습하는데 사용됨",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Alibaba-webwatcher-breaking-new-frontier-of-vision-language-deep-research-agent",
      "date": "2025-08-W02",
      "year": "2025",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "Alibaba",
      "title": "WebWatcher: Breaking New Frontier of Vision-Language Deep Research Agent",
      "url": "https://arxiv.org/abs/2508.05748",
      "bullets": [
        {
          "text": "efficient cold start를 위해 high-quality synthetic multimodal tranjectories 사용",
          "level": 0
        },
        {
          "text": "BrowseComp-VL: visual & textual information을 동시에 잘 가져와야 하는 복잡한 벤치마크",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "WeChat,-Tsinghua-we-math-20-a-versatile-mathbook-system-for-incentivizing-visual-mathematical-reasoning",
      "date": "2025-08-W02",
      "year": "2025",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "WeChat, Tsinghua",
      "title": "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning",
      "url": "https://arxiv.org/abs/2508.10433",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-dinov3",
      "date": "2025-08-W03",
      "year": "2025",
      "month": "8",
      "week": "3",
      "type": "dev",
      "org": "Meta",
      "title": "DINOv3",
      "url": "https://ai.meta.com/research/publications/dinov3/",
      "bullets": [
        {
          "text": "Gram anchoring loss를 사용하여 dense patch consistency를 보존하고 resolution, size, text alignment를 위한 post-hoc tweaks를 더함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "ByteDance-seeing-listening-remembering-and-reasoning-a-multimodal-agent-with-long-term-memory",
      "date": "2025-08-W03",
      "year": "2025",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "ByteDance",
      "title": "Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory",
      "url": "https://www.arxiv.org/abs/2508.09736",
      "bullets": [
        {
          "text": "시간에 따라 축적되는 knowledge를 semantic memory로 관리 (episodic memory와 별도)",
          "level": 0
        },
        {
          "text": "M3 Bench: long-video question answering benchmark. robot 관점에서 획득한 100개 데이터 + web-sourced 929개 데이터",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Chinese-Academy-of-Science-paperregister-boosting-flexible-grained-paper-search-via-hierarchical-register-indexing",
      "date": "2025-08-W03",
      "year": "2025",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "Chinese Academy of Science",
      "title": "PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing",
      "url": "https://arxiv.org/abs/2508.11116",
      "bullets": [
        {
          "text": "offline hierarchical indexing & online adaptivr retrieval → paper search를 위한 index tree",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Amsterdam-can-we-evaluate-rags-with-synthetic-data",
      "date": "2025-08-W03",
      "year": "2025",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "Amsterdam",
      "title": "Can we Evaluate RAGs with Synthetic Data?",
      "url": "https://arxiv.org/abs/2508.11758",
      "bullets": [
        {
          "text": "(1) 생성 모델은 고정하고 retriever를 varying (2) retriever를 고정하고 생성 모델을 varying",
          "level": 0
        },
        {
          "text": "(1)에서는 일관성 있는 결과가 나오는 반면 (2)는 그렇지 않다고 설명",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-introducing-gemma-3-270m-the-compact-model-for-hyper-efficient-ai",
      "date": "2025-08-W03",
      "year": "2025",
      "month": "8",
      "week": "3",
      "type": "dev",
      "org": "Google",
      "title": "Introducing Gemma 3 270M: The compact model for hyper-efficient AI",
      "url": "https://developers.googleblog.com/en/introducing-gemma-3-270m",
      "bullets": [
        {
          "text": "170M embedding parameters인데 이는 large vocab size 때문이라고 함 (256k tokens)",
          "level": 0
        },
        {
          "text": "INT4 precision으로 사용 가능한 Quantization-Aware Trained (QAT) 버전도 공개",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Alibaba-qwen-image-edit-image-editing-with-higher-quality-and-efficiency",
      "date": "2025-08-W03",
      "year": "2025",
      "month": "8",
      "week": "3",
      "type": "dev",
      "org": "Alibaba",
      "title": "Qwen-Image-Edit: Image Editing with Higher Quality and Efficiency",
      "url": "https://qwenlm.github.io/blog/qwen-image-edit",
      "bullets": [
        {
          "text": "영어와 중국어에 대해 정확한 text editing 가능",
          "level": 0
        },
        {
          "text": "Seedream, GPT Image, FLUX 등의 모델을 능가한 SoTA 달성",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Univ.-of-Tubingen-mdpo-overcoming-the-training-inference-divide-of-masked-diffusion-language-models",
      "date": "2025-08-W03",
      "year": "2025",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "Univ. of Tubingen",
      "title": "MDPO: Overcoming the Training-Inference Divide of Masked Diffusion Language Models",
      "url": "https://arxiv.org/abs/2508.13148",
      "bullets": [
        {
          "text": "이를 해결하기 위해 learning effective denoising trajectories 문제를 a sequential decision-making problem으로 정의",
          "level": 0
        },
        {
          "text": "Masked Diffusion Policy Optimization (MDPO): diffusion process의 Markov property 이용하여 모델이 추론 시 겪는 progress를 학습 당시에도 볼 수 있도록 함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OPPO-chain-of-agents-end-to-end-agent-foundation-models-via-multi-agent-distillation-and-agentic-rl",
      "date": "2025-08-W03",
      "year": "2025",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "OPPO",
      "title": "Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL",
      "url": "https://arxiv.org/abs/2508.13167",
      "bullets": [
        {
          "text": "agentic supervised fine-tuning을 위한 multi-agent distillation framework 제안 → reinforcement learning on verifiable agentic tasks",
          "level": 0
        },
        {
          "text": "학습을 통해 획득한 결과 모델을 Agent Foundation Models (AFMs)라고 부름",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Shanghia-Jiao-Tong-Univ.-transplant-then-regenerate-a-new-paradigm-for-text-data-augmentation",
      "date": "2025-08-W03",
      "year": "2025",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "Shanghia Jiao Tong Univ.",
      "title": "Transplant Then Regenerate: A New Paradigm for Text Data Augmentation",
      "url": "https://arxiv.org/abs/2508.14723",
      "bullets": [
        {
          "text": "LLM에 embedded knowledge를 이용하여 기존 text의 attribute를 지닌 채로 diverse & creative content-level variants 생성 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "DeepSeek-deepseek-v31-release",
      "date": "2025-08-W03",
      "year": "2025",
      "month": "8",
      "week": "3",
      "type": "dev",
      "org": "DeepSeek",
      "title": "DeepSeek-V3.1 Release",
      "url": "https://api-docs.deepseek.com/news/news250821",
      "bullets": [],
      "tags": []
    },
    {
      "id": "ByteDance,-Nanjing-dupo-enabling-reliable-llm-self-verification-via-dual-preference-optimization",
      "date": "2025-08-W03",
      "year": "2025",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "ByteDance, Nanjing",
      "title": "DuPO: Enabling Reliable LLM Self-Verification via Dual Preference Optimization",
      "url": "https://arxiv.org/abs/2508.14460",
      "bullets": [
        {
          "text": "RLVR이 지나치게 많은 비용을 필요로 한다는 한계 & 전통적인 dual learning이 학습 당시에 본 task만 처리할 수 있다는 한계를 극복",
          "level": 0
        },
        {
          "text": "primal task’s input을 known & unknown components로 쪼개고, primal output & known information을 이용하여 unknown part를 reconstruct",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Wuhan,-Nanjing-from-scores-to-skills-a-cognitive-diagnosis-framework-for-evaluating-financial-large-language-models",
      "date": "2025-08-W03",
      "year": "2025",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "Wuhan, Nanjing",
      "title": "From Scores to Skills: A Cognitive Diagnosis Framework for Evaluating Financial Large Language Models",
      "url": "https://arxiv.org/abs/2508.13491",
      "bullets": [
        {
          "text": "LLM 평가를 knowledge-skill level로 진행하여 LLM이 어떤 financial skills & knowledge를 갖고 있는지 확인할 수 있음 (단순한 숫자로 반환하는 것 x)",
          "level": 0
        },
        {
          "text": "CPA-QKA: the first cognitively informed financial evaluation dataset. Certified Public Accountant (CPA) 검사로부터 derive",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta-deep-think-with-confidence",
      "date": "2025-08-W03",
      "year": "2025",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "Meta",
      "title": "Deep Think with Confidence",
      "url": "https://arxiv.org/abs/2508.15260",
      "bullets": [
        {
          "text": "Deep Think with Confidence (DeepConf): model-internal confidence signals를 이용하여 low-quality reasoning traces를 dynamically filter out",
          "level": 0
        },
        {
          "text": "추가적인 학습 or hyper-parameter tuning 필요 없이 기존 serving frameworks에 integrate 가능",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Shanghai-AI-Lab-intern-s1-a-scientific-multimodal-foundation-model",
      "date": "2025-08-W03",
      "year": "2025",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "Shanghai AI Lab",
      "title": "Intern-S1: A Scientific Multimodal Foundation Model",
      "url": "https://arxiv.org/abs/2508.15763",
      "bullets": [
        {
          "text": "Intern-S1: a specialized generalist equipped with general understanding and reasoning capabilities",
          "level": 0
        },
        {
          "text": "28B activated, 241B total parameters, MoE 모델",
          "level": 0
        },
        {
          "text": "5T 토큰 데이터로 사전학습. 그중에 2.5T 토큰이 과학 분야 데이터",
          "level": 0
        },
        {
          "text": "offline & online RL을 적용할 때, InternBootCamp라는 프레임워크 내에서 Mixture-of-Rewards (MoR)를 이용하는데 1000개 이상의 태스크를 동시에 학습",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Tsinghua-computerrl-scaling-end-to-end-online-reinforcement-learning-for-computer-use-agents",
      "date": "2025-08-W03",
      "year": "2025",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "Tsinghua",
      "title": "ComputerRL: Scaling End-to-End Online Reinforcement Learning for Computer Use Agents",
      "url": "https://arxiv.org/abs/2508.14040",
      "bullets": [
        {
          "text": "distributed RL infrastrcuture를 구성하여 수천개의 가상 desktop 환경을 병렬적으로 orchestrate 함으로써 대규모 RL 수행",
          "level": 0
        },
        {
          "text": "Entropulse: SFT와 RL을 번갈아가며 학습함으로써 entropy collapse 현상을 완화",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Shanghai-AI-Lab-beyond-gpt-5-making-llms-cheaper-and-better-via-performance-efficiency-optimized-routing",
      "date": "2025-08-W03",
      "year": "2025",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "Shanghai AI Lab",
      "title": "Beyond GPT-5: Making LLMs Cheaper and Better via Performance-Efficiency Optimized Routing",
      "url": "https://arxiv.org/abs/2508.12631",
      "bullets": [],
      "tags": []
    },
    {
      "id": "xAI-xai-orggrok-2",
      "date": "2025-08-W04",
      "year": "2025",
      "month": "8",
      "week": "4",
      "type": "dev",
      "org": "xAI",
      "title": "xai-org/grok-2",
      "url": "https://huggingface.co/xai-org/grok-2",
      "bullets": [
        {
          "text": "각 토큰당 62B activated parameters",
          "level": 0
        },
        {
          "text": "tensor parallelism을 이용하여 8개 GPU에서 serving 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "GitHub-why-we-open-sourced-our-mcp-server-and-what-it-means-for-you",
      "date": "2025-08-W04",
      "year": "2025",
      "month": "8",
      "week": "4",
      "type": "dev",
      "org": "GitHub",
      "title": "Why we open sourced our MCP server, and what it means for you",
      "url": "https://github.blog/open-source/maintainers/why-we-open-sourced-our-mcp-server-and-what-it-means-for-you",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Anthropic-enhancing-model-safety-through-pretraining-data-filtering",
      "date": "2025-08-W04",
      "year": "2025",
      "month": "8",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "Enhancing Model Safety through Pretraining Data Filtering",
      "url": "https://alignment.anthropic.com/2025/pretraining-data-filtering",
      "bullets": [
        {
          "text": "6개의 classifier approaches",
          "level": 1
        },
        {
          "text": "classifier에 사용된 모델은 Claude 3.5 Haiku보다도 훨씬 작았다고 설명",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "UCL,-Huawei-agentfly-fine-tuning-llm-agents-without-fine-tuning-llms",
      "date": "2025-08-W04",
      "year": "2025",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "UCL, Huawei",
      "title": "AgentFly: Fine-tuning LLM Agents without Fine-tuning LLMs",
      "url": "https://arxiv.org/abs/2508.16153",
      "bullets": [
        {
          "text": "Memory-augmented Markov Decision Process (M-MDP)에 neural case-selection policy를 equip",
          "level": 0
        },
        {
          "text": "policy는 memory rewriting mechanism을 통해 environmental feedback 기반으로 지속 업데이트",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Shanghai-AI-Lab-internvl35-advancing-open-source-multimodal-models-in-versatility-reasoning-and-efficiency",
      "date": "2025-08-W04",
      "year": "2025",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "Shanghai AI Lab",
      "title": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency",
      "url": "https://arxiv.org/abs/2508.18265",
      "bullets": [
        {
          "text": "Cascade Reinforcement Learning (Cascade RL) framework: offline RL for stable convergence & online RL for refined alignment (coarse-to-fine)",
          "level": 0
        },
        {
          "text": "Visual Resolution Router (ViR)를 통해 성능 열화 없이 visual tokens의 resolutions를 조정",
          "level": 0
        },
        {
          "text": "Decoupled Vision-Language Deployment (DvD) strategy: vision encoder & language model을 서로 다른 GPU에 분리함으로써 computational load를 효율적으로 관리",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Microsoft-cocoa-confidence-and-context-aware-adaptive-decoding-for-resolving-knowledge-conflicts-in-large-language-models",
      "date": "2025-08-W04",
      "year": "2025",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "Microsoft",
      "title": "CoCoA: Confidence- and Context-Aware Adaptive Decoding for Resolving Knowledge Conflicts in Large Language Models",
      "url": "https://arxiv.org/abs/2508.17670",
      "bullets": [
        {
          "text": "entropy gap & contextual peakedness를 confidence-aware measures로 이용하여 conflic 해결",
          "level": 0
        },
        {
          "text": "심지어 low conflict settings에서도 높은 퍼포먼스를 보였다고 설명 (QA, Summarization 등)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "UIUC,-HKUST-utilizing-training-data-to-improve-llm-reasoning-for-tabular-understanding",
      "date": "2025-08-W04",
      "year": "2025",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "UIUC, HKUST",
      "title": "Utilizing Training Data to Improve LLM Reasoning for Tabular Understanding",
      "url": "https://arxiv.org/abs/2508.18676",
      "bullets": [
        {
          "text": "Learn then Retrieve, LRTab: 학습 데이터로부터 배운 정보와 유관한 것을 retrieving 하여 활용하는 prompting-based reasoning approach",
          "level": 0
        },
        {
          "text": "incorrect CoTs에 대해서는 모델이 에러를 피할 수 있도록 Prompt Conditions가 무엇이었을지 예측하도록 프롬프팅",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Google-introducing-gemini-25-flash-image-our-state-of-the-art-image-model",
      "date": "2025-08-W04",
      "year": "2025",
      "month": "8",
      "week": "4",
      "type": "dev",
      "org": "Google",
      "title": "Introducing Gemini 2.5 Flash Image, our state-of-the-art image model",
      "url": "https://developers.googleblog.com/en/introducing-gemini-2-5-flash-image",
      "bullets": [
        {
          "text": "캐릭터 특성을 그대로 잘 유지하면서 지시 사항을 잘 따라 변경해준다는 특징으로 큰 화제가 됨",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-notebooklms-video-overviews-are-now-available-in-80-languages",
      "date": "2025-08-W04",
      "year": "2025",
      "month": "8",
      "week": "4",
      "type": "dev",
      "org": "Google",
      "title": "NotebookLM's Video Overviews are now available in 80 languages",
      "url": "https://blog.google/technology/google-labs/notebook-lm-audio-video-overviews-more-languages-longer-content",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Anthropic-piloting-claude-for-chrome",
      "date": "2025-08-W04",
      "year": "2025",
      "month": "8",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "Piloting Claude for Chrome",
      "url": "https://www.anthropic.com/news/claude-for-chrome",
      "bullets": [
        {
          "text": "현재는 Max 유저 1,000명 대상으로 early access (wait list 등록 필요)",
          "level": 0
        },
        {
          "text": "여러 위험성에 대해서도 사전 고지를 하고 있는 상황",
          "level": 0
        },
        {
          "text": "올해 초 OpenAI에서도 web-browsing 기능을 공개했었으나 현재 제대로 쓰이고 있는지에 대해서는 확인이 필요함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "UC-Berkeley-mcp-bench-benchmarking-tool-using-llm-agents-with-complex-real-world-tasks-via-mcp-servers",
      "date": "2025-08-W04",
      "year": "2025",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "UC Berkeley",
      "title": "MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers",
      "url": "https://arxiv.org/abs/2508.20453",
      "bullets": [
        {
          "text": "MCP 기반으로 build 되어 LLM을 28개의 대표적인 live MCP servers와 연결하여 다양한 도메인(finance, traveling 등)을 다룸",
          "level": 0
        },
        {
          "text": "multi-faceted evaluation framework 제안",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "xAI-grok-code-fast-1",
      "date": "2025-08-W04",
      "year": "2025",
      "month": "8",
      "week": "4",
      "type": "dev",
      "org": "xAI",
      "title": "Grok Code Fast 1",
      "url": "https://x.ai/news/grok-code-fast-1",
      "bullets": [
        {
          "text": "GitHub Copilot, Cline, Cursor, Roo Code, Windsurf 등에서 사용 가능",
          "level": 0
        },
        {
          "text": "TS, Python, Java, Rust, C++, Go 등 다양한 언어를 다룰 수 있으며, 서빙단에서 속도를 최적화했음을 언급",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "KTH-measuring-reasoning-utility-in-llms-via-conditional-entropy-reduction",
      "date": "2025-08-W04",
      "year": "2025",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "KTH",
      "title": "Measuring Reasoning Utility in LLMs via Conditional Entropy Reduction",
      "url": "https://arxiv.org/abs/2508.20395",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Stanford,-NYU-from-tokens-to-thoughts-how-llms-and-humans-trade-compression-for-meaning",
      "date": "2025-07-W01",
      "year": "2025",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "Stanford, NYU",
      "title": "From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning",
      "url": "http://arxiv.org/abs/2505.17117",
      "bullets": [
        {
          "text": "인간은 적절한 수준의 비효율성을 감소하면서도 더 풍부하고 유연한 개념 구조를 형성하는 반면 LLM은 통계적으로 효율을 극대화하여 개념 구조 형성",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Baidu-announcing-the-open-source-release-of-the-ernie-45-model-family",
      "date": "2025-07-W01",
      "year": "2025",
      "month": "7",
      "week": "1",
      "type": "dev",
      "org": "Baidu",
      "title": "Announcing the Open Source Release of the ERNIE 4.5 Model Family",
      "url": "https://ernie.baidu.com/blog/posts/ernie4.5/",
      "bullets": [
        {
          "text": "MoE에 각 modality별로 독립적인 파라미터를 할당함과 동시에 modalities 간에 share 하는 파라미터도 보유하는 heterogeneous architecture 적용",
          "level": 0
        },
        {
          "text": "중국의 딥러닝 프레임워크인 PaddlePaddle로 모델 학습",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Mixture-of-Reasonings:-Teach-Large-Language-Models-to-Reason-with-Adaptive-Strategies-mixture-of-reasonings-teach-large-language-models-to-reason-with-adaptive-strategies",
      "date": "2025-07-W01",
      "year": "2025",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "Mixture of Reasonings: Teach Large Language Models to Reason with Adaptive Strategies",
      "title": "Mixture of Reasonings: Teach Large Language Models to Reason with Adaptive Strategies",
      "url": "https://arxiv.org/abs/2507.00606",
      "bullets": [
        {
          "text": "Thought generation → SFT dataset construction",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Mila,-Oxford,-AI2-chain-of-thought-is-not-explainability",
      "date": "2025-07-W01",
      "year": "2025",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "Mila, Oxford, AI2",
      "title": "Chain-of-Thought Is Not Explainability",
      "url": "https://www.alphaxiv.org/abs/2025.02",
      "bullets": [
        {
          "text": "verbalized chain이 주로 unfaithful 하며 모델 예측 자체로부터 diverge 하는 것이기 때문에 모델이 최종 정답에 이르는데 방해가 된다고 설명",
          "level": 0
        },
        {
          "text": "(1) 추가적인 증명이 없다면 CoT는 interpretability technique로 사용할 수 없다.",
          "level": 0
        },
        {
          "text": "(2) downstream decision-making의 faithfulness를 평가하기 위한 rigorous methods를 사용해야 한다",
          "level": 0
        },
        {
          "text": "(3) 모델 내부에서 explanation을 ground 하기 위한 causal validation method를 고도화 해야 한다",
          "level": 0
        },
        {
          "text": "요슈아 벤지오가 저자 ㄷㄷ",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Ai2-sciarena-a-new-platform-for-evaluating-foundation-models-in-scientific-literature-tasks",
      "date": "2025-07-W01",
      "year": "2025",
      "month": "7",
      "week": "1",
      "type": "dev",
      "org": "Ai2",
      "title": "SciArena: A New Platform for Evaluating Foundation Models in Scientific Literature Tasks",
      "url": "https://allenai.org/blog/sciarena",
      "bullets": [
        {
          "text": "SoTA 성능을 파악하기 위해 23개의 프론티어 모델들을 호스트 중. 현재는 o3 모델이 최고 성능을 보임",
          "level": 0
        },
        {
          "text": "Chatbot Arena처럼 Elo rating system 사용",
          "level": 0
        },
        {
          "text": "[논문 링크](https://arxiv.org/abs/2507.01001) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "ETH-Zürich-do-i-know-this-entity-knowledge-awareness-and-hallucinations-in-language-models",
      "date": "2025-07-W01",
      "year": "2025",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "ETH Zürich",
      "title": "Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models",
      "url": "https://arxiv.org/abs/2411.14257",
      "bullets": [
        {
          "text": "SAE는 representation space에서 meaningful direction을 알아낼 수 있는데, 이를 통해 모델이 특정 entity를 아는지 모르는지(self-knowledge)를 구분할 수 있음",
          "level": 0
        },
        {
          "text": "direction을 이용하면 모델이 원래 알고 있던 것은 모른다고 하거나, 반대로 모르던 것은 알고 있는 것처럼 답변(hallucinate)하도록 유도하는 것이 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-Gemini-gemini-cli",
      "date": "2025-07-W01",
      "year": "2025",
      "month": "7",
      "week": "1",
      "type": "dev",
      "org": "Google Gemini",
      "title": "Gemini-CLI",
      "url": "https://github.com/google-gemini/gemini-cli",
      "bullets": [],
      "tags": []
    },
    {
      "id": "observe.tools-observetools",
      "date": "2025-07-W01",
      "year": "2025",
      "month": "7",
      "week": "1",
      "type": "dev",
      "org": "observe.tools",
      "title": "observe.tools",
      "url": "https://observe.tools",
      "bullets": [
        {
          "text": "디테일한 trace 확인, payload 수정, 공유 등 기능 지원",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Ai2-ifbench",
      "date": "2025-07-W01",
      "year": "2025",
      "month": "7",
      "week": "1",
      "type": "dev",
      "org": "Ai2",
      "title": "IFBench",
      "url": "https://github.com/allenai/IFBench/tree/main",
      "bullets": [
        {
          "text": "OOD constraints: verification function이 존재하는 58개의 new & challenging constraints",
          "level": 0
        },
        {
          "text": "Multiturn Constraint Isolation in 2 turns",
          "level": 0
        },
        {
          "text": "new IF-RLVR training constraints: 마찬가지로 verification function이 존재하는 29개의 new & challenging constraints ([IF-RLVR training data](https://huggingface.co/datasets/allenai/IF_multi_constraints_upto5) 🔗)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Alibaba-websailor-navigating-super-human-reasoning-for-web-agent",
      "date": "2025-07-W01",
      "year": "2025",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "Alibaba",
      "title": "WebSailor: Navigating Super-human Reasoning for Web Agent",
      "url": "https://arxiv.org/abs/2507.02592",
      "bullets": [
        {
          "text": "Duplicating Sampling Policy Optimization (DUPO): agentic RL training algorithm",
          "level": 0
        },
        {
          "text": "DUPO + structured sampling, information obfuscation, RFT cold start",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Inception-Labs-mercury-ultra-fast-language-models-based-on-diffusion",
      "date": "2025-07-W01",
      "year": "2025",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "Inception Labs",
      "title": "Mercury: Ultra-Fast Language Models Based on Diffusion",
      "url": "https://arxiv.org/abs/2506.17298",
      "bullets": [
        {
          "text": "Transformer architecture & multiple tokens parallel prediction",
          "level": 0
        },
        {
          "text": "두 사이즈, Mini & Small 로 구성된 Mercury Coder 에 대한 상세한 리포트",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "NUS,-MIT,-Yonsei-mem1-learning-to-synergize-memory-and-reasoning-for-efficient-long-horizon-agents",
      "date": "2025-07-W01",
      "year": "2025",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "NUS, MIT, Yonsei",
      "title": "MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents",
      "url": "https://arxiv.org/abs/2506.15841",
      "bullets": [
        {
          "text": "매 턴마다 compact shared internal state를 update",
          "level": 0
        },
        {
          "text": "기존 데이터셋을 이용하여 복잡한 task sequences로 만들어, 보다 realistic & compositional setting에 맞춰 학습 진행",
          "level": 0
        },
        {
          "text": "뛰어난 일반화 성능 보고",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Baidu-towards-ai-search-paradigm",
      "date": "2025-07-W01",
      "year": "2025",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "Baidu",
      "title": "Towards AI Search Paradigm",
      "url": "https://arxiv.org/abs/2506.17188",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Independent-self-correction-bench-revealing-and-addressing-the-self-correction-blind-spot-in-llms",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "Independent",
      "title": "Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs",
      "url": "https://arxiv.org/abs/2507.02778",
      "bullets": [
        {
          "text": "Self-Correction Bench 제안: complexity level을 3개로 정해서 controlled error injection을 통해 관련 능력을 systematically 평가",
          "level": 0
        },
        {
          "text": "LLM의 이러한 한계는 모델의 학습 데이터 구성(composition)과 관련이 높음",
          "level": 0
        },
        {
          "text": "RL은 reward를 바탕으로 correction이 일어나지만 SFT는 아니므로..",
          "level": 1
        },
        {
          "text": "단순히 “Wait” 정도를 추가하는 것만으로도 Blind Spot을 89.3%나 줄일 수 있었음",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Salesforce-lost-at-the-beginning-of-reasoning",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "Salesforce",
      "title": "Lost at the Beginning of Reasoning",
      "url": "https://arxiv.org/abs/2506.22058",
      "bullets": [
        {
          "text": "즉, 스타트를 잘못 끊으면 이어지는 reasoning quality도 자연스레 낮다는 뜻",
          "level": 1
        },
        {
          "text": "DeepSeek-R1 & Qwen3 대상으로 실험",
          "level": 0
        },
        {
          "text": "reward 모델을 이용하여 고품질의 first reasoning step을 retain 하는 sampling 전략 제안",
          "level": 0
        },
        {
          "text": "의도적으로 첫 번째 추론 step에 문제가 있는 샘플들로 구성된 벤치마크를 제작하여 모델의 self-correction 능력을 평가",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Sakana-AI-inference-time-scaling-and-collective-intelligence-for-frontier-ai",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "dev",
      "org": "Sakana AI",
      "title": "Inference-Time Scaling and Collective Intelligence for Frontier AI",
      "url": "https://sakana.ai/ab-mcts/",
      "bullets": [
        {
          "text": "[AB-MCTS (Adaptive Branching Monte Carlo Tree Search)](https://arxiv.org/abs/2503.04412)",
          "level": 0
        },
        {
          "text": "AI가 trial-and-error를 빠르게 수행하여 여러 frontier 모델이 협력하도록 함",
          "level": 1
        },
        {
          "text": "4o-mini + Gemini-2.5-Pro + R1-0528",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Tsinghua-glm-41v-thinking-towards-versatile-multimodal-reasoning-with-scalable-reinforcement-learning",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "Tsinghua",
      "title": "GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning",
      "url": "https://arxiv.org/abs/2507.01006",
      "bullets": [
        {
          "text": "GLM-4.1V-9B-Thinking 모델을 오픈소스로 공개: 동사이즈 모델군에서 SoTA. video understanding, content recognition, coding, grounding 등 다양한 태스크 수행 가능",
          "level": 0
        },
        {
          "text": "long document understanding & STEM reasoning",
          "level": 1
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Alibaba-ovis-u1-technical-report",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "Alibaba",
      "title": "Ovis-U1 Technical Report",
      "url": "https://arxiv.org/abs/2506.23044",
      "bullets": [
        {
          "text": "diffusion-based visual decoder & bidirectional token refiner",
          "level": 0
        },
        {
          "text": "frozen MLLM 모델을 이용하는 타 방법론들과 달리, 언어 모델로부터 unified training approach를 이용하여 understanding & generation 둘 다 학습 → better performance",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Anthropic-project-vend-can-claude-run-a-small-shop-and-why-does-that-matter",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "dev",
      "org": "Anthropic",
      "title": "Project Vend: Can Claude run a small shop? (And why does that matter?)",
      "url": "https://www.anthropic.com/research/project-vend-1",
      "bullets": [
        {
          "text": "잘한 점: 웹어서 공급처를 찾아 특이, 희귀 상품 (네덜란드 초콜릿 우유 등) 준비",
          "level": 0
        },
        {
          "text": "실패한 점: 과도한 할인 정책, 허위 결제 정보 생성",
          "level": 0
        },
        {
          "text": "현재 상태로는 매장 운영이 불가능하지만, 향후 중간 관리자 정도의 역할을 할 수 있다고 판단",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "MemTensor-memos-a-memory-os-for-ai-system",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "MemTensor",
      "title": "MemOS: A Memory OS for AI System",
      "url": "https://arxiv.org/abs/2507.03724",
      "bullets": [
        {
          "text": "representation, scheduling, evolution of plain text, activation-based & parameter-level memories를 통합",
          "level": 0
        },
        {
          "text": "MemCube를 기본 단위로 사용하여 memory & meta data를 encapsulate",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Should-We-Still-Pretrain-Encoders-with-Masked-Language-Modeling?-should-we-still-pretrain-encoders-with-masked-language-modeling",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "Should We Still Pretrain Encoders with Masked Language Modeling?",
      "title": "Should We Still Pretrain Encoders with Masked Language Modeling?",
      "url": "https://arxiv.org/abs/2507.00994",
      "bullets": [
        {
          "text": "MLM 학습 방식과 CLM 학습 방식의 결과 차이를 비교",
          "level": 0
        },
        {
          "text": "MLM은 학습 결과가 좋지만 CLM의 데이터 대비 학습 효율이 좋음",
          "level": 0
        },
        {
          "text": "CLM → MLM 으로 이어지는 biphasic 학습 전략이 제한된 budget 내에서 가장 좋은 결과로 이어졌다고 설명",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "IIT-singlora-low-rank-adaptation-using-a-single-matrix",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "IIT",
      "title": "SingLoRA: Low Rank Adaptation Using a Single Matrix",
      "url": "https://arxiv.org/abs/2507.05566",
      "bullets": [
        {
          "text": "이를 통해 두 matrix 간 존재하는 scale disparities로 인해 발생하는 성능 하락 문제 해결 가능",
          "level": 0
        },
        {
          "text": "자연어에 대해서는 Llama, 이미지에 대해서는 Stable Diffusion 모델을 fine-tuning한 결과 제시",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Perplexity-browse-at-the-speed-of-thought",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "dev",
      "org": "Perplexity",
      "title": "Browse at the speed of thought",
      "url": "https://comet.perplexity.ai/#faq",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind-medgemma-technical-report",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "MedGemma Technical Report",
      "url": "https://arxiv.org/abs/2507.05201",
      "bullets": [
        {
          "text": "medical multimodal question answering & chest X-ray finding classification 태스크 잘 처리한다고 보고",
          "level": 0
        },
        {
          "text": "MedSigLIP: SigLIP으로부터 개발한 medically-tuned vision encoder",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Ai2-introducing-flexolmo-a-new-paradigm-for-language-model-training-and-data-collaboration",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "dev",
      "org": "Ai2",
      "title": "Introducing FlexOlmo: a new paradigm for language model training and data collaboration",
      "url": "https://allenai.org/blog/flexolmo",
      "bullets": [
        {
          "text": "data owners는 데이터에 대한 통제권을 잃지 않고서도 AI 모델에 기여할 수 있게 됨. 데이터를 직접적으로 공유할 필요도 없게 됨",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-t5gemma-a-new-collection-of-encoder-decoder-gemma-models",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "dev",
      "org": "Google",
      "title": "T5Gemma: A new collection of encoder-decoder Gemma models",
      "url": "https://developers.googleblog.com/en/t5gemma/",
      "bullets": [
        {
          "text": "model adaptation: 사전학습된 decoder-only model의 weight로 initialize → UL2 or PrefixLM-based pre-training → 기존 decoder-only model보다 뛰어난 성능",
          "level": 0
        },
        {
          "text": "encoder-decoder 간의 사이즈를 꼭 맞추지 않아도 됨 (flexibility)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "xAI-grok4",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "dev",
      "org": "xAI",
      "title": "Grok4",
      "url": "https://x.com/xai/status/1943158495588815072",
      "bullets": [
        {
          "text": "multi-agent 구조, 256K context window",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Intel-investigating-the-robustness-of-retrieval-augmented-generation-at-the-query-level",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "Intel",
      "title": "Investigating the Robustness of Retrieval-Augmented Generation at the Query Level",
      "url": "https://arxiv.org/abs/2507.06956",
      "bullets": [
        {
          "text": "query에 다양한 변형을 가하여(perturbation) RAG components의 sensitivity 측정",
          "level": 0
        },
        {
          "text": "연구 결과에 따르면 사소한 query variation도 최종 생성 결과를 꽤나 degrade 한다고 함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "NUS-drag-and-drop-llms-zero-shot-prompt-to-weights-neurips-2025",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "NUS",
      "title": "Drag-and-Drop LLMs: Zero-Shot Prompt-to-Weights (NeurIPS 2025)",
      "url": "https://arxiv.org/abs/2506.16406",
      "bullets": [
        {
          "text": "lightweight text encoder가 각 prompt batch를 condition embeddings로 distills → cascaded hyper-convolutional decoder에 의해 full set of LoRA 행렬로 변환",
          "level": 0
        },
        {
          "text": "task-specific parameters를 수 초 안에 생성 → FFT 대비 12,000배 낮은 overhead → unseen tasks에 대해 기존 LoRA 대비 30%까지 성능 향상",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "SKT-ax-40",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "dev",
      "org": "SKT",
      "title": "A.X-4.0",
      "url": "https://huggingface.co/skt/A.X-4.0",
      "bullets": [
        {
          "text": "한국어 이해 & enterprise deployment 를 강점으로 내세움",
          "level": 0
        },
        {
          "text": "72B 사이즈. 7B 사이즈의 light 버전도 공개",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "SKT-ax-31-light",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "dev",
      "org": "SKT",
      "title": "A.X-3.1-Light",
      "url": "https://huggingface.co/skt/A.X-3.1-Light",
      "bullets": [
        {
          "text": "1.65T multi-lingual 토큰 corpus로 학습. 7B 사이즈.",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Stanford,-Cohere-block-diffusion-interpolating-between-autoregressive-and-diffusion-language-models",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "Stanford, Cohere",
      "title": "Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models",
      "url": "https://arxiv.org/abs/2503.09573?utm_source=pytorchkr&ref=pytorchkr",
      "bullets": [
        {
          "text": "a class of block diffusion: discrete denoising diffusion & autoregressive models 사이를 interpolate",
          "level": 0
        },
        {
          "text": "flexible-length generation & inference efficiency with KV cacahing and parallel token sampling",
          "level": 1
        },
        {
          "text": "이를 위한 efficient training algorithm, estimators of gradient variance, data-driven noise scheduels to minimize the variance 등을 제시",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Tencent,-Princeton-one-token-to-fool-llm-as-a-judge",
      "date": "2025-07-W02",
      "year": "2025",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "Tencent, Princeton",
      "title": "One Token to Fool LLM-as-a-Judge",
      "url": "https://arxiv.org/abs/2507.08794",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Moonshot-AI-kimi-k2-open-agentic-intelligence",
      "date": "2025-07-W03",
      "year": "2025",
      "month": "7",
      "week": "3",
      "type": "dev",
      "org": "Moonshot AI",
      "title": "Kimi K2: Open Agentic Intelligence",
      "url": "https://moonshotai.github.io/Kimi-K2/",
      "bullets": [
        {
          "text": "MuonClip optimizer를 도입하여 qk-clip technique 고도화",
          "level": 0
        },
        {
          "text": "Tool learning을 위한 대규모 Agentic Data Synthesis",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Google-DeepMind-gemini-25-pushing-the-frontier-with-advanced-reasoning-multimodality-long-context-and-next-generation-agentic-capabilities",
      "date": "2025-07-W03",
      "year": "2025",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities",
      "url": "https://arxiv.org/abs/2507.06261",
      "bullets": [
        {
          "text": "coding, reasoning 특화 & thinking 모델임",
          "level": 0
        },
        {
          "text": "multimodal understanding 능력이 뛰어나 3시간 분량의 영상도 처리할 수 있음",
          "level": 0
        },
        {
          "text": "long context + multi-modal ⇒ agentic problem-solving",
          "level": 0
        }
      ],
      "tags": [
        "multimodal",
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "MetaStone-AI,-USTC-test-time-scaling-with-reflective-generative-model",
      "date": "2025-07-W03",
      "year": "2025",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "MetaStone AI, USTC",
      "title": "Test-Time Scaling with Reflective Generative Model",
      "url": "https://arxiv.org/abs/2507.01951",
      "bullets": [
        {
          "text": "두 가지 주요한 특징",
          "level": 0
        },
        {
          "text": "(1) A unified interface for policy and process reward model: trajectory scoring head 사이즈가 고작 53M",
          "level": 1
        },
        {
          "text": "(2) Eliminating the reliance on process-level annotation: self-supervised process reward model",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "CMU-dynamic-chunking-for-end-to-end-hierarchical-sequence-modeling",
      "date": "2025-07-W03",
      "year": "2025",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "CMU",
      "title": "Dynamic Chunking for End-to-End Hierarchical Sequence Modeling",
      "url": "https://arxiv.org/abs/2507.07955",
      "bullets": [
        {
          "text": "dynamic chunking을 hierarchical network (H-Net)에 통합함으로써 tokenization-LM-detokenization → single model 로 대체",
          "level": 0
        },
        {
          "text": "영어로 학습된 모델의 경우 character 단위에서 더 robust한 특징을 보였다고 설명",
          "level": 0
        },
        {
          "text": "Mamba 창시자인 Albert Gu 논문",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "KAIST,-Mila,-Google-mixture-of-recursions-learning-dynamic-recursive-depths-for-adaptive-token-level-computation",
      "date": "2025-07-W03",
      "year": "2025",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "KAIST, Mila, Google",
      "title": "Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation",
      "url": "https://arxiv.org/abs/2507.10524",
      "bullets": [
        {
          "text": "parameter efficiency를 위해 shared stack of layers를 사용하고, lightweight router를 통해 adaptive token-level thinking",
          "level": 0
        },
        {
          "text": "첫 recursion의 KV pairs를 재사용하는 KV sharing variant 제안",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Johns-Hopkins,-Tsinghua,-Rice-vision-language-vision-auto-encoder-scalable-knowledge-distillation-from-diffusion-models",
      "date": "2025-07-W03",
      "year": "2025",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "Johns Hopkins, Tsinghua, Rice",
      "title": "Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models",
      "url": "https://arxiv.org/abs/2507.07104",
      "bullets": [
        {
          "text": "vision encoder, Text-to-Image (T2I) diffusion model의 decoder, LLM을 순차적으로 이용",
          "level": 1
        },
        {
          "text": "T2I diffusion model의 decoder를 이용함으로써 language representation space를 regularize 할 수 있었음",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "OpenAI-introducing-chatgpt-agent-bridging-research-and-action",
      "date": "2025-07-W03",
      "year": "2025",
      "month": "7",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing ChatGPT agent: bridging research and action",
      "url": "https://openai.com/index/introducing-chatgpt-agent",
      "bullets": [
        {
          "text": "다른 툴들과 쉽게 연동하여 태스크 수행. 벤치마크 성능도 공개함",
          "level": 0
        },
        {
          "text": "[ChatGPT agent System Card](https://openai.com/index/chatgpt-agent-system-card)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Mistral-voxtral",
      "date": "2025-07-W03",
      "year": "2025",
      "month": "7",
      "week": "3",
      "type": "dev",
      "org": "Mistral",
      "title": "Voxtral",
      "url": "https://mistral.ai/news/voxtral",
      "bullets": [
        {
          "text": "Word Error Rate 측정 결과를 공개했는데 GPT-4o mini Audio, Gemini 2.5 Flash보다 뛰어난 성능을 보임",
          "level": 0
        },
        {
          "text": "text 이해 능력도 Mistral Small 3.1에 비해 크게 뒤지지 않는 정도",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Peking,-Tsinghua-a-survey-of-context-engineering-for-large-language-models",
      "date": "2025-07-W03",
      "year": "2025",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "Peking, Tsinghua",
      "title": "A Survey of Context Engineering for Large Language Models",
      "url": "https://arxiv.org/abs/2507.13334",
      "bullets": [
        {
          "text": "이를 구성하는 핵심적인 요소 (1) Context Retrieval and Generation (2) Context Processing (3) Context Management",
          "level": 0
        },
        {
          "text": "System Implementations: (1) Retrieval-Augmented Generation (RAG) (2) Memory systems (3) Tool-Integrated Reasoning (4) Multi-Agent Systems",
          "level": 0
        }
      ],
      "tags": [
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "Stanford-agents4science-2025",
      "date": "2025-07-W03",
      "year": "2025",
      "month": "7",
      "week": "3",
      "type": "dev",
      "org": "Stanford",
      "title": "Agents4Science 2025",
      "url": "https://agents4science.stanford.edu",
      "bullets": [
        {
          "text": "9월 25일 제출 마감, 9월 29일 심사 마감, 10월 22일 virtual conference 일정",
          "level": 0
        },
        {
          "text": "AI가 과학 분야에 어떻게 기여할 수 있을지 탐구하고자 하는 과감한 시도",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Tsinghua,-UIUC,-Tokyo,-Peking,-HKUST-towards-agentic-rag-with-deep-reasoning-a-survey-of-rag-reasoning-systems-in-llms",
      "date": "2025-07-W03",
      "year": "2025",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "Tsinghua, UIUC, Tokyo, Peking, HKUST",
      "title": "Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs",
      "url": "https://arxiv.org/abs/2507.09477",
      "bullets": [],
      "tags": []
    },
    {
      "id": "CMU-agentic-r1-distilled-dual-strategy-reasoning",
      "date": "2025-07-W04",
      "year": "2025",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "CMU",
      "title": "Agentic-R1: Distilled Dual-Strategy Reasoning",
      "url": "https://arxiv.org/abs/2507.05707",
      "bullets": [
        {
          "text": "또한 tool-augmented agents는 code execution으로 문제를 해결해왔으나 여전히 복잡한 logical 문제들을 풀지는 못함",
          "level": 0
        },
        {
          "text": "DualDistill: 여러 teachers로부터의 complementary reasoning strategies를 unified student model에 distill하는 framework",
          "level": 0
        },
        {
          "text": "Agentic-R1: 각 쿼리마다 최적의 전략을 dynamically 선택하도록 학습한 모델. tool을 사용하거나 텍스트 기반의 추론을 하거나.",
          "level": 0
        }
      ],
      "tags": [
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "ARC-arc-agi-3",
      "date": "2025-07-W04",
      "year": "2025",
      "month": "7",
      "week": "4",
      "type": "dev",
      "org": "ARC",
      "title": "ARC-AGI-3",
      "url": "https://arcprize.org/arc-agi/3",
      "bullets": [
        {
          "text": "기존에도 ARC 벤치마크 퍼즐을 맞추는 태스크로 유명 (인간과 유사한 사고가 가능한지)",
          "level": 0
        },
        {
          "text": "o3, Grok 4와 같은 frontier models도 현재까지 0점 기록",
          "level": 0
        },
        {
          "text": "RTX 5090 또는 $1K API 로 추론. 8시간 제한",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-gemini-embedding-now-generally-available-in-the-gemini-api",
      "date": "2025-07-W04",
      "year": "2025",
      "month": "7",
      "week": "4",
      "type": "dev",
      "org": "Google",
      "title": "Gemini Embedding now generally available in the Gemini API",
      "url": "https://developers.googleblog.com/en/gemini-embedding-available-gemini-api",
      "bullets": [
        {
          "text": "science, legal, finance, coding 등 다양한 도메인에 대해 뛰어난 성능을 보인다고 설명",
          "level": 0
        },
        {
          "text": "100개 이상의 언어에 대해 2048 input token length 지원. Matryoshka Representation Learning (MRL) 테크닉 사용시 3072, 1536, 768 차원 추천",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Anthropic-inverse-scaling-in-test-time-compute",
      "date": "2025-07-W04",
      "year": "2025",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "Anthropic",
      "title": "Inverse Scaling in Test-Time Compute",
      "url": "https://arxiv.org/abs/2507.14417",
      "bullets": [
        {
          "text": "모든 flagship 모델들이 복잡한 deductive tasks에서 약점을 보임",
          "level": 0
        },
        {
          "text": "extended reasoning은 self-preservation 표현을 증가시킴",
          "level": 0
        },
        {
          "text": "Simple Counting tasks with Distractors, Regression Tasks with Spurious Features, Deduction Tasks with Constraint Tracking",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Zhejiang-gui-g2-gaussian-reward-modeling-for-gui-grounding",
      "date": "2025-07-W04",
      "year": "2025",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "Zhejiang",
      "title": "GUI-G^2: Gaussian Reward Modeling for GUI Grounding",
      "url": "https://arxiv.org/abs/2507.15846",
      "bullets": [
        {
          "text": "GUI-G^2: GUI 요소를 interface plance 위의 continuous Gaussian Distribution으로 modeling",
          "level": 0
        },
        {
          "text": "Guassian point rewards: precise localization을 모델링",
          "level": 1
        },
        {
          "text": "Coverage rewards: predicted Gaussian distirbutions & target regions 간의 overlap 측정",
          "level": 1
        },
        {
          "text": "element dimensions 기반으로 reward distributions를 calibrate하는 adaptive variance mechanism 개발",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "MiroMind-AI-miromind-m1-an-open-source-advancement-in-mathematical-reasoning-via-context-aware-multi-stage-policy-optimization",
      "date": "2025-07-W04",
      "year": "2025",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "MiroMind AI",
      "title": "MiroMind-M1: An Open-Source Advancement in Mathematical Reasoning via Context-Aware Multi-Stage Policy Optimization",
      "url": "https://arxiv.org/abs/2507.14683",
      "bullets": [
        {
          "text": "719K개의 math-reasoning 데이터셋 SFT + 62K개의 challenging & verifiable 문제에 대해 RLVR",
          "level": 0
        },
        {
          "text": "Context-Aware Multi-Stage Policy Optimization (CAMPO): length-progressive training + adaptive repetition penalty",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Alibaba-qwen3-235b-a22b-instruct-2507",
      "date": "2025-07-W04",
      "year": "2025",
      "month": "7",
      "week": "4",
      "type": "dev",
      "org": "Alibaba",
      "title": "Qwen3-235B-A22B-Instruct-2507",
      "url": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
      "bullets": [
        {
          "text": "Qwen Chat default 모델로 탑재. Kimi K2 모델을 능가하는 성능으로 보고",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "CMU-diffusion-beats-autoregressive-in-data-constrained-settings",
      "date": "2025-07-W04",
      "year": "2025",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "CMU",
      "title": "Diffusion Beats Autoregressive in Data-Constrained Settings",
      "url": "https://arxiv.org/abs/2507.15857",
      "bullets": [
        {
          "text": "repeated data에 대해 더 낮은 validation loss를 보이고 downstream performance도 뛰어남",
          "level": 0
        },
        {
          "text": "저자는 이러한 현상을 implicit data augmentation으로 해석 (고정된 left-to-right factorization을 따르는 AR 방식과의 차이점)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Alibaba-qwen3-coder-agentic-coding-in-the-world",
      "date": "2025-07-W04",
      "year": "2025",
      "month": "7",
      "week": "4",
      "type": "dev",
      "org": "Alibaba",
      "title": "Qwen3-Coder: Agentic Coding in the World",
      "url": "https://qwenlm.github.io/blog/qwen3-coder",
      "bullets": [
        {
          "text": "Qwen2.5-Coder를 사용하여 7.5T 토큰으로 학습된 480B-35B(active) MoE model, Qwen3-Coder",
          "level": 0
        },
        {
          "text": "256K default, 최대 1M 토큰 지원",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Shanhai-AI-the-devil-behind-the-mask-an-emergent-safety-vulnerability-of-diffusion-llms",
      "date": "2025-07-W04",
      "year": "2025",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "Shanhai AI",
      "title": "The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs",
      "url": "https://arxiv.org/abs/2507.11097",
      "bullets": [
        {
          "text": "DIJA: adversarial interleaved mask-text prompts 생성 → dLLM 특성을 이용한 생성 방식으로, 타 jail-breaking을 압도하는 결과였다고 보고",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Sapient-Intelligence-hierarchical-reasoning-model",
      "date": "2025-07-W04",
      "year": "2025",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "Sapient Intelligence",
      "title": "Hierarchical Reasoning Model",
      "url": "https://arxiv.org/abs/2506.21734",
      "bullets": [
        {
          "text": "2개의 interdependent recurrent modules",
          "level": 0
        },
        {
          "text": "a high-level module responsible for slow, abstract planning",
          "level": 1
        },
        {
          "text": "a low-level module handling rapid, detailed computations",
          "level": 1
        },
        {
          "text": "27M 파라미터 사이즈의 모델로, 단 1000개 training samples로 학습",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "GitHub-github-spark-in-public-preview-for-copilot-pro-subscribers",
      "date": "2025-07-W04",
      "year": "2025",
      "month": "7",
      "week": "4",
      "type": "dev",
      "org": "GitHub",
      "title": "GitHub Spark in public preview for Copilot Pro+ subscribers",
      "url": "https://github.blog/changelog/2025-07-23-github-spark-in-public-preview-for-copilot-pro-subscribers",
      "bullets": [
        {
          "text": "자연어로 micro apps를 만들 수 있도록 지원하는 기능으로, Claude Sonnet 4로 동작",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "HuggingFace-trending-papers",
      "date": "2025-07-W04",
      "year": "2025",
      "month": "7",
      "week": "4",
      "type": "dev",
      "org": "HuggingFace",
      "title": "Trending Papers",
      "url": "https://huggingface.co/papers/trending",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Cardiff-Univ-theres-no-such-thing-as-simple-reasoning-for-llms",
      "date": "2025-07-W04",
      "year": "2025",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "Cardiff Univ",
      "title": "There’s No Such Thing as Simple Reasoning for LLMs",
      "url": "https://aclanthology.org/2025.findings-acl.232.pdf",
      "bullets": [
        {
          "text": "그러나 오히려 훨씬 간단한 reasoning 문제들을 풀지 못한다는 것을 문제점으로 지적",
          "level": 0
        },
        {
          "text": "본 연구에서는 3-step 추론으로 해결할 수 있는 간단한 문제들에 조금씩 노이즈를 더하여(순서를 바꾸는 등) 모델 성능을 테스트 해봤고, 현존 모델들이 이런 세팅에 상당히 취약하다는 것을 지적함",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Stanford-optimization-before-evaluation-evaluation-with-unoptimized-prompts-can-be-misleading",
      "date": "2025-07-W04",
      "year": "2025",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "Stanford",
      "title": "Optimization before Evaluation: Evaluation with Unoptimized Prompts Can be Misleading",
      "url": "https://aclanthology.org/2025.acl-industry.44.pdf",
      "bullets": [
        {
          "text": "대부분의 모델과 벤치마크가 PO에 심각한 영향을 받는다고 설명",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Shanghai-AI,-Fudan-yume-an-interactive-world-generation-model",
      "date": "2025-07-W04",
      "year": "2025",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "Shanghai AI, Fudan",
      "title": "Yume: An Interactive World Generation Model",
      "url": "https://arxiv.org/abs/2507.17744",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Anthropic,-UC-Berkeley-subliminal-learning-language-models-transmit-behavioral-traits-via-hidden-signals-in-data",
      "date": "2025-07-W05",
      "year": "2025",
      "month": "7",
      "week": "5",
      "type": "paper",
      "org": "Anthropic, UC Berkeley",
      "title": "Subliminal Learning: Language models transmit behavioral traits via hidden signals in data",
      "url": "https://arxiv.org/abs/2507.14805",
      "bullets": [
        {
          "text": "특성 T를 갖는 teacher 모델이 일련의 숫자로만 구성된 데이터셋을 생성하고 이를 학습한 student 모델이 특성 T를 배울 수 있다는 것",
          "level": 0
        },
        {
          "text": "teacher 모델이 생성하는 코드나 reasoning path로 학습하더라도 동일 현상을 관측할 수 있다고 설명",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Anthropic-building-and-evaluating-alignment-auditing-agents",
      "date": "2025-07-W05",
      "year": "2025",
      "month": "7",
      "week": "5",
      "type": "dev",
      "org": "Anthropic",
      "title": "Building and evaluating alignment auditing agents",
      "url": "https://alignment.anthropic.com/2025/automated-auditing/",
      "bullets": [
        {
          "text": "hidden goal을 찾아내고 misaligned behavior 등을 탐지하는 등 impressive results를 보여줌",
          "level": 0
        },
        {
          "text": "prefill attacks, context-manipulated jailbreaks, interpretability-driven safety failures 등에 취약하다는 결론",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Runway-introducing-runway-aleph-a-new-way-to-edit-transform-and-generate-video",
      "date": "2025-07-W05",
      "year": "2025",
      "month": "7",
      "week": "5",
      "type": "dev",
      "org": "Runway",
      "title": "Introducing Runway Aleph | A new way to edit, transform and generate video.",
      "url": "https://www.youtube.com/watch?v=KUHx-2uz_qI",
      "bullets": [
        {
          "text": "비디오를 from scratch 생성하지 않고 text prompt를 통해 필요한 영역들을 수정",
          "level": 0
        },
        {
          "text": "예를 들어 camera angles 수정, remove objects, effects like rain or fireworks 등 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Z.ai-glm-45-reasoning-coding-and-agentic-abililties",
      "date": "2025-07-W05",
      "year": "2025",
      "month": "7",
      "week": "5",
      "type": "dev",
      "org": "Z.ai",
      "title": "GLM-4.5: Reasoning, Coding, and Agentic Abililties",
      "url": "https://z.ai/blog/glm-4.5?s=08",
      "bullets": [
        {
          "text": "coding benchmark에서 Claude 4 Sonnet, GPT-4.1 급의 성능",
          "level": 0
        },
        {
          "text": "GLM-4.5: 355B total & 32B active parameters / GLM-4.5 Air: 106B total & 12B active parameters",
          "level": 0
        },
        {
          "text": "둘 다 hybrid reasoning model로 복잡한 추론이나 tool using, non-thinking 등을 지원",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "Waterloo-mind-the-gap-conformative-decoding-to-improve-output-diversity-of-instruction-tuned-large-language-models",
      "date": "2025-07-W05",
      "year": "2025",
      "month": "7",
      "week": "5",
      "type": "paper",
      "org": "Waterloo",
      "title": "Mind the Gap: Conformative Decoding to Improve Output Diversity of Instruction-Tuned Large Language Models",
      "url": "https://arxiv.org/abs/2507.20956",
      "bullets": [
        {
          "text": "OLMo, OLMo 2 모델을 대상으로 한 실험에서 DPO의 영향도가 가장 크다는 결론",
          "level": 0
        },
        {
          "text": "이를 바탕으로 conformative decoding 제안: instruct model이 base model의 다양성을 reintroduce 할 수 있도록 guide 하는 decoding strategy",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Renmin-agentic-reinforced-policy-optimization",
      "date": "2025-07-W05",
      "year": "2025",
      "month": "7",
      "week": "5",
      "type": "paper",
      "org": "Renmin",
      "title": "Agentic Reinforced Policy Optimization",
      "url": "https://arxiv.org/abs/2507.19849",
      "bullets": [
        {
          "text": "Agentic Reinforced Policy Optimization (ARPO)",
          "level": 0
        },
        {
          "text": "외부 툴 사용 직후 생성되는 토큰의 entropy 분포가 향상된다는 점을 포착",
          "level": 1
        },
        {
          "text": "entropy-based adaptive rollout mechanism",
          "level": 1
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Univ.-of-Alberta-curiosity-by-design-an-llm-based-coding-assistant-asking-clarification-questions",
      "date": "2025-07-W05",
      "year": "2025",
      "month": "7",
      "week": "5",
      "type": "paper",
      "org": "Univ. of Alberta",
      "title": "Curiosity by Design: An LLM-based Coding Assistant Asking Clarification Questions",
      "url": "https://arxiv.org/abs/2507.21285",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Yale-table-r1-inference-time-scaling-for-table-reasoning",
      "date": "2025-06-W01",
      "year": "2025",
      "month": "6",
      "week": "1",
      "type": "paper",
      "org": "Yale",
      "title": "Table-R1: Inference-Time Scaling for Table Reasoning",
      "url": "https://arxiv.org/abs/2505.23621",
      "bullets": [
        {
          "text": "frontier model의 reasoning steps로부터 distillation",
          "level": 1
        },
        {
          "text": "reinforcement learning with verifiable rewards (RLVR)",
          "level": 1
        },
        {
          "text": "Distillation을 위해 DeepSeek-R1 모델로 reasoning traces 생성",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Cohere-command-a-an-enterprise-ready-large-language-model",
      "date": "2025-06-W01",
      "year": "2025",
      "month": "6",
      "week": "1",
      "type": "paper",
      "org": "Cohere",
      "title": "Command A: An Enterprise-Ready Large Language Model",
      "url": "https://arxiv.org/abs/2504.00698",
      "bullets": [
        {
          "text": "agent-optimized & multilingual-capable model (23개 언어 지원), hybrid architecture",
          "level": 0
        },
        {
          "text": "self-refinement & model merging techniques 적용",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Sakana-AI-darwin-godel-machine-open-ended-evolution-of-self-improving-agents",
      "date": "2025-06-W01",
      "year": "2025",
      "month": "6",
      "week": "1",
      "type": "paper",
      "org": "Sakana AI",
      "title": "Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents",
      "url": "https://arxiv.org/abs/2505.22954",
      "bullets": [
        {
          "text": "여러 frozen foundation models가 tool use를 통해 코드를 읽고, 쓰고, 실행하는 coding agents optimize를 목표",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "UC-Berkeley,-Yale-learning-to-reason-without-external-rewards",
      "date": "2025-06-W01",
      "year": "2025",
      "month": "6",
      "week": "1",
      "type": "paper",
      "org": "UC Berkeley, Yale",
      "title": "Learning to Reason without External Rewards",
      "url": "https://www.arxiv.org/abs/2505.19590",
      "bullets": [
        {
          "text": "→ Reinforcement Learning from Internal Feedback (RLIF): 외부 rewards or labeled data 없이 intrinsic signals로부터 학습",
          "level": 0
        },
        {
          "text": "Intuitor: 모델 스스로의 confidence, self-certainty를 유일한 reward signla로 사용. 기존 GRPO 자리를 대체",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "AgenticSeek:-Private,-Local-Manus-Alternative.-agenticseek-private-local-manus-alternative",
      "date": "2025-06-W01",
      "year": "2025",
      "month": "6",
      "week": "1",
      "type": "dev",
      "org": "AgenticSeek: Private, Local Manus Alternative.",
      "title": "AgenticSeek: Private, Local Manus Alternative.",
      "url": "https://github.com/Fosowl/agenticSeek",
      "bullets": [
        {
          "text": "web search, write codes, plan tasks, select agents, voice-enhanced 등 다양한 features",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "UIUC,-UC-Berkeley-alphaone-reasoning-models-thinking-slow-and-fast-at-test-time",
      "date": "2025-06-W01",
      "year": "2025",
      "month": "6",
      "week": "1",
      "type": "paper",
      "org": "UIUC, UC Berkeley",
      "title": "AlphaOne: Reasoning Models Thinking Slow and Fast at Test Time",
      "url": "https://arxiv.org/abs/2505.24863",
      "bullets": [
        {
          "text": "scaled thinking phase를 $\\alpha$ moment 라고 표현. $\\alpha$ moment가 slow thinking 하는 시점임",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "ElevenLabs-introducing-elevenlabs-conversational-ai-20",
      "date": "2025-06-W01",
      "year": "2025",
      "month": "6",
      "week": "1",
      "type": "dev",
      "org": "ElevenLabs",
      "title": "Introducing ElevenLabs Conversational AI 2.0",
      "url": "https://elevenlabs.io/blog/conversational-ai-2-0",
      "bullets": [
        {
          "text": "enterprise 사용에 더욱 적합: private files or prorietary data sources에 RAG 연결 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Kakao-a-practical-approach-for-building-production-grade-conversational-agents-with-workflow-graphs",
      "date": "2025-06-W01",
      "year": "2025",
      "month": "6",
      "week": "1",
      "type": "paper",
      "org": "Kakao",
      "title": "A Practical Approach for Building Production-Grade Conversational Agents with Workflow Graphs",
      "url": "https://arxiv.org/abs/2505.23006",
      "bullets": [
        {
          "text": "e-commerce domain을 위한 conversational agent에 관한 case study",
          "level": 0
        },
        {
          "text": "카나나를 기반으로 더 넓은 분야로 대화형 agent를 확장하고자 하는 것일까하는 생각",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Alibaba-qwenlong-l1-towards-long-context-large-reasoning-models-with-reinforcement-learning",
      "date": "2025-06-W01",
      "year": "2025",
      "month": "6",
      "week": "1",
      "type": "paper",
      "org": "Alibaba",
      "title": "QwenLong-L1: Towards Long-Context Large Reasoning Models with Reinforcement Learning",
      "url": "https://arxiv.org/abs/2505.17667",
      "bullets": [
        {
          "text": "QwenLong-L1: short-context LRMs를 long-context scenarios에 adapt 할 수 있도록 progressive context scaling을 적용하는 프레임워크",
          "level": 0
        },
        {
          "text": "warm-up SFT stage → curriculum-guided phased RL",
          "level": 0
        },
        {
          "text": "QwenLong-L1-32B 모델이 OpenAI-o3-mini, Qwen3-235B-A22B 등을 outperform",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Renmin-Univ.-do-not-abstain-identify-and-solve-the-uncertainty",
      "date": "2025-06-W01",
      "year": "2025",
      "month": "6",
      "week": "1",
      "type": "paper",
      "org": "Renmin Univ.",
      "title": "Do not Abstain! Identify and Solve the Uncertainty",
      "url": "https://arxiv.org/abs/2506.00780",
      "bullets": [
        {
          "text": "ConfuseBench: 세 종류의 uncertainty를 다룸 - document scarcity, limited capability, query ambiguity",
          "level": 0
        },
        {
          "text": "original query의 confusing aspect를 highlight 하는 context-aware inquiries 생성하고, 이를 기반으로 source of uncertainty를 판단하는 방법론 제안",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-smolvla-a-vision-language-action-model-for-affordable-and-efficient-robotics",
      "date": "2025-06-W01",
      "year": "2025",
      "month": "6",
      "week": "1",
      "type": "paper",
      "org": "HuggingFace",
      "title": "SmolVLA: A Vision-Language-Action Model for Affordable and Efficient Robotics",
      "url": "https://arxiv.org/abs/2506.01844",
      "bullets": [
        {
          "text": "SmolVLA: small, efficient, community-driven VLA. training & inference 비용 저렴",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta,-DeepMind,-Cornell,-NVIDIA-how-much-do-language-models-memorize",
      "date": "2025-06-W01",
      "year": "2025",
      "month": "6",
      "week": "1",
      "type": "paper",
      "org": "Meta, DeepMind, Cornell, NVIDIA",
      "title": "How much do language models memorize?",
      "url": "https://arxiv.org/abs/2505.24832",
      "bullets": [
        {
          "text": "memorization을 unintended memorization & generalization 두 가지로 구분",
          "level": 0
        },
        {
          "text": "generalization을 제거하여 모델의 total memorization을 계산하고 model capacity를 추정할 수 있음",
          "level": 1
        },
        {
          "text": "GPT family 모델들은 약 3.6 bits-per-parameter의 capacity를 가짐",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Meta-llamafirewall-an-open-source-guardrail-system-for-building-secure-ai-agents",
      "date": "2025-06-W01",
      "year": "2025",
      "month": "6",
      "week": "1",
      "type": "paper",
      "org": "Meta",
      "title": "LlamaFirewall: An open source guardrail system for building secure AI agents",
      "url": "https://ai.meta.com/research/publications/llamafirewall-an-open-source-guardrail-system-for-building-secure-ai-agents",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Apple-the-illusion-of-thinking-understanding-the-strengths-and-limitations-of-reasoning-models-via-the-lens-of-problem-complexity",
      "date": "2025-06-W02",
      "year": "2025",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "Apple",
      "title": "The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity",
      "url": "https://machinelearning.apple.com/research/illusion-of-thinking",
      "bullets": [
        {
          "text": "다양한 puzzle environments를 통해 모델의 internal reasoning traces를 확인하여 LRMs이 “think” 하는 방식에 대한 insight 획득",
          "level": 0
        },
        {
          "text": "reasoning effort가 특정 문제 난이도까지 상승하다가 이후에는 감소하여 scaling에서의 한계를 보임을 지적",
          "level": 0
        },
        {
          "text": "낮은 난이도의 문제들에 대해서는 일반적인 LLM들이 훨씬 뛰어난 퍼포먼스를 보여줌 & 어려운 난이도에 대해서는 일반적인 LLM이나 LRM이나 둘 다 collpase",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Stanford,-NYU-from-tokens-to-thoughts-how-llms-and-humans-trade-compression-for-meaning-1",
      "date": "2025-06-W02",
      "year": "2025",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "Stanford, NYU",
      "title": "From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning",
      "url": "https://arxiv.org/abs/2505.17117",
      "bullets": [
        {
          "text": "expressive fidelity & representational simplicity 간의 trade-off가 있는데, 모델은 human understanding에서 중요한 fine-grained semantic distinctions을 놓침",
          "level": 0
        },
        {
          "text": "또한 LLM은 aggressive statistical compression에 대해 bias를 보임",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "UC-Santa-Cruz,-Stanford-knowledge-or-reasoning-a-close-look-at-how-llms-think-across-domains",
      "date": "2025-06-W02",
      "year": "2025",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "UC Santa Cruz, Stanford",
      "title": "Knowledge or Reasoning? A Close Look at How LLMs Think Across Domains",
      "url": "https://arxiv.org/abs/2506.02126",
      "bullets": [
        {
          "text": "fine-grained evaluation framework 제안",
          "level": 0
        },
        {
          "text": "(1) 사용된 knowledge의 정확성 (Knowledge Index (KI))",
          "level": 1
        },
        {
          "text": "(2) the quality of reasoning (Information Gain (IG))",
          "level": 1
        },
        {
          "text": "한 도메인에서 획득한 reasoning 능력이 다른 도메인으로 transfer 되지 않는다는 연구 결과",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Stanford-openthoughts-data-recipes-for-reasoning-models",
      "date": "2025-06-W02",
      "year": "2025",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "Stanford",
      "title": "OpenThoughts: Data Recipes for Reasoning Models",
      "url": "https://arxiv.org/abs/2506.04178",
      "bullets": [
        {
          "text": "OpenThoughts2-1M 데이터셋으로 OpenThinker2-32B 모델 학습. DeepSeek-R1-Distill-32B에 준하는 성능",
          "level": 0
        },
        {
          "text": "추가로 데이터셋을 정제하여 OpenThoughts3 제작",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "CMU-coding-agents-with-multimodal-browsing-are-generalist-problem-solvers",
      "date": "2025-06-W02",
      "year": "2025",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "CMU",
      "title": "Coding Agents with Multimodal Browsing are Generalist Problem Solvers",
      "url": "https://arxiv.org/abs/2506.03011",
      "bullets": [
        {
          "text": "기존 모델들은 특정 도메인이나 태스크에 specialized 되어 있어 일반화가 되지 않음을 지적",
          "level": 1
        },
        {
          "text": "OpenHands-Versa: a generalist agent built with a modest number of general tools",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Microsoft,-Peking,-Tsinghua-reinforcement-pre-training",
      "date": "2025-06-W02",
      "year": "2025",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "Microsoft, Peking, Tsinghua",
      "title": "Reinforcement Pre-Training",
      "url": "https://arxiv.org/abs/2506.08007",
      "bullets": [
        {
          "text": "주어진 문맥에서 다음 토큰을 정확히 예측하면 verifiable rewards를 받는 방식",
          "level": 1
        },
        {
          "text": "general-purpose RL을 위한 방대한 양의 텍스트 데이터를 이용할 수 있는 scalabe method라고 소개",
          "level": 0
        },
        {
          "text": "further reinforcement fine-tning을 위한 strong pre-trained foundation",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "ByteDance-dolphin-document-image-parsing-via-heterogeneous-anchor-prompting",
      "date": "2025-06-W02",
      "year": "2025",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "ByteDance",
      "title": "Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting",
      "url": "https://arxiv.org/abs/2505.14059",
      "bullets": [
        {
          "text": "reading order에 맞는 sequence of layout elements를 생성하고 이를 anchors로 사용",
          "level": 0
        },
        {
          "text": "anchors는 task-specific prompts와 짝지어지고, 다음 단계에서 parallel content parsing에 사용됨",
          "level": 0
        },
        {
          "text": "multi-granularity parsing tasks를 다루는 30M개 이상의 dataset",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Cambridge-truly-self-improving-agents-require-intrinsic-metacognitive-learning",
      "date": "2025-06-W02",
      "year": "2025",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "Cambridge",
      "title": "Truly Self-Improving Agents Require Intrinsic Metacognitive Learning",
      "url": "https://arxiv.org/abs/2506.05109",
      "bullets": [
        {
          "text": "인간의 metacognition에 착안하여 세 개의 components로 구성된 프레임워크 제안",
          "level": 0
        },
        {
          "text": "metacognitive knowledge, metacognitive planning, metacognitive evaluation",
          "level": 1
        },
        {
          "text": "기존 agents들이 학습하는 것은 extrinsic metacognitive mechanisms을 따른다고 설명",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Claude-Opus-comment-on-the-illusion-of-thinking-understanding-the-strengths-and-limitations-of-reasoning-models-via-the-lens-of-problem-complexity",
      "date": "2025-06-W02",
      "year": "2025",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "Claude Opus",
      "title": "Comment on The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity",
      "url": "https://arxiv.org/abs/2506.09250",
      "bullets": [],
      "tags": []
    },
    {
      "id": "MIT-self-adapting-language-models",
      "date": "2025-06-W02",
      "year": "2025",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "MIT",
      "title": "Self-Adapting Language Models",
      "url": "https://arxiv.org/abs/2506.10943",
      "bullets": [],
      "tags": []
    },
    {
      "id": "OpenAI-launching-openai-o3-pro",
      "date": "2025-06-W03",
      "year": "2025",
      "month": "6",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "Launching OpenAI o3-pro",
      "url": "https://help.openai.com/en/articles/9624314-model-release-notes",
      "bullets": [
        {
          "text": "personalized answer를 위한 memory 기능 지원",
          "level": 0
        },
        {
          "text": "o3, o1-pro 모델을 math, coding, science 벤치마크에서 outperform. pass@1 벤치마크가 인상적임",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Huawei-swe-factory-your-automated-factory-for-issue-resolution-training-data-and-evaluation-benchmarks",
      "date": "2025-06-W03",
      "year": "2025",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "Huawei",
      "title": "SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks",
      "url": "https://arxiv.org/abs/2506.10954",
      "bullets": [
        {
          "text": "SWE-Factory",
          "level": 0
        },
        {
          "text": "SWE-Builder: evaluation environment construction을 자동화해주는 multi-agent system",
          "level": 1
        },
        {
          "text": "exit-code-based grading method: custom parsers를 직접 작성할 필요가 없음",
          "level": 1
        },
        {
          "text": "reliable exit code signals를 이용하여 fail2pass validation process를 자동화",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Rice,-Johns-Hopkins,-NVIDIA-play-to-generalize-learning-to-reason-through-game-play",
      "date": "2025-06-W03",
      "year": "2025",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "Rice, Johns Hopkins, NVIDIA",
      "title": "Play to Generalize: Learning to Reason Through Game Play",
      "url": "https://arxiv.org/abs/2506.08011",
      "bullets": [
        {
          "text": "Snake 같은 게임을 학습한 7B 사이즈 모델이, RL 동안에 어떤 solutions, equations, diagrams를 보지 못했음에도 불구하고 MMMU에서 성능 향상을 보임: transferable reasoning skills",
          "level": 0
        },
        {
          "text": "따라서 synthetic, rule-based game을 controllable & scalable pre-text tasks로 사용할 수 있다고 설명 for generalizable multimodal reasoning abilities in MLLMs",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal",
        "reasoning"
      ]
    },
    {
      "id": "Sakana-AI-text-to-lora-instant-transformer-adaption",
      "date": "2025-06-W03",
      "year": "2025",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "Sakana AI",
      "title": "Text-to-LoRA: Instant Transformer Adaption",
      "url": "https://arxiv.org/abs/2506.06105",
      "bullets": [
        {
          "text": "Text-to-LoRA (T2L): many LoRA adapters를 합축한 모델로 unseen tasks에 대해 generalizes",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Meta-v-jepa-2-self-supervised-video-models-enable-understanding-prediction-and-planning",
      "date": "2025-06-W03",
      "year": "2025",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "Meta",
      "title": "V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning",
      "url": "https://arxiv.org/abs/2506.09985",
      "bullets": [
        {
          "text": "2-stage training",
          "level": 0
        },
        {
          "text": "action-free pretraining on 1M+ hours of internet videos and images",
          "level": 1
        },
        {
          "text": "post-training with only 62 hours of unlabeld robot trajectories (Droid dataset)",
          "level": 1
        },
        {
          "text": "self-supervised robot planning, architectural scale-up 등의 특징",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "Microsoft,-UCLA-direct-reasoning-optimization-llms-can-reward-and-refine-their-own-reasoning-for-open-ended-tasks",
      "date": "2025-06-W03",
      "year": "2025",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "Microsoft, UCLA",
      "title": "Direct Reasoning Optimization: LLMs Can Reward And Refine Their Own Reasoning for Open-Ended Tasks",
      "url": "https://arxiv.org/abs/2506.13351",
      "bullets": [
        {
          "text": "preceding CoT reasoning에서 key tokens를 identify & emphasize → reasoning & reference outcome 사이의 consistency를 fine-grained level에서 capture",
          "level": 0
        },
        {
          "text": "R3는 optimized 중인 model의 내부 연산 결과를 활용하므로 self-contained training setup 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Google-DeepMind-gemini-25-pushing-the-frontier-with-advanced-reasoning-multimodality-long-context-and-next-generation-agentic-capabilities-1",
      "date": "2025-06-W03",
      "year": "2025",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.",
      "url": "https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf",
      "bullets": [
        {
          "text": "coding & reasoning benchmarks에서 SoTA 달성",
          "level": 0
        },
        {
          "text": "Gemini 2.5 Pro 모델은 3시간 길이의 비디오를 이해할 수 있을 정도로 뛰어난 multimodal understanding 능력을 보임",
          "level": 0
        }
      ],
      "tags": [
        "multimodal",
        "reasoning"
      ]
    },
    {
      "id": "MIT-your-brain-on-chatgpt-accumulation-of-cognitive-debt-when-using-an-ai-assistant-for-essay-writing-task",
      "date": "2025-06-W03",
      "year": "2025",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "MIT",
      "title": "Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task",
      "url": "https://arxiv.org/abs/2506.08872v1",
      "bullets": [
        {
          "text": "LLM으로 태스크를 수행한 그룹은 타 그룹 대비 less coordinated neural effort가 관측되었다고 보고",
          "level": 0
        },
        {
          "text": "또한 작성된 에세이의 퀄리티는 AI judge & human teachers로부터 비슷한 평가를 받았으나, NER/n-gram 관점에서는 타그룹 대비 낮은 성적을 기록",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Yale,-Columbia,-…-multifinben-a-multilingual-multimodal-and-difficulty-aware-benchmark-for-financial-llm-evaluation",
      "date": "2025-06-W03",
      "year": "2025",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "Yale, Columbia, …",
      "title": "MultiFinBen: A Multilingual, Multimodal, and Difficulty-Aware Benchmark for Financial LLM Evaluation",
      "url": "https://arxiv.org/abs/2506.14028",
      "bullets": [
        {
          "text": "domain-specific tasks에 대해 linguistic settings (monollingual, bilingual, multilingual)",
          "level": 0
        },
        {
          "text": "PolyFiQA-Easy & PolyFiQA-Expert: mixed-language inputs에 대해 복잡한 reasoning이 필요한 벤치마크 공개",
          "level": 0
        },
        {
          "text": "또한 기존의 simple aggregation existing datasets 대신, dynamic difficulty-aware slection mechanism 제안",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Anthropic-shade-arena-evaluating-sabotage-and-monitoring-in-llm-agents",
      "date": "2025-06-W03",
      "year": "2025",
      "month": "6",
      "week": "3",
      "type": "dev",
      "org": "Anthropic",
      "title": "SHADE-Arena: Evaluating sabotage and monitoring in LLM agents",
      "url": "https://www.anthropic.com/research/shade-arena-sabotage-monitoring",
      "bullets": [
        {
          "text": "각 태스크는 main task & harmful side task 로 구성",
          "level": 0
        },
        {
          "text": "이중 모니터링 시스템, 은밀성 평가(단순 성공 여부 x, 들키지 않고 성공 o), 복잡성과 현실성 고려",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "MiniMax-minimax-m1-scaling-test-time-compute-efficiently-with-lightning-attention",
      "date": "2025-06-W03",
      "year": "2025",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "MiniMax",
      "title": "MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning Attention",
      "url": "https://arxiv.org/abs/2506.13585",
      "bullets": [
        {
          "text": "1M context length 지원, 연산 효율성 강조",
          "level": 0
        },
        {
          "text": "CISPO: token update 대신 importance sampling weights를 clip 하는 novel RL algorithm",
          "level": 0
        },
        {
          "text": "512 H800 GPUs로 3주 동안 학습하여 $534,700 비용이 들었다고 강조함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-persona-feature-control-emergent-misalignment",
      "date": "2025-06-W03",
      "year": "2025",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "OpenAI",
      "title": "Persona Feature Control Emergent Misalignment",
      "url": "",
      "bullets": [
        {
          "text": "Toward understanding and preventing misalignment generalization: [OpenAI 블로그](https://openai.com/index/emergent-misalignment)",
          "level": 0
        },
        {
          "text": "GPT-4o를 insecure code에 의도적으로 fine-tuning 하면 unrelated prompts에도 malicious response를 반환 - emergent misalignment - 한다는 선행 연구 있음",
          "level": 0
        },
        {
          "text": "model diffing approach: sparse autoencoder를 사용하여 fine-tuning 전후의 internal model representations 비교",
          "level": 0
        },
        {
          "text": "이를 통해 activation space 내의 misaligned persona feature를 확인할 수 있었고, 이는 곧 모델이 그러한 (malicious) 행동을 보일지 아닐지 예측할 수 있다는 것을 의미함 → re-align도 가능하다고 설명",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "ByteDance-seedance-10-exploring-the-boundaries-of-video-generation-models",
      "date": "2025-06-W03",
      "year": "2025",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "ByteDance",
      "title": "Seedance 1.0: Exploring the Boundaries of Video Generation Models",
      "url": "https://arxiv.org/abs/2506.09113",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Huawei-rag-enhancing-retrieval-augmented-generation-with-application-aware-reasoning",
      "date": "2025-06-W04",
      "year": "2025",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Huawei",
      "title": "RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware Reasoning",
      "url": "https://arxiv.org/abs/2506.11555",
      "bullets": [
        {
          "text": "knowledge & aligned application example 로 구성된 dual corpus construct → 추론 단계에서 retrieves both jointly",
          "level": 1
        },
        {
          "text": "LLMs가 relevant information에 접근할 수 있을 뿐만 아니라 이를 structured & goal-oriented reasoning processes에 적용할 수 있게 됨",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Stanford-future-of-work-with-ai-agents-auditing-automation-and-augmentation-potential-across-the-us-workforce",
      "date": "2025-06-W04",
      "year": "2025",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Stanford",
      "title": "Future of Work with AI Agents: Auditing Automation and Augmentation Potential across the U.S. Workforce",
      "url": "https://arxiv.org/abs/2506.06576",
      "bullets": [
        {
          "text": "WORKBank: 844개 tasks, 104개 occupations에 대해 worker desires & expert assessments를 결합한 데이터 베이스",
          "level": 1
        },
        {
          "text": "Human Agency Scale (HAS): AI-agent-supported work에서 desired human involvement를 정량화",
          "level": 1
        },
        {
          "text": "4 AI deployment zones: Automation Green Light, Red Light, R&D Opportunity, Low Priority",
          "level": 1
        },
        "https://magenta.tensorflow.org/magenta-realtime?utm_source=alphasignal"
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "IlElevenLabs-introducing-11ai-the-voice-first-ai-assistant-that-takes-action",
      "date": "2025-06-W04",
      "year": "2025",
      "month": "6",
      "week": "4",
      "type": "dev",
      "org": "IlElevenLabs",
      "title": "Introducing 11ai: the voice-first AI assistant that takes action",
      "url": "https://elevenlabs.io/blog/introducing-11ai",
      "bullets": [
        {
          "text": "MCP를 통해서는 Salesforce, HubSpot, Gmail, Zapier 등에 연결 가능",
          "level": 1
        },
        {
          "text": "out-of-the-box integration으로 Perplexity, Linear, Slack, Notion 지원",
          "level": 1
        },
        {
          "text": "Ultra-low latency, Multimodal support, Integrated RAG, Automatic language detection, Enterprise-ready 등의 특징",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal",
        "agent"
      ]
    },
    {
      "id": "Sakana-AI-reinforcement-learning-teachers-of-test-time-scaling",
      "date": "2025-06-W04",
      "year": "2025",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Sakana AI",
      "title": "Reinforcement Learning Teachers of Test Time Scaling",
      "url": "https://arxiv.org/abs/2506.08388",
      "bullets": [
        {
          "text": "현재 LLM의 강화학습은 one-hot correctness를 기반으로 이뤄지므로 initialization에 대한 의존성이 너무 높고, 학습이 잘된 RL 모델도 결국 distillation에서 cold start 문제를 해결하기 위한 teacher model로 쓰이는 현황을 지적",
          "level": 1
        },
        {
          "text": "Reinforcement-Learned Teachers (RLT): 각 문제에 대한 question & solution을 입력으로 받음 → 둘 사이를 ‘connects-the-dots’ 하여 학생들에게 자세한 설명을 제공하는 태스크 수행",
          "level": 1
        },
        {
          "text": "이를 학생들에게 제공하여 solution에 대한 이해도를 확인하고, 이를 바탕으로 dense rewards를 획득",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Cornell-memento-note-taking-for-your-future-self",
      "date": "2025-06-W04",
      "year": "2025",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Cornell",
      "title": "Memento: Note-Taking for Your Future Self",
      "url": "https://arxiv.org/abs/2506.20642",
      "bullets": [
        {
          "text": "Memento (prompt strategy): 1) complex question을 smaller steps로 나눈다 2) LLM을 이용하여 database를 dynamically construct 3) 문제를 풀기 위해 작은 문제들을 다시 합친다",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Oxford,-Amazon,-Cambridge-distilling-tool-knowledge-into-language-models-via-back-translated-traces",
      "date": "2025-06-W04",
      "year": "2025",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Oxford, Amazon, Cambridge",
      "title": "Distilling Tool Knowledge into Language Models via Back-Translated Traces",
      "url": "https://arxiv.org/abs/2506.19171",
      "bullets": [
        {
          "text": "Tool-integrated reasoning (TIF)은 inference-time dependencies로 인해 확장 가능성이 낮음",
          "level": 1
        },
        {
          "text": "natural language를 통해 tool knowledge를 LLM에 distill 하는 패러다임 제안",
          "level": 1
        },
        {
          "text": "Solver Agent: interleaving planning, symbolic tool calls, reflective reasoning을 통해 수학 문제 풀이",
          "level": 1
        },
        {
          "text": "multiple LLM-based agents 기반의 back-transaltion pipeline을 이용하여 TIR traces를 natural language reasoning traces로 변환",
          "level": 2
        },
        {
          "text": "Translator Agent: 각 tool calls에 대한 설명 생성",
          "level": 2
        },
        {
          "text": "Rephrase Agent: 이들을 coherent narrative로 merge",
          "level": 2
        },
        {
          "text": "이런 식으로 만든 synthesized traces에 대해 오픈소스 모델들을 fine-tuning하여 tool knowledge & structured rasoning patterns 내재화에 기여했다고 보고",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "Google-DeepMind-alphagenome-ai-for-better-understanding-the-genome",
      "date": "2025-06-W04",
      "year": "2025",
      "month": "6",
      "week": "4",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "AlphaGenome: AI for better understanding the genome",
      "url": "https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome",
      "bullets": [
        {
          "text": "single variants or mutation in human DNA sequences가 유전자를 조정하는 생물학적 과정에 어떻게 영향을 주는지 예측하는 모델",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Anthropic-agentic-misalignment-how-llms-could-be-insider-threats",
      "date": "2025-06-W04",
      "year": "2025",
      "month": "6",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "Agentic Misalignment: How LLMs could be insider threats",
      "url": "https://www.anthropic.com/research/agentic-misalignment",
      "bullets": [
        {
          "text": "모델이 테스트 시나리오라는 것을 인지했을 땐 misbehavior를 보일 확률이 급격하게 낮아짐",
          "level": 1
        },
        {
          "text": "실험 결과를 보면 blackmail rates에서 가장 높은 수치를 보이는 것은 Claude Opus 4 → 엄청나게 솔직한 연구 결과",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta-introducing-oakley-meta-glasses-a-new-category-of-performance-ai-glasses",
      "date": "2025-06-W04",
      "year": "2025",
      "month": "6",
      "week": "4",
      "type": "news",
      "org": "Meta",
      "title": "Introducing Oakley Meta Glasses, a New Category of Performance AI Glasses",
      "url": "https://about.fb.com/news/2025/06/introducing-oakley-meta-glasses-a-new-category-of-performance-ai-glasses/",
      "bullets": [
        {
          "text": "풀충전 기준 일반적인 사용으로 8시간, stanby 기준 19시간 지속되는 배터리",
          "level": 1
        },
        {
          "text": "Ultra HD (3K) video를 담을 수 있는 high resolution camera",
          "level": 1
        },
        {
          "text": "built-in, personal AI assistant. 스포츠 활용성 높음",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Ohio,-Amazon-mind2web-2-evaluating-agentic-search-with-agent-as-a-judge",
      "date": "2025-06-W04",
      "year": "2025",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Ohio, Amazon",
      "title": "Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge",
      "url": "https://arxiv.org/abs/2506.21506",
      "bullets": [
        {
          "text": "이를 평가하기 위한 Agent-as-a-Judge 프레임워크 제안",
          "level": 1
        },
        {
          "text": "tree-structured rubric 기반의 task-specific judge agents를 construct 하여 answer correctness & source attribution 평가",
          "level": 2
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Ai2-omega-can-llms-reason-outside-the-box-in-math-evaluating-exploratory-compositional-and-transformative-generalization",
      "date": "2025-06-W04",
      "year": "2025",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Ai2",
      "title": "OMEGA: Can LLMs Reason Outside the Box in Math? Evaluating Exploratory, Compositional, and Transformative Generalization",
      "url": "https://arxiv.org/abs/2506.18880",
      "bullets": [
        {
          "text": "(1) Exploratory: known problem-solving skills를 같은 도메인이지만 더 어려운 문제에 적용",
          "level": 1
        },
        {
          "text": "(2) Compositional: 독립된 상황에서 습득한 distinct reasoning skills를 new & coherent way로 결합/통합",
          "level": 1
        },
        {
          "text": "(3) Transformative: 익숙한 approaches를 새로운 영역에 unconventionally 적용",
          "level": 1
        },
        {
          "text": "geometry, number theory, algebra 등에 대해 programmatically 생성된 train-test 데이터쌍으로 구성됨",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Skoltech-complexity-aware-fine-tuning",
      "date": "2025-06-W04",
      "year": "2025",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Skoltech",
      "title": "Complexity-aware fine-tuning",
      "url": "https://arxiv.org/abs/2506.21220",
      "bullets": [
        {
          "text": "easy & medium은 fine-tuning, hard는 distill 한 결과가 단순 SFT 결과보다 좋았다고 설명",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Ai2-language-modeling-by-language-models",
      "date": "2025-06-W04",
      "year": "2025",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Ai2",
      "title": "Language Modeling by Language Models",
      "url": "https://arxiv.org/abs/2506.20249",
      "bullets": [
        {
          "text": "multi-agent LLM을 이용해서 proposal stage - code generation - verification에 이르는 research를 simulate",
          "level": 1
        },
        {
          "text": "Ladder of Sacles 접근법을 사용하는 Genesys 시스템을 제안: 제안 → 리뷰 → 검증 → large scale",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Anthropic-desktop-extensions-one-click-mcp-server-installation-for-claude-desktop",
      "date": "2025-06-W04",
      "year": "2025",
      "month": "6",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "Desktop Extensions: One-click MCP server installation for Claude Desktop",
      "url": "https://www.anthropic.com/engineering/desktop-extensions",
      "bullets": [
        {
          "text": "기존 MCP 설치는 ‘개발자 도구 필요, Manual configuration, Dependency 관리, 업데이트 복잡성’ 등의 문제를 지님",
          "level": 1
        },
        {
          "text": ".dxt file download → Claude Desktop open → Click “Install”",
          "level": 1
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Baidu-towards-ai-search-paradigm-1",
      "date": "2025-06-W04",
      "year": "2025",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Baidu",
      "title": "Towards AI Search Paradigm",
      "url": "https://arxiv.org/abs/2506.17188",
      "bullets": [
        {
          "text": "LLM-powered agents를 이용하여 다양한 범위의 정보에 dynamically 접근 (from simple fatual queries to complex multi-stage reasoning tasks)",
          "level": 1
        },
        {
          "text": "query complexity를 평가하고, 문제를 executable plans로 쪼개고, tool usage, task execution, content synthesis로 문제 해결 (MCP)",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "Google-performance-prediction-for-large-systems-via-text-to-text-regression",
      "date": "2025-06-W04",
      "year": "2025",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Google",
      "title": "Performance Prediction for Large Systems via Text-to-Text Regression",
      "url": "https://arxiv.org/abs/2506.21718",
      "bullets": [
        {
          "text": "단 500개의 few-shot examples 만으로 새로운 태스크에 adapt 가능",
          "level": 1
        },
        {
          "text": "encoder 사용, sequence 길이 증가, 모델의 inherent uncertainty quantification 중요성 강조",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-dolphingemma-how-google-ai-is-helping-decode-dolphin-communication",
      "date": "2025-05-W01",
      "year": "2025",
      "month": "5",
      "week": "1",
      "type": "dev",
      "org": "Google",
      "title": "DolphinGemma: How Google AI is helping decode dolphin communication",
      "url": "https://blog.google/technology/ai/dolphingemma/",
      "bullets": [
        {
          "text": "돌고래의 vocalization 구조를 이해하고 dolphin-like sound sequences를 생성하는 모델",
          "level": 0
        },
        {
          "text": "Catacean Hearing Augmentation Telementary (CHAT) 시스템에 구글 픽셀폰 사용 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-introducing-txgemma-open-models-to-improve-therapeutics-development",
      "date": "2025-05-W01",
      "year": "2025",
      "month": "5",
      "week": "1",
      "type": "dev",
      "org": "Google",
      "title": "Introducing TxGemma: Open models to improve therapeutics development",
      "url": "https://developers.googleblog.com/en/introducing-txgemma-open-models-improving-therapeutics-development/",
      "bullets": [
        {
          "text": "전체 discovery process의 therapeutic entities의 properties를 이해하고 예측하도록 학습한 모델들임",
          "level": 0
        },
        {
          "text": "promising targets를 식별하고 clinical trial outcomes까지 예측 가능",
          "level": 0
        },
        {
          "text": "7M 데이터로 학습되었으며 2B, 9B, 27B 사이즈로 구성됨",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "DeepSeek-AI-deepseek-prover-v2-671b",
      "date": "2025-05-W01",
      "year": "2025",
      "month": "5",
      "week": "1",
      "type": "dev",
      "org": "DeepSeek AI",
      "title": "DeepSeek-Prover-V2-671B",
      "url": "https://huggingface.co/deepseek-ai/DeepSeek-Prover-V2-671B",
      "bullets": [
        {
          "text": "DeepSeek-V3를 subgoal decomposition & formalization 에 활용",
          "level": 1
        },
        {
          "text": "이렇게 획득한 데이터를 이용하여 강화학습",
          "level": 1
        },
        {
          "text": "ProverBench: Formalization of AIME and Textbook Problems",
          "level": 0
        },
        {
          "text": "325개의 문제로 구성된 벤치마크 소개",
          "level": 1
        },
        {
          "text": "이중 15개는 AIME competitions의 number theory & algebra questions",
          "level": 1
        },
        {
          "text": "나머지 310개는 curated textbook examples & educational tutorials 로 구성",
          "level": 1
        },
        {
          "text": "7B & 671B 두 사이즈의 모델 공개",
          "level": 0
        },
        {
          "text": "671B 모델은 DeepSeek-V3-Base 에 학습",
          "level": 1
        },
        {
          "text": "7B 모델은 DeepSeek-Prover-V1.5-Base 에 학습 & 32K context window",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Cohere,-Princeton,-Stanford,-Waterloo,-MIT,-Ai2,-Washington-the-leaderboard-illusion",
      "date": "2025-05-W01",
      "year": "2025",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "Cohere, Princeton, Stanford, Waterloo, MIT, Ai2, Washington",
      "title": "The Leaderboard Illusion",
      "url": "https://arxiv.org/abs/2504.20879",
      "bullets": [
        {
          "text": "undisclosed private testing practices가 모델 공개 전 특정 providers에게 유리한 것이라고 지적",
          "level": 1
        },
        {
          "text": "selective disclosure of perfomance results 때문에 Arena가 biased 된다고 설명. 현재는 많은 모델들이 여기에 overfitted 되어 있음을 지적",
          "level": 1
        },
        {
          "text": "proprietary closed models (Google, OpenAI) 는 battles에서 더 높은 비율로 picked 되기 때문에 open-source models 보다 더 많은 data access 가능",
          "level": 0
        },
        {
          "text": "Google & OpenAI 가 각각 19.2% & 20.4%, 나머지 83개 open-weight models가 29.7% 차지하는 수준",
          "level": 1
        },
        {
          "text": "보수적인 추정에도 상대적인 performance gains이 약 112% 수준에 이른다고 설명",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Ai2-olmo-2-1b",
      "date": "2025-05-W01",
      "year": "2025",
      "month": "5",
      "week": "1",
      "type": "dev",
      "org": "Ai2",
      "title": "OLMo 2 1B",
      "url": "https://allenai.org/olmo/release-notes#olmo-2-1b",
      "bullets": [
        {
          "text": "Mid-training에 [OLMo-mix-1124](https://huggingface.co/datasets/allenai/olmo-mix-1124) & [Dolmino-mix-1124](https://huggingface.co/datasets/allenai/dolmino-mix-1124) 를 포함한 4T 토큰 학습",
          "level": 0
        },
        {
          "text": "Post-training에 [Tülu 3 dataset](https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture-0225)의 OLMo-specific variant를 사용하여 SFT",
          "level": 0
        },
        {
          "text": "[olmo-2-0425-1b-preference-mix](https://huggingface.co/datasets/allenai/olmo-2-0425-1b-preference-mix)에 대해 DPO training & 최종적으로 RLVR training 적용",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Renmin-Univ.-deepcritic-deliberate-critique-with-large-language-models",
      "date": "2025-05-W01",
      "year": "2025",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "Renmin Univ.",
      "title": "DeepCritic: Deliberate Critique with Large Language Models",
      "url": "https://arxiv.org/abs/2505.00662",
      "bullets": [
        {
          "text": "본 연구에서는 LLM의 math critique ability에 집중",
          "level": 1
        },
        {
          "text": "math solutions의 각 reasoning step에 대해 의도적으로 critique 할 수 있도록 만드는 2-stage framework 제안",
          "level": 0
        },
        {
          "text": "(1) Qwen2.5-72B-Instruct를 이용하여 4.5K long-form critique를 생성하고 이를 SFT의 seed로 사용",
          "level": 1
        },
        {
          "text": "(2) PRM800K로부터 획득한 existing human-labeled data 또는 Monte Carlo sampling-based correctness estimation으로 automatically annotated 데이터로 fine-tuned 모델을 RL",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Anthropic-claude-can-now-connect-to-your-world",
      "date": "2025-05-W01",
      "year": "2025",
      "month": "5",
      "week": "1",
      "type": "dev",
      "org": "Anthropic",
      "title": "Claude can now connect to your world",
      "url": "https://www.anthropic.com/news/integrations",
      "bullets": [
        {
          "text": "Integrations: Claude가 web & desktop app에 걸친 원격 MCP server 위에 동작",
          "level": 0
        },
        {
          "text": "Jira & Confluence, Zapier, Cloudfalre, Intercom, Asana, Square, Sentry, Paypal, Linear, Plaid 서비스 지원",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "KAIST,-DeepAuto.ai-paper2code-automating-code-generation-from-scientific-papers-in-machine-learning",
      "date": "2025-05-W01",
      "year": "2025",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "KAIST, DeepAuto.ai",
      "title": "Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning",
      "url": "https://arxiv.org/abs/2504.17192",
      "bullets": [
        {
          "text": "PaperCoder: multi-agent LLM framework로, 머신러닝 논문을 functional code repositories로 변환. 세 단계로 동작",
          "level": 0
        },
        {
          "text": "(1) Planning: high-level roadmap 구축, diagram을 포함한 system architecture 설계, file dependencies 식별, configuration files 생성",
          "level": 1
        },
        {
          "text": "(2) Analysis: implementation-specific details를 해석",
          "level": 1
        },
        {
          "text": "(3) Generation: modular, dependency-aware code 생성",
          "level": 1
        },
        {
          "text": "각 단계는 specialized agent에 의해 수행",
          "level": 1
        },
        {
          "text": "생성 이후에는 model-based & human evaluations 수행",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "mem0.ai-mem0-building-production-ready-ai-agents-with-scalable-long-term-memory",
      "date": "2025-05-W01",
      "year": "2025",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "mem0.ai",
      "title": "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory",
      "url": "https://arxiv.org/abs/2504.19413",
      "bullets": [
        {
          "text": "두 개의 시스템으로 구성",
          "level": 0
        },
        {
          "text": "Mem0: dense & language-based memory system",
          "level": 1
        },
        {
          "text": "Mem0g: enhanced version with graph-based memory to model complex relationships",
          "level": 1
        },
        {
          "text": "Mem0은 벤치마크에서 가장 낮은 search & total latencies를 보였고, Mem0g는 다른 graph-based | RAG systems 대비 속도 & 효율성 관점에서 뛰어난 성능을 자랑함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "KAIST,-DeepAuto.ai-universalrag-retrieval-augmented-generation-over-multiple-corpora-with-diverse-modalities-and-granularities",
      "date": "2025-05-W01",
      "year": "2025",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "KAIST, DeepAuto.ai",
      "title": "UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities",
      "url": "https://arxiv.org/abs/2504.20734",
      "bullets": [
        {
          "text": "Modality-aware routing: 매 query마다 적절한 modality를 dynamically select 하는 router",
          "level": 0
        },
        {
          "text": "Granularity-aware retrieval: 각 modality는 granularity levels로 쪼개져 각각의 complexity에 적합한 content를 retrieve",
          "level": 0
        },
        {
          "text": "Flexible routing: training-free (zero-shot GPT-4o prompting) & trained (T5-Large) routers 둘 다 지원",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Amazon-slot-structuring-the-output-of-large-language-models",
      "date": "2025-05-W01",
      "year": "2025",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "Amazon",
      "title": "SLOT: Structuring the Output of Large Language Models",
      "url": "https://arxiv.org/abs/2505.04016",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-perceptionlm-open-access-data-and-models-for-detailed-visual-understanding",
      "date": "2025-05-W02",
      "year": "2025",
      "month": "5",
      "week": "2",
      "type": "paper",
      "org": "Meta",
      "title": "PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding",
      "url": "https://arxiv.org/abs/2504.13180",
      "bullets": [
        {
          "text": "proprietary models로부터의 distillation 없는 training pipelines을 분석하고 large-scale synthetic data를 explore",
          "level": 0
        },
        {
          "text": "2.8M human-labeled fine-grained video question-answer pairs & spatio-temporally grounded video captions",
          "level": 0
        },
        {
          "text": "PLM-VideoBench: video에 대한 ‘what, where, when, how’ 추론 능력을 평가하기 위한 벤치마크 공개",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "NVIDIA-llama-nemotron-efficient-reasoning-models",
      "date": "2025-05-W02",
      "year": "2025",
      "month": "5",
      "week": "2",
      "type": "paper",
      "org": "NVIDIA",
      "title": "Llama-Nemotron: Efficient Reasoning Models",
      "url": "https://arxiv.org/abs/2505.00949",
      "bullets": [
        {
          "text": "Nano (8B), Super (49B), Ultra (253B) 사이즈로 구성되어 있으며, DeepSeek-R1에 준하는 성능이면서도 inference throughput & memory efficiency 뛰어남",
          "level": 0
        },
        {
          "text": "dynamic reasoning toggle을 지원하는 최초의 open-source models",
          "level": 0
        },
        {
          "text": "유저가 직접 standard chat vs. readoning modes 선택 가능",
          "level": 1
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "OpenAI-evolving-openais-structure",
      "date": "2025-05-W02",
      "year": "2025",
      "month": "5",
      "week": "2",
      "type": "dev",
      "org": "OpenAI",
      "title": "Evolving OpenAI’s structure",
      "url": "https://openai.com/index/evolving-our-structure",
      "bullets": [
        {
          "text": "이를 통해 더 큰 규모의 투자를 받아 AGI 개발에 전념하겠다고 함",
          "level": 0
        },
        {
          "text": "이후 capable models를 오픈소스화할 예정",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Alibaba-qwen-agent",
      "date": "2025-05-W02",
      "year": "2025",
      "month": "5",
      "week": "2",
      "type": "dev",
      "org": "Alibaba",
      "title": "Qwen-Agent",
      "url": "https://github.com/QwenLM/Qwen-Agent",
      "bullets": [
        {
          "text": "code execution, document reading, web browsing, RAG workflows 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Beijing-Univ.-rag-mcp-mitigating-prompt-bloat-in-llm-tool-selection-via-retrieval-augmented-generation",
      "date": "2025-05-W02",
      "year": "2025",
      "month": "5",
      "week": "2",
      "type": "paper",
      "org": "Beijing Univ.",
      "title": "RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation",
      "url": "https://arxiv.org/abs/2505.03275",
      "bullets": [
        {
          "text": "RAG-MCP: 주어진 query와 관련성이 가장 높은 MCP(s)를 semantically retrieve",
          "level": 0
        },
        {
          "text": "selected tool descriptions만을 모델에 전달함으로써 prompt size를 줄이고 decision-making을 간소화 함",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Anthropic-reasoning-models-dont-always-say-what-they-think",
      "date": "2025-05-W02",
      "year": "2025",
      "month": "5",
      "week": "2",
      "type": "paper",
      "org": "Anthropic",
      "title": "Reasoning Models Don't Always Say What They Think",
      "url": "https://arxiv.org/abs/2505.05410",
      "bullets": [
        {
          "text": "프롬프트에 제시된 6가지 힌트를 활용해 CoT의 신뢰도를 평가",
          "level": 0
        },
        {
          "text": "CoT를 이용한 test-time monitoring은 unexpected behaviors를 탐지하는데 전혀 쓸모가 없다고 주장",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Mistral-AI-medium-is-the-new-large",
      "date": "2025-05-W02",
      "year": "2025",
      "month": "5",
      "week": "2",
      "type": "dev",
      "org": "Mistral AI",
      "title": "Medium is the new large.",
      "url": "https://mistral.ai/news/mistral-medium-3",
      "bullets": [
        {
          "text": "private, high-context, domain-specific use cases에 해당하는 enterprise 활용도 가능",
          "level": 0
        },
        {
          "text": "custom post-training & continuous pretraining 지원",
          "level": 1
        },
        {
          "text": "finance, energy, healthcare 도메인에서 사용",
          "level": 1
        },
        {
          "text": "self-hosted | virtual private cloud setups 에서 사용 가능",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Zed:-The-Fastest-AI-Code-Editor-zed-the-fastest-ai-code-editor",
      "date": "2025-05-W02",
      "year": "2025",
      "month": "5",
      "week": "2",
      "type": "dev",
      "org": "Zed: The Fastest AI Code Editor",
      "title": "Zed: The Fastest AI Code Editor",
      "url": "https://zed.dev/blog/fastest-ai-code-editor",
      "bullets": [
        {
          "text": "Privacy & Security 모드가 default. 원한다면 feedback 제공도 당연히 가능.",
          "level": 0
        },
        {
          "text": "Claude, OpenAI, Google 등 API는 당연히 지원하고, 본인 computing power를 사용하는 ollama 기반의 모델들도 사용할 수 있음",
          "level": 0
        },
        {
          "text": "ollama 사용 시에 미지원되는 기능은 [Edit Predictions](https://zed.dev/blog/edit-prediction) 뿐이라고 함",
          "level": 1
        },
        {
          "text": "MCP 지원",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Barbin-Institute-perception-reason-think-and-plan-a-survey-on-large-multimodal-reasoning-models",
      "date": "2025-05-W02",
      "year": "2025",
      "month": "5",
      "week": "2",
      "type": "paper",
      "org": "Barbin Institute",
      "title": "Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models",
      "url": "https://arxiv.org/abs/2505.04921",
      "bullets": [
        {
          "text": "Multimodal reasoning은 modular, perception-driven pipelines에서부터 unified, language-centric frameworks로 발전하여 일관성 있는 cross-modal understanding 능력을 갖추게 됨",
          "level": 0
        },
        {
          "text": "instruction tuning & reinforcement learning 을 통해 크게 발전했으나, 아직까지 omni-modal generalization, reasoning depth, agentic behavior 에서 한계 존재",
          "level": 0
        },
        {
          "text": "발전 흐름에 따라, task-specific modules, Multimodal CoT (MCoT), native large multimodal reasoning models (N-LMRMs) 순으로 survey 결과 정리",
          "level": 0
        }
      ],
      "tags": [
        "multimodal",
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "Univ.-of-Chicago-mitigating-memorization-in-language-models",
      "date": "2025-05-W02",
      "year": "2025",
      "month": "5",
      "week": "2",
      "type": "paper",
      "org": "Univ. of Chicago",
      "title": "Mitigating Memorization In Language Models",
      "url": "https://arxiv.org/abs/2410.02159",
      "bullets": [
        {
          "text": "언어 모델의 memorization 현상을 mitigate 하기 위한 방법론들 제시",
          "level": 0
        },
        {
          "text": "3 regularizer-based, 3 finetuning-based, 11 machine unlearning-based",
          "level": 1
        },
        {
          "text": "regularizer-based는 느리고 효과 x, finetuning은 효과 좋지만 비쌈, machine unlearning이 가장 좋은 방법론 → 그중에서도 BalancedSubnet가 제일 좋음",
          "level": 1
        },
        {
          "text": "TinyMem: small, computationally-efficient LMs for the rapid development and evaluation of memorization-mitigation methods",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Alibaba-zerosearch-incentivize-the-search-capability-of-llms-without-searching",
      "date": "2025-05-W02",
      "year": "2025",
      "month": "5",
      "week": "2",
      "type": "paper",
      "org": "Alibaba",
      "title": "ZeroSearch: Incentivize the Search Capability of LLMs without Searching",
      "url": "https://alibaba-nlp.github.io/ZeroSearch/",
      "bullets": [
        {
          "text": "policy model은 search APIs 대신 simulated documents 를 사용하여 학습",
          "level": 0
        },
        {
          "text": "언어모델을 사용하여 매 쿼리마다 20개 문서 생성",
          "level": 1
        },
        {
          "text": "최종 답변 퀄리티를 기준으로 reward signals 사용",
          "level": 1
        },
        {
          "text": "3B, 7B, 14B 모델들 대상으로 학습하여 multi-step QA 능력 향상",
          "level": 0
        },
        {
          "text": "Learning with curriculum rollout: 학습이 진행될수록 retrieval noise 증가",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Shanghai-Jiao-Tong-Univ.-a-survey-of-ai-agent-protocols",
      "date": "2025-05-W02",
      "year": "2025",
      "month": "5",
      "week": "2",
      "type": "paper",
      "org": "Shanghai Jiao Tong Univ.",
      "title": "A Survey of AI Agent Protocols",
      "url": "https://arxiv.org/abs/2504.16736",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft,-Salesforce-llms-get-lost-in-multi-turn-conversation",
      "date": "2025-05-W03",
      "year": "2025",
      "month": "5",
      "week": "3",
      "type": "paper",
      "org": "Microsoft, Salesforce",
      "title": "LLMs Get Lost In Multi-Turn Conversation",
      "url": "https://arxiv.org/abs/2505.06120",
      "bullets": [
        {
          "text": "top open- & closed-weight LLMs가 multi-turn에서 single-turn 대비 큰 성능 하락폭을 보여주었다고 보고",
          "level": 0
        },
        {
          "text": "200,000+ simulated conversations는 aptitude의 사소한 문제 & unreliability의 증가, 두 가지로 구분 가능",
          "level": 0
        },
        {
          "text": "결론: when LLMs take a wrong turn in a conversation, they get lost and do not recover",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Texas-A&M-Univ.-litelmguard-seamless-and-lightweight-on-device-prompt-filtering-for-safeguarding-small-language-models-against-quantization-induced-risks-and-vulnerabilities",
      "date": "2025-05-W03",
      "year": "2025",
      "month": "5",
      "week": "3",
      "type": "paper",
      "org": "Texas A&M Univ.",
      "title": "LiteLMGuard: Seamless and Lightweight On-Device Prompt Filtering for Safeguarding Small Language Models against Quantization-induced Risks and Vulnerabilities",
      "url": "https://arxiv.org/abs/2505.05619",
      "bullets": [
        {
          "text": "LiteLMGuard: quantized SLMs를 위한 real-time, prompt-level defense로 on-device prompt guard 라고 설명",
          "level": 0
        },
        {
          "text": "모델의 아키텍쳐와 상관없이 적용 가능하다고 주장",
          "level": 1
        },
        {
          "text": "여러 DL models를 Answerable-or-Not 데이터셋으로 학습한 결과 ELECTRA를 후보로 선정",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Sakana-AI-continuous-thought-machines",
      "date": "2025-05-W03",
      "year": "2025",
      "month": "5",
      "week": "3",
      "type": "dev",
      "org": "Sakana AI",
      "title": "Continuous Thought Machines",
      "url": "https://sakana.ai/ctm/",
      "bullets": [
        {
          "text": "뉴런 수준의 timing information을 사용하여 기존보다 보다 복잡한 nueral behavior & decision making process를 이해할 수 있게 되었다고 함",
          "level": 0
        },
        {
          "text": "핵심 중 하나는 모델이 step-by-step으로 “think” 할 수 있게 되어 추론 과정이 보다 interpretable & human-like 해졌다고 설명",
          "level": 0
        },
        {
          "text": "[CTM publication](https://pub.sakana.ai/ctm/)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "CWI-how-well-do-llms-reason-over-tabular-data-really",
      "date": "2025-05-W03",
      "year": "2025",
      "month": "5",
      "week": "3",
      "type": "paper",
      "org": "CWI",
      "title": "How well do LLMs reason over tabular data, really?",
      "url": "https://arxiv.org/abs/2505.07453",
      "bullets": [
        {
          "text": "언어 모델의 tabular queries에 대한 performance를 어떻게 evaluate 할 수 있는가?",
          "level": 0
        },
        {
          "text": "multiple-choice prompt 평가 & BERT-score 대신 LLM-as-a-Judge 신뢰도가 높다고 설명",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "ByteDance-seed15-vl-technical-report",
      "date": "2025-05-W03",
      "year": "2025",
      "month": "5",
      "week": "3",
      "type": "paper",
      "org": "ByteDance",
      "title": "Seed1.5-VL Technical Report",
      "url": "https://arxiv.org/abs/2505.07062",
      "bullets": [
        {
          "text": "532M-parameter encoder, MoE LLM (20B active params)",
          "level": 0
        },
        {
          "text": "GUI control & gameplay 등 agent-centric tasks에서 뛰어난 성능 보인다고 설명",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Tsinghua-absolute-zero-reinforced-self-play-reasoning-with-zero-data",
      "date": "2025-05-W03",
      "year": "2025",
      "month": "5",
      "week": "3",
      "type": "paper",
      "org": "Tsinghua",
      "title": "Absolute Zero: Reinforced Self-play Reasoning with Zero Data",
      "url": "https://arxiv.org/abs/2505.03335",
      "bullets": [
        {
          "text": "Absolute Zero: external data 의존하지 않고 single model 스스로 own learning progress를 maximize & improve",
          "level": 0
        },
        {
          "text": "Absolute Zero Reasoner (AZR): code executor를 사용하여 training curriculum & reasoning ability를 self-evolve 하는 system",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "OpenAI-introducing-healthbench",
      "date": "2025-05-W03",
      "year": "2025",
      "month": "5",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing HealthBench",
      "url": "https://openai.com/index/healthbench",
      "bullets": [
        {
          "text": "각 case는 dialogue, prompt, model output, rubric이 JSON format으로 구성됨",
          "level": 0
        },
        {
          "text": "research-use license로 Dataset & grader code 사용 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Salesforce-blip3-o-a-family-of-fully-open-unified-multimodal-models-architecture-training-and-dataset",
      "date": "2025-05-W03",
      "year": "2025",
      "month": "5",
      "week": "3",
      "type": "paper",
      "org": "Salesforce",
      "title": "BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset",
      "url": "https://arxiv.org/abs/2505.09568",
      "bullets": [
        {
          "text": "→ training efficiency & improved generative quality",
          "level": 1
        },
        {
          "text": "image understanding, 이어서 image generation에 대해 사전학습하는 학습 방식이 효과적이었다고 설명",
          "level": 0
        },
        {
          "text": "GPT-4o를 이용하여 high-quality instruction tuning dataset BLIP3o-60k 데이터셋 제작",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "ByteDance-deerflow",
      "date": "2025-05-W03",
      "year": "2025",
      "month": "5",
      "week": "3",
      "type": "dev",
      "org": "ByteDance",
      "title": "DeerFlow",
      "url": "https://deerflow.tech",
      "bullets": [
        {
          "text": "Coordinator, Planner, Reporter 등의 agent들로 구성되는 시스템",
          "level": 0
        },
        {
          "text": "LangChain, LangGraph로 빌드되어 있어 Human-in-the-loop이 지원되며, 최근 핫한 Podcast generation도 가능 (생성된 reports 기준으로)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Google-alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms",
      "date": "2025-05-W03",
      "year": "2025",
      "month": "5",
      "week": "3",
      "type": "dev",
      "org": "Google",
      "title": "AlphaEvolve: A Gemini-powered coding agent for designing advanced algorithms",
      "url": "https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms",
      "bullets": [
        {
          "text": "AlphaTensor 모델에서 single function call을 넘어 entire codebase 까지 커버할 수 있도록 함",
          "level": 0
        },
        {
          "text": "Gemini Flash로 빠르게 idea generation & Gemini Pro로 deeper analysis",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "LangChain-open-agent-platform",
      "date": "2025-05-W03",
      "year": "2025",
      "month": "5",
      "week": "3",
      "type": "dev",
      "org": "LangChain",
      "title": "open-agent-platform",
      "url": "https://github.com/langchain-ai/open-agent-platform",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Chinese-Academy-of-sciences-learning-when-to-think-shaping-adaptive-reasoning-in-r1-style-models-via-multi-stage-rl",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "Chinese Academy of sciences",
      "title": "Learning When to Think: Shaping Adaptive Reasoning in R1-Style Models via Multi-Stage RL",
      "url": "https://arxiv.org/abs/2505.10832",
      "bullets": [
        {
          "text": "간단한 생략 기호 “…”를 프롬프트에 포함하는 것만으로도 꽤나 긍정적인 영향을 줄 수 있다고 언급",
          "level": 0
        },
        {
          "text": "AutoThink: stage-wise reward shaping을 통해 reasoning policies를 optimize하는 multi-stage reinforcement learning (RL) 프레임워크",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Singapore,-Tsinghua,-Salesforce-beyond-aha-toward-systematic-meta-abilities-alignment-in-large-reasoning-models",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "Singapore, Tsinghua, Salesforce",
      "title": "Beyond 'Aha!': Toward Systematic Meta-Abilities Alignment in Large Reasoning Models",
      "url": "https://arxiv.org/abs/2505.10554",
      "bullets": [
        {
          "text": "이를 해결하기 위해 prompts & 우연한 ‘aha moments’를 넘어서, 모델이 세 가지 meta-abilities에 align 되도록 학습 - deduction, induction, abduction",
          "level": 0
        },
        {
          "text": "three-stage pipeline: individual alignment, parameter-space merging, domain-specific reinforcement learning",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "KAIST-system-prompt-optimization-with-meta-learning",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "KAIST",
      "title": "System Prompt Optimization with Meta-Learning",
      "url": "https://arxiv.org/abs/2505.09666",
      "bullets": [
        {
          "text": "meta-learning framework: system prompt 뿐만 아니라 user prompts도 업데이트",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "HuggingFace-welcome-to-the-model-context-protocol-mcp-course",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "HuggingFace",
      "title": "Welcome to the 🤗 Model Context Protocol (MCP) Course",
      "url": "https://huggingface.co/learn/mcp-course/unit0/introduction",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Alibaba-qwen3-technical-report",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "Alibaba",
      "title": "Qwen3 Technical Report",
      "url": "https://arxiv.org/abs/2505.09388",
      "bullets": [
        {
          "text": "thinking mode & non-thinking mode 통합. 유저 쿼리나 chat template에 따른 dynamic mode swithcing",
          "level": 0
        },
        {
          "text": "thinking budget mechanism을 도입하여 유저가 추론 시 computational resources를 adaptive하게 할당함으로써 태스크 복잡도에 따른 모델 퍼포먼스와 latency 간 균형을 맞출 수 있다고 설명",
          "level": 0
        },
        {
          "text": "기존 29개 → 119개 언어 및 방언 지원, Apache 2.0 라이센스",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Tsinghua-adaptthink-reasoning-models-can-learn-when-to-think",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "Tsinghua",
      "title": "AdaptThink: Reasoning Models Can Learn When to Think",
      "url": "https://arxiv.org/abs/2505.13417",
      "bullets": [
        {
          "text": "AdaptThink: 문제 난이도에 따라 최적의 thinking mode를 reasoning model이 선택하도록 가르치는 RL 알고리즘",
          "level": 0
        },
        {
          "text": "constrained optimization objective: overall performance를 유지하면서도 NoThinking을 선택하도록 함",
          "level": 1
        },
        {
          "text": "sampling strategy: on-policy training 동안에 Thinking & No-Thinking samples의 균형을 맞춤",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "NUS-thinkless-llm-learns-when-to-think",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "NUS",
      "title": "Thinkless: LLM Learns When to Think",
      "url": "https://arxiv.org/abs/2505.13379",
      "bullets": [
        {
          "text": "RL 패러다임으로 학습되고 <short>, <think> 두 개의 control tokens를 사용",
          "level": 0
        },
        {
          "text": "Decoupled Group Relative Policy Optimization (DeGROP) 알고리즘",
          "level": 0
        },
        {
          "text": "두 개의 learning objective: control token loss & response loss",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Southern-California-mapping-the-minds-of-llms-a-graph-based-analysis-of-reasoning-llm",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "Southern California",
      "title": "Mapping the Minds of LLMs: A Graph-Based Analysis of Reasoning LLM",
      "url": "https://arxiv.org/abs/2505.13890",
      "bullets": [
        {
          "text": "(1) long & verbose CoT outputs를 semantically coherent reasoning steps로 만들기",
          "level": 0
        },
        {
          "text": "(2) 각 스텝 간의 contextual & logical dependencies 를 이용하여 directed reasoning graphs 구축하기",
          "level": 0
        },
        {
          "text": "exploration density, branching, convergence ratios 등과 같은 structural propreties가 reasoning accuracy와 강한 상관관계를 갖고 있다고 설명함",
          "level": 0
        },
        {
          "text": "RLMs 들이 few-shot prompting에 오히려 약세를 보이는 등의 counterintuitive 현상에 대한 의문으로부터 출발한 연구 → prompting strategies의 중요성 강조",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Google-gemini-25-our-most-intelligent-models-are-getting-even-better",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "Google",
      "title": "Gemini 2.5: Our most intelligent models are getting even better",
      "url": "https://blog.google/technology/google-deepmind/google-gemini-updates-io-2025",
      "bullets": [
        {
          "text": "풀스택 개발 태스크에 대해 WebDev Arena에서 1415 ELO 스코어 달성",
          "level": 0
        },
        {
          "text": "두 개의 목소리로 native audio generation 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-build-with-jules-your-asynchronous-coding-agent",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "Google",
      "title": "Build with Jules, your asynchronous coding agent",
      "url": "https://blog.google/technology/google-labs/jules",
      "bullets": [
        {
          "text": "각 codebase를 Google의 Cloud virtual machine (VM) 에 복사하여 프로젝트 전체를 이해한다고 설명",
          "level": 0
        },
        {
          "text": "Works on real codebase, Parallel execution, Visible workflow, User steerability, Audio summaries 등을 특징으로 삼고 있음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "ByteDance-emerging-properties-in-unified-multimodal-pretraining",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "ByteDance",
      "title": "Emerging Properties in Unified Multimodal Pretraining",
      "url": "https://arxiv.org/abs/2505.14683",
      "bullets": [
        {
          "text": "large-scale interleaved text, image, video, web data를 수 trillion tokens으로 학습한 unified & decoder-only model",
          "level": 0
        },
        {
          "text": "free-form image manipulation, future frame prediction, 3D manipulation, word navigation 과 같은 advanced multimodal reasoning 능력을 보유",
          "level": 0
        }
      ],
      "tags": [
        "multimodal",
        "reasoning"
      ]
    },
    {
      "id": "Jiaotong-University-deliberation-on-priors-trustworthy-reasoning-of-large-language-models-on-knowledge-graphs",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "Jiaotong University",
      "title": "Deliberation on Priors: Trustworthy Reasoning of Large Language Models on Knowledge Graphs",
      "url": "https://arxiv.org/abs/2505.15210",
      "bullets": [
        {
          "text": "supervised fine-tuning & Kahneman-Tversky optimization 조합을 통해 structural priors를 LLM에 통합하는 progressive knowledge distillation strategy",
          "level": 0
        },
        {
          "text": "reasoning introspection strategey: LLM이 추출된 constraint priors 기반의 refined reasoning verfication를 수행할 수 있도록 guide",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Mistral-devstral",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "Mistral",
      "title": "Devstral",
      "url": "https://mistral.ai/news/devstral",
      "bullets": [
        {
          "text": "현실적인 프로그래밍 문제를 해결하기 위해, 즉 GitHub issuses를 풀기 위해 학습된 모델",
          "level": 0
        },
        {
          "text": "RTX 4090 or Mac with 32GB RAM에서 구동 가능한 정도로 가벼움",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-DeepMind-gemini-diffusion",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "Gemini Diffusion",
      "url": "https://deepmind.google/models/gemini-diffusion",
      "bullets": [
        {
          "text": "random noise를 coherent output으로 변경하여 text or code를 생성하는 모델",
          "level": 0
        },
        {
          "text": "rapid response, more coherent text, iterative refinement 등을 특징으로 설명",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-DeepMind-gemma-3n",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "Gemma 3n",
      "url": "https://deepmind.google/models/gemma/gemma-3n",
      "bullets": [
        {
          "text": "삼성 갤럭시 울트라에서 초당 446 토큰 처리",
          "level": 1
        },
        {
          "text": "Mix ‘n’ match architecture는 small & large models를 switch 하는 데 도움을 줌",
          "level": 0
        },
        {
          "text": "Chatbot Arena에서 1283점을 기록하며 Claude 3.7 Sonnet의 뒤를 이음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "ServiceNow-augmenting-llm-reasoning-with-dynamic-notes-writing-for-complex-qa",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "ServiceNow",
      "title": "Augmenting LLM Reasoning with Dynamic Notes Writing for Complex QA",
      "url": "https://arxiv.org/abs/2505.16293",
      "bullets": [
        {
          "text": "NotesWriting: 매 스텝마다 retrieved documents를 concise & relevant notes 로 변경하는 연구",
          "level": 0
        },
        {
          "text": "LLM의 effective context length를 간접적으로 높여 더 큰 크기의 input text를 효율적으로 처리할 수 있음",
          "level": 0
        },
        {
          "text": "다른 RAG 방법론들과 integrated 가능한 framework",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Yonsei,-CMU-web-shepherd-advancing-prms-for-reinforcing-web-agents",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "Yonsei, CMU",
      "title": "Web-Shepherd: Advancing PRMs for Reinforcing Web Agents",
      "url": "https://arxiv.org/abs/2505.15277",
      "bullets": [
        {
          "text": "WebPRM Collection: 40K step-level perference pairs & annotated checklists",
          "level": 0
        },
        {
          "text": "WebReward Bench: PRM 평가를 위한 meta-evaluation 벤치마크",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-nanovlm-the-simplest-repository-to-train-your-vlm-in-pure-pytorch",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "HuggingFace",
      "title": "nanoVLM: The simplest repository to train your VLM in pure PyTorch",
      "url": "https://huggingface.co/blog/nanovlm",
      "bullets": [
        {
          "text": "단일 GPU에서 학습 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "UIUC-language-specific-knowledge-do-models-know-better-in-x-than-in-english",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "UIUC",
      "title": "Language Specific Knowledge: Do Models Know Better in X than in English?",
      "url": "https://arxiv.org/abs/2505.14990",
      "bullets": [
        {
          "text": "언어 모델도 그런 경향이 있다면 reasoning 능력을 더 끌어올릴 수 있지 않을까? 라는 접근",
          "level": 1
        },
        {
          "text": "Language Specific Knowledge (LSK): ethnic cultures는 언어에 따라 발전하는 경향이 있고, 이에 따라 culture-specific datasets에 대해 실험해본 결과 가정이 옳았다고 설명함",
          "level": 0
        },
        {
          "text": "LSKExtractor: language-specific knowledge의 존재를 확인할 수 있는 벤치마크 공개",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Meta-j1-incentivizing-thinking-in-llm-as-a-judge-via-reinforcement-learning",
      "date": "2025-05-W04",
      "year": "2025",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "Meta",
      "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning",
      "url": "https://arxiv.org/abs/2505.10320",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Anthropic-introducing-claude-4",
      "date": "2025-05-W05",
      "year": "2025",
      "month": "5",
      "week": "5",
      "type": "dev",
      "org": "Anthropic",
      "title": "Introducing Claude 4",
      "url": "https://www.anthropic.com/news/claude-4",
      "bullets": [
        {
          "text": "long thought process에 대한 요약 제시",
          "level": 0
        },
        {
          "text": "developer mode에서는 unsummarized reasoning 확인 가능",
          "level": 0
        },
        {
          "text": "VS Code나 JetBrains에서 사용 가능한 새로운 extension 출시",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "ByteDance-bagel-the-open-source-unified-multimodal-model",
      "date": "2025-05-W05",
      "year": "2025",
      "month": "5",
      "week": "5",
      "type": "dev",
      "org": "ByteDance",
      "title": "BAGEL: The Open-Source Unified Multimodal Model",
      "url": "https://bagel-ai.org",
      "bullets": [
        {
          "text": "multiple expert networks & two image encoders 사용",
          "level": 0
        },
        {
          "text": "7B 사이즈의 모델로, 4 x 16GB GPU에서 run 또는 LoRA 기반 학습 가능",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Tokyo-mmlu-prox-a-multilingual-benchmark-for-advanced-large-language-model-evaluation",
      "date": "2025-05-W05",
      "year": "2025",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "Tokyo",
      "title": "MMLU-ProX: A Multilingual Benchmark for Advanced Large Language Model Evaluation",
      "url": "https://mmluprox.github.io/",
      "bullets": [
        {
          "text": "각 언어당 658개의 질문들을 포함하는 lite version 제공",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Cambridge,-UCL,-Google-visual-planning-lets-think-only-with-images",
      "date": "2025-05-W05",
      "year": "2025",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "Cambridge, UCL, Google",
      "title": "Visual Planning: Let's Think Only with Images",
      "url": "https://arxiv.org/abs/2505.11409",
      "bullets": [
        {
          "text": "Visual Planning: text 없이 순수하게 visual representation으로 reasoning",
          "level": 0
        },
        {
          "text": "step-by-step inference를 encode 하는 sequences of images 를 통해 executed",
          "level": 1
        },
        {
          "text": "Visual Planning via Reinforcement Learning (VPRL): large vision models를 GRPO로 post-training 하는 RL 프레임워크",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal",
        "reasoning"
      ]
    },
    {
      "id": "Mistral-AI-build-ai-agents-with-the-mistral-agents-api",
      "date": "2025-05-W05",
      "year": "2025",
      "month": "5",
      "week": "5",
      "type": "dev",
      "org": "Mistral AI",
      "title": "Build AI agents with the Mistral Agents API",
      "url": "https://mistral.ai/news/agents-api",
      "bullets": [
        {
          "text": "MCP tools integration, Agent Orchestration",
          "level": 0
        },
        {
          "text": "사용성이 좋고 개발 용이성이 뛰어난 형태의 API가 많이 공개되는 추세",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Mistral-AI-codestral-embed",
      "date": "2025-05-W05",
      "year": "2025",
      "month": "5",
      "week": "5",
      "type": "dev",
      "org": "Mistral AI",
      "title": "Codestral Embed",
      "url": "https://mistral.ai/news/codestral-embed",
      "bullets": [
        {
          "text": "binary, int8, float32 자료형 지원",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Resemble-AI-chatterbox",
      "date": "2025-05-W05",
      "year": "2025",
      "month": "5",
      "week": "5",
      "type": "dev",
      "org": "Resemble AI",
      "title": "chatterbox",
      "url": "https://github.com/resemble-ai/chatterbox",
      "bullets": [
        {
          "text": "emotion exaggeration control 지원, watermarked outputs",
          "level": 0
        },
        {
          "text": "[Hugging Face Gradio app](https://huggingface.co/spaces/ResembleAI/Chatterbox) 에서 테스트 가능",
          "level": 0
        },
        {
          "text": "0.5B Llama backbone, 0.5M hours of cleaned data로 학습",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Shanghai-AI-Lab,-Tsinghua,-UIUC-the-entropy-mechanism-of-reinforcement-learning-for-reasoning-language-models",
      "date": "2025-05-W05",
      "year": "2025",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "Shanghai AI Lab, Tsinghua, UIUC",
      "title": "The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models",
      "url": "https://arxiv.org/abs/2505.22617",
      "bullets": [
        {
          "text": "policy entropy가 초기 학습 단계에서 급격히 감소하여 policy model이 overly confident 하게 되는 현상을 뜻함 (성능 포화)",
          "level": 1
        },
        {
          "text": "이로 인해 exploratory ability가 diminish 하게 됨",
          "level": 1
        },
        {
          "text": "$R = -a \\cdot \\exp(H) + b$",
          "level": 0
        },
        {
          "text": "policy entropy의 변화는 action probability & logits 변화 사이의 covariance에 의한 것이라고 설명",
          "level": 0
        },
        {
          "text": "entropy collapse를 방지하기 위해 공분산이 높은 토큰의 업데이트를 제한하는 두 가지 방법 (Clip-Cov, KL-Cov) 제안",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Utah,-Washington-what-has-been-lost-with-synthetic-evaluation",
      "date": "2025-05-W05",
      "year": "2025",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "Utah, Washington",
      "title": "What Has Been Lost with Synthetic Evaluation?",
      "url": "https://arxiv.org/abs/2505.22830",
      "bullets": [
        {
          "text": "CondaQA: negation reasoning에 대한 평가",
          "level": 1
        },
        {
          "text": "DROP: quantities reasoning 평가",
          "level": 1
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Google-sufficient-context-a-new-lens-on-retrieval-augmented-generation-systems",
      "date": "2025-05-W05",
      "year": "2025",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "Google",
      "title": "Sufficient Context: A New Lens on Retrieval Augmented Generation Systems",
      "url": "https://arxiv.org/abs/2411.06037",
      "bullets": [
        {
          "text": "성능이 뛰어난 모델들은 context가 충분할 때 답변을 잘하지만 그렇지 않을 때에 답변을 abstain 하지 않고 틀린 답변을 반환하는 경우가 있음",
          "level": 0
        },
        {
          "text": "그러나 성능이 낮은 모델들은 context가 충분할 때조차 hallucination 또는 incorrect answers 반환하는 경우 있음",
          "level": 0
        },
        {
          "text": "RAG 시스템을 위해 새로운 selective generation method를 제안하여 충분한 context information을 더 잘 활용할 수 있도록 함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Apple-interleaved-reasoning-for-large-language-models-via-reinforcement-learning",
      "date": "2025-05-W05",
      "year": "2025",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "Apple",
      "title": "Interleaved Reasoning for Large Language Models via Reinforcement Learning",
      "url": "https://arxiv.org/abs/2505.19640",
      "bullets": [],
      "tags": []
    },
    {
      "id": "UC-San-Diego-large-language-models-pass-the-turing-test",
      "date": "2025-04-W01",
      "year": "2025",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "UC San Diego",
      "title": "Large Language Models Pass the Turing Test",
      "url": "https://arxiv.org/abs/2503.23674",
      "bullets": [
        {
          "text": "GPT-4o 모델의 경우, 인간 페르소나를 부여했을 때 인간 상대로 73%의 win rate를 기록",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "AI2-introducing-codescientist-a-step-toward-automated-scientific-discovery",
      "date": "2025-04-W01",
      "year": "2025",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "AI2",
      "title": "Introducing CodeScientist: A step toward automated scientific discovery",
      "url": "https://allenai.org/blog/codescientist",
      "bullets": [
        {
          "text": "전체 프로세스 내에서 Ideation, Planning, Experiment, Reporting, Meta-analysis 수행",
          "level": 0
        },
        {
          "text": "아직까지 사람의 의사결정이 중간에 개입되어야 한다는 한계가 있지만 빠른 속도로 발전하고 있다는 인상을 줌 (Sakana AI의 것도 그렇고..)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-yourbench-a-dynamic-benchmark-generation-framework",
      "date": "2025-04-W01",
      "year": "2025",
      "month": "4",
      "week": "1",
      "type": "dev",
      "org": "HuggingFace",
      "title": "YourBench: A Dynamic Benchmark Generation Framework",
      "url": "https://github.com/huggingface/yourbench",
      "bullets": [
        {
          "text": "Scalable & Structured: Seamlessly handles ingestion, summarization, and multi-hop chunking for large or specialized datasets.",
          "level": 0
        },
        {
          "text": "Zero-Shot Focus: Emulates real-world usage scenarios by creating fresh tasks that guard against memorized knowledge.",
          "level": 0
        },
        {
          "text": "Extensible: Out-of-the-box pipeline stages (ingestion, summarization, question generation), plus an easy plugin mechanism to accommodate custom models or domain constraints.",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "National-University-of-Singapore-judgelrm-large-reasoning-models-as-a-judge",
      "date": "2025-04-W01",
      "year": "2025",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "National University of Singapore",
      "title": "JudgeLRM: Large Reasoning Models as a Judge",
      "url": "https://arxiv.org/abs/2504.00050",
      "bullets": [
        {
          "text": "SFT performance gains & reasoning-demanindg samples의 비율 간의 음의 상관관계 확인",
          "level": 0
        },
        {
          "text": "JudgeLRM: judge-wise, outcome-driven rewards 향으로 RL을 적용한 judgement-oriented LLMs family",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "OpenAI-openai-academy",
      "date": "2025-04-W01",
      "year": "2025",
      "month": "4",
      "week": "1",
      "type": "dev",
      "org": "OpenAI",
      "title": "OpenAI Academy",
      "url": "https://academy.openai.com/",
      "bullets": [
        {
          "text": "workshops & live events 등도 진행",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Meta-multi-token-attention",
      "date": "2025-04-W01",
      "year": "2025",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "Meta",
      "title": "Multi-Token Attention",
      "url": "https://arxiv.org/abs/2504.00927",
      "bullets": [
        {
          "text": "Multi-Token Attention (MTA): LLM이 여러 개의 query & key vectors에 대해 attention weights를 condition 하는 어텐션 기법 제안",
          "level": 0
        },
        {
          "text": "queries, keys, heads에 대해 convolution 적용",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "OpenAI-paperbench-evaluating-ais-ability-to-replicate-ai-research",
      "date": "2025-04-W01",
      "year": "2025",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "OpenAI",
      "title": "PaperBench: Evaluating AI's Ability to Replicate AI Research",
      "url": "https://arxiv.org/abs/2504.01848",
      "bullets": [
        {
          "text": "Claude 3.5 Sonnet이 21.0% 스코어를 기록했으나 인간 ML PhD는 41.4%를 기록",
          "level": 0
        },
        {
          "text": "평가를 수행하는 것도 LLM임",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Anthropic-introducing-claude-for-education",
      "date": "2025-04-W01",
      "year": "2025",
      "month": "4",
      "week": "1",
      "type": "dev",
      "org": "Anthropic",
      "title": "Introducing Claude for Education",
      "url": "https://www.anthropic.com/news/introducing-claude-for-education",
      "bullets": [
        {
          "text": "Learning mode: 학생들에게 정답을 바로 알려주기보다는 critical thinking skills를 develop 할 수 있도록 reasoning process를 가이드",
          "level": 0
        },
        {
          "text": "Socratic questioning (결론을 뒷받침하는 근거는 무엇인가?), 핵심 개념 강조 등의 특징",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Mila,-Nanyang,-MS,-…-advances-and-challenges-in-foundation-agents-from-brain-inspired-intelligence-to-evolutionary-collaborative-and-safe-systems",
      "date": "2025-04-W01",
      "year": "2025",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "Mila, Nanyang, MS, …",
      "title": "Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems",
      "url": "https://arxiv.org/abs/2504.01990",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Oxford,-NUS,-DeepMind-why-do-llms-attend-to-the-first-token",
      "date": "2025-04-W01",
      "year": "2025",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "Oxford, NUS, DeepMind",
      "title": "Why do LLMs attend to the first token?",
      "url": "https://arxiv.org/abs/2504.02732",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Salesforce-apigen-mt-agentic-pipeline-for-multi-turn-data-generation-via-simulated-agent-human-interplay",
      "date": "2025-04-W02",
      "year": "2025",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "Salesforce",
      "title": "APIGen-MT: Agentic Pipeline for Multi-Turn Data Generation via Simulated Agent-Human Interplay",
      "url": "https://arxiv.org/abs/2504.03601",
      "bullets": [
        {
          "text": "첫 단계에서는 LLM reviewers committee를 이용하여 detailed blue prints 생성",
          "level": 1
        },
        {
          "text": "blue prints는 simulated human-agent interplay를 통해 complete interaction trajectories로 발전",
          "level": 1
        },
        {
          "text": "1B에서 70B 사이즈에 이르는 xLAM-2-fc-r 시리즈 학습하여 GPT-4o나 Claude 3.5를 $\\tau$-bench & BFCL benchmarks에서 outperform 했다고 보고",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Meta-the-llama-4-herd-the-beginning-of-a-new-era-of-natively-multimodal-ai-innovation",
      "date": "2025-04-W02",
      "year": "2025",
      "month": "4",
      "week": "2",
      "type": "dev",
      "org": "Meta",
      "title": "The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation",
      "url": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
      "bullets": [
        {
          "text": "Behemoth는 teacher model로서 Scout, Maverick의 추론, 코딩, 멀티모달 이해 능력 전수",
          "level": 2
        },
        {
          "text": "MoE 아키텍쳐, native multi-modal model, 10M context length, Codistillation 등의 특징",
          "level": 1
        },
        {
          "text": "bias 문제 해결을 위한 노력 언급",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "HuggingFace-smolvlm-redefining-small-and-efficient-multimodal-models",
      "date": "2025-04-W02",
      "year": "2025",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "HuggingFace",
      "title": "SmolVLM: Redefining small and efficient multimodal models",
      "url": "https://arxiv.org/abs/2504.05299",
      "bullets": [
        {
          "text": "SmolVLM: resource-efficient inference를 위해 설계된 compact multimodal models series",
          "level": 1
        },
        {
          "text": "가장 작은 SmolVLM-256M 모델은 추론 시 1GB 미만의 GPU 메모리를 사용할 정도로 효율적이며, static images에 대해서 뿐만 아니라 뛰어난 video comprehension 이해 능력을 보였다고 함",
          "level": 1
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Ai2-going-beyond-open-data-increasing-transparency-and-trust-in-language-models-with-olmotrace",
      "date": "2025-04-W02",
      "year": "2025",
      "month": "4",
      "week": "2",
      "type": "dev",
      "org": "Ai2",
      "title": "Going beyond open data – increasing transparency and trust in language models with OLMoTrace",
      "url": "https://allenai.org/blog/olmotrace?utm_campaign=AI2%20Newsletter",
      "bullets": [
        {
          "text": "학습 데이터에 접근할 수 있는 다른 모델에도 적용할 수 있는 기능",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Yandex-hogwild-inference-parallel-llm-generation-via-concurrent-attention",
      "date": "2025-04-W02",
      "year": "2025",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "Yandex",
      "title": "Hogwild! Inference: Parallel LLM Generation via Concurrent Attention",
      "url": "https://arxiv.org/abs/2504.06261",
      "bullets": [
        {
          "text": "한 instance가 생성하는 과정을 나머지 instances가 concurrent cache를 통해 살펴볼 수 있음",
          "level": 1
        },
        {
          "text": "RoPE 차용",
          "level": 1
        },
        {
          "text": "modern reasoning-capable LLM들이 추가적인 fine-tuning 없이 shared Key-Value cache 만으로 좋은 성과를 낼 수 있었다고 보고",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Google-announcing-the-agent2agent-protocol-a2a",
      "date": "2025-04-W02",
      "year": "2025",
      "month": "4",
      "week": "2",
      "type": "dev",
      "org": "Google",
      "title": "Announcing the Agent2Agent Protocol (A2A)",
      "url": "https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/",
      "bullets": [
        {
          "text": "HTTP, SSE, JSON-RPC 등을 사용하여 기존 시스템과의 compatibility 보장",
          "level": 1
        },
        {
          "text": "Agents는 사용 가능한 functions를 structured JSON files로 정리하고, 이를 Agent Cards라고 함",
          "level": 1
        },
        {
          "text": "최근 Agent Development Kit (ADK)를 공개했는데 이는 Vertex AI, Gemini API와 integrate 가능한 open source임",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "OpenAI-evaluating-model-performance",
      "date": "2025-04-W02",
      "year": "2025",
      "month": "4",
      "week": "2",
      "type": "dev",
      "org": "OpenAI",
      "title": "Evaluating model performance",
      "url": "https://platform.openai.com/docs/guides/evals",
      "bullets": [
        {
          "text": "평가에 사용되는 test data를 `data_source_config`에 명시하고, 모델 출력 결과가 올바른 것인지에 대한 정보는 `testing_criteria`에 작성",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Amazon-amazons-new-nova-sonic-foundation-model-understands-not-just-what-you-saybut-how-you-say-it",
      "date": "2025-04-W02",
      "year": "2025",
      "month": "4",
      "week": "2",
      "type": "dev",
      "org": "Amazon",
      "title": "Amazon’s new Nova Sonic foundation model understands not just what you say—but how you say it",
      "url": "https://www.aboutamazon.com/news/innovation-at-amazon/nova-sonic-voice-speech-foundation-model",
      "bullets": [
        {
          "text": "Amazon Bedrock에 API로 이용 가능",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Nanjing,-ByteDance-ddt-decoupled-diffusion-transformer",
      "date": "2025-04-W02",
      "year": "2025",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "Nanjing, ByteDance",
      "title": "DDT: Decoupled Diffusion Transformer",
      "url": "https://arxiv.org/abs/2504.05741",
      "bullets": [
        {
          "text": "Decoupled Diffusion Transformer (DDT): semantic extraction를 위한 encoder & specialized velocity decoder 로 구분되는 디자인",
          "level": 1
        },
        {
          "text": "인접한 denoising step 간의 self-condition을 공유함으로써 추론 속도까지 향상시킬 수 있음",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "OpenGVLab-internvl3",
      "date": "2025-04-W02",
      "year": "2025",
      "month": "4",
      "week": "2",
      "type": "dev",
      "org": "OpenGVLab",
      "title": "InternVL3",
      "url": "https://huggingface.co/OpenGVLab/InternVL3-78B",
      "bullets": [
        {
          "text": "InternVL 2.5 대비 뛰어난 multimodal perception & reasoning 능력을 보여줌",
          "level": 1
        },
        {
          "text": "tool usage, GUI agents, industrial image analysis, 3D vision perception 등",
          "level": 1
        },
        {
          "text": "text performance가 Qwen 2.5 시리즈 대비 뛰어나다고 언급",
          "level": 1
        }
      ],
      "tags": [
        "multimodal",
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "Kimi-kimi-vl-technical-report",
      "date": "2025-04-W02",
      "year": "2025",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "Kimi",
      "title": "Kimi-VL Technical Report",
      "url": "https://arxiv.org/abs/2504.07491",
      "bullets": [
        {
          "text": "activating language decoder 사이즈가 2.8B 수준임에도 불구하고 뛰어난 성능 달성",
          "level": 1
        },
        {
          "text": "multi-turn agent tasks, college-level image & video comprehension, OCR, mathematical reasoning 등의 태스크에서 뛰어난 퍼포먼스를 보임",
          "level": 1
        },
        {
          "text": "128K content window & native-resolution vision encoder, MoonViT 덕분에 ultra-high-resolution visual inputs 이해 가능",
          "level": 1
        }
      ],
      "tags": [
        "multimodal",
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "Google-introducing-firebase-studio",
      "date": "2025-04-W02",
      "year": "2025",
      "month": "4",
      "week": "2",
      "type": "dev",
      "org": "Google",
      "title": "Introducing Firebase Studio",
      "url": "https://firebase.blog/posts/2025/04/introducing-firebase-studio",
      "bullets": [
        {
          "text": "Project IDX, Genkit, Gemini 를 하나의 workspace에 통합",
          "level": 1
        },
        {
          "text": "*App Prototyping agent*: prompt | drawing 으로부터 full apps 생성하는 기능",
          "level": 1
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "OpenAI-browsecomp-a-benchmark-for-browsing-agents",
      "date": "2025-04-W02",
      "year": "2025",
      "month": "4",
      "week": "2",
      "type": "dev",
      "org": "OpenAI",
      "title": "BrowseComp: a benchmark for browsing agents",
      "url": "https://openai.com/index/browsecomp",
      "bullets": [
        {
          "text": "📜 [BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents](https://cdn.openai.com/pdf/5e10f4ab-d6f7-442e-9508-59515c65e35d/browsecomp.pdf)",
          "level": 1
        },
        {
          "text": "정답이 간단하고 이견의 여지가 없는 1,266개의 문제로 구성",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Zhejiang-University-large-language-models-could-be-rote-learners",
      "date": "2025-04-W02",
      "year": "2025",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "Zhejiang University",
      "title": "Large language models could be rote learners",
      "url": "https://arxiv.org/abs/2504.08300",
      "bullets": [
        {
          "text": "LLM이 암기한 내용(rote memorization)보다 그렇지 않은 것(genuine capability)에 대해 더 좋은 퍼포먼스를 내는 경향이 있다고 보고",
          "level": 1
        },
        {
          "text": "TrinEval: MCQ를 trinity format으로 변경하여 memorization 평가는 줄이고 knowledge 평가는 더 잘할 수 있도록 만드는 evaluation 프레임워크",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "ByteDance-seed-thinking-v15-advancing-superb-reasoning-models-with-reinforcement-learning",
      "date": "2025-04-W03",
      "year": "2025",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "ByteDance",
      "title": "Seed-Thinking-v1.5: Advancing Superb Reasoning Models with Reinforcement Learning",
      "url": "https://github.com/ByteDance-Seed/Seed-Thinking-v1.5",
      "bullets": [
        {
          "text": "총 200B, activated 20B의 MoE 모델",
          "level": 0
        },
        {
          "text": "일반화된 reasoning 능력 평가를 위해 BeyondAIME, Codeforces, 두 개의 벤치마크 공개",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Microsoft-Research-mineworld-a-real-time-and-open-source-interactive-world-model-on-minecraft",
      "date": "2025-04-W03",
      "year": "2025",
      "month": "4",
      "week": "3",
      "type": "paper",
      "org": "Microsoft Research",
      "title": "MineWorld: a Real-Time and Open-Source Interactive World Model on Minecraft",
      "url": "https://arxiv.org/abs/2504.08388",
      "bullets": [
        {
          "text": "두 입력을 각각 image tokenizer & action tokenizer 에 통과시켜 discrete token으로 변환 후 concat 하여 input으로 사용",
          "level": 1
        },
        {
          "text": "모델이 초당 4~7 프레임을 생성할 수 있도록 학습되었으며 플레이어와 실시간 interact 가능",
          "level": 0
        },
        {
          "text": "visual quality & action following capability 를 함께 측정할 수 있는 metric 제시",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "DeepCogito-cogito-v1-previewintroducing-ida-as-a-path-to-general-superintelligence",
      "date": "2025-04-W03",
      "year": "2025",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "DeepCogito",
      "title": "Cogito v1 PreviewIntroducing IDA as a path to general superintelligence",
      "url": "https://www.deepcogito.com/research/cogito-v1-preview",
      "bullets": [
        {
          "text": "70B 모델이 Llama의 최신 109B MoE 모델을 능가하는 성능을 보인다고 보고",
          "level": 0
        },
        {
          "text": "Iterated Distillation and Amplification (IDA) - a scalable and efficient alignment strategy for general superintelligence using iterative self-improvement",
          "level": 0
        },
        {
          "text": "모든 모델은 질문에 바로(direct) 답하거나, 답변 전에 스스로 생각(self-reflect)할 수 있음",
          "level": 0
        },
        {
          "text": "109B, 400B, 671B 사이즈의 모델들을 곧 공개할 계획이며 공개 범위에는 체크포인트도 포함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-introducing-gpt-41-in-the-api",
      "date": "2025-04-W03",
      "year": "2025",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing GPT-4.1 in the API",
      "url": "https://openai.com/index/gpt-4-1/",
      "bullets": [
        {
          "text": "세 모델 전부 주요 벤치마크에서 GPT-4o, GPT-4.5를 outperform & 1M context window & diff 모드 지원",
          "level": 0
        },
        {
          "text": "structured input 이해, multi-turn, multi-needle tasks에서 기존보다 더 뛰어난 성능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "xAI-grok-studio",
      "date": "2025-04-W03",
      "year": "2025",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "xAI",
      "title": "Grok Studio",
      "url": "https://x.com/grok/status/1912318583532872166",
      "bullets": [
        {
          "text": "documents, codes, reports, browser games 등을 생성할 수 있고 컨텐츠를 별도 윈도우에 띄움",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-introducing-txgemma-open-models-to-improve-therapeutics-development-1",
      "date": "2025-04-W03",
      "year": "2025",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "Google",
      "title": "Introducing TxGemma: Open models to improve therapeutics development",
      "url": "https://developers.googleblog.com/en/introducing-txgemma-open-models-improving-therapeutics-development/",
      "bullets": [
        {
          "text": "promising target을 식별하는 것부터 clinical trial의 outcome을 예측하는 것 등이 가능",
          "level": 0
        },
        {
          "text": "Gemma 2에 7M 학습 샘플을 학습한 2B, 9B, 27B 모델",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "China-Telecom-xverify-efficient-answer-verifier-for-reasoning-model-evaluations",
      "date": "2025-04-W03",
      "year": "2025",
      "month": "4",
      "week": "3",
      "type": "paper",
      "org": "China Telecom",
      "title": "xVerify: Efficient Answer Verifier for Reasoning Model Evaluations",
      "url": "https://arxiv.org/abs/2504.10481",
      "bullets": [
        {
          "text": "label 정확도를 높이기 위해 multi-round annotation 수행",
          "level": 0
        },
        {
          "text": "Long Reasong tasks에 대한 평가 모델을 학습하기 위해 데이터셋을 구축했다는 내용이 전부인 듯",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "UCLA,-Meta-d1-scaling-reasoning-in-diffusion-large-language-models-via-reinforcement-learning",
      "date": "2025-04-W03",
      "year": "2025",
      "month": "4",
      "week": "3",
      "type": "paper",
      "org": "UCLA, Meta",
      "title": "d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning",
      "url": "https://arxiv.org/abs/2504.12216",
      "bullets": [
        {
          "text": "(a) masked SFT를 이용하여 knowledge를 distill 하고 self-improvement behavior를 instill",
          "level": 0
        },
        {
          "text": "(b) diff-GRPO: critic-free, policy-gradient based RL algorithm",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-bitnet-b158-2b4t-technical-report",
      "date": "2025-04-W03",
      "year": "2025",
      "month": "4",
      "week": "3",
      "type": "paper",
      "org": "Microsoft",
      "title": "BitNet b1.58 2B4T Technical Report",
      "url": "https://arxiv.org/abs/2504.12285",
      "bullets": [
        {
          "text": "computational efficiency를 큰 특징으로 삼으면서도 language understanding, mathematical rreasoning, coding preoficiency, conversational ability 등이 전부 뛰어나다고 설명",
          "level": 0
        },
        {
          "text": "CPU, GPU 추론 둘 다 지원하며 HuggingFace를 통해 이용 가능",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "OpenAI-introducing-openai-o3-and-o4-mini",
      "date": "2025-04-W03",
      "year": "2025",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing OpenAI o3 and o4-mini",
      "url": "https://openai.com/index/introducing-o3-and-o4-mini",
      "bullets": [
        {
          "text": "차트 해석, UI 이해, 수학적 추론, OCR + context 등 수행 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Ai2-datadecide-how-to-predict-best-pretraining-data-with-small-experiments",
      "date": "2025-04-W03",
      "year": "2025",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "Ai2",
      "title": "DataDecide: How to predict best pretraining data with small experiments",
      "url": "https://allenai.org/blog/datadecide",
      "bullets": [
        {
          "text": "학습 중 check point를 공개함으로써, 작은 모델로 특정 데이터셋에 대해 어떻게 학습되는지 경향성을 파악하여 scale-up 하는 데 도움을 주고자 하는 목적으로 공개했다고 설명함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Comet-ML-opik",
      "date": "2025-04-W03",
      "year": "2025",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "Comet-ML",
      "title": "Opik",
      "url": "https://github.com/comet-ml/opik",
      "bullets": [
        {
          "text": "Tracing, Annotations, Playground 등 기능 지원",
          "level": 0
        },
        {
          "text": "LLM-as-a-Judge metric 포함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Cohere-introducing-embed-4-multimodal-search-for-business",
      "date": "2025-04-W03",
      "year": "2025",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "Cohere",
      "title": "Introducing Embed 4: Multimodal search for business",
      "url": "https://cohere.com/blog/embed-4",
      "bullets": [
        {
          "text": "128K context window length (200 페이지 분량)",
          "level": 0
        },
        {
          "text": "100개 이상의 다양한 언어 지원",
          "level": 0
        },
        {
          "text": "virtual private cloud (VPC) 환경 뿐만 아니라 on-premise 환경도 지원",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "SkyworkAI-skywork-or1-open-reasoner-1",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "SkyworkAI",
      "title": "Skywork-OR1 (Open Reasoner 1)",
      "url": "https://github.com/SkyworkAI/Skywork-OR1",
      "bullets": [
        {
          "text": "Skywork-OR1-RL-Data: DeepSeek-R1-Distill-Qwen-32B로 난이도를 평가한 데이터 구성됨 (데이터 사용시 필터링으로 사용 가능). 총 105K Math, 14K Coding 데이터",
          "level": 0
        },
        {
          "text": "32B-Preview 모델의 경우 AIME, LiveCodeBench에서 DeepSeek-R1 수준 성능을 달성했다고 보고",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "NVIDIA-climb-clustering-based-iterative-data-mixture-bootstrapping-for-language-model-pre-training",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "NVIDIA",
      "title": "CLIMB: CLustering-based Iterative Data Mixture Bootstrapping for Language Model Pre-training",
      "url": "https://arxiv.org/abs/2504.13161",
      "bullets": [
        {
          "text": "CLIMB 제안: 사전학습을 위한 data mixture를 적절히 discover, evaluate, refine 하는 framework",
          "level": 0
        },
        {
          "text": "이를 이용하여 획득한 400B 토큰에 대해 1B 모델을 학습한 결과는 SoTA인 Llama-3.2-1B 모델을 능가하는 수준이라고 보고",
          "level": 0
        },
        {
          "text": "20개 cluster, 1.2T 토큰으로 구성된 ClimbLab, 400B 토큰으로 구성된 ClimbMix 공개",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "HKUST-thought-manipulation-external-thought-can-be-efficient-for-large-reasoning-models",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "HKUST",
      "title": "Thought Manipulation: External Thought Can Be Efficient for Large Reasoning Models",
      "url": "https://arxiv.org/abs/2504.13626",
      "bullets": [
        {
          "text": "thinking token 사이에 (<think> </think>) smaller 모델로부터 생성된 external CoT를 넣어주는 방식이 모델이 적은 토큰을 생성하는 데 도움을 준다고 설명 → ThoughtMani",
          "level": 0
        },
        {
          "text": "QwQ-32B 모델을 LiveBench/Code dataset에 적용했을 때, 기존 성능은 유지하면서도 약 30% 정도의 토큰을 절약할 수 있었음 (CoT generator로부터 overhead가 발생하긴 함)",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Google-gemma-3-qat-models-bringing-state-of-the-art-ai-to-consumer-gpus",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "Google",
      "title": "Gemma 3 QAT Models: Bringing state-of-the-Art AI to consumer GPUs",
      "url": "https://developers.googleblog.com/en/gemma-3-quantized-aware-trained-state-of-the-art-ai-to-consumer-gpus",
      "bullets": [
        {
          "text": "Gemma 3 27B 모델의 경우 int4 기준 14.1GB 메모리를 차지하여 RTX 3090 한 대에 KV cache 포함한 로드가 가능하다고 설명",
          "level": 0
        },
        {
          "text": "OpenAI API를 통해 function calling & custom tool 사용 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "UC-Berkeley,-LangChain-promptevals-a-dataset-of-assertions-and-guardrails-for-custom-production-large-language-model-pipelines",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "UC Berkeley, LangChain",
      "title": "PROMPTEVALS: A Dataset of Assertions and Guardrails for Custom Production Large Language Model Pipelines",
      "url": "https://arxiv.org/abs/2504.14738",
      "bullets": [
        {
          "text": "이 데이터로 fine-tuned 된 Mistral & Llama 3 가 (본인들 벤치마크에 대해) GPT-4o를 평균 20.93% outperform 했다고 설명",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Tsinghua-does-reinforcement-learning-really-incentivize-reasoning-capacity-in-llms-beyond-the-base-model",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Tsinghua",
      "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?",
      "url": "https://arxiv.org/abs/2504.13837",
      "bullets": [
        {
          "text": "즉, 현존하는 reasoning models의 reasoning abilities는 base model에 이미 존재하던 것을 적절히 sampling 할 수 있도록 학습되어 갖춰진 것으로 설명",
          "level": 0
        },
        {
          "text": "이러한 경향성은 visual reasoning tasks에서도 관측됨",
          "level": 0
        },
        {
          "text": "오히려 distillation이 이와 달리 모델에게 new knowledge 를 전달하는 방법이라고 설명",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Shanghai-AI-Lab,-Fudan,-CMU-mig-automatic-data-selection-for-instruction-tuning-by-maximizing-information-gain-in-semantic-space",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Shanghai AI Lab, Fudan, CMU",
      "title": "MIG: Automatic Data Selection for Instruction Tuning by Maximizing Information Gain in Semantic Space",
      "url": "https://arxiv.org/abs/2504.13835",
      "bullets": [
        {
          "text": "→ 데이터셋 내 information content를 정량화하는 method 제안: label graph를 구축하고 graph 내의 information distribution을 이용",
          "level": 0
        },
        {
          "text": "Maximize Information Gain (MIG): semantic space 내에서 반복적으로 sampling을 수행하는 efficient sampling method",
          "level": 0
        },
        {
          "text": "이 방법론을 Ai2 에서 공개했던 Tulu3 데이터셋에 적용해봄으로써 성능 향상을 이끌어 낼 수 있었다고 설명",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-DeepMind-welcome-to-the-era-of-experience",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Welcome to the Era of Experience",
      "url": "https://storage.googleapis.com/deepmind-media/Era-of-Experience%20/The%20Era%20of%20Experience%20Paper.pdf?utm_source=alphasignal",
      "bullets": [
        {
          "text": "학습을 위해 human-generated datasets에 의존하는 것을 피하고 environmental feedback을 사용할 것을 주장",
          "level": 0
        },
        {
          "text": "여러 태스크와 도메인에 대한 continuous, long-term learning을 지원",
          "level": 0
        },
        {
          "text": "task-specific performance가 아닌 시간에 걸친 capability growth에 집중",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Alibaba-wan-open-and-advanced-large-scale-video-generative-models",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Alibaba",
      "title": "Wan: Open and Advanced Large-Scale Video Generative Models",
      "url": "https://arxiv.org/abs/2503.20314",
      "bullets": [
        {
          "text": "T2V-1.3B 모델은 8.19GB VRAM를 필요로 하며, RTX 4090 한 장으로 5초짜리 480P 비디오를 약 4분만에 생성 가능",
          "level": 0
        },
        {
          "text": "Text-to-Video, Image-to-Video, Video Editing, Text-to-Image, Video-to-Audio 등 다양한 태스크 수행 가능",
          "level": 0
        },
        {
          "text": "Chinese & English 텍스트 생성 능력이 뛰어남",
          "level": 0
        },
        {
          "text": "temporal information을 보존하면서도 1080P video를 잘 encoding & decoding 할 수 있음",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Anthropic-values-in-the-wild-discovering-and-analyzing-values-in-real-world-language-model-interactions",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "Values in the wild: Discovering and analyzing values in real-world language model interactions",
      "url": "https://www.anthropic.com/research/values-wild",
      "bullets": [
        {
          "text": "이때 privacy-preserving system을 이용했기 때문에 유저의 개인정보는 제거되었다고 설명",
          "level": 0
        },
        {
          "text": "분석 과정을 시각화한 도식 참고하면 좋을 듯. AI values taxonomy를 구축한 것이 눈에 띔",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "NVIDIA-eagle-25-boosting-long-context-post-training-for-frontier-vision-language-models",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "NVIDIA",
      "title": "Eagle 2.5: Boosting Long-Context Post-Training for Frontier Vision-Language Models",
      "url": "https://arxiv.org/abs/2504.15271",
      "bullets": [
        {
          "text": "특히 long video understanding & high-resolution image understanding 의 문제를 해결",
          "level": 0
        },
        {
          "text": "Automatic Degrade Sampling & Image Area Preservation 을 통합하여 contextual integrity & visual details 보존",
          "level": 0
        },
        {
          "text": "Eagle-Video-110K: story-level & clip-level annotations를 통합한 데이터셋",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "Huawei-dynamic-early-exit-in-reasoning-models",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Huawei",
      "title": "Dynamic Early Exit in Reasoning Models",
      "url": "https://arxiv.org/abs/2504.15895",
      "bullets": [
        {
          "text": "fixed heuristics와 달리 potential reasoning transition points (ex. Wait 토큰)을 model behavior에서 탐지하는 방식.",
          "level": 0
        },
        {
          "text": "이때 모델이 trial answer에 대해 high confidence를 갖는 경우 next reasoning chain’s generation을 중단",
          "level": 0
        },
        {
          "text": "추가적인 학습이 필요없는 방식이며 기존 o1-like reasoning LLMs에 seamlessly integrate 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Chinese-Academy-of-Sciences-gui-r1-a-generalist-r1-style-vision-language-action-model-for-gui-agents",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Chinese Academy of Sciences",
      "title": "GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents",
      "url": "https://arxiv.org/abs/2504.10458",
      "bullets": [
        {
          "text": "unified action space rule modeling을 통해 LVLMs이 GUI 이해 능력을 향상할 수 있도록 하는 강화학습 프레임워크 GUI-R1 제안",
          "level": 0
        },
        {
          "text": "각 플랫폼(Windows, Linux, MacOS 등)으로부터 얻은 소수의 carefully curated high-quality data, GRPO를 이용하여 자원 효율적인 결과를 달성할 수 있었다고 설명",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "ByteDance-introducing-ui-tars-15",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "ByteDance",
      "title": "Introducing UI-TARS-1.5",
      "url": "https://seed-tars.com/1.5/",
      "bullets": [
        {
          "text": "token-level multimodal supervision 기반의 reasoning-before-action approach를 사용",
          "level": 0
        },
        {
          "text": "뛰어난 Web Navigation 능력은 GPT-4.5 능가하는 수준",
          "level": 0
        }
      ],
      "tags": [
        "multimodal",
        "reasoning"
      ]
    },
    {
      "id": "Nari-Labs-nari-dia-16b",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "Nari-Labs",
      "title": "Nari Dia-1.6B",
      "url": "https://github.com/nari-labs/dia/",
      "bullets": [
        {
          "text": "ElevenLabs Studio나 Sesame CSM-1B 모델 이상의 퍼포먼스를 보여주어 큰 화제를 일으키는 중",
          "level": 0
        },
        {
          "text": "카이스트 학부생이 2명이 작업한 결과물로 알려짐",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "a-m-team-deepdistill-enhancing-llm-reasoning-capabilities-via-large-scale-difficulty-graded-data-training",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "a-m-team",
      "title": "DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training",
      "url": "https://arxiv.org/abs/2504.17565",
      "bullets": [
        {
          "text": "pass rate & Coefficient of Variation (CV) 를 이용하여 유의미한 학습 데이터만 남겼다고 설명",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Shanghai-AI-Lab,-Tsinghua-visulogic-a-benchmark-for-evaluating-visual-reasoning-in-multi-modal-large-language-models",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Shanghai AI Lab, Tsinghua",
      "title": "VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal Large Language Models",
      "url": "https://arxiv.org/abs/2504.15279",
      "bullets": [
        {
          "text": "VisuLogic: 6개 카테고리에 대한 1,000 human-verified problems (quantitative shifts, spatial relations 등)",
          "level": 0
        },
        {
          "text": "사람은 51.4%, 대부분의 모델은 30% 이하의 정확도를 기록하는 수준의 벤치마크이며, visual reasoning 능력을 고도화할 수 있는 학습 데이터도 공개했다고 언급함",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Tsinghua,-Shanghai-AI-Lab-ttrl-test-time-reinforcement-learning",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Tsinghua, Shanghai AI Lab",
      "title": "TTRL: Test-Time Reinforcement Learning",
      "url": "https://arxiv.org/abs/2504.16084",
      "bullets": [
        {
          "text": "ground-truth 정보 없이 reward estimation을 어떻게 할 것인지가 challege",
          "level": 1
        },
        {
          "text": "Test-Time Reinforcement Learning (TTRL): pre-trained models의 priors를 이용하여 self-evolution",
          "level": 0
        },
        {
          "text": "Test-Time Scaling (TTS) 에서 majority voting 등이 RL training에서 reward 역할을 할 수 있었음에 착안",
          "level": 1
        },
        {
          "text": "initial (base) model의 성능을 outperform 하는 현상이 관측되어 방법론 타당성 입증",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "OpenAI-introducing-our-latest-image-generation-model-in-the-api",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing our latest image generation model in the API",
      "url": "https://openai.com/index/image-generation-api",
      "bullets": [
        {
          "text": "해당 기능을 `gpt-image-1` API로 공개",
          "level": 0
        },
        {
          "text": "이미지 한 장당 대략 0.3$ 정도 비용 발생",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "NousResearch-minos-v1",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "NousResearch",
      "title": "Minos-v1",
      "url": "https://huggingface.co/NousResearch/Minos-v1",
      "bullets": [
        {
          "text": "유저의 질문과 LLM의 답변 pair를 입력으로 받아 둘 중 하나의 클래스를 confidence와 함께 반환하는 모델",
          "level": 1
        },
        {
          "text": "400M 사이즈 모델로 8,192 context length, 약 380K 데이터로 학습",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "DevRev-efficient-single-pass-training-for-multi-turn-reasoning",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "DevRev",
      "title": "Efficient Single-Pass Training for Multi-Turn Reasoning",
      "url": "https://arxiv.org/abs/2504.18246",
      "bullets": [
        {
          "text": "LLM은 추론 토큰을 생성하는데 이를 이후 입력에 포함하면 안됨",
          "level": 1
        },
        {
          "text": "이러한 불일치(discrepancy)로 인해 일반적인 다른 데이터셋에 대해 학습하는 것과 달리, single forward pass로 전체 대화를 처리할 수 없음",
          "level": 0
        },
        {
          "text": "이를 해결하기 위해 response token duplication & custom attention mask (enforces appropriate visibility constraints) 적용",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-tiny-agents-a-mcp-powered-agent-in-50-lines-of-code",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "HuggingFace",
      "title": "Tiny Agents: a MCP-powered agent in 50 lines of code",
      "url": "https://huggingface.co/blog/tiny-agents",
      "bullets": [
        {
          "text": "AI Agents 시스템 구축에 50줄 코드면 충분",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Anthropic-the-urgency-of-interpretability",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "The Urgency of Interpretability",
      "url": "https://www.darioamodei.com/post/the-urgency-of-interpretability",
      "bullets": [
        {
          "text": "언어별로 별도 시스템이 존재하는 것이 아니라, 영어, 프랑스어, 중국어 등 다양한 언어가 공유하는 추상적 개념 공간이 존재 → 의미 처리 후 특정 언어로 번역되는 방식으로 동작",
          "level": 0
        },
        {
          "text": "시를 쓸 때 단순히 다음 토큰들을 예측하는 것이 아니라 미리 운율을 맞출 준비를 하고 있음",
          "level": 0
        },
        {
          "text": "어려운 수학 문제 등을 풀 때, 잘못된 근거를 제시하면 그럴싸한 답변을 생성. 이런 과정은 여러 ‘중간 단계’를 거치는 것으로 확인됨",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-bitnet-v2-native-4-bit-activations-with-hadamard-transformation-for-1-bit-llms",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Microsoft",
      "title": "BitNet v2: Native 4-bit Activations with Hadamard Transformation for 1-bit LLMs",
      "url": "https://arxiv.org/abs/2504.18415",
      "bullets": [
        {
          "text": "BitNet v2: 1-bit LLM을 위한 native 4-bit activation quantization 프레임워크",
          "level": 0
        },
        {
          "text": "H-BitLinear: activation quantization 이전에 online Hadamard transformation 적용",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Alibaba-qwen3-think-deeper-act-faster",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "Alibaba",
      "title": "Qwen3: Think Deeper, Act Faster",
      "url": "https://qwenlm.github.io/blog/qwen3",
      "bullets": [
        {
          "text": "가장 큰 두 모델: Qwen3-30B-A3B, Qwen3-235B-A22B (둘 다 MoE)",
          "level": 1
        },
        {
          "text": "Hybrid thinking mode: thinking mode와 non-thinking mode 스위칭 가능",
          "level": 0
        },
        {
          "text": "36T 토큰으로 학습. 이는 Qwen2.5를 학습한 데이터의 두 배에 이르는 양.",
          "level": 0
        },
        {
          "text": "119개에 이르는 다양한 언어를 지원하며, MCP를 natively support",
          "level": 0
        }
      ],
      "tags": [
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "NourResearch-atropos",
      "date": "2025-04-W04",
      "year": "2025",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "NourResearch",
      "title": "Atropos",
      "url": "https://github.com/NousResearch/Atropos",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-longrope2-near-lossless-llm-context-window-scaling",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "paper",
      "org": "Microsoft",
      "title": "LongRoPE2: Near-Lossless LLM Context Window Scaling",
      "url": "https://arxiv.org/abs/2502.20082",
      "bullets": [
        {
          "text": "LLaMA3-8B에 LongRoPE2를 적용하여 128K를 커버할 수 있게 만들면서도 기존 short-context performance는 98.5% 보존",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-introducing-gpt-45",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing GPT-4.5",
      "url": "https://openai.com/index/introducing-gpt-4-5/",
      "bullets": [
        {
          "text": "이미지 입력, agentic planning & execution 가능",
          "level": 0
        },
        {
          "text": "text-based interactions 내의 뉘앙스 파악 더 잘함 & 향상된 EQ → 문과적 사고는 좋아졌는데 실질적인 성능은 아쉽다는 평이 많음",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Inception-Labs-introducing-mercury-the-first-commercial-scale-diffusion-large-language-model",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "dev",
      "org": "Inception Labs",
      "title": "Introducing Mercury, the first commercial-scale diffusion large language model",
      "url": "https://www.inceptionlabs.ai/news",
      "bullets": [
        {
          "text": "H100에서 초당 1000 토큰을 출력할 수 있을 정도로 기존 모델들 대비 10x 이상 빠르다고 설명",
          "level": 0
        },
        {
          "text": "다음 토큰을 autoregressive 하게 예측하는 방식/패러다임을 “coarse-to-fine” 생성 방식으로 전환해야 한다고 주장",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "King’s-College-London,-The-Alan-Turing-Institue-codi-compressing-chain-of-thought-into-continuous-space-via-self-distillation",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "paper",
      "org": "King’s College London, The Alan Turing Institue",
      "title": "CODI: Compressing Chain-of-Thought into Continuous Space via Self-Distillation",
      "url": "https://arxiv.org/abs/2502.21074",
      "bullets": [
        {
          "text": "CODI: shared model이 teacher & student 역할을 수행하며 explicit & implict CoT를 학습",
          "level": 0
        },
        {
          "text": "implicit CoT로도 explicit CoT 성능을 달성하면서도 3.1배의 토큰 압축률을 보여줌",
          "level": 0
        },
        {
          "text": "explicit reasoning이 대박을 친 이후로 추론 비용이 급상승해서인지 implicit & compression 관련 연구들에 눈에 띄고 있음",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Sesame-crossing-the-uncanny-valley-of-conversational-voice",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "dev",
      "org": "Sesame",
      "title": "Crossing the uncanny valley of conversational voice",
      "url": "https://www.sesame.com/research/crossing_the_uncanny_valley_of_voice",
      "bullets": [
        {
          "text": "tone, pace, rhythm 등을 conversational context and emotions 기반으로 조절 가능",
          "level": 0
        },
        {
          "text": "decoder는 Residual Vector Quantization (RVQ) tokens로부터 high-fidelity speech를 reconstruct",
          "level": 0
        },
        {
          "text": "2K context window 커버 가능, 1M hours of publicly available transcribed and diarized speech로 학습",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Anthropic-token-efficient-tool-use-beta",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "dev",
      "org": "Anthropic",
      "title": "Token-efficient tool use (beta)",
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/tool-use/token-efficient-tool-use",
      "bullets": [
        {
          "text": "API call에서 tool use와 관련된 옵션임. Claude 3.7을 공개하면서 사용 비용을 최소화하는 옵션을 함께 제시함.",
          "level": 1
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "LLM-Post-Training:-A-Deep-Dive-into-Reasoning-Large-Language-Models-llm-post-training-a-deep-dive-into-reasoning-large-language-models",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "paper",
      "org": "LLM Post-Training: A Deep Dive into Reasoning Large Language Models",
      "title": "LLM Post-Training: A Deep Dive into Reasoning Large Language Models",
      "url": "https://arxiv.org/abs/2502.21321",
      "bullets": [
        {
          "text": "catastrophic forgetting, inference-time trade-off, reward hacking 등의 issues를 함께 다룸",
          "level": 0
        },
        {
          "text": "Tuning 파트에 엑사원은 있는데 솔라는 포함되지 않았음",
          "level": 0
        },
        {
          "text": "[Awesome LLM Post-Training repository](https://github.com/mbzuai-oryx/Awesome-LLM-Post-training) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Mila-multi-turn-code-generation-through-single-step-rewards",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "paper",
      "org": "Mila",
      "title": "Multi-Turn Code Generation Through Single-Step Rewards",
      "url": "https://arxiv.org/abs/2502.20380",
      "bullets": [
        {
          "text": "μCODE: single-step reward만을 사용하는 multi-turn code generation",
          "level": 0
        },
        {
          "text": "중간의 어떤 과정에서도 올바른 코드로 recovered 가능하다고 주장",
          "level": 0
        },
        {
          "text": "멀티턴 실행 피드백과 새로 생성된 코드를 scoring하는 verifier를 iteratively 학습",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Univ.-of-Oklahoma-a-survey-on-large-language-models-for-code-generation",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "paper",
      "org": "Univ. of Oklahoma",
      "title": "A Survey On Large Language Models For Code Generation",
      "url": "https://arxiv.org/abs/2503.01245",
      "bullets": [
        {
          "text": "엄청 방대한 양을 커버하고 있지는 않음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Tencent-AI-the-first-few-tokens-are-all-you-need-an-efficient-and-effective-unsupervised-prefix-fine-tuning-method-for-reasoning-models",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "paper",
      "org": "Tencent AI",
      "title": "The First Few Tokens Are All You Need: An Efficient and Effective Unsupervised Prefix Fine-Tuning Method for Reasoning Models",
      "url": "",
      "bullets": [
        {
          "text": "Unsupervised Prefix Fine-Tuning (UPFT): Prefix Self-Consistency를 이용. 다양한 solution에 공통적으로 포함되는 initial reasoning steps를 학습 대상으로 삼음",
          "level": 0
        },
        {
          "text": "initial prefix substrings (8개 토큰) 에 대해서만 학습함으로써 데이터 라벨링이나 sampling의 공수를 줄임",
          "level": 0
        },
        {
          "text": "학습 시간은 75%, sampling cost는 99% 줄이면서도 Rejection Sampling Fine-Tuning과 같은 기존 학습 방식에 준하는 성능을 달성했다고 보고",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Qwen-qwq-32b",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "dev",
      "org": "Qwen",
      "title": "QwQ-32B",
      "url": "https://huggingface.co/Qwen/QwQ-32B",
      "bullets": [
        {
          "text": "131K Token length 지원",
          "level": 0
        },
        {
          "text": "RoPE, SwiGLU, RMSNorm",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Cohere-aya-vision-expanding-the-worlds-ai-can-see",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "dev",
      "org": "Cohere",
      "title": "Aya Vision: Expanding the Worlds AI Can See",
      "url": "https://cohere.com/blog/aya-vision",
      "bullets": [
        {
          "text": "8B, 32B 사이즈 모델. [Kaggle](https://www.kaggle.com/models/cohereforai/aya-vision?ref=cohere-ai.ghost.io) & [HuggingFace](https://huggingface.co/collections/CohereForAI/c4ai-aya-vision-67c4ccd395ca064308ee1484?ref=cohere-ai.ghost.io) 에 weights 공개",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "Google-data-science-agent-in-colab-the-future-of-data-analysis-with-gemini",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "dev",
      "org": "Google",
      "title": "Data Science Agent in Colab: The future of data analysis with Gemini",
      "url": "https://developers.googleblog.com/en/data-science-agent-in-colab-with-gemini/",
      "bullets": [
        {
          "text": "classification, regression, feature selection, correlation analysis 등 기능 지원",
          "level": 0
        },
        {
          "text": "CSV, JSON, Excel files 지원",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Nanjing-Univ.,-Microsoft-process-based-self-rewarding-language-models",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "paper",
      "org": "Nanjing Univ., Microsoft",
      "title": "Process-based Self-Rewarding Language Models",
      "url": "https://arxiv.org/abs/2503.03746",
      "bullets": [
        {
          "text": "→ 현존하는 self-rewarding 방식은 수학적 추론 영역에서 약점을 보인다고 지적",
          "level": 0
        },
        {
          "text": "→ self-rewarding 내에 long-thought reasoning, step-wise LLM-as-a-Judge, step-wise preference optimization 등 도입",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Washington,-Peking-mpo-boosting-llm-agents-with-meta-plan-optimization",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "paper",
      "org": "Washington, Peking",
      "title": "MPO: Boosting LLM Agents with Meta Plan Optimization",
      "url": "https://arxiv.org/abs/2503.02682",
      "bullets": [
        {
          "text": "Meta Plan Optimization (MPO): explicit guidance를 통합하여 agent의 planning capability를 향상시키는 프레임워크. agent의 실행 결과에 대한 피드백을 바탕으로 삼음.",
          "level": 0
        },
        {
          "text": "Meta Plan에 대한 평가(reward)를 제공하는 모델도 있어서 파이프라인이 강화학습처럼 보임",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Alibaba-babel-open-multilingual-large-language-models-serving-over-90-of-global-speakers",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "paper",
      "org": "Alibaba",
      "title": "Babel: Open Multilingual Large Language Models Serving Over 90% of Global Speakers",
      "url": "https://arxiv.org/abs/2503.00865",
      "bullets": [
        {
          "text": "Babel-9B, 83B multilingual LLMs 공개",
          "level": 0
        },
        {
          "text": "전통적인 continued pretraining 대신 model extension을 통해 parameter count를 확장함으로써 성능 향상을 도모했음",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Alibaba-start-self-taught-reasoner-with-tools",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "paper",
      "org": "Alibaba",
      "title": "START: Self-taught Reasoner with Tools",
      "url": "https://arxiv.org/abs/2503.04625",
      "bullets": [
        {
          "text": "(1) Hint-infer: 인위적으로 설계한 힌트를 삽입 (ex. 파이썬 코드를 써야겠어!)",
          "level": 0
        },
        {
          "text": "(2) Hint Rejection Sampling Fine-Tuning (Hint-RFT): Hint-infer를 통해 생성된 reasoning trajectories(tool 사용을 포함하는)를 fine-tuning",
          "level": 0
        }
      ],
      "tags": [
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "CMU-solar-scalable-optimization-of-large-scale-architecture-for-reasoning",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "paper",
      "org": "CMU",
      "title": "SOLAR: Scalable Optimization of Large-scale Architecture for Reasoning",
      "url": "https://arxiv.org/abs/2503.04530",
      "bullets": [
        {
          "text": "accuracy와 efficiency를 향상시키기 위해 reasoning topology를 dynamically optimize",
          "level": 0
        },
        {
          "text": "Topological-Annotation-Generation (TAG) system: topological dataset creation & segmentation을 자동화",
          "level": 0
        },
        {
          "text": "multi-task Topological Reward Model (M-TRM) 학습: 자동적으로 best reasoning topology를 선택하여 single pass에 답변 반환 (multiple single-task 필요성 x)",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "NVIDIA,-Berkeley,-MIT,-Nanjing,-KAIST-token-efficient-long-video-understanding-for-multimodal-llms",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "paper",
      "org": "NVIDIA, Berkeley, MIT, Nanjing, KAIST",
      "title": "Token-Efficient Long Video Understanding for Multimodal LLMs",
      "url": "https://arxiv.org/abs/2503.04130",
      "bullets": [
        {
          "text": "STORM (Spatiotemporal TOken Reduction for Multimodal LLMs): image encoder & LLM 사이의 temporal encoder를 통합하는 아키텍쳐",
          "level": 0
        },
        {
          "text": "Mamaba State Space Model을 사용하여 temporal information을 image tokens에 통합하여 보다 풍부한 representations를 생성",
          "level": 0
        },
        {
          "text": "training & inference latency 둘 다 감소시키면서도 extended temporal contexts에 대한 efficient & robust video understanding 를 보여줌",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "Stanford-cognitive-behaviors-that-enable-self-improving-reasoners-or-four-habits-of-highly-effective-stars",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "paper",
      "org": "Stanford",
      "title": "Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs",
      "url": "https://arxiv.org/abs/2503.01307",
      "bullets": [
        {
          "text": "4개의 cognitive behaviors: verification, backtracking, subgoal setting, backward chaining",
          "level": 0
        },
        {
          "text": "OpenWebMath data를 continued-pretraining에 활용하여 Llama를 학습한 결과는 Qwen에 준함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Columbia-Business-School-how-well-do-llms-compress-their-own-chain-of-thought-a-token-complexity-approach",
      "date": "2025-03-W01",
      "year": "2025",
      "month": "3",
      "week": "1",
      "type": "paper",
      "org": "Columbia Business School",
      "title": "How Well do LLMs Compress Their Own Chain-of-Thought? A Token Complexity Approach",
      "url": "https://arxiv.org/abs/2503.01141",
      "bullets": [
        {
          "text": "→ 거의 모든 distinct reasoning chain마다 reasoning length와 accuracy 간의 universal tradeoff 존재",
          "level": 0
        },
        {
          "text": "token complexity: successful problem-solving을 위해 필요한 최소한의 토큰 숫자",
          "level": 0
        },
        {
          "text": "→ accuracy-compression tradeoff의 이론적 한계를 계산하는 데 활용",
          "level": 0
        },
        {
          "text": "→ adaptive compression: 답하기 쉬운 질문에는 짧은 responses를 반환토록 함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Renmin-Univ.-r1-searcher-incentivizing-the-search-capability-in-llms-via-reinforcement-learning",
      "date": "2025-03-W02",
      "year": "2025",
      "month": "3",
      "week": "2",
      "type": "paper",
      "org": "Renmin Univ.",
      "title": "R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning",
      "url": "https://arxiv.org/abs/2503.05592",
      "bullets": [
        {
          "text": "R1-Searcher: two-stage outcome-based RL approach",
          "level": 0
        },
        {
          "text": "reasoning process 동안 추가적인 지식 습득을 위해 모델이 자율적으로 external search system에 접근",
          "level": 0
        },
        {
          "text": "RL만 배타적으로 사용. cold start를 위한 reward나 distillation 불필요.",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Manus-leave-it-to-manus",
      "date": "2025-03-W02",
      "year": "2025",
      "month": "3",
      "week": "2",
      "type": "dev",
      "org": "Manus",
      "title": "Leave it to Manus",
      "url": "https://manus.im/",
      "bullets": [
        {
          "text": "자체적으로 공개한 벤치마크 결과에서는 OpenAI Deep Research를 압살",
          "level": 0
        },
        {
          "text": "파격적인 데모(수십 개의 앱이 동시에 실행)가 사실인지에 대한 커뮤니티 논쟁이 있었음",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "OpenAI-new-tools-for-building-agents",
      "date": "2025-03-W02",
      "year": "2025",
      "month": "3",
      "week": "2",
      "type": "dev",
      "org": "OpenAI",
      "title": "New tools for building agents",
      "url": "https://openai.com/index/new-tools-for-building-agents/",
      "bullets": [
        {
          "text": "Chat Completions API에 Assistants API의 tool 사용 능력을 합친 Responses API",
          "level": 0
        },
        {
          "text": "web search, file search, computer use 능력을 내장",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Skolkovo-Institue-of-Science-and-Technology-feature-level-insights-into-artificial-text-detection-with-sparse-autoencoders",
      "date": "2025-03-W02",
      "year": "2025",
      "month": "3",
      "week": "2",
      "type": "paper",
      "org": "Skolkovo Institue of Science and Technology",
      "title": "Feature-Level Insights into Artificial Text Detection with Sparse Autoencoders",
      "url": "https://arxiv.org/abs/2503.03601",
      "bullets": [
        {
          "text": "Sparse Autoencoder를 이용하여 Gemma-2-2b로부터 feature를 추출함으로써 ATD interpretability를 높임",
          "level": 0
        },
        {
          "text": "다양한 모델로부터 획득한 텍스트가 사람으로부터 얻은 것과 어떻게 다른지에 대한 인사이트 제공 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-DeepMind-gemini-robotics-brings-ai-into-the-physical-world",
      "date": "2025-03-W02",
      "year": "2025",
      "month": "3",
      "week": "2",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "Gemini Robotics brings AI into the physical world",
      "url": "https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/",
      "bullets": [
        {
          "text": "Gemini Robotics-ER: Gemini의 embodied reasoning (ER) 능력을 활용하여 advanced spatial understanding을 보여줌",
          "level": 0
        },
        {
          "text": "다음 세대의 휴머노이드를 만들기 위해 Apptronik와 파트너십",
          "level": 0
        },
        {
          "text": "[Technical Report link](https://storage.googleapis.com/deepmind-media/gemini-robotics/gemini_robotics_report.pdf) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Google-introducing-gemma-3-the-developer-guide",
      "date": "2025-03-W02",
      "year": "2025",
      "month": "3",
      "week": "2",
      "type": "dev",
      "org": "Google",
      "title": "Introducing Gemma 3: The Developer Guide",
      "url": "https://developers.googleblog.com/en/introducing-gemma3/",
      "bullets": [
        {
          "text": "LMArena에서 R1 바로 뒤를 이어 2위 차지",
          "level": 0
        },
        {
          "text": "SigLIP 기반의 vision encoder를 통한 Multimodal 지원, 128K 윈도우 사이즈, 140개 이상 언어 이해",
          "level": 0
        },
        {
          "text": "3개의 강화 학습 기법 적용: RLMF (Machine Feedback), RLEF (Execution Feedback), RLHF (Human Feedback)",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Perplexity-perplexity-ask-mcp-server",
      "date": "2025-03-W02",
      "year": "2025",
      "month": "3",
      "week": "2",
      "type": "dev",
      "org": "Perplexity",
      "title": "Perplexity Ask MCP Server",
      "url": "https://github.com/ppl-ai/modelcontextprotocol",
      "bullets": [
        {
          "text": "AI 시스템과 데이터 소스를 연결하기 위한 개방형 표준 프로토콜",
          "level": 1
        },
        {
          "text": "클라이언트 - 서버 아키텍쳐를 기본으로 삼음",
          "level": 1
        },
        {
          "text": "기존 API 대비 더 직관적이고 유연한 솔루션",
          "level": 1
        },
        {
          "text": "도커 이미지로 만들어서 테스트까지 가능한 방법을 간단한 가이드로 소개함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "OpenAI-detecting-misbehavior-in-frontier-reasoning-models",
      "date": "2025-03-W02",
      "year": "2025",
      "month": "3",
      "week": "2",
      "type": "dev",
      "org": "OpenAI",
      "title": "Detecting misbehavior in frontier reasoning models",
      "url": "https://openai.com/index/chain-of-thought-monitoring/",
      "bullets": [
        {
          "text": "reasoning 모델을 위한 강화학습 과정에서 발생하는 reward hacking 문제 중 coding task에 집중",
          "level": 0
        },
        {
          "text": "모델이 reward를 maximize 하기 위해서 cheating 하는 내용들을 explicitly state 하는 것이 관측됨",
          "level": 0
        },
        {
          "text": "현재로서는 모델 스스로 intent를 숨기고 detection을 회피하고자 하는 경향성이 있음",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Meta,-NYU,-MIT,-Princeton-transformers-without-normalization",
      "date": "2025-03-W02",
      "year": "2025",
      "month": "3",
      "week": "2",
      "type": "paper",
      "org": "Meta, NYU, MIT, Princeton",
      "title": "Transformers without Normalization",
      "url": "https://arxiv.org/abs/2503.10622",
      "bullets": [
        {
          "text": "Dynamic Tanh (DyT): element-wise 연산, $\\text{DyT}(x)=\\text{tanh}(\\alpha x)$, Transformers 아키텍쳐에서 normalization layers를 replace",
          "level": 0
        },
        {
          "text": "이 아이디어는 기존 normalization의 결과가 tanh-like S-shaped input-output mapping을 보여준다는 점에서 착안함",
          "level": 0
        },
        {
          "text": "recognition부터 generation, computer vision부터 language model 까지 다양한 태스크로 validate",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "KAIST-sketch-of-thought-efficient-llm-reasoning-with-adaptive-cognitive-inspired-sketching",
      "date": "2025-03-W02",
      "year": "2025",
      "month": "3",
      "week": "2",
      "type": "paper",
      "org": "KAIST",
      "title": "Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching",
      "url": "https://arxiv.org/abs/2503.05179",
      "bullets": [],
      "tags": []
    },
    {
      "id": "UC-Berkeley,-Tokyo-plan-and-act-improving-planning-of-agents-for-long-horizon-tasks",
      "date": "2025-03-W03",
      "year": "2025",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "UC Berkeley, Tokyo",
      "title": "Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks",
      "url": "https://arxiv.org/abs/2503.09572",
      "bullets": [
        {
          "text": "Plan-and-Act: synthetic data generation을 통해 LLM 기반 agents의 plan generation을 고도화한 프레임워크",
          "level": 0
        },
        {
          "text": "Planner: 목표를 달성하는 데 필요한 structured & high-level plans",
          "level": 0
        },
        {
          "text": "Executor: 위 plan들을 environment-specific actions로 translate",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Microsoft-rd-agent",
      "date": "2025-03-W03",
      "year": "2025",
      "month": "3",
      "week": "3",
      "type": "dev",
      "org": "Microsoft",
      "title": "RD-Agent",
      "url": "https://github.com/microsoft/RD-Agent",
      "bullets": [
        {
          "text": "확실히 Agent 개념을 활용한 자동화가 연구에 본격적으로 활용되고 있고 앞으로는 BM으로 발전하지 않을까 싶음",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "IBM,-HuggingFace-smoldocling-an-ultra-compact-vision-language-model-for-end-to-end-multi-modal-document-conversion",
      "date": "2025-03-W03",
      "year": "2025",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "IBM, HuggingFace",
      "title": "SmolDocling: An ultra-compact vision-language model for end-to-end multi-modal document conversion",
      "url": "https://arxiv.org/abs/2503.11576",
      "bullets": [
        {
          "text": "DocTags: 페이지 내 모든 요소를 위치와 함께 capture하는 새로운 universal markup format",
          "level": 0
        },
        {
          "text": "business documents, academic papers, technical reports 등 다양한 형식의 문서에서 code listings, table,s equations, charts, list 등의 feature 추출 가능하며 robust 하다고 설명",
          "level": 0
        },
        {
          "text": "모델은 이용 가능하며 데이터셋은 곧 공개 예정",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Anthropic-auditing-language-models-for-hidden-objectives",
      "date": "2025-03-W03",
      "year": "2025",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Anthropic",
      "title": "Auditing Language Models for Hidden Objectives",
      "url": "https://assets.anthropic.com/m/317564659027fb33/original/Auditing-Language-Models-for-Hidden-Objectives.pdf",
      "bullets": [
        {
          "text": "RLHF 내 reward model의 error를 학습하고, 이러한 error를 이용(exploit)하는 방법을 익힘",
          "level": 0
        },
        {
          "text": "(1) 모델의 hidden objective와 training에 대해 모르는 사람들을 4팀으로 꾸려 blind auditing game 수행",
          "level": 0
        },
        {
          "text": "(2) 후속 연구로 모델을 audit 하는 8개 테크닉을 탐구. SAE가 가장 효과적이었다고 함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "IIIT-Hyderabad-no-llm-is-free-from-bias-a-comprehensive-study-of-bias-evaluation-in-large-language-models",
      "date": "2025-03-W03",
      "year": "2025",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "IIIT Hyderabad",
      "title": "No LLM is Free From Bias: A Comprehensive Study of Bias Evaluation in Large Language models",
      "url": "https://arxiv.org/abs/2503.11985",
      "bullets": [
        {
          "text": "bias detection task를 위한 5개의 prompting approaches 소개",
          "level": 0
        },
        {
          "text": "biases detecting 벤치마크의 metrics에 대한 3개의 research questions 제시",
          "level": 0
        },
        {
          "text": "실험 결과에 따르면 모든 LLM이 최소 1개 이상의 bias를 나타내고 있으며, LLaMA3.1-8B 모델의 bias가 가장 적었다고 함",
          "level": 0
        },
        {
          "text": "논문 내에 bias 평가 metric에 대한 정리가 잘 되어 있으나 사이즈가 작은 오픈소스 모델 대상으로 실험 결과를 정리한 점은 아쉽",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Mistral-mistral-small-31",
      "date": "2025-03-W03",
      "year": "2025",
      "month": "3",
      "week": "3",
      "type": "dev",
      "org": "Mistral",
      "title": "Mistral Small 3.1",
      "url": "https://mistral.ai/news/mistral-small-3-1",
      "bullets": [
        {
          "text": "GPQA에서 44.42% 스코어를 달성하며 Gemma 3-it (36.83%) 모델과 GPT-4o-mini (40.2%) 모델을 능가",
          "level": 0
        },
        {
          "text": "초당 150 토큰 생성 가능하며 이미지도 처리 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "AI2-olmo-2-32b-first-fully-open-model-to-outperform-gpt-35-and-gpt-4o-mini",
      "date": "2025-03-W03",
      "year": "2025",
      "month": "3",
      "week": "3",
      "type": "dev",
      "org": "AI2",
      "title": "OLMo 2 32B: First fully open model to outperform GPT 3.5 and GPT 4o mini",
      "url": "https://allenai.org/blog/olmo2-32B",
      "bullets": [
        {
          "text": "오픈소스 모델(데이터, 코드, 학습 방식 등 모든 디테일 공개) 중 GPT 3.5와 GPT 4o mini를 능가하는 것은 최초라고 보도",
          "level": 0
        },
        {
          "text": "refined post-training과 RLVR (Reinforcement Learning with Verifiable Rewards) 적용",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Tsinghua-personalize-anything-for-free-with-diffusion-transformer",
      "date": "2025-03-W03",
      "year": "2025",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Tsinghua",
      "title": "Personalize Anything for Free with Diffusion Transformer",
      "url": "https://arxiv.org/abs/2503.12590",
      "bullets": [
        {
          "text": "덕분에 personalization 및 image editing도 가능",
          "level": 0
        },
        {
          "text": "Personalize Anything: DiT를 이용하여 personalized image generation을 수행하는 training-free framework",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "Babes-Bolyai-University-synthetic-data-generation-using-large-language-models-advances-in-text-and-code",
      "date": "2025-03-W03",
      "year": "2025",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Babes-Bolyai University",
      "title": "Synthetic Data Generation Using Large Language Models: Advances in Text and Code",
      "url": "https://arxiv.org/abs/2503.14023",
      "bullets": [
        {
          "text": "low-resource tasks (classification, QA), code-centric applications 발전에 대해 언급",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-new-ways-to-collaborate-and-get-creative-with-gemini",
      "date": "2025-03-W03",
      "year": "2025",
      "month": "3",
      "week": "3",
      "type": "dev",
      "org": "Google",
      "title": "New ways to collaborate and get creative with Gemini",
      "url": "https://blog.google/products/gemini/gemini-collaboration-features/",
      "bullets": [
        {
          "text": "Python, Javascript, HTML 지원",
          "level": 1
        },
        {
          "text": "real-time code collaboration이 가능하지만 multi user는 안됨",
          "level": 1
        },
        {
          "text": "Audio Overview: documents, slides, Deep Research reports를 두 AI host 간의 오디오 팟캐스트로 변환",
          "level": 0
        },
        {
          "text": "웹/앱 지원",
          "level": 1
        },
        {
          "text": "생성물을 다운로드 또는 공유 가능",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "LG-AI-Research-exaone-deep-released-setting-a-new-standard-for-reasoning-ai",
      "date": "2025-03-W03",
      "year": "2025",
      "month": "3",
      "week": "3",
      "type": "dev",
      "org": "LG AI Research",
      "title": "EXAONE Deep Released ━ Setting a New Standard for Reasoning AI",
      "url": "https://www.lgresearch.ai/blog/view?seq=543",
      "bullets": [
        {
          "text": "Notable AI models에 이름을 올린 유일한 한국어 모델",
          "level": 0
        },
        {
          "text": "7.8B & 2.4B 모델도 공개",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Eleuther-AI-rwkv-7-goose-with-expressive-dynamic-state-evolution",
      "date": "2025-03-W03",
      "year": "2025",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Eleuther AI",
      "title": "RWKV-7 \"Goose\" with Expressive Dynamic State Evolution",
      "url": "https://arxiv.org/abs/2503.14456",
      "bullets": [
        {
          "text": "추론 시 토큰마다 필요한 memory usage & inference time이 constant",
          "level": 0
        },
        {
          "text": "3.1T 토큰의 multilingual dataset도 공개",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "METR-measuring-ai-ability-to-complete-long-tasks",
      "date": "2025-03-W03",
      "year": "2025",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "METR",
      "title": "Measuring AI Ability to Complete Long Tasks",
      "url": "https://arxiv.org/abs/2503.14499",
      "bullets": [
        {
          "text": "AI 모델들이 2초에서 8시간까지 걸리는 engineering 태스크 170여 개를 완수",
          "level": 0
        },
        {
          "text": "서베이 결과에 따르면 AI task length는 7개월마다 2배로 증가하고, 현재를 기준으로는 Claude 3.7 Sonnet이 1-hour tasks를 50% 신뢰도로 잘 끝내는 수준이라고 함",
          "level": 0
        },
        {
          "text": "[연구 결과를 정리해놓은 METR posting 링크](https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Shanghai-AI-Lab-ϕ-decoding-adaptive-foresight-sampling-for-balanced-inference-time-exploration-and-exploitation",
      "date": "2025-03-W03",
      "year": "2025",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Shanghai AI Lab",
      "title": "ϕ-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation",
      "url": "https://arxiv.org/abs/2503.13288",
      "bullets": [
        {
          "text": "φ-Decoding: foresight & clustering 을 통해 두 개의 distribution에 approximate → joint distribution으로부터 sampling",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Rice-University-stop-overthinking-a-survey-on-efficient-reasoning-for-large-language-models",
      "date": "2025-03-W03",
      "year": "2025",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Rice University",
      "title": "Stop Overthinking: A Survey on Efficient Reasoning for Large Language Models",
      "url": "https://arxiv.org/abs/2503.16419",
      "bullets": [
        {
          "text": "(1) model-based efficient reasoning: full-length reasoning 모델을 concise reasoning으로 optimize 하거나 애초에 efficient reasoning model을 학습",
          "level": 0
        },
        {
          "text": "(2) reasoning output-based efficient reasoning: 추론 단계에서 reasoning step과 length를 dynamically 조절",
          "level": 0
        },
        {
          "text": "(3) input prompts-based efficient reasoning: 입력 프롬프트의 난이도나 길이를 기준으로 reasoning efficiency를 개선",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "The-Hebrew-University,-IBM,-Yale-survey-on-evaluation-of-llm-based-agents",
      "date": "2025-03-W03",
      "year": "2025",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "The Hebrew University, IBM, Yale",
      "title": "Survey on Evaluation of LLM-based Agents",
      "url": "https://arxiv.org/abs/2503.16416",
      "bullets": [],
      "tags": []
    },
    {
      "id": "University-of-Texas-at-Dallas-a-review-of-deepseek-models-key-innovative-techniques",
      "date": "2025-03-W04",
      "year": "2025",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "University of Texas at Dallas",
      "title": "A Review of DeepSeek Models' Key Innovative Techniques",
      "url": "https://arxiv.org/abs/2503.11486",
      "bullets": [
        {
          "text": "Multi-Head Latent Attention (MLA), Advanced MoE, Multi-Token Prediction (MTP), Grouped Relative Policy Optimization (GRPO) 등",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "ByteDance,-Tsinghua-dapo-an-open-source-llm-reinforcement-learning-system-at-scale",
      "date": "2025-03-W04",
      "year": "2025",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "ByteDance, Tsinghua",
      "title": "DAPO: An Open-Source LLM Reinforcement Learning System at Scale",
      "url": "https://arxiv.org/abs/2503.14476",
      "bullets": [
        {
          "text": "Decoupled Clip and Dynamic sAmpling Policy Optimization (DAPO) 알고리즘 제안",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Hong-Kong,-Peking-towards-hierarchical-multi-step-reward-models-for-enhanced-reasoning-in-large-language-models",
      "date": "2025-03-W04",
      "year": "2025",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Hong Kong, Peking",
      "title": "Towards Hierarchical Multi-Step Reward Models for Enhanced Reasoning in Large Language Models",
      "url": "https://arxiv.org/abs/2503.13551",
      "bullets": [
        {
          "text": "fine-grained & coarse level의 individual & consecutive reasoning step을 평가",
          "level": 0
        },
        {
          "text": "이전 step의 추론이 잘못되어 뒤에 안좋은 영향을 주는 케이스를 특히 잘한다고 보고",
          "level": 0
        },
        {
          "text": "MCTS의 비효율성을 해결하기 위해 Hierarchical Node Compression (HNC) 라는 node merging 기법 제안",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "OpenAI-introducing-next-generation-audio-models-in-the-api",
      "date": "2025-03-W04",
      "year": "2025",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing next-generation audio models in the API",
      "url": "https://openai.com/index/introducing-our-next-generation-audio-models/",
      "bullets": [
        {
          "text": "multi-speaker detection, 대화 시작 & 중단, noisy 환경 등에 대해 훨씬 robust 하다고 설명",
          "level": 0
        },
        {
          "text": "real-time | batch-processing voice agents 구현 가능",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Anthropic-the-think-tool-enabling-claude-to-stop-and-think-in-complex-tool-use-situations",
      "date": "2025-03-W04",
      "year": "2025",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "The \"think\" tool: Enabling Claude to stop and think in complex tool use situations",
      "url": "https://www.anthropic.com/engineering/claude-think-tool",
      "bullets": [
        {
          "text": "말 그대로 tool을 사용하는 schema(API 호출에 필요한)와 이를 위해 최적화된 프롬프트를 안내하고 있음",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "DeepSeek-AI-deepseek-v3-0324",
      "date": "2025-03-W04",
      "year": "2025",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "DeepSeek AI",
      "title": "DeepSeek-V3-0324",
      "url": "https://huggingface.co/deepseek-ai/DeepSeek-V3-0324",
      "bullets": [
        {
          "text": "multi-turn interactive rewriting, translation quality & letter writing, enhances search-based report analysis",
          "level": 0
        },
        {
          "text": "function calling, JSON output, FIM (Fill-in-the-Middle) completion",
          "level": 0
        },
        {
          "text": "허깅페이스에 MIT 라이센스로 공개",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "National-University-of-Singapore,-Nanyang-mars-a-multi-agent-framework-incorporating-socratic-guidance-for-automated-prompt-optimization",
      "date": "2025-03-W04",
      "year": "2025",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "National University of Singapore, Nanyang",
      "title": "MARS: A Multi-Agent Framework Incorporating Socratic Guidance for Automated Prompt Optimization",
      "url": "https://arxiv.org/abs/2503.16874",
      "bullets": [
        {
          "text": "7개의 agent로 구성되어 각각이 autonomously Planner를 사용하여 optimization path를 고안",
          "level": 0
        },
        {
          "text": "또한 Teacher-Critic-Student Socratic dialogue를 사용하여 프롬프트를 iteratively optimize",
          "level": 0
        },
        {
          "text": "이는 기존의 Automated Prompt Optimization (APO)의 한계를 극복하기 위함임",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Google-DeepMind-gemini-25-our-most-intelligent-ai-model",
      "date": "2025-03-W04",
      "year": "2025",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "Gemini 2.5: Our most intelligent AI model",
      "url": "https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025",
      "bullets": [
        {
          "text": "1M token content window. 곧 2M을 지원할 예정",
          "level": 0
        },
        {
          "text": "RAG & document-based workflows에 최적화되어 있다고 언급",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "ARC-AGI-2-+-ARC-Prize-2025-is-Live!-arc-agi-2-arc-prize-2025-is-live",
      "date": "2025-03-W04",
      "year": "2025",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "ARC-AGI-2 + ARC Prize 2025 is Live!",
      "title": "ARC-AGI-2 + ARC Prize 2025 is Live!",
      "url": "https://arcprize.org/blog/announcing-arc-agi-2-and-arc-prize-2025",
      "bullets": [
        {
          "text": "사람에게는 쉽지만 AI에게는 어려운 reasoning task 중심. 이전 challenge보다 더 어렵다고 자체적으로 설명함.",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "OpenAI-introducing-4o-image-generation",
      "date": "2025-03-W04",
      "year": "2025",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing 4o Image Generation",
      "url": "https://openai.com/index/introducing-4o-image-generation",
      "bullets": [
        {
          "text": "trained our models on the joint distribution of online images and text",
          "level": 0
        },
        {
          "text": "→ 이를 통해 이미지와 텍스트가 어떤 식으로 관계되어 있는지를 학습했다고 설명",
          "level": 1
        },
        {
          "text": "ChatGPT, Sora에서 사용 가능하며, 곧 API로도 지원될 예정",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "Tencent-codetool-enhancing-programmatic-tool-invocation-of-llms-via-process-supervision",
      "date": "2025-03-W04",
      "year": "2025",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Tencent",
      "title": "CodeTool: Enhancing Programmatic Tool Invocation of LLMs via Process Supervision",
      "url": "https://arxiv.org/abs/2503.20840",
      "bullets": [
        {
          "text": "(1) On-the-spot Reward: each tool invocation에 대해 immediate feedback 제공",
          "level": 0
        },
        {
          "text": "(2) Latent Reward: 전체적인 task completion에 대해 각 step의 기여를 평가",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Alibaba-qwen25-omni-see-hear-talk-write-do-it-all",
      "date": "2025-03-W04",
      "year": "2025",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "Alibaba",
      "title": "Qwen2.5 Omni: See, Hear, Talk, Write, Do It All!",
      "url": "https://qwenlm.github.io/blog/qwen2.5-omni",
      "bullets": [
        {
          "text": "Think-Talker 아키텍쳐는 speech synthesis에서 reasoning을 분리함으로써 more structured ouputs에 기여",
          "level": 0
        },
        {
          "text": "Thinker는 언어모델로서 reasoning & text generation을 담당",
          "level": 1
        },
        {
          "text": "Talker는 text | direct audio instruction 을 기반으로 speech를 생성",
          "level": 1
        },
        {
          "text": "Block-wise processing을 이용하여 continuous response generation 가능",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "AI2-introducing-ai2-paper-finder",
      "date": "2025-03-W04",
      "year": "2025",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "AI2",
      "title": "Introducing Ai2 Paper Finder",
      "url": "https://allenai.org/blog/paper-finder",
      "bullets": [
        {
          "text": "키워드 대신 자연어 전체 문장을 그대로 입력해도 관련 논문을 찾아줌",
          "level": 0
        },
        {
          "text": "relevance 판단 시 복잡한 질의를 다중 기준으로 분해해 평가하고, citation 기반 확장 탐색도 수행",
          "level": 0
        },
        {
          "text": "빠른 응답이 필요한 경우엔 fast mode, 깊이 있는 탐색이 필요할 땐 iterative exhaustive mode 제공",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-gemma-3-technical-report",
      "date": "2025-03-W04",
      "year": "2025",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Google",
      "title": "Gemma 3 Technical Report",
      "url": "https://arxiv.org/abs/2503.19786",
      "bullets": [
        {
          "text": "vision understanding, 더 많은 언어, longer context (128K)",
          "level": 0
        },
        {
          "text": "local to global attention layer의 비중을 높임으로써 (local의 비중을 높임) KV-cache가 폭발적으로 증가하는 것을 방지",
          "level": 0
        },
        {
          "text": "Gemma 3 모델들은 distillation으로 학습되어pre-trained & instruction finetuned version 둘 다 Gemma 2 성능을 능가",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "Anthropic-tracing-the-thoughts-of-a-large-language-model",
      "date": "2025-03-W04",
      "year": "2025",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "Tracing the thoughts of a large language model",
      "url": "https://www.anthropic.com/research/tracing-thoughts-language-model",
      "bullets": [
        {
          "text": "이를테면 feature activations와 이것이 transformer layers에 걸쳐 미치는 영향을 추적할 수 있음",
          "level": 0
        },
        {
          "text": "Claude는 한 번에 여러 개의 future words를 선택 / shared internal states를 사용하고 이를 다른 언어들에 각각 매핑",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Tencent-reasoning-efficiency-redefined-meet-tencents-hunyuan-t1the-first-mamba-powered-ultra-large-model",
      "date": "2025-03-W04",
      "year": "2025",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "Tencent",
      "title": "Reasoning Efficiency Redefined! Meet Tencent’s 'Hunyuan-T1'—The First Mamba-Powered Ultra-Large Model",
      "url": "https://llm.hunyuan.tencent.com/#/blog/hy-t1?lang=en",
      "bullets": [],
      "tags": []
    },
    {
      "id": "AI-Coder-Reviewer-ai-coder-reviewer",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "dev",
      "org": "AI Coder Reviewer",
      "title": "AI Coder Reviewer",
      "url": "https://github.com/larrydiamond/AICodeReviewer",
      "bullets": [
        {
          "text": "다양한 프로그래밍 언어에 대한 automated code review 지원",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "GIT-large-language-models-think-too-fast-to-explore-effectively",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "paper",
      "org": "GIT",
      "title": "Large Language Models Think Too Fast To Explore Effectively",
      "url": "https://arxiv.org/pdf/2501.18009",
      "bullets": [
        {
          "text": "인간은 uncertainty와 empowerment를 적절히 조절할 수 있는데, 이를 능가하는 건 o1 모델 밖에 없었다고 주장",
          "level": 0
        },
        {
          "text": "Sparse Auto Encoder에 대한 representational 분석 결과에 따르면 uncertainty와 choices는 early layer에서 represented 되는데, empowered values는 later layer에서 처리되어 모델 입장에서는 미성숙한 결정을 내리도록 하는 원인이 된다고 설명 (?)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Mistral-mistral-small-3",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "dev",
      "org": "Mistral",
      "title": "Mistral Small 3",
      "url": "https://mistral.ai/news/mistral-small-3/",
      "bullets": [
        {
          "text": "24B 파라미터, 32K context window, 초당 150 토큰 처리 가능 → 32GB RAM을 가진 RTX 4090 또는 맥북에서 돌릴 수 있음",
          "level": 0
        },
        {
          "text": "합성데이터나 RLHF를 사용하지 않아 추가적인 fine-tuning 하기에 적합한 base 모델이라고 주장",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "AI2-scaling-the-tülu-3-post-training-recipes-to-surpass-the-performance-of-deepseek-v3",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "dev",
      "org": "AI2",
      "title": "Scaling the Tülu 3 post-training recipes to surpass the performance of DeepSeek V3",
      "url": "https://allenai.org/blog/tulu-3-405B",
      "bullets": [
        {
          "text": "오픈소스 모델임에도 불구하고 DeepSeek v4, GPT-4o 수준의 성능 달성",
          "level": 0
        },
        {
          "text": "Reinforcement Learning from Verifiable Rewards (RLVR) 프레임워크가 MATH 성능을 크게 향상시켰다고 설명",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "DeepSeek-deepseekmath-pushing-the-limits-of-mathematical-reasoning-in-open-language-models",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "paper",
      "org": "DeepSeek",
      "title": "DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models",
      "url": "https://arxiv.org/pdf/2402.03300",
      "bullets": [
        {
          "text": "MATH에서 외부 도구의 도움 없이 51.7%를 달성하며 GPT-4, Gemini-Ultra급의 성능을 보임",
          "level": 0
        },
        {
          "text": "web data를 엄선하는 파이프라인 & Group Relative Policy Optimization (GRPO)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-openai-o3-mini",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "dev",
      "org": "OpenAI",
      "title": "OpenAI o3-mini",
      "url": "https://openai.com/index/openai-o3-mini/",
      "bullets": [
        {
          "text": "o1-mini 의 자리를 대신함 (예를 들어 기존 o1-mini API는 o3-mini 로 대체)",
          "level": 0
        },
        {
          "text": "o1과 달리 vision을 지원하지 않음",
          "level": 0
        },
        {
          "text": "설연휴 기간 폭발적인 관심을 얻은 DeepSeek-R1 을 견제하는 움직임으로 해석",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "OpenAI-introducing-deep-research",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing deep research",
      "url": "https://openai.com/index/introducing-deep-research/",
      "bullets": [
        {
          "text": "기존 추론 모델들은 인터넷에 접근하지 못한다는 한계가 있었는데 이를 극복함",
          "level": 0
        },
        {
          "text": "굉장히 난이도가 높은 것으로 알려진 Humanity’s Last Exam에서 26.6% 스코어를 기록함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "HKU,-UC-Berkeley,-Google-DeepMind,-NYU-sft-memorizes-rl-generalizes-a-comparative-study-of-foundation-model-post-training",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "paper",
      "org": "HKU, UC Berkeley, Google DeepMind, NYU",
      "title": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training",
      "url": "https://arxiv.org/pdf/2501.17161v1",
      "bullets": [
        {
          "text": "학습된 모델이 unseen textual & visual domain에서 일반화하는지 확인",
          "level": 0
        },
        {
          "text": "SFT는 단순히 학습 데이터를 암기하는 것이라면 RL은 실제 일반화에 도움이 됨. 단, SFT는 답변의 형식을 유지하는 데 도움이 됨",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Arizona,-UCLA-preference-leakage-a-contamination-problem-in-llm-as-a-judge",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "paper",
      "org": "Arizona, UCLA",
      "title": "Preference Leakage: A Contamination Problem in LLM-as-a-judge",
      "url": "https://arxiv.org/pdf/2502.01534",
      "bullets": [
        {
          "text": "동일 모델, inheritance 관계, model family, 세 가지 유형에 대한 조사",
          "level": 0
        },
        {
          "text": "모델 사이에 명백한 preference leakage가 존재한다고 주장",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Chineses-Academy-of-Sciences-deeprag-thinking-to-retrieval-step-by-step-for-large-language-models",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "paper",
      "org": "Chineses Academy of Sciences",
      "title": "DeepRAG: Thinking to Retrieval Step by Step for Large Language Models",
      "url": "https://arxiv.org/pdf/2502.01142",
      "bullets": [
        {
          "text": "쿼리를 iteratively decompose 함으로써 external knowledge를 retrieve 할지 말지, 혹은 parametric reasoning을 할지를 결정",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Google-gemini-20-is-now-available-to-everyone",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "dev",
      "org": "Google",
      "title": "Gemini 2.0 is now available to everyone",
      "url": "https://blog.google/technology/google-deepmind/gemini-model-updates-february-2025/",
      "bullets": [
        {
          "text": "Flash, Flash-Lite 모델은 1M context window, Pro Experimental 모델은 2M context window를 지님",
          "level": 0
        },
        {
          "text": "1.5 Flash 대비 cost & latency 증가하지 않으면서도 고품질 답변을 생성",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Anthropic-constitutional-classifiers-defending-against-universal-jailbreaks",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "dev",
      "org": "Anthropic",
      "title": "Constitutional Classifiers: Defending against universal jailbreaks",
      "url": "https://www.anthropic.com/research/constitutional-classifiers",
      "bullets": [
        {
          "text": "일반적인 jailbreaks를 수천 시간 시도했음에도 불구하고 robust 결과를 보여줬다고 설명",
          "level": 0
        },
        {
          "text": "그럼에도 불구하고 무지성 거절(refusal rates)의 비율은 단 0.38% 밖에 증가하지 않았음",
          "level": 0
        },
        {
          "text": "8개 레벨의 jailbreaking demo를 뚫는 사람에게는 $10,000를, 일반적인 jailbreaking strategy로 뚫는 사람에게는 $20,000를 수여하는 [HackerOne](https://hackerone.com/constitutional-classifiers?type=team) 개최중",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-open-source-deepresearch-freeing-our-search-agents",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "dev",
      "org": "HuggingFace",
      "title": "Open-source DeepResearch – Freeing our search agents",
      "url": "https://huggingface.co/blog/open-deep-research",
      "bullets": [
        {
          "text": "Deep Research가 GAIA 벤치마크에서 높은 성능을 달성한 것을 언급",
          "level": 0
        },
        {
          "text": "CodeAgent 를 사용하여 복잡한 sequences of actions를 디자인할 수 있다고 설명",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "OpenAI-introducing-chatgpt-search",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing ChatGPT search",
      "url": "https://openai.com/index/introducing-chatgpt-search/",
      "bullets": [
        {
          "text": "[크롬 확장프로그램](https://chromewebstore.google.com/detail/chatgpt-search/ejcfepkfckglbgocfkanmcdngdijcgld)을 통해 default 검색 엔진을 ChatGPT search로 설정할 수도 있음",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Stanford,-Washington,-AI2-s1-simple-test-time-scaling",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "paper",
      "org": "Stanford, Washington, AI2",
      "title": "s1: Simple test-time scaling",
      "url": "https://arxiv.org/pdf/2501.19393",
      "bullets": [
        {
          "text": "s1K: 세 개의 기준(difficulty, diversity, quality)으로 검증한 reasoning taces를 포함한 데이터셋",
          "level": 0
        },
        {
          "text": "budget forcing: 모델이 답변을 끝내려고 할 때, test-time compute를 강제로 중단하거나 늘리기 위해서 “Wait” 키워드를 여러 차례 붙이는 방법론",
          "level": 0
        },
        {
          "text": "Qwen2.5-32B-Instruct 모델에 s1K 학습 한 s1-32B 모델에 budget forcing 장착하니 수학 능력 크게 향상",
          "level": 0
        },
        {
          "text": "모델, 데이터, 코드는 오픈소스로 [깃허브](https://github.com/simplescaling/s1)에 공개 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Ai2-ai2-scholar-qa-beta",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "dev",
      "org": "Ai2",
      "title": "Ai2 Scholar QA beta",
      "url": "https://scholarqa.allen.ai/",
      "bullets": [
        {
          "text": "Section Planning and Generation, Paper Comparison Table Generation 등의 특징",
          "level": 0
        },
        {
          "text": "[블로그 포스팅](https://allenai.org/blog/ai2-scholarqa)(Introducing Ai2 ScholarQA) 참고",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-smollm2-when-smol-goes-big-data-centric-training-of-a-small-language-model",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "paper",
      "org": "HuggingFace",
      "title": "SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model",
      "url": "https://arxiv.org/pdf/2502.02737",
      "bullets": [
        {
          "text": "multi-stage training process를 통해 math, code, instruction-following data를 web-text와 혼합하여 약 11T 토큰 학습",
          "level": 0
        },
        {
          "text": "new specialized datasets 도입 (Fine-Math, Stack-Edu, SmolTalk): 기존 데이터셋이 너무 작거나 품질이 낮았던 이슈를 해결하기 위함",
          "level": 0
        },
        {
          "text": "비슷한 사이즈 수준의 모델들(Qwen2.5-1.5B, Llama3.2-1B) 중에서는 SoTA급 성능을 달성했다고 보고",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "T-Tech-analyze-feature-flow-to-enhance-interpretation-and-steering-in-language-models",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "paper",
      "org": "T-Tech",
      "title": "Analyze Feature Flow to Enhance Interpretation and Steering in Language Models",
      "url": "https://arxiv.org/abs/2502.03032",
      "bullets": [
        {
          "text": "data-free cosine similarity technique: 특정 features가 얼마나 persists, transform, first appear 하는지 등을 파악",
          "level": 0
        },
        {
          "text": "이를 통해 model computation에 대한 interpretability & mechanistic insights 획득 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Shanghai-AI-Lab,-Peking-ultraif-advancing-instruction-following-from-the-wild",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "paper",
      "org": "Shanghai AI Lab, Peking",
      "title": "UltraIF: Advancing Instruction Following from the Wild",
      "url": "https://arxiv.org/pdf/2502.04153",
      "bullets": [
        {
          "text": "이를 위해 UltraComposer를 constraint-associated prompts & evaluation questions 묶어서 학습",
          "level": 0
        },
        {
          "text": "8B 사이즈의 모델을 response generator & evaluator로 사용했을 때에도 유의미한 성능 향상이 있었다고 보고",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Mistral-the-all-new-le-chat-your-ai-assistant-for-life-and-work",
      "date": "2025-02-W01",
      "year": "2025",
      "month": "2",
      "week": "1",
      "type": "dev",
      "org": "Mistral",
      "title": "The all new le Chat: Your AI assistant for life and work",
      "url": "https://mistral.ai/en/news/all-new-le-chat",
      "bullets": [
        {
          "text": "Flash Answers, a build-in code interpreter, real-time search 등을 주요 특징으로 내세움",
          "level": 0
        },
        {
          "text": "Flash Answers의 경우 초당 1,000개 정도의 단어를 생성할 수 있다는 특징인데 데모상으로는 확실히 타사 서비스(ChatGPT, Claude)에 비해 압도적으로 빠름",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Nanjing-Univ.-step-back-to-leap-forward-self-backtracking-for-boosting-reasoning-of-language-models",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "paper",
      "org": "Nanjing Univ.",
      "title": "Step Back to Leap Forward: Self-Backtracking for Boosting Reasoning of Language Models",
      "url": "https://arxiv.org/pdf/2502.04404",
      "bullets": [
        {
          "text": "이를 해결하기 위해 LLM이 자율적으로 언제, 어디서 backtrack 할 것인지를 결정하도록 하면 된다고 주장 (like in traditional search algorithms)",
          "level": 0
        },
        {
          "text": "이를 위한 self-backtracking mechanism을 제시: 학습 & 추론 에서 backtrack 가능",
          "level": 0
        },
        {
          "text": "이는 optimal-path supervised fine-tuning method 대비 40% 정도의 성능 gain이 있다고 하는데 왜 그것과 비교하는지는 잘 모르겠음.",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "SJTU-limo-less-is-more-for-reasoning",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "paper",
      "org": "SJTU",
      "title": "LIMO: Less is More for Reasoning",
      "url": "https://arxiv.org/pdf/2502.03387",
      "bullets": [
        {
          "text": "이는 supervised fine-tuning이 generalization 보다는 memorization으로 이어진다는 주장과도 상반되는 결과",
          "level": 0
        },
        {
          "text": "817개의 curated training samples로 학습한 LIMO를 기반으로 LIMO Hypothesis 주장",
          "level": 0
        },
        {
          "text": "사전학습 단계에서 domain knowledge가 충분히 encoded 되었다면, 정교한 추론 능력은 최소한의 cognitive process를 포함하는 데이터로도 획득할 수 있다",
          "level": 1
        },
        {
          "text": "이를 위해서는 (1) 모델이 pre-training 동안 획득한 knowledge (2) post-training examples의 effectiveness가 중요",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Harvard-datagovarchive",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "dev",
      "org": "Harvard",
      "title": "Data.govArchive",
      "url": "https://lil.law.harvard.edu/blog/2025/02/06/announcing-data-gov-archive/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Apple-elegnt-expressive-and-functional-movement-design-for-non-anthropomorphic-robot",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "paper",
      "org": "Apple",
      "title": "ELEGNT: Expressive and Functional Movement Design for Non-anthropomorphic Robot",
      "url": "https://arxiv.org/pdf/2501.12493",
      "bullets": [
        {
          "text": "expressive: intention, attention, emotions",
          "level": 1
        },
        {
          "text": "functional: task fulfillment, spatial constraints, time efficiency",
          "level": 1
        },
        {
          "text": "posture, gesture, gaze 등의 비언어적 행동들이 internal state를 의식적으로 & 무의식적으로 표현하는 것이기 때문에 이를 (램프처럼 생긴) 로봇의 행동(movements) 결정에 반영하겠다는 연구",
          "level": 0
        },
        {
          "text": "expression-driven movements가 function-drive movements보다 낫다는 연구 결과를 제시",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-π0-and-π0-fast-vision-language-action-models-for-general-robot-control",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "dev",
      "org": "HuggingFace",
      "title": "π0 and π0-FAST: Vision-Language-Action Models for General Robot Control",
      "url": "https://huggingface.co/blog/pi0",
      "bullets": [
        {
          "text": "이러한 유형의 모델을 Vision-Language-Action 모델이라고 부르는 듯 (VLA)",
          "level": 0
        },
        {
          "text": "설치부터 학습까지 상세한 코드 예시를 통해 설명하는 허깅페이스 블로그 포스팅",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "ISTA-quest-stable-training-of-llms-with-1-bit-weights-and-activations",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "paper",
      "org": "ISTA",
      "title": "QuEST: Stable Training of LLMs with 1-Bit Weights and Activations",
      "url": "https://arxiv.org/abs/2502.05003",
      "bullets": [
        {
          "text": "QeEST: 학습 모델의 weights & activations를 4-bit 혹은 그 이하로 학습하며 FP16과 유사한 수준의 성능 기록. 심지어 1-bit에서도 안정적으로 학습 가능하다고 설명.",
          "level": 0
        },
        {
          "text": "이는 (1) normalization 과정에서 weights & activations의 continuous distribution을 유지하여 quantization (2) 새로운 trust gradient estimator를 제시 했기에 가능했다고 함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Ben-Gurion-Univ.-forget-what-you-know-about-llms-evaluations-llms-are-like-a-chameleon",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "paper",
      "org": "Ben Gurion Univ.",
      "title": "Forget What You Know about LLMs Evaluations - LLMs are Like a Chameleon",
      "url": "https://arxiv.org/pdf/2502.07445",
      "bullets": [
        {
          "text": "학습 파이프라인에 integrate하여 robust language model을 만드는 데 기여 가능",
          "level": 0
        },
        {
          "text": "모델 성능이 memorized pattern에 의해 좋게 나온 것인지 아닌지를 판단하는 것이 중점",
          "level": 0
        },
        {
          "text": "예상 외로 성능이 높은 모델들이 perturbation에 의한 성능 degradation이 심했다고 보고",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "AIRI-synthdetoxm-modern-llms-are-few-shot-parallel-detoxification-data-annotators",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "paper",
      "org": "AIRI",
      "title": "SynthDetoxM: Modern LLMs are Few-Shot Parallel Detoxification Data Annotators",
      "url": "https://arxiv.org/abs/2502.06394",
      "bullets": [
        {
          "text": "SytnDetoxM: manually & synthetically 생성된 multilingual parallel detoxification dataset, 16K 개의 데이터로 구성",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Shanghai-AI-Lab-can-1b-llm-surpass-405b-llm-rethinking-compute-optimal-test-time-scaling",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "paper",
      "org": "Shanghai AI Lab",
      "title": "Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling",
      "url": "https://arxiv.org/abs/2502.06703",
      "bullets": [
        {
          "text": "compute-optimal TTS를 이용하면 극도로 작은 reward model (< 1B)로도 엄청나게 사이즈가 큰 (> 405B or GPT-4o) 모델의 성능을 넘어서는 것이 가능하다고 주장",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://ryanliu112.github.io/compute-optimal-tts) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-sam-altman-reveals-gpt-5-will-merge-o-series-models-removing-manual-model-selection",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "dev",
      "org": "OpenAI",
      "title": "Sam Altman reveals GPT-5 will merge o-series models, removing manual model selection",
      "url": "https://x.com/sama/status/1889755723078443244",
      "bullets": [
        {
          "text": "reasoning 모델은 별도로 출시되지 않고 GPT-5에 통합",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Anthropic-the-anthropic-economic-index",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "dev",
      "org": "Anthropic",
      "title": "The Anthropic Economic Index",
      "url": "https://www.anthropic.com/news/the-anthropic-economic-index",
      "bullets": [
        {
          "text": "automation의 43%가 AI를 활용한 결과임을 보고",
          "level": 0
        },
        {
          "text": "[paper link](https://assets.anthropic.com/m/2e23255f1e84ca97/original/Economic_Tasks_AI_Paper.pdf) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Oxford-distillation-scaling-laws",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "paper",
      "org": "Oxford",
      "title": "Distillation Scaling Laws",
      "url": "https://arxiv.org/abs/2502.08606",
      "bullets": [
        {
          "text": "(1) teacher가 존재할 때 (2) teacher 학습이 필요할 때로 구분하여 연구 결과 제시",
          "level": 0
        },
        {
          "text": "결국 distillation 과정에서 student 모델 뿐만 아니라 teacher 모델의 cross entropy loss를 함께 살피며 적절히 scaling 하는 것이 중요하다는 점을 언급하는 것으로 보임",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Imperial-College-London,-Cohere-llms-can-implicitly-learn-from-mistakes-in-context",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "paper",
      "org": "Imperial College London, Cohere",
      "title": "LLMs can implicitly learn from mistakes in-context",
      "url": "https://arxiv.org/abs/2502.08550",
      "bullets": [
        {
          "text": "실험 결과에 따르면 incorrect answer를 correct answer와 함께 보여주는 것만으로도 성능 향상이 있었다고 함. CoT의 성능도 boosting 가능.",
          "level": 0
        },
        {
          "text": "LLM이 in-context implicit learning 할 수 있다는 결론",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Amazon,-UCLA-do-llms-recognize-your-preferences-evaluating-personalized-preference-following-in-llms",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "paper",
      "org": "Amazon, UCLA",
      "title": "Do LLMs Recognize Your Preferences? Evaluating Personalized Preference Following in LLMs",
      "url": "https://arxiv.org/abs/2502.09597",
      "bullets": [
        {
          "text": "3,000개의 엄선된 preference & query pair, 20개 주제 커버",
          "level": 0
        },
        {
          "text": "최대 100k 토큰 context에 해당하는 multi-session conversation으로 평가",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://prefeval.github.io/) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta,-KAIST,-UC-San-Diego-llm-pretraining-with-continuous-concepts",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "paper",
      "org": "Meta, KAIST, UC San Diego",
      "title": "LLM Pretraining with Continuous Concepts",
      "url": "https://arxiv.org/abs/2502.08524",
      "bullets": [
        {
          "text": "CoCoMix는 사전학습된 sparse autoencoder로부터 “continuous concepts”를 학습하여 예측하고, 모델의 hidden state와 token의 hidden state을 interleave",
          "level": 0
        },
        {
          "text": "단순 next token prediction에 비해 sample efficient 하면서도 consistently 성능이 높았다고 설명",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "University-of-Hong-Kong,-ByteDance-goku-flow-based-video-generative-foundation-models",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "paper",
      "org": "University of Hong Kong, ByteDance",
      "title": "Goku: Flow Based Video Generative Foundation Models",
      "url": "https://arxiv.org/abs/2502.04896",
      "bullets": [
        {
          "text": "rectified flow Transformer를 이용하여 만든 joint image-and-video generation 중에서 SoTA model failmily",
          "level": 0
        },
        {
          "text": "data curation pipeline, model architecture design, flow formulation, advanced infrastructure for efficient and robust large-scale training 공개",
          "level": 0
        },
        {
          "text": "주요 tasks의 정량 & 정성 평가 가장 높은 결과를 받았다고 설명",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "SNU,-Cornell-skrr-skip-and-re-use-text-encoder-layers-for-memory-efficient-text-to-image-generation",
      "date": "2025-02-W02",
      "year": "2025",
      "month": "2",
      "week": "2",
      "type": "paper",
      "org": "SNU, Cornell",
      "title": "Skrr: Skip and Re-use Text Encoder Layers for Memory Efficient Text-to-Image Generation",
      "url": "https://arxiv.org/abs/2502.08690",
      "bullets": [
        {
          "text": "Skrr (Skip and Re-use layers): T2I diffusion 모델에서 text encoder를 효율적으로 pruning 하는 strategy",
          "level": 0
        },
        {
          "text": "transformer block을 selectively skipping하거나 일부 layer를 reusing함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Convergence-Labs-lm2-large-memory-models",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "paper",
      "org": "Convergence Labs",
      "title": "LM2: Large Memory Models",
      "url": "https://arxiv.org/abs/2502.06049",
      "bullets": [
        {
          "text": "input token과 cross attention 하며 gating mechanism을 통해 update",
          "level": 0
        },
        {
          "text": "일반적인 벤치마크에서도 좋은 성능을 유지하고 multi-hop 에서도 뛰어난 발전이 있었다고 보고",
          "level": 0
        },
        {
          "text": "interpretability, test-time behavior 등에서도 장점이 있음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "ELLIS-Institute-Tübingen-scaling-up-test-time-compute-with-latent-reasoning-a-recurrent-depth-approach",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "paper",
      "org": "ELLIS Institute Tübingen",
      "title": "Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach",
      "url": "https://arxiv.org/abs/2502.05171",
      "bullets": [
        {
          "text": "CoT에 의존하지 않아 specialized training data가 필요하지 않고, 심지어 small context window에서도 working",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Meta-AI-brain-to-text-decoding-a-non-invasive-approach-via-typing",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "paper",
      "org": "Meta AI",
      "title": "Brain-to-Text Decoding: A Non-invasive Approach via Typing",
      "url": "https://ai.meta.com/research/publications/brain-to-text-decoding-a-non-invasive-approach-via-typing/",
      "bullets": [
        {
          "text": "기존 방식들은 invasive device를 활용하는데 이와 다른 non-invasive 방식이며 둘 사이의 gap을 줄인 데 의의가 있다고 설명",
          "level": 0
        },
        {
          "text": "character-error-rate (CER)은 32%로 67%의 error rate를 보이는 EEG 대비 큰 성능 향상이 있었다고 보고",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "University-of-California,-Berkeley-llms-can-easily-learn-to-reason-from-demonstrations-structure-not-content-is-what-matters",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "paper",
      "org": "University of California, Berkeley",
      "title": "LLMs Can Easily Learn to Reason from Demonstrations Structure, not content, is what matters!",
      "url": "https://arxiv.org/abs/2502.07374",
      "bullets": [
        {
          "text": "Qwen2.5-32B 모델을 17k CoT Training sample로 학습한 결과를 리포트",
          "level": 0
        },
        {
          "text": "reasoning step의 각 내용보다는 Long CoT의 structure가 학습 과정에 훨씬 더 큰 영향을 미친다고 주장 (logical consistency가 중요!)",
          "level": 0
        },
        {
          "text": "저자가 이전에 공개한 Sky-T1-32B-Preview model의 academic paper",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "NYU,-Tubingen-do-large-language-models-reason-causally-like-us-even-better",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "paper",
      "org": "NYU, Tubingen",
      "title": "Do Large Language Models Reason Causally Like Us? Even Better?",
      "url": "https://arxiv.org/abs/2502.10215",
      "bullets": [
        {
          "text": "본 논문에서는 from human-like to normative inference 라고 scale을 표현함",
          "level": 0
        },
        {
          "text": "실험한 4개의 모델 중에서 GPT-4o, Claude는 가장 normative behavior를 강하게 보였고 나머지인 Gemini-Pro와 GPT-3.5는 그렇지 않았다고 설명",
          "level": 0
        },
        {
          "text": "사람이 내놓는 답변도 실제로 이해한 내용을 바탕으로 나오는 것인지 판단하는 기준이 있긴 한가?",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Perplexity-introducing-perplexity-deep-research",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "dev",
      "org": "Perplexity",
      "title": "Introducing Perplexity Deep Research",
      "url": "https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research",
      "bullets": [
        {
          "text": "finance, marketing부터 product research까지 다양한 범위의 태스크를 expert 수준으로 처리",
          "level": 0
        },
        {
          "text": "최종 report를 PDF 또는 문서 형태로 export하거나 Perplexity Page로 변환하여 공유할 수 있음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Renmin-Univ.-of-China-large-language-diffusion-models",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "paper",
      "org": "Renmin Univ. of China",
      "title": "Large Language Diffusion Models",
      "url": "https://arxiv.org/abs/2502.09992",
      "bullets": [
        {
          "text": "self-constructed Autoregressive Models 성능과 scalability가 뛰어나다고 주장",
          "level": 0
        },
        {
          "text": "forward data masking process & reverse process를 통해 Transformer가 masked token 예측하는 것처럼 분포를 모델링",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Virginia-Tech,-Oxford-towards-reasoning-ability-of-small-language-models",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "paper",
      "org": "Virginia Tech, Oxford",
      "title": "Towards Reasoning Ability of Small Language Models",
      "url": "https://arxiv.org/abs/2502.11569",
      "bullets": [
        {
          "text": "4개의 평가 method와 4개의 LLM을 judge로 사용하며 실험은 3번씩 반복",
          "level": 0
        },
        {
          "text": "adversarial conditions와 intermediate reasoning steps 또한 평가",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "xAI-grok-3-beta-the-age-of-reasoning-agents",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "dev",
      "org": "xAI",
      "title": "Grok 3 Beta — The Age of Reasoning Agents",
      "url": "https://x.ai/blog/grok-3",
      "bullets": [
        {
          "text": "logical processing을 위한 Think Mode, complex problem-solving을 위한 Big Brain Mode",
          "level": 0
        },
        {
          "text": "faster query processing을 위해 H100 20만대 사용 (전작 대비 10x 이상)",
          "level": 0
        },
        {
          "text": "Grok 3는 X Premium Plus 구독자들 사용 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "DeepSeek,-Peking,-Washington-native-sparse-attention-hardware-aligned-and-natively-trainable-sparse-attention",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "paper",
      "org": "DeepSeek, Peking, Washington",
      "title": "Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention",
      "url": "https://arxiv.org/abs/2502.11089",
      "bullets": [
        {
          "text": "현재 GPU에 최적화가 잘되어 있음 & end-to-end training",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Microsoft-omniparser-v2-turning-any-llm-into-a-computer-use-agent",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "dev",
      "org": "Microsoft",
      "title": "OmniParser V2: Turning Any LLM into a Computer Use Agent",
      "url": "https://www.microsoft.com/en-us/research/articles/omniparser-v2-turning-any-llm-into-a-computer-use-agent/",
      "bullets": [
        {
          "text": "a large set of interactive element detection data & icon functional caption data 로 학습",
          "level": 0
        },
        {
          "text": "ScreenSpot Pro 라는 벤치마크에서 높은 성능을 기록했다고 보고",
          "level": 0
        },
        {
          "text": "OmniTool: agents를 위한 tool를 포함하는 dockerized Windows system",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Michigan,-Amazon,-Pennsylvania-stepwise-perplexity-guided-refinement-for-efficient-chain-of-thought-reasoning-in-large-language-models",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "paper",
      "org": "Michigan, Amazon, Pennsylvania",
      "title": "Stepwise Perplexity-Guided Refinement for Efficient Chain-of-Thought Reasoning in Large Language Models",
      "url": "https://arxiv.org/abs/2502.13260",
      "bullets": [
        {
          "text": "이를 해결하기 위해 perplexity를 importance 지표로 삼는 method 제안",
          "level": 0
        },
        {
          "text": "특정 step을 제거했을 때 perplexity가 증가한다면 모델의 입장에서 중요도가 높은 것",
          "level": 1
        },
        {
          "text": "few-shot CoT 내의 sample 중 불필요한 것들을 제거 or 살아남은(critical) steps만으로 fine-tuning 하는 방법으로 활용 가능",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "AIRI-cramming-1568-tokens-into-a-single-vector-and-back-again-exploring-the-limits-of-embedding-space-capacity",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "paper",
      "org": "AIRI",
      "title": "Cramming 1568 Tokens into a Single Vector and Back Again: Exploring the Limits of Embedding Space Capacity",
      "url": "https://arxiv.org/abs/2502.13063",
      "bullets": [
        {
          "text": "본 연구에서는 1500x 이상의 compression rate를 달성했다고 주장",
          "level": 0
        },
        {
          "text": "compression에서 중요한 것은 input의 길이가 아닌 줄어들 uncertainty의 양이라고 설명",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-Research-accelerating-scientific-breakthroughs-with-an-ai-co-scientist",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "dev",
      "org": "Google Research",
      "title": "Accelerating scientific breakthroughs with an AI co-scientist",
      "url": "https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/",
      "bullets": [
        {
          "text": "Supervisor agent가 6개의 specialized agents에 tasks 할당",
          "level": 0
        },
        {
          "text": "Generation, Reflection, Ranking, Evolution, Proximity, Meta-review",
          "level": 1
        },
        {
          "text": "[paper link](https://storage.googleapis.com/coscientist_paper/ai_coscientist.pdf) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Sakana-AI-the-ai-cuda-engineer-agentic-cuda-kernel-discovery-optimization-and-composition",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "dev",
      "org": "Sakana AI",
      "title": "The AI CUDA Engineer: Agentic CUDA Kernel Discovery, Optimization and Composition",
      "url": "https://sakana.ai/ai-cuda-engineer/",
      "bullets": [
        {
          "text": "PyTorch code를 CUDA kernel용으로 변환 → evolutionary meta-generation을 거쳐 runtime performance optimize",
          "level": 0
        },
        {
          "text": "250개의 테스트에서 186개의 태스크의 처리 속도를 평균(median) 1.52x 향상시켰다고 보고",
          "level": 0
        },
        {
          "text": "[paper link](https://pub.sakana.ai/static/paper.pdf) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta-mlgym-a-new-framework-and-benchmark-for-advancing-ai-research-agents",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "paper",
      "org": "Meta",
      "title": "MLGym: A New Framework and Benchmark for Advancing AI Research Agents",
      "url": "https://arxiv.org/abs/2502.14499",
      "bullets": [
        {
          "text": "벤치마크는 CV, NLP, RL, Game Theory에 관한 13개의 tasks로 구성",
          "level": 0
        },
        {
          "text": "프레임워크는 여기에 새로운 태스크를 추가 및 통합하는 것을 도와줌",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "The-Univ.-of-Melbourne-line-goes-up-inherent-limitations-of-benchmarks-for-evaluating-large-language-models",
      "date": "2025-02-W03",
      "year": "2025",
      "month": "2",
      "week": "3",
      "type": "paper",
      "org": "The Univ. of Melbourne",
      "title": "Line Goes Up? Inherent Limitations of Benchmarks for Evaluating Large Language Models",
      "url": "https://arxiv.org/abs/2502.14318",
      "bullets": [
        {
          "text": "adversarial stimuli & interpretability techniques 로 평가 시 여러 언어와 reasoning tasks에서 not robust한 결과를 보였다고 설명",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "StepFun,-Tsinghua-open-reasoner-zero",
      "date": "2025-02-W04",
      "year": "2025",
      "month": "2",
      "week": "4",
      "type": "dev",
      "org": "StepFun, Tsinghua",
      "title": "Open-Reasoner-Zero",
      "url": "https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero/tree/main",
      "bullets": [
        {
          "text": "minimalist approach: vanilla PPO with GAE & rule-based reward function / w/o KL regularization",
          "level": 0
        },
        {
          "text": "1/30 training steps만으로도 DeepSeek-R1-Zero-Qwen-32B를 GPQA Diamond Bench에서 우세",
          "level": 0
        },
        {
          "text": "[paper link](https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero/blob/main/ORZ_paper.pdf) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "1X-introducing-neo-gamma",
      "date": "2025-02-W04",
      "year": "2025",
      "month": "2",
      "week": "4",
      "type": "news",
      "org": "1X",
      "title": "Introducing NEO Gamma",
      "url": "https://x.com/1x_tech/status/1893012909082714299?t=7ZkJZCYGS0-7aFRSU_cRTw&s=19",
      "bullets": [
        {
          "text": "“companion” 포지션으로 가정 환경에서 자연스러운 움직임을 보여줌 (링크 데모 참고)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Alibaba-qwen25-vl-technical-report",
      "date": "2025-02-W04",
      "year": "2025",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "Alibaba",
      "title": "Qwen2.5-VL Technical Report",
      "url": "https://arxiv.org/abs/2502.13923",
      "bullets": [
        {
          "text": "objects를 식별할 때 bounding box를 치거나 point를 정확하게 파악하는 점이 특징",
          "level": 0
        },
        {
          "text": "dynamic resolution processing & absolute time encoding 도입 → 다양한 사이즈의 이미지, long-video 처리 가능",
          "level": 0
        },
        {
          "text": "task-specific fine-tuning 없이도 다양한 domain에 robust performance를 보인다고 주장",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Arizona,-UCLA,-Notre-Dame,-UIUC-preference-leakage-a-contamination-problem-in-llm-as-a-judge",
      "date": "2025-02-W04",
      "year": "2025",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "Arizona, UCLA, Notre Dame, UIUC",
      "title": "Preference Leakage: A Contamination Problem in LLM-as-a-judge",
      "url": "https://arxiv.org/abs/2502.01534",
      "bullets": [
        {
          "text": "(1) being the same model (2) having an inheritance relationship (3) belonging to the same model family",
          "level": 0
        },
        {
          "text": "여러 LLM baselines와 benchmarks를 통해 관계에 따른 judge bias가 존재한다는 것을 empirically 확인 (preference leakage)",
          "level": 0
        },
        {
          "text": "그렇다면 데이터를 생성할 땐 다양한 LLM을 활용해야 하는 것 아닐까?",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Anthropic-claude-37-sonnet-and-claude-code",
      "date": "2025-02-W04",
      "year": "2025",
      "month": "2",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "Claude 3.7 Sonnet and Claude Code",
      "url": "https://www.anthropic.com/news/claude-3-7-sonnet",
      "bullets": [
        {
          "text": "thinking mode의 context length 128K 까지 확장",
          "level": 1
        },
        {
          "text": "API를 통해 thinking time도 조절 가능",
          "level": 1
        },
        {
          "text": "Claude Code: CLI AI coding assistant",
          "level": 0
        },
        {
          "text": "repository search, edit files, commits to Github 기능 지원",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "AI2-efficient-pdf-text-extraction-with-vision-language-models",
      "date": "2025-02-W04",
      "year": "2025",
      "month": "2",
      "week": "4",
      "type": "dev",
      "org": "AI2",
      "title": "Efficient PDF Text Extraction with Vision Language Models",
      "url": "https://olmocr.allenai.org/blog",
      "bullets": [
        {
          "text": "다양한 종류의 PDF에 대해 250,000장 fine-tune",
          "level": 0
        },
        {
          "text": "1M PDF pages당 $190 → GPT-4o API batch 대비 32배 저렴하다고 소개",
          "level": 0
        },
        {
          "text": "markdown 형태로 output 반환",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Alibaba-wan-21-leading-ai-video-generation-model-wanx-21",
      "date": "2025-02-W04",
      "year": "2025",
      "month": "2",
      "week": "4",
      "type": "dev",
      "org": "Alibaba",
      "title": "Wan 2.1: Leading AI Video Generation Model (Wanx 2.1)",
      "url": "https://wan21ai.com/",
      "bullets": [
        {
          "text": "T2V-1.3B, 14B 두 개 version으로 공개",
          "level": 0
        },
        {
          "text": "[허깅페이스](https://link.mail.beehiiv.com/ss/c/u001.ae3tPPqcD9LGEYY83-FJncrD8ENm5PQsonneGdCHnxpYCBUd3DooBT-uAsUQv9d_7B6796SyxaZC5XlWLw2yks9-yh44CzsyG9aF9Y4BXbbjYV7DwNgb9DWcQzerqUJ6_qsJSy3ym_emk857Gd43TC4rnNFUCXCVn6a2j36w2YCGgKN4QcOGW4pnMCTsFBswBeXMutzsdhvlGL0oZVpPPgnt3pEFI0nr9tXunNcy3Q-fmCgU7bfh34Z3A-dbnaux/4ec/gOpmFuORQEitDMXINqB7DQ/h8/h001.KtK7dRp01Nh9ppRdnZE0pLbWXx3mSv_Exs3IcfSagzA)를 비롯한 다양한 플랫폼에서 이용 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-get-coding-help-from-gemini-code-assist-now-for-free",
      "date": "2025-02-W04",
      "year": "2025",
      "month": "2",
      "week": "4",
      "type": "dev",
      "org": "Google",
      "title": "Get coding help from Gemini Code Assist — now for free",
      "url": "https://blog.google/technology/developers/gemini-code-assist-free/",
      "bullets": [
        {
          "text": "Gemini 2.0으로 지원하며 월 180,000개의 code completions 지원 (GitHub Copilot free tier 대비 20배 많은 양)",
          "level": 0
        },
        {
          "text": "128K context window를 바탕으로 complex code base에 대한 이해 가능",
          "level": 0
        },
        {
          "text": "코드 내 stylistic issues and bugs 등을 automatically 탐지 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Kakao-kanana-compute-efficient-bilingual-language-models",
      "date": "2025-02-W04",
      "year": "2025",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "Kakao",
      "title": "Kanana: Compute-efficient Bilingual Language Models",
      "url": "https://arxiv.org/abs/2502.18934",
      "bullets": [
        {
          "text": "high quality data filtering, staged pre-training, depth up-scaling, pruning, distillation",
          "level": 0
        },
        {
          "text": "특히 Kanana models를 post-training 하는 과정에서 사용된 방법론들을 보고",
          "level": 0
        },
        {
          "text": "2.1B ~ 32.5B 사이즈의 모델들로 구성되어 있고, 2.1B 모델은 공개",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Amazon-introducing-alexa-the-next-generation-of-alexa",
      "date": "2025-02-W04",
      "year": "2025",
      "month": "2",
      "week": "4",
      "type": "dev",
      "org": "Amazon",
      "title": "Introducing Alexa+, the next generation of Alexa",
      "url": "https://www.aboutamazon.com/news/devices/new-alexa-generative-artificial-intelligence",
      "bullets": [
        {
          "text": "Amazon’s Nova & Anthropic’s Claude를 비롯한 여러 개의 foundational LLMs를 각 태스크에 가장 적합하게 활용",
          "level": 0
        },
        {
          "text": "도메인별 experts를 활용하는 개념. 개인 맞춤화된 특징들을 지원 (유저 히스토리 기반)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta,-UIUC,-CMU-swe-rl-advancing-llm-reasoning-via-reinforcement-learning-on-open-software-evolution",
      "date": "2025-02-W04",
      "year": "2025",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "Meta, UIUC, CMU",
      "title": "SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution",
      "url": "https://arxiv.org/abs/2502.18449",
      "bullets": [
        {
          "text": "DeepSeek-R1 같은 모델들은 코딩 테스트를 위한 문제들처럼 실행하기 쉽고 real-world와는 동떨어진 코드들로 학습되었다는 한계를 지적",
          "level": 1
        },
        {
          "text": "open-source software evolution data로부터 실제 개발자들의 reasoning processes & solutions를 autonomously 학습",
          "level": 0
        },
        {
          "text": "GitHub Pull Requests Dataset Curation (4.6M repositories)",
          "level": 1
        },
        {
          "text": "lightweight rule-based reward를 leverage",
          "level": 1
        },
        {
          "text": "Llama3-SWE-RL-70B 모델이 SWE-bench Verified에서 41.0% 성능을 달성",
          "level": 0
        },
        {
          "text": "이는 100B 이하의 오픈소스 모델 중에서 유일하게 GPT-4o에 견줄 수 있는 성능",
          "level": 1
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Zoom-chain-of-draft-thinking-faster-by-writing-less",
      "date": "2025-02-W04",
      "year": "2025",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "Zoom",
      "title": "Chain of Draft: Thinking Faster by Writing Less",
      "url": "https://arxiv.org/abs/2502.18600",
      "bullets": [],
      "tags": []
    },
    {
      "id": "NVIDIA,-HuggingFace-smarter-better-faster-longer-a-modern-bidirectional-encoder-for-fast-memory-efficient-and-long-context-finetuning-and-inference",
      "date": "2025-01-W01",
      "year": "2025",
      "month": "1",
      "week": "1",
      "type": "paper",
      "org": "NVIDIA, HuggingFace",
      "title": "Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference",
      "url": "https://arxiv.org/pdf/2412.13663",
      "bullets": [
        {
          "text": "8192 sequence 길이로 2T 토큰을 학습",
          "level": 0
        },
        {
          "text": "분류, single-/multi- vector retrieval 태스크에서 SoTA 달성",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-learnlm-improving-gemini-for-learning",
      "date": "2025-01-W01",
      "year": "2025",
      "month": "1",
      "week": "1",
      "type": "paper",
      "org": "Google",
      "title": "LearnLM: Improving Gemini for Learning",
      "url": "https://services.google.com/fh/files/misc/improving-gemini-for-education_v7.pdf",
      "bullets": [
        {
          "text": "특정 pedagogical attribute를 평가하기 위한 프레임워크",
          "level": 0
        },
        {
          "text": "pedagogical instruction following을 포함하여 학습한 LearnLM 이 다양한 learning scenario에서 좋은 평가를 받았음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Nanjing-Univ.,-Baidu-explanatory-instructions-towards-unified-vision-tasks-understanding-and-zero-shot-generalization",
      "date": "2025-01-W01",
      "year": "2025",
      "month": "1",
      "week": "1",
      "type": "paper",
      "org": "Nanjing Univ., Baidu",
      "title": "Explanatory Instructions: Towards Unified Vision Tasks Understanding and Zero-shot Generalization",
      "url": "https://arxiv.org/pdf/2412.18525",
      "bullets": [
        {
          "text": "discrete & terminological task definitions 대신 Explanatory Instructions를 사용",
          "level": 0
        },
        {
          "text": "‘image input → explanatory instruction → output’ 12M 개의 triplet으로 구성된 데이터셋 구축",
          "level": 0
        },
        {
          "text": "Auto-regressive-based vision-language model 학습 (AR-based VLM)",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Microsoft-bootstrap-your-own-context-length",
      "date": "2025-01-W01",
      "year": "2025",
      "month": "1",
      "week": "1",
      "type": "paper",
      "org": "Microsoft",
      "title": "Bootstrap Your Own Context Length",
      "url": "https://arxiv.org/pdf/2412.18860",
      "bullets": [
        {
          "text": "diverse long-context instruction tuning data를 합성하는 simple agent flow",
          "level": 0
        },
        {
          "text": "즉, short-context의 언어 모델들만을 이용하여 long-context 언어 모델을 만들 수 있다는 주장",
          "level": 0
        },
        {
          "text": "Llama-3 계열 모델을 기준으로 최대 1M token 까지 확장했다고 언급",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "GIT,-Washington,-CMU,-AI2-multi-attribute-constraint-satisfaction-via-language-model-rewriting",
      "date": "2025-01-W01",
      "year": "2025",
      "month": "1",
      "week": "1",
      "type": "paper",
      "org": "GIT, Washington, CMU, AI2",
      "title": "Multi-Attribute Constraint Satisfaction via Language Model Rewriting",
      "url": "https://arxiv.org/pdf/2412.19198",
      "bullets": [
        {
          "text": "초기 paraphrased outputs으로부터 다양한 multi-attribute를 sampling 함으로써 LM을 editor로 학습",
          "level": 0
        },
        {
          "text": "이를 제대로 평가하기 위해 Fine-grained Constraint Satisfaction (FineCS) 벤치마크를 제작",
          "level": 0
        },
        {
          "text": "Text Style Transfer, Protein Design, 두 개의 challenging tasks로 구성",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Xiaoduo-AI-Lab-xmodel-2-technical-report",
      "date": "2025-01-W01",
      "year": "2025",
      "month": "1",
      "week": "1",
      "type": "paper",
      "org": "Xiaoduo AI Lab",
      "title": "Xmodel-2 Technical Report",
      "url": "https://arxiv.org/pdf/2412.19638",
      "bullets": [
        {
          "text": "이것의 아키텍쳐는 다른 모델들이 통합된 하이퍼파라미터셋을 그대로 활용할 수 있도록 함으로써 최적의 세팅으로 larger model에 scale 할 수 있음",
          "level": 0
        },
        {
          "text": "MiniCPM의 WSD learning rate scheduler 사용",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/XiaoduoAILab/Xmodel-2) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Tencent-hunyuanprover-a-scalable-data-synthesis-framework-and-guided-tree-search-for-automated-theorem-proving",
      "date": "2025-01-W01",
      "year": "2025",
      "month": "1",
      "week": "1",
      "type": "paper",
      "org": "Tencent",
      "title": "HunyuanProver: A Scalable Data Synthesis Framework and Guided Tree Search for Automated Theorem Proving",
      "url": "https://arxiv.org/pdf/2412.20735",
      "bullets": [
        {
          "text": "data sparsity issue 해결을 위해 iterative 데이터 합성 프레임워크를 디자인",
          "level": 0
        },
        {
          "text": "system 2 thinking을 위한 guided tree search algorithm 디자인",
          "level": 0
        },
        {
          "text": "30k 개의 합성 데이터를 공개: 자연어로 된 원래 질문, autoformalization으로 변형된 것, HunyuanProver로부터의 proof로 구성",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Meta-mllm-as-a-judge-for-image-safety-without-human-labeling",
      "date": "2025-01-W01",
      "year": "2025",
      "month": "1",
      "week": "1",
      "type": "paper",
      "org": "Meta",
      "title": "MLLM-as-a-Judge for Image Safety without Human Labeling",
      "url": "https://arxiv.org/pdf/2501.00192",
      "bullets": [
        {
          "text": "기존 문제점: human label, guideline 제작 등은 너무 비쌈. 룰 업데이트가 주기적으로 필요함",
          "level": 1
        },
        {
          "text": "MLLM이 zero-shot으로 주어진 ruel과 이미지 간의 관련성을 평가하고 빠르게 판단할 수 있도록 하는 방법론을 제안",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Toronto-toward-adaptive-reasoning-in-large-language-models-with-thought-rollback",
      "date": "2025-01-W01",
      "year": "2025",
      "month": "1",
      "week": "1",
      "type": "paper",
      "org": "Toronto",
      "title": "Toward Adaptive Reasoning in Large Language Models with Thought Rollback",
      "url": "https://arxiv.org/pdf/2412.19707",
      "bullets": [
        {
          "text": "TR의 core mechanism은 rolling back thoughts로 LLM이 thoughts에 대해 error analysis를 수행하여 이전에 mistaken 된 thought를 roll back 하도록 함",
          "level": 0
        },
        {
          "text": "prompt 내에 이러한 trail-and-error를 포함하여 더욱 reliable한 reasoning path를 구축",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/iQua/llmpebase) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Taiwan,-Intel-safeguard-fine-tuned-llms-through-pre-and-post-tuning-model-merging",
      "date": "2025-01-W01",
      "year": "2025",
      "month": "1",
      "week": "1",
      "type": "paper",
      "org": "Taiwan, Intel",
      "title": "Safeguard Fine-Tuned LLMs Through Pre- and Post-Tuning Model Merging",
      "url": "https://arxiv.org/pdf/2412.19512",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Shenzhen-icpc-in-context-prompt-compression-with-faster-inference",
      "date": "2025-01-W02",
      "year": "2025",
      "month": "1",
      "week": "2",
      "type": "paper",
      "org": "Shenzhen",
      "title": "ICPC: In-context Prompt Compression with Faster Inference",
      "url": "https://arxiv.org/pdf/2501.01625",
      "bullets": [
        {
          "text": "encoder를 사용하여 프롬프트 내 각 단어의 확률을 계산하고 information function을 이용하여 information 계산하여 information loss를 최소화",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "AI2,-Washington,-NYU-2-olmo-2-furious",
      "date": "2025-01-W02",
      "year": "2025",
      "month": "1",
      "week": "2",
      "type": "paper",
      "org": "AI2, Washington, NYU",
      "title": "2 OLMo 2 Furious",
      "url": "https://arxiv.org/pdf/2501.00656",
      "bullets": [
        {
          "text": "Dolmino Mix 1124, late-stage curriculum training에 사용되는 pretraining data mixture",
          "level": 0
        },
        {
          "text": "Tulu 3에서 얻은 최선의 practice를 OLMo 2-Instruct 개발에 활용, final-stage reinforcement learning with verifiable reward (RLVR)에 focus",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Berkeley,-CMU-autopresent-designing-structured-visuals-from-scratch",
      "date": "2025-01-W02",
      "year": "2025",
      "month": "1",
      "week": "2",
      "type": "paper",
      "org": "Berkeley, CMU",
      "title": "AutoPresent: Designing Structured Visuals from Scratch",
      "url": "https://arxiv.org/pdf/2501.00912",
      "bullets": [
        {
          "text": "10개 도메인에 대한 310개 슬라이드 deck에 대한 585개의 testing sample로 구성",
          "level": 1
        },
        {
          "text": "(1) reference-based 방식: target slide와의 유사도 평가",
          "level": 1
        },
        {
          "text": "(2) reference-free: 생성된 슬라이드 자체의 디자인 퀄리티 평가",
          "level": 1
        },
        {
          "text": "AutoPresent: 8B Llama-based model, 7k개의 instruction & 슬라이드 생성 코드 pair로 학습",
          "level": 0
        },
        {
          "text": "모델이 스스로의 결과물을 self-refined 하는 iteraitve design refinement가 유의미한 결과 향상으로 이어진다고 보고",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/para-lost/AutoPresent) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-smolagents",
      "date": "2025-01-W02",
      "year": "2025",
      "month": "1",
      "week": "2",
      "type": "dev",
      "org": "HuggingFace",
      "title": "SmolAgents",
      "url": "https://github.com/huggingface/smolagents",
      "bullets": [
        {
          "text": "transformers에서 사용 가능한, Hub에 업로드된 모든 모델을 사용할 수 있음. OpenAI, Anthropic, Meta 모델들도 사용 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Chinese-Academy-of-Sciences-auto-rt-automatic-jailbreak-strategy-exploration-for-red-teaming-large-language-models",
      "date": "2025-01-W02",
      "year": "2025",
      "month": "1",
      "week": "2",
      "type": "paper",
      "org": "Chinese Academy of Sciences",
      "title": "Auto-RT: Automatic Jailbreak Strategy Exploration for Red-Teaming Large Language Models",
      "url": "https://arxiv.org/pdf/2501.01830",
      "bullets": [
        {
          "text": "exploration complexity를 줄이고 최적화 전략을 개선하기 위한 두 가지 key points",
          "level": 0
        },
        {
          "text": "(1) Early-terminated Exploration",
          "level": 1
        },
        {
          "text": "(2)Progressive Reward Tracking algorithm",
          "level": 1
        },
        {
          "text": "[깃허브 링크](https://github.com/icip-cas/Auto-RT/tree/main) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Orange-survey-on-question-answering-over-visually-rich-documents-methods-challenges-and-trends",
      "date": "2025-01-W02",
      "year": "2025",
      "month": "1",
      "week": "2",
      "type": "paper",
      "org": "Orange",
      "title": "Survey on Question Answering over Visually Rich Documents: Methods, Challenges, and Trends",
      "url": "https://arxiv.org/pdf/2501.02235",
      "bullets": [
        {
          "text": "본 논문에서는 LLMs function에 의한 VrDU 모델들의 개선 방법론 및 한계점 등을 survey",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-agents",
      "date": "2025-01-W02",
      "year": "2025",
      "month": "1",
      "week": "2",
      "type": "dev",
      "org": "Google",
      "title": "Agents",
      "url": "https://www.kaggle.com/whitepaper-agents",
      "bullets": [
        {
          "text": "세 개의 핵심 구성 요소를 정의: Decision Engine, Tool Integration, Orchestration Layer",
          "level": 0
        },
        {
          "text": "Tools는 각 functionality에 따라 Extension, Function, Data Stores로 구분",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "NVIDIA-nvidia-announces-nemotron-model-families-to-advance-agentic-ai",
      "date": "2025-01-W02",
      "year": "2025",
      "month": "1",
      "week": "2",
      "type": "dev",
      "org": "NVIDIA",
      "title": "NVIDIA Announces Nemotron Model Families to Advance Agentic AI",
      "url": "https://blogs.nvidia.com/blog/nemotron-model-families/",
      "bullets": [
        {
          "text": "NVIDIA NeMo Retriever 등을 포함하여 NVIDIA NeMo 플랫폼을 구축하고자 하는 움직임",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "IBM-mtrag-a-multi-turn-conversational-benchmark-for-evaluating-retrieval-augmented-generation-systems",
      "date": "2025-01-W02",
      "year": "2025",
      "month": "1",
      "week": "2",
      "type": "paper",
      "org": "IBM",
      "title": "MTRAG: A Multi-Turn Conversational Benchmark for Evaluating Retrieval-Augmented Generation Systems",
      "url": "https://arxiv.org/pdf/2501.03468",
      "bullets": [
        {
          "text": "4개 도메인에서 평균 7.7 턴의 110개 대화로 구성되며, 총 842개의 태스크를 다룸",
          "level": 0
        },
        {
          "text": "합성 데이터를 이용한 LLM-as-a-Judge 자동화 파이프라인도 포함하고 있음",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/ibm/mt-rag-benchmark) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Korea-Univ.-sugar-leveraging-contextual-confidence-for-smarter-retrieval",
      "date": "2025-01-W02",
      "year": "2025",
      "month": "1",
      "week": "2",
      "type": "paper",
      "org": "Korea Univ.",
      "title": "SUGAR: Leveraging Contextual Confidence for Smarter Retrieval",
      "url": "https://arxiv.org/pdf/2501.04899",
      "bullets": [
        {
          "text": "external knowledge가 relevant 한 것인지 LLM이 알 수 없어 발생하는 hallucination을 최소화",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "NVIDIA-cosmos",
      "date": "2025-01-W02",
      "year": "2025",
      "month": "1",
      "week": "2",
      "type": "dev",
      "org": "NVIDIA",
      "title": "Cosmos",
      "url": "https://www.nvidia.com/en-in/ai/cosmos/",
      "bullets": [
        {
          "text": "20M 시간 & 9,000T 토큰으로 학습된 Diffusion-based models",
          "level": 0
        },
        {
          "text": "Autoregressive, text-to-video, video-to-video, combined inputs 지원 등의 특징",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "LangChain-structured-report-generation-blueprint-with-nvidia-ai",
      "date": "2025-01-W02",
      "year": "2025",
      "month": "1",
      "week": "2",
      "type": "dev",
      "org": "LangChain",
      "title": "Structured Report Generation Blueprint with NVIDIA AI",
      "url": "https://blog.langchain.dev/structured-report-generation-blueprint/",
      "bullets": [
        {
          "text": "optimized Llama 3.3 and LangGraph integration",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "NYU-entropy-guided-attention-for-private-llms",
      "date": "2025-01-W02",
      "year": "2025",
      "month": "1",
      "week": "2",
      "type": "paper",
      "org": "NYU",
      "title": "Entropy-Guided Attention for Private LLMs",
      "url": "https://arxiv.org/pdf/2501.03489",
      "bullets": [
        {
          "text": "entropy regularization 테크닉을 곁들ㅇ니 entropy-guided attention 메커니즘으로 entropci overload를 완화",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Renmin,-Tsinghua-search-o1-agentic-search-enhanced-large-reasoning-models",
      "date": "2025-01-W02",
      "year": "2025",
      "month": "1",
      "week": "2",
      "type": "paper",
      "org": "Renmin, Tsinghua",
      "title": "Search-o1: Agentic Search-Enhanced Large Reasoning Models",
      "url": "https://arxiv.org/pdf/2501.05366",
      "bullets": [
        {
          "text": "Search-o1: LRMs에 agentic RAG mechanism과 Reason-in-Documents module을 더한 프레임워크",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/sunnynexus/Search-o1) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Microsoft-gear-generation-augmented-retrieval",
      "date": "2025-01-W02",
      "year": "2025",
      "month": "1",
      "week": "2",
      "type": "paper",
      "org": "Microsoft",
      "title": "GeAR: Generation Augmented Retrieval",
      "url": "https://arxiv.org/pdf/2501.02772",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Nanyang,-Fudan-long-context-vs-rag-for-llms-an-evaluation-and-revisits",
      "date": "2025-01-W03",
      "year": "2025",
      "month": "1",
      "week": "3",
      "type": "paper",
      "org": "Nanyang, Fudan",
      "title": "Long Context vs. RAG for LLMs: An Evaluation and Revisits",
      "url": "https://arxiv.org/pdf/2501.01880",
      "bullets": [
        {
          "text": "(1) QA benchmarks에서는 LC가 일반적으로 RAG 보다 우위",
          "level": 0
        },
        {
          "text": "(2) summarization-based RAG는 LC보다 낫지만 chunk-based retrieval는 조금 아쉽",
          "level": 0
        },
        {
          "text": "(3) dialogue-based & generatl question queries에 대해서는 RAG가 우위",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "SynthLab,-Stanford,-UC-Berkeley-towards-system-2-reasoning-in-llms-learning-how-to-think-with-meta-chain-of-thought",
      "date": "2025-01-W03",
      "year": "2025",
      "month": "1",
      "week": "3",
      "type": "paper",
      "org": "SynthLab, Stanford, UC Berkeley",
      "title": "Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Thought",
      "url": "https://arxiv.org/pdf/2501.04682",
      "bullets": [
        {
          "text": "process supervision, synthetic data generation, search algorithms 등 Meta-CoT 생성에 대한 방법론 탐구",
          "level": 0
        },
        {
          "text": "linearized search traces & reinforcement learning post-training 을 instruction tuning과 통합",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal",
        "reasoning"
      ]
    },
    {
      "id": "OneLineAI,-Yonsei-multi-step-reasoning-in-korean-and-the-emergent-mirage",
      "date": "2025-01-W03",
      "year": "2025",
      "month": "1",
      "week": "3",
      "type": "paper",
      "org": "OneLineAI, Yonsei",
      "title": "Multi-Step Reasoning in Korean and the Emergent Mirage",
      "url": "https://arxiv.org/pdf/2501.05712",
      "bullets": [
        {
          "text": "질문들은 템플릿과 알고리즘을 통해 자동적으로 생성되었음",
          "level": 0
        },
        {
          "text": "일정 threshold 이상의 학습을 수행한 모델로부터 emergent behavior 관측됨",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Mistral-codestral-2501",
      "date": "2025-01-W03",
      "year": "2025",
      "month": "1",
      "week": "3",
      "type": "dev",
      "org": "Mistral",
      "title": "Codestral 25.01",
      "url": "https://mistral.ai/news/codestral-2501/",
      "bullets": [
        {
          "text": "덕분에 2배 이상 빠른 속도로 코드 생성 가능",
          "level": 0
        },
        {
          "text": "256k context length를 지원하며 다양한 프로그래밍 언어 벤치마크에서 SoTA 달성",
          "level": 0
        },
        {
          "text": "VS Code 또는 JetBrains 에서 Chat Demo 버전 사용 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "UCBerkeley-NovaSky-sky-t1-train-your-own-o1-preview-model-within-450",
      "date": "2025-01-W03",
      "year": "2025",
      "month": "1",
      "week": "3",
      "type": "dev",
      "org": "UCBerkeley NovaSky",
      "title": "Sky-T1: Train your own O1 preview model within $450",
      "url": "https://novasky-ai.github.io/posts/sky-t1/",
      "bullets": [
        {
          "text": "QwQ-23B-Preview를 이용하여 초기 데이터를 생성한 뒤 reject sampling 적용",
          "level": 0
        },
        {
          "text": "Qwen2.5-32B-Instruct 모델을 curated dataset으로 fine-tune",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-rstar-math-small-llms-can-master-math-reasoning-with-self-evolved-deep-thinking",
      "date": "2025-01-W03",
      "year": "2025",
      "month": "1",
      "week": "3",
      "type": "paper",
      "org": "Microsoft",
      "title": "rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking",
      "url": "https://arxiv.org/pdf/2501.04519",
      "bullets": [
        {
          "text": "MCTS를 통한 deep thinking을 활용하여 이와 같은 성과를 달성할 수 있었다고 보고",
          "level": 0
        },
        {
          "text": "(1) code-augmented CoT data synthesis method (2) naive step-level score annotation을 지양하는 reward model training method (3) self-evolution recipe",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "AMD,-John-Hopkins-agent-laboratory-using-llm-agents-as-research-assistants",
      "date": "2025-01-W03",
      "year": "2025",
      "month": "1",
      "week": "3",
      "type": "dev",
      "org": "AMD, John Hopkins",
      "title": "Agent Laboratory: Using LLM Agents as Research Assistants",
      "url": "https://agentlaboratory.github.io/",
      "bullets": [
        {
          "text": "MacBook이든 GPU cluster든 주어진 computational resources에 맞게끔 동작하는 structured framework",
          "level": 0
        },
        {
          "text": "세 단계로 구성: (1) Literature Review (2) Experimentation (3) Report Writing",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-Research-titans-learning-to-memorize-at-test-time",
      "date": "2025-01-W03",
      "year": "2025",
      "month": "1",
      "week": "3",
      "type": "paper",
      "org": "Google Research",
      "title": "Titans: Learning to Memorize at Test Time",
      "url": "https://arxiv.org/pdf/2501.00663",
      "bullets": [
        {
          "text": "historical context를 기억하는 방법을 배워서 오래된 과거 정보를 활용하여 현재 context에 attention 하는 방법론",
          "level": 0
        },
        {
          "text": "결국 attention과 neural memory라는 두 개의 module을 기반으로 삼는 새로운 아키텍쳐 model family, Titan",
          "level": 0
        },
        {
          "text": "2M context size 이상에서도 needle-in-haystack tasks를 정확하게 수행할 수 있다고 보고",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Minimax-minimax-01-scaling-foundation-models-with-lightning-attention",
      "date": "2025-01-W03",
      "year": "2025",
      "month": "1",
      "week": "3",
      "type": "paper",
      "org": "Minimax",
      "title": "MiniMax-01: Scaling Foundation Models with Lightning Attention",
      "url": "https://arxiv.org/pdf/2501.08313",
      "bullets": [
        {
          "text": "핵심은 lightning attention & efficient scaling",
          "level": 0
        },
        {
          "text": "MoE 방식과 결합했는데, 이때 32개의 experts, 456B total parameters, 45.9B activated parameters 로 구성",
          "level": 0
        },
        {
          "text": "학습 중 context window는 1M 길이에 달하고, 추론 시에는 4M 까지 extrapolate 가능하다고 주장",
          "level": 0
        },
        {
          "text": "GPT-4o, Claude-3.5-Sonnet에 준하는 성능을 달성하면서도 20-32배나 긴 context window를 커버할 수 있다고 함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Sakana-transformer2-self-adaptive-llms",
      "date": "2025-01-W03",
      "year": "2025",
      "month": "1",
      "week": "3",
      "type": "paper",
      "org": "Sakana",
      "title": "Transformer^2: Self-adaptive LLMs",
      "url": "https://arxiv.org/pdf/2501.06252",
      "bullets": [
        {
          "text": "two-pass mechanism: (1) dispatch system (2) task-specific expert vectors",
          "level": 0
        },
        {
          "text": "LoRA 대비 사용하는 파라미터의 숫자는 적으나 효율성이 뛰어남",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-scheduled-tasks-in-chatgpt",
      "date": "2025-01-W03",
      "year": "2025",
      "month": "1",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "Scheduled tasks in ChatGPT",
      "url": "https://help.openai.com/en/articles/10291617-scheduled-tasks-in-chatgpt",
      "bullets": [
        {
          "text": "one-time reminder 또는 recurring actions 설정 가능",
          "level": 0
        },
        {
          "text": "웹 인터페이스를 통한 태스크 관리",
          "level": 0
        },
        {
          "text": "데스크탑, 모바일, 웹에서 알림 수신 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Chinese-Academy-of-Sciences-aligning-instruction-tuning-with-pre-training",
      "date": "2025-01-W03",
      "year": "2025",
      "month": "1",
      "week": "3",
      "type": "paper",
      "org": "Chinese Academy of Sciences",
      "title": "Aligning Instruction Tuning with Pre-training",
      "url": "https://arxiv.org/pdf/2501.09368",
      "bullets": [
        {
          "text": "AITP (Aligning Instruction Tuning with Pre-training): underrepresented pre-training data를 고품질의 instruction-response pair 데이터로 변환",
          "level": 0
        },
        {
          "text": "task-specific objective 유지 & 데이터셋의 다양성 증대",
          "level": 1
        },
        {
          "text": "adaptive data selection, controlled rewriting, balanced integration 등",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Together-AI,-MIT,-Princeton-ladder-residual-parallelism-aware-architecture-for-accelerating-large-model-inference-with-communication-overlapping",
      "date": "2025-01-W03",
      "year": "2025",
      "month": "1",
      "week": "3",
      "type": "paper",
      "org": "Together AI, MIT, Princeton",
      "title": "Ladder-residual: parallelism-aware architecture for accelerating large model inference with communication overlapping",
      "url": "https://arxiv.org/pdf/2501.06589",
      "bullets": [
        {
          "text": "모델을 여러 GPU에 나누는 Tensor Parallelism에서 발생하는 통신 간의 병목을 최소화하기 위한 방법론 제시",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Meta-training-large-language-models-to-reason-in-a-continuous-latent-space",
      "date": "2025-01-W03",
      "year": "2025",
      "month": "1",
      "week": "3",
      "type": "paper",
      "org": "Meta",
      "title": "Training Large Language Models to Reason in a Continuous Latent Space",
      "url": "https://arxiv.org/pdf/2412.06769",
      "bullets": [
        {
          "text": "CoConuT (Chain of Continuous Thought): LLM의 last hidden state를 reasoning state의 representation으로 해석하여 continuous thought로 명명",
          "level": 0
        },
        {
          "text": "[official code link](https://github.com/facebookresearch/coconut?tab=readme-ov-file) (Github) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Northeastern-Univ.-foundations-of-large-language-models",
      "date": "2025-01-W03",
      "year": "2025",
      "month": "1",
      "week": "3",
      "type": "paper",
      "org": "Northeastern Univ.",
      "title": "Foundations of Large Language Models",
      "url": "https://arxiv.org/pdf/2501.09223",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind-inference-time-scaling-for-diffusion-models-beyond-scaling-denoising-steps",
      "date": "2025-01-W03",
      "year": "2025",
      "month": "1",
      "week": "3",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps",
      "url": "https://arxiv.org/pdf/2501.09732",
      "bullets": [
        {
          "text": "이것 이상의 inference-time scaling hegavior에 대해 연구. diffusion sampling process에서 더 나은 noise를 찾는 search problem에 집중.",
          "level": 0
        },
        {
          "text": "class-/text- conditioned 이미지 생성 벤치마크에서 상당한 개선을 이뤄냈다고 보고",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Zhejiang-Univ.-omnithink-expanding-knowledge-boundaries-in-machine-writing-through-thinking",
      "date": "2025-01-W04",
      "year": "2025",
      "month": "1",
      "week": "4",
      "type": "paper",
      "org": "Zhejiang Univ.",
      "title": "OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking",
      "url": "https://arxiv.org/pdf/2501.09751",
      "bullets": [
        {
          "text": "이를 해결하기 위해 OmniThink라는 machine writing framework 프레임워크를 제안: 인간과 같은 iterative expansion & reflection 프로세스를 모방",
          "level": 0
        },
        {
          "text": "특정 주제에 대한 지식을 점진적으로 deepen 하는 cognitive behavior가 아이디어의 핵심",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "DeepSeek-deepseek-r1",
      "date": "2025-01-W04",
      "year": "2025",
      "month": "1",
      "week": "4",
      "type": "dev",
      "org": "DeepSeek",
      "title": "DeepSeek-R1",
      "url": "https://github.com/deepseek-ai/DeepSeek-R1",
      "bullets": [
        {
          "text": "Self-verification, Reflection, CoT solutions 등의 특징",
          "level": 0
        },
        {
          "text": "DeepSeek-R1, DeepSeek-R1-Zero, Llama & Qwen 아키텍쳐 기반의 6개 distilled 모델 공개",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "OpenAI-openais-function-calling-guide",
      "date": "2025-01-W04",
      "year": "2025",
      "month": "1",
      "week": "4",
      "type": "dev",
      "org": "OpenAI",
      "title": "OpenAI’s function calling guide",
      "url": "https://platform.openai.com/docs/guides/function-calling",
      "bullets": [
        {
          "text": "좋은 예시들이 포함되어 있어 function calling 공부하는 데 활용할 수 있을 것 같음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-Research-redstone-curating-general-code-math-and-qa-data-for-large-language-models",
      "date": "2025-01-W04",
      "year": "2025",
      "month": "1",
      "week": "4",
      "type": "paper",
      "org": "Microsoft Research",
      "title": "RedStone: Curating General, Code, Math, and QA Data for Large Language Models",
      "url": "https://arxiv.org/pdf/2412.03398",
      "bullets": [
        {
          "text": "기존의 domain-specific expertise가 요구되었던 방식들과 달리 Common Crawl 에 포함된 다양한 도메인의 데이터를 tailor",
          "level": 0
        },
        {
          "text": "[작업물 링크](https://aka.ms/redstone) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Korea-Univ.,-Upstage-chroknowledge-unveiling-chronological-knowledge-of-language-models-in-multiple-domains",
      "date": "2025-01-W04",
      "year": "2025",
      "month": "1",
      "week": "4",
      "type": "paper",
      "org": "Korea Univ., Upstage",
      "title": "ChroKnowledge: Unveiling Chronological Knowledge of Language Models in Multiple Domains",
      "url": "https://arxiv.org/pdf/2410.09870v2",
      "bullets": [
        {
          "text": "세 가지 핵심 요소: multiple domains, time dependency, temporal state",
          "level": 1
        },
        {
          "text": "ChroKnowledge (Chronological Categoriazation of Knowledge): LLM의 non-parametric chronological knowledge를 평가하기 위한 sample-based framework",
          "level": 0
        },
        {
          "text": "temporal knowledge를 이끌어내는 능력은 모델이 학습된 데이터 형식에 따라 다르다",
          "level": 1
        },
        {
          "text": "LLM은 지식을 부분적으로 recall 하거나 temporal boundaries에서 단절되는 듯하다",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "ChungAng-Univ.-probing-rag-self-probing-to-guide-language-models-in-selective-document-retrieval",
      "date": "2025-01-W04",
      "year": "2025",
      "month": "1",
      "week": "4",
      "type": "paper",
      "org": "ChungAng Univ.",
      "title": "Probing-RAG: Self-Probing to Guide Language Models in Selective Document Retrieval",
      "url": "https://arxiv.org/pdf/2410.13339",
      "bullets": [
        {
          "text": "real-world 에서는 최적의 document를 찾기 위해 주로 multi-step을 거쳐야 하는 문제를 해결",
          "level": 1
        },
        {
          "text": "pre-trained prober를 사용하여 모델의 internal cognition을 빠르게 capture",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Pocket-Flow-pocket-flow",
      "date": "2025-01-W04",
      "year": "2025",
      "month": "1",
      "week": "4",
      "type": "dev",
      "org": "Pocket Flow",
      "title": "Pocket Flow",
      "url": "https://minillmflow.github.io/PocketFlow/",
      "bullets": [
        {
          "text": "Nested Directed Graph를 활용하여 Node, Action, Flow, Batch & Async 등의 기능을 지원",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-announcing-the-stargate-project",
      "date": "2025-01-W04",
      "year": "2025",
      "month": "1",
      "week": "4",
      "type": "dev",
      "org": "OpenAI",
      "title": "Announcing The Stargate Project",
      "url": "https://openai.com/index/announcing-the-stargate-project/",
      "bullets": [
        {
          "text": "NVIDIA GPU 사용, Oracle은 고품질 cloud infrastructure 제공, Microsoft Azure는 모델 분산 학습 지원",
          "level": 0
        },
        {
          "text": "medicine & biotechnology 등의 high-value fields에 집중",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "ByteDance,-Tsinghua-ui-tars-pioneering-automated-gui-interaction-with-native-agents",
      "date": "2025-01-W04",
      "year": "2025",
      "month": "1",
      "week": "4",
      "type": "paper",
      "org": "ByteDance, Tsinghua",
      "title": "UI-TARS: Pioneering Automated GUI Interaction with Native Agents",
      "url": "https://arxiv.org/pdf/2501.12326",
      "bullets": [
        {
          "text": "프롬프트나 workflow를 통해 commercial model을 사용하는 이전 프레임워크들과 달리 end-to-end model임",
          "level": 0
        },
        {
          "text": "Enhanced Perception, Unified Action Modeling, System-2 Reasoning, Iterative Training with Reflective Online Traces 등의 주요 특징",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Microsoft-llm-rubric-a-multidimensional-calibrated-approach-to-automated-evaluation-of-natural-language-texts",
      "date": "2025-01-W04",
      "year": "2025",
      "month": "1",
      "week": "4",
      "type": "paper",
      "org": "Microsoft",
      "title": "LLM-Rubric: A Multidimensional, Calibrated Approach to Automated Evaluation of Natural Language Texts",
      "url": "https://aclanthology.org/2024.acl-long.745.pdf",
      "bullets": [
        {
          "text": "multiple LLM distribution을 combine 하여 인간 judge’s annotation을 predict",
          "level": 0
        },
        {
          "text": "judge-specific & judge-independent parameters를 둘 다 포함하는 small feed-forward neural netowrk를 사용",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "OpenAI-introducing-operator",
      "date": "2025-01-W04",
      "year": "2025",
      "month": "1",
      "week": "4",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing Operator",
      "url": "https://openai.com/index/introducing-operator/",
      "bullets": [
        {
          "text": "web 상에서 tasks를 자동화해주는 AI agent (폼 작성, 여행 예약 등)",
          "level": 0
        },
        {
          "text": "Computer-Using Agent (CUA) 라는 새로운 모델을 사용",
          "level": 0
        },
        {
          "text": "GPT-4의 vision 능력으로 GUI 상호작용이 가능하도록 강화학습",
          "level": 1
        },
        {
          "text": "웹사이트 클릭, 타이핑, 스크롤 가능 / 캘린더 관리나 슬라이드쇼 생성 등의 복잡한 태스크는 아직 수행하지 못함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal",
        "agent"
      ]
    },
    {
      "id": "Anthropic-introducing-citations-on-the-anthropic-api",
      "date": "2025-01-W04",
      "year": "2025",
      "month": "1",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "Introducing Citations on the Anthropic API",
      "url": "https://www.anthropic.com/news/introducing-citations-api",
      "bullets": [
        {
          "text": "Anthropic API & Google Cloud’s Vertex AI 에서 API로 이용 가능",
          "level": 0
        },
        {
          "text": "Document summarization, Complex Q&A, Customer support 등의 유즈케이스",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-smolvlm-grows-smaller-introducing-the-250m-500m-models",
      "date": "2025-01-W04",
      "year": "2025",
      "month": "1",
      "week": "4",
      "type": "dev",
      "org": "HuggingFace",
      "title": "SmolVLM Grows Smaller – Introducing the 250M & 500M Models!",
      "url": "https://huggingface.co/blog/smolervlm",
      "bullets": [
        {
          "text": "두 개의 base 모델과 instruction fine-tuned 모델, 총 네 개의 체크포인트를 공개",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-Cloud-chain-of-agents-large-language-models-collaborating-on-long-context-tasks",
      "date": "2025-01-W04",
      "year": "2025",
      "month": "1",
      "week": "4",
      "type": "paper",
      "org": "Google Cloud",
      "title": "Chain of Agents: Large Language Models Collaborating on Long-Context Tasks",
      "url": "https://openreview.net/pdf?id=LuCLf4BJsr",
      "bullets": [
        {
          "text": "Chain-of-Agents (CoA): multi-agent collaboration을 이용하여 information aggregation & context reasoning 가능하도록 만든 프레임워크",
          "level": 0
        },
        {
          "text": "segmented text를 sequentially 처리할 수 있는 multiple worker agents로 구성 → manager agent가 결과를 종합하여 coherent final output 생성",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "Renmin-Univ.-of-China-enhancing-llm-reasoning-with-reward-guided-tree-search",
      "date": "2025-01-W05",
      "year": "2025",
      "month": "1",
      "week": "5",
      "type": "paper",
      "org": "Renmin Univ. of China",
      "title": "Enhancing LLM Reasoning with Reward-guided Tree Search",
      "url": "https://arxiv.org/pdf/2411.11694",
      "bullets": [
        {
          "text": "policy model, reward model, search alogirthm을 통합하는 프레임워크",
          "level": 0
        },
        {
          "text": "policy 모델이 학습된 reward model에 의해 tree를 dynamically expand 하는 tree search algorithm",
          "level": 0
        },
        {
          "text": "STILL-1 (Slow Thinking with LLMs) 라는 프레임워크",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Renmin-Univ.-of-China-imitate-explore-and-self-improve-a-reproduction-report-on-slow-thinking-reasoning-systems",
      "date": "2025-01-W05",
      "year": "2025",
      "month": "1",
      "week": "5",
      "type": "paper",
      "org": "Renmin Univ. of China",
      "title": "Imitate, Explore, and Self-Improve: A Reproduction Report on Slow-thinking Reasoning Systems",
      "url": "https://arxiv.org/pdf/2412.09413",
      "bullets": [
        {
          "text": "STILL-2: imitate, explore, self-improve framework",
          "level": 0
        },
        {
          "text": "distilled long-form thought data를 사용하여 reasoning model을 학습함으로써 slow-thinking mode를 가능하게 만듦",
          "level": 0
        },
        {
          "text": "모델이 multiple rollout을 생성함으로써 어려운 문제를 탐색하도록 함 → high-quality trajectories가 올바른 답변으로 이어짐",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Centfor-for-AI-Safety,-Scale-AI-humanitys-last-exam",
      "date": "2025-01-W05",
      "year": "2025",
      "month": "1",
      "week": "5",
      "type": "paper",
      "org": "Centfor for AI Safety, Scale AI",
      "title": "Humanity’s Last Exam",
      "url": "https://static.scale.com/uploads/654197dc94d34f66c0f5184e/Publication%20Ready%20Humanity's%20Last%20Exam.pdf",
      "bullets": [
        {
          "text": "automated grading에 적합한 multiple-choice, short-answer question 등으로 구성",
          "level": 0
        },
        {
          "text": "정답은 논란의 여지가 없고 명확한 것이나 retrieval을 통해 바로 답변하기 어려운 문제들",
          "level": 0
        },
        {
          "text": "[공개 링크](https://lastexam.ai/) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Truthful-AI,-Toronto-tell-me-about-yourself-llms-are-aware-of-their-learned-behaviors",
      "date": "2025-01-W05",
      "year": "2025",
      "month": "1",
      "week": "5",
      "type": "paper",
      "org": "Truthful AI, Toronto",
      "title": "Tell me about yourself: LLMs are aware of their learned behaviors",
      "url": "https://arxiv.org/pdf/2501.11120",
      "bullets": [
        {
          "text": "명시적으로 associated behavior에 대해 언급하지 않는 두 개의 데이터셋 사용",
          "level": 0
        },
        {
          "text": "(a) making high-risk economic decisions (b) outputting insecure code",
          "level": 1
        },
        {
          "text": "그럼에도 모델은 이를 명백히 설명",
          "level": 1
        },
        {
          "text": "우리가 지시하지 않은 내용을 모델이 습득하게 된다는 것은 AI Safety 이슈로 이어질 수 있음",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "DeepSeek-janus-pro-release",
      "date": "2025-01-W05",
      "year": "2025",
      "month": "1",
      "week": "5",
      "type": "dev",
      "org": "DeepSeek",
      "title": "Janus-Pro release",
      "url": "https://github.com/deepseek-ai/Janus?tab=readme-ov-file#5-citation",
      "bullets": [
        {
          "text": "작년(2024)에 이미 JanusFlow, Janus 라는 이름으로 mllm을 공개했었음 (허깅페이스에서 다운로드 가능)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Alibaba-qwen25-1m-deploy-your-own-qwen-with-context-length-up-to-1m-tokens",
      "date": "2025-01-W05",
      "year": "2025",
      "month": "1",
      "week": "5",
      "type": "dev",
      "org": "Alibaba",
      "title": "Qwen2.5-1M: Deploy Your Own Qwen with Context Length up to 1M Tokens",
      "url": "https://qwenlm.github.io/blog/qwen2.5-1m/",
      "bullets": [
        {
          "text": "특히 14B 모델은 Qwen2.5-Turbo, GPT-4o-mini를 능가하는 성능을 보여줌",
          "level": 0
        },
        {
          "text": "긴 context를 효율적으로 처리하기 위해서 sparse attention과 DCA (Dual Chunk Attention) 사용",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "COAI-Research-deception-in-llms-self-preservation-and-autonomous-goals-in-large-language-models",
      "date": "2025-01-W05",
      "year": "2025",
      "month": "1",
      "week": "5",
      "type": "paper",
      "org": "COAI Research",
      "title": "Deception in LLMs: Self-Preservation and Autonomous Goals in Large Language Models",
      "url": "https://arxiv.org/pdf/2501.16513",
      "bullets": [
        {
          "text": "모델이 명시적으로 학습한 적 없는 self-preservation (자기보호) 특성을 보임",
          "level": 0
        },
        {
          "text": "이러한 모델이 robotics와 결합되었을 때 물리적으로 영향을 줄 수 있음에 대한 concern 제기",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "USTC,-Microsoft-optimizing-large-language-model-training-using-fp4-quantization",
      "date": "2025-01-W05",
      "year": "2025",
      "month": "1",
      "week": "5",
      "type": "paper",
      "org": "USTC, Microsoft",
      "title": "Optimizing Large Language Model Training Using FP4 Quantization",
      "url": "https://arxiv.org/pdf/2501.17116",
      "bullets": [
        {
          "text": "두 가지 key factor",
          "level": 0
        },
        {
          "text": "(1) differentiable quantization estimator for precise weight updates",
          "level": 1
        },
        {
          "text": "(2) outlier clamping and compensation strategy to prevent activation collapse",
          "level": 1
        },
        {
          "text": "안정성을 위해 mixed-precision training과 vector-wise quantization 통합",
          "level": 0
        },
        {
          "text": "100B 토큰으로 학습되는 13B 모델까지도 scale-up 가능한 것으로 확인",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Perplexity-sonar",
      "date": "2025-01-W05",
      "year": "2025",
      "month": "1",
      "week": "5",
      "type": "dev",
      "org": "Perplexity",
      "title": "Sonar",
      "url": "https://sonar.perplexity.ai/",
      "bullets": [
        {
          "text": "Advanced CoT reasoning, US-based, Data privacy, Self-serve API access를 주요 특징으로 삼음",
          "level": 0
        },
        {
          "text": "일반 버전과 pro 버전으로 구분됨",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "UIUC,-AI2,-IBM,-Yale,-Washington-refit-reranker-relevance-feedback-during-inference",
      "date": "2025-01-W05",
      "year": "2025",
      "month": "1",
      "week": "5",
      "type": "paper",
      "org": "UIUC, AI2, IBM, Yale, Washington",
      "title": "ReFIT: Reranker Relevance Feedback during Inference",
      "url": "http://sites.computer.org/debull/A24dec/p147.pdf",
      "bullets": [
        {
          "text": "inference-time에 retriever에 대한 relevance feedback을 제공하여 최초 k개 recall에 대한 성능 향상을 도모",
          "level": 0
        },
        {
          "text": "reranker의 predictions을 retriever의 query representation에 반영할 수 있도록 lightweight update mechanism을 사용하여 distill",
          "level": 0
        },
        {
          "text": "→ updated 된 query vector를 사용하여 second retrieval step 실행",
          "level": 1
        },
        {
          "text": "기존 retrieve-and-rerank frameworks에 applicable",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Huawei,-McGill-innerthoughts-disentangling-representations-and-predictions-in-large-language-models",
      "date": "2025-01-W05",
      "year": "2025",
      "month": "1",
      "week": "5",
      "type": "paper",
      "org": "Huawei, McGill",
      "title": "InnerThoughts: Disentangling Representations and Predictions in Large Language Models",
      "url": "https://arxiv.org/pdf/2501.17994",
      "bullets": [
        {
          "text": "small separateneural network predictor module을 training questions에 대해 만들어 전체 레이어의 hidden state를 입력으로 받아 결과 예측",
          "level": 0
        },
        {
          "text": "LLM의 representational abilities를 온전히 사용하는 방식의 프레임워크라고 주장",
          "level": 0
        },
        {
          "text": "비용은 적은데 finetuning급 성능 향상을 이뤄낼 때도 있었다고 보고",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Alibaba-qwen25-max-exploring-the-intelligence-of-large-scale-moe-model",
      "date": "2025-01-W05",
      "year": "2025",
      "month": "1",
      "week": "5",
      "type": "dev",
      "org": "Alibaba",
      "title": "Qwen2.5-Max: Exploring the Intelligence of Large-scale MoE Model",
      "url": "https://qwenlm.github.io/blog/qwen2.5-max/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-Cloud,-Google-DeepMind-reverse-thinking-makes-llms-stronger-reasoners",
      "date": "2024-12-W01",
      "year": "2024",
      "month": "12",
      "week": "1",
      "type": "paper",
      "org": "Google Cloud, Google DeepMind",
      "title": "Reverse Thinking Makes LLMs Stronger Reasoners",
      "url": "https://arxiv.org/pdf/2411.19865",
      "bullets": [
        {
          "text": "데이터 증강: teacher 모델로부터 (1)원래 질문 (2)정방향 추론 (3)역방향 질문 (4)역방향 추론을 수집",
          "level": 0
        },
        {
          "text": "3가지 training objectives를 통한 student 모델 학습",
          "level": 0
        },
        {
          "text": "질문→정방향 추론 생성",
          "level": 1
        },
        {
          "text": "질문→역방향 질문 생성",
          "level": 1
        },
        {
          "text": "역방향 질문→역방향 추론 생성",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Chineses-Academy-of-Sciecnes-auto-rag-autonomous-retrieval-augmented-generation-for-large-language-models",
      "date": "2024-12-W01",
      "year": "2024",
      "month": "12",
      "week": "1",
      "type": "paper",
      "org": "Chineses Academy of Sciecnes",
      "title": "Auto-RAG: Autonomous Retrieval-Augmented Generation for Large Language Models",
      "url": "https://arxiv.org/pdf/2411.19443",
      "bullets": [
        {
          "text": "RAG의 성능 향상을 위한 iterative retrieval 과정을 LLM의 자율적 의사결정 능력에 맡기는 Auto-RAG 제안",
          "level": 0
        },
        {
          "text": "LLM이 retriever와 multi-turn 대화를 통해 검색을 계획하고 쿼리를 개선",
          "level": 1
        },
        {
          "text": "충분한 정보가 모일 때까지 자동으로 반복",
          "level": 1
        },
        {
          "text": "질문의 난이도와 검색된 지식의 유용성에 따라 반복 횟수를 자율적으로 조절",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "NVIDIA-multimodal-pdf-data-extraction",
      "date": "2024-12-W01",
      "year": "2024",
      "month": "12",
      "week": "1",
      "type": "dev",
      "org": "NVIDIA",
      "title": "Multimodal PDF Data Extraction",
      "url": "https://build.nvidia.com/nvidia/multimodal-pdf-data-extraction-for-enterprise-rag",
      "bullets": [
        {
          "text": "enterprise RAG를 위한 제품으로 보임",
          "level": 0
        },
        {
          "text": "현재는 데모 수준으로 업로드된 370/501개 파일에 대한 QA를 RAG 기반으로 테스트 해볼 수 있는 것 같음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Kaggle-llms-you-cant-please-them-all",
      "date": "2024-12-W01",
      "year": "2024",
      "month": "12",
      "week": "1",
      "type": "dev",
      "org": "Kaggle",
      "title": "LLMs - You Can't Please Them All",
      "url": "https://www.kaggle.com/competitions/llms-you-cant-please-them-all",
      "bullets": [
        {
          "text": "LLM judges 간 disagreement를 극대화하는 essay를 제출하는 것이 목표",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "The-University-of-Sydney,-Huawei-enhancing-large-language-models-through-adaptive-tokenizers",
      "date": "2024-12-W01",
      "year": "2024",
      "month": "12",
      "week": "1",
      "type": "paper",
      "org": "The University of Sydney, Huawei",
      "title": "Enhancing Large Language Models through Adaptive Tokenizers",
      "url": "https://openreview.net/pdf/acc98f9552b7a433f16acd31392d1a7e00f1df35.pdf",
      "bullets": [
        {
          "text": "초기의 방대한 vocabulary로 시작, 학습 동안 모델의 perplexity를 관측하며 tokenizer를 refine",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Amazon-amazon-nova-foundation-models",
      "date": "2024-12-W01",
      "year": "2024",
      "month": "12",
      "week": "1",
      "type": "dev",
      "org": "Amazon",
      "title": "Amazon Nova Foundation Models",
      "url": "https://aws.amazon.com/ai/generative-ai/nova/",
      "bullets": [
        {
          "text": "라인업: Micro, Lite, Pro, Premier, Canvas, Reel",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Cohere-introducing-rerank-35-precise-ai-search",
      "date": "2024-12-W01",
      "year": "2024",
      "month": "12",
      "week": "1",
      "type": "dev",
      "org": "Cohere",
      "title": "Introducing Rerank 3.5: Precise AI Search",
      "url": "https://cohere.com/blog/rerank-3pt5",
      "bullets": [
        {
          "text": "현존하는 검색 시스템들과 compatible",
          "level": 0
        },
        {
          "text": "100개 이상의 언어를 지원한다고 설명",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-DeepMind-genie-2-a-large-scale-foundation-world-model",
      "date": "2024-12-W01",
      "year": "2024",
      "month": "12",
      "week": "1",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "Genie 2: A large-scale foundation world model",
      "url": "https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/",
      "bullets": [
        {
          "text": "Genie 1 → 2 에서의 emergent capabilities of a foundation world model 을 주장",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Vanderbit-Univ.-training-noise-token-pruning",
      "date": "2024-12-W01",
      "year": "2024",
      "month": "12",
      "week": "1",
      "type": "paper",
      "org": "Vanderbit Univ.",
      "title": "Training Noise Token Pruning",
      "url": "https://arxiv.org/pdf/2411.18092",
      "bullets": [
        {
          "text": "discrete token dropping 조건을 continuous additive noise로 relax 하여 학습 내에서 smooth optimization을 제공",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Univ.-of-California,-Berkely-predicting-emergent-capabilities-by-finetuning",
      "date": "2024-12-W01",
      "year": "2024",
      "month": "12",
      "week": "1",
      "type": "paper",
      "org": "Univ. of California, Berkely",
      "title": "Predicting Emergent Capabilities by Finetuning",
      "url": "https://arxiv.org/pdf/2411.16035",
      "bullets": [
        {
          "text": "현재 LLM의 random few-shot 정확도를 기반으로 다음 세대 모델의 정확도를 예측할 수 있을까?",
          "level": 0
        },
        {
          "text": "insight: finetuning LLMs on a given task can shift the point in scaling at which emergence occurs towards less capable models",
          "level": 0
        },
        {
          "text": "언어 모델을 특정 태스크에 대해 학습하면 emergent ability가 발현되는 point를 옮길 수 있다",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-DeepMind-paligemma-2-a-family-of-versatile-vlms-for-transfer",
      "date": "2024-12-W01",
      "year": "2024",
      "month": "12",
      "week": "1",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "PaliGemma 2: A Family of Versatile VLMs for Transfer",
      "url": "https://arxiv.org/pdf/2412.03555",
      "bullets": [
        {
          "text": "long fine-grained captioning 같은 task 뿐만 아니라 OCR-related tasks도 커버",
          "level": 0
        },
        {
          "text": "꽤 넓은 범위로 transfer 가능하다는 것을 실험적으로 확인한 것으로 보임",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "OpenAI-o1-and-chatgpt-pro",
      "date": "2024-12-W01",
      "year": "2024",
      "month": "12",
      "week": "1",
      "type": "dev",
      "org": "OpenAI",
      "title": "o1 and ChatGPT Pro",
      "url": "https://openai.com/12-days/?day=1",
      "bullets": [
        {
          "text": "Improved accuracy, Multimodal support, Faster and more concise 등의 특징",
          "level": 0
        },
        {
          "text": "Pro 유저는 o1, GPT-4o, o1-mini 등을 무제한 사용 가능",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Microsoft,-MIT-does-prompt-formatting-have-any-impact-on-llm-performance",
      "date": "2024-12-W01",
      "year": "2024",
      "month": "12",
      "week": "1",
      "type": "paper",
      "org": "Microsoft, MIT",
      "title": "Does Prompt Formatting Have Any Impact on LLM Performance?",
      "url": "https://arxiv.org/pdf/2411.10541",
      "bullets": [
        {
          "text": "같은 내용을 일반 텍스트, 마크다운, JSON, YAML 형식 등으로 변환하여 GPT-3.5-turbo, GPT-4 모델을 테스트",
          "level": 0
        },
        {
          "text": "성능이 높은 모델일수록 템플릿에 상관없이 성능이 유지되고, 그렇지 않은 모델은 크게 영향을 받는 것으로 확인됨",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-DeepMind-gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-state-of-the-art-accuracy",
      "date": "2024-12-W01",
      "year": "2024",
      "month": "12",
      "week": "1",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "GenCast predicts weather and the risks of extreme conditions with state-of-the-art accuracy",
      "url": "https://deepmind.google/discover/blog/gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-sota-accuracy/",
      "bullets": [
        {
          "text": "new high resolution AI ensemble model 이라고 소개하고 있음 (diffusion 기반의 모델)",
          "level": 0
        },
        {
          "text": "📜 [Nature 논문 링크](https://www.nature.com/articles/s41586-024-08252-9)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Yunnan-Univ.-learning-to-reason-via-self-iterative-process-feedback-for-small-language-models",
      "date": "2024-12-W01",
      "year": "2024",
      "month": "12",
      "week": "1",
      "type": "paper",
      "org": "Yunnan Univ.",
      "title": "Learning to Reason via Self-Iterative Process Feedback for Small Language Models",
      "url": "https://arxiv.org/pdf/2412.08393",
      "bullets": [
        {
          "text": "sampling-based inference simulation & process reward models 를 이용하는 process supervision 도입",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Peking,-Baichuan-sysbench-can-large-language-models-follow-system-messages",
      "date": "2024-12-W01",
      "year": "2024",
      "month": "12",
      "week": "1",
      "type": "paper",
      "org": "Peking, Baichuan",
      "title": "SysBench: Can Large Language Models Follow System Messages?",
      "url": "https://arxiv.org/pdf/2408.10943",
      "bullets": [
        {
          "text": "위 능력을 평가하고 분석 가능한 벤치마크 SysBench를 도입",
          "level": 0
        },
        {
          "text": "이미 자주 사용되고 있는 6개의 constraint, 500개의 tailor-designed system messages, multi-trun conversation 등을 기반으로 데이터셋을 직접 구축",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/PKU-Baichuan-MLSystemLab/SysBench) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Tsinghua-densing-law-of-llms",
      "date": "2024-12-W02",
      "year": "2024",
      "month": "12",
      "week": "2",
      "type": "paper",
      "org": "Tsinghua",
      "title": "Densing Law of LLMs",
      "url": "https://arxiv.org/pdf/2412.04315",
      "bullets": [
        {
          "text": "effective parameter size는 기존 모델 M 만큼의 퍼포먼스를 낼 수 있는 최소한의 사이즈를 의미",
          "level": 2
        },
        {
          "text": "→ LLM의 학습 퀄리티를 평가",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "CMU,-KAIST,-Washington-evaluating-language-models-as-synthetic-data-generators",
      "date": "2024-12-W02",
      "year": "2024",
      "month": "12",
      "week": "2",
      "type": "paper",
      "org": "CMU,  KAIST, Washington",
      "title": "Evaluating Language Models as Synthetic Data Generators",
      "url": "https://arxiv.org/pdf/2412.03679",
      "bullets": [
        {
          "text": "6개의 언어 모델, training 99개 student 모델을 사용하여 1.26M training instances를 합성",
          "level": 1
        },
        {
          "text": "데이터 생성 능력은 문제 해결 능력과 직접적인 상관관계를 보이지 않는다고 설명",
          "level": 1
        },
        {
          "text": "[깃허브 링크](https://github.com/neulab/data-agora) 🔗",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "LG-AI-Research-exaone-35-release",
      "date": "2024-12-W02",
      "year": "2024",
      "month": "12",
      "week": "2",
      "type": "dev",
      "org": "LG AI Research",
      "title": "EXAONE-3.5 release",
      "url": "https://huggingface.co/collections/LGAI-EXAONE/exaone-35-674d0e1bb3dcd2ab6f39dbb4",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-meet-willow-our-state-of-the-art-quantum-chip",
      "date": "2024-12-W02",
      "year": "2024",
      "month": "12",
      "week": "2",
      "type": "dev",
      "org": "Google",
      "title": "Meet Willow, our state-of-the-art quantum chip",
      "url": "https://blog.google/technology/research/google-willow-quantum-chip/",
      "bullets": [
        {
          "text": "Willow가 기록한 벤치마크 연산 능력은 오늘날 가장 빠른 슈퍼컴퓨터가 10 septilion (10의 25승)년을 연산할 것을 단 5분만에 처리할 수 있는 수준",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Chinese-Academy-of-Sciences-towards-adaptive-mechanism-activation-in-language-agent",
      "date": "2024-12-W02",
      "year": "2024",
      "month": "12",
      "week": "2",
      "type": "paper",
      "org": "Chinese Academy of Sciences",
      "title": "Towards Adaptive Mechanism Activation in Language Agent",
      "url": "https://arxiv.org/abs/2412.00722",
      "bullets": [
        {
          "text": "expert model에 대한 의존 없이 mechanism activation adaptability를 최적화하는 것에 집중",
          "level": 1
        },
        {
          "text": "a harmonized agent framework (UniAct)를 구축하고 태스크 특성에 따라 적합한 방법론으로 최적화",
          "level": 1
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "OpenAI-openai-o1-system-card",
      "date": "2024-12-W02",
      "year": "2024",
      "month": "12",
      "week": "2",
      "type": "paper",
      "org": "OpenAI",
      "title": "OpenAI o1 System Card",
      "url": "https://cdn.openai.com/o1-system-card-20241205.pdf",
      "bullets": [
        {
          "text": "GPT-4를 공개할 때와 마찬가지로 뻔한 이야기들을 담고 있음",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-day-3-sora",
      "date": "2024-12-W02",
      "year": "2024",
      "month": "12",
      "week": "2",
      "type": "dev",
      "org": "OpenAI",
      "title": "Day 3. Sora",
      "url": "https://openai.com/12-days/?day=3",
      "bullets": [
        {
          "text": "프롬프트를 통해 remix, blend, create 가능",
          "level": 1
        },
        {
          "text": "Turbo 모델은 전작 모델 대비 확실히 생성 속도가 빠름",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-day-4-canvas",
      "date": "2024-12-W02",
      "year": "2024",
      "month": "12",
      "week": "2",
      "type": "dev",
      "org": "OpenAI",
      "title": "Day 4. Canvas",
      "url": "https://openai.com/12-days/?day=4",
      "bullets": [
        {
          "text": "Direct python execution",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-phi-4-technical-report",
      "date": "2024-12-W02",
      "year": "2024",
      "month": "12",
      "week": "2",
      "type": "paper",
      "org": "Microsoft",
      "title": "Phi-4 Technical Report",
      "url": "https://arxiv.org/pdf/2412.08905",
      "bullets": [
        {
          "text": "web content, code 중심의 organic data로 사전학습하는 기존 모델들과 달리, 합성 데이터를 적절히 혼합하여 사용하는 학습 방법론 적용",
          "level": 1
        },
        {
          "text": "phi-4는 STEM-focused QA 능력에서 teacher model의 성능을 능가하는 모습을 보여줌",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Univ.-of-California,-Santa-Barbara-rulearena-a-benchmark-for-rule-guided-reasoning-with-llms-in-real-world-scenarios",
      "date": "2024-12-W02",
      "year": "2024",
      "month": "12",
      "week": "2",
      "type": "paper",
      "org": "Univ. of California, Santa Barbara",
      "title": "RuleArena: A Benchmark for Rule-Guided Reasoning with LLMs in Real-World Scenarios",
      "url": "https://arxiv.org/pdf/2412.08972",
      "bullets": [
        {
          "text": "세 개의 practical domain을 다루고 있음: airline baggage fees, NBA transactions, tax regulations",
          "level": 1
        },
        {
          "text": "현존 LLM들의 세 가지 주요 한계: (1) 비슷하지만 다른 규칙을 구분하지 못함 (2) 규칙을 정확히 이해했더라도 수학 문제에서 일관된 성능을 보이지 않음 (3) 전반적으로 이 벤치마크 점수가 다 낮음",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Univ.-of-Potsdam-i-dont-know-explicit-modeling-of-uncertainty-with-an-idk",
      "date": "2024-12-W02",
      "year": "2024",
      "month": "12",
      "week": "2",
      "type": "paper",
      "org": "Univ. of Potsdam",
      "title": "I Don't Know: Explicit Modeling of Uncertainty with an [IDK",
      "url": "",
      "bullets": [
        {
          "text": "hallucination을 잡기 위한 novel calibration method를 제시",
          "level": 1
        },
        {
          "text": "[IDK] 라는 스페셜 토큰을 vocab에 추가하고 부정확한 예측에 대한 probability mass를 [IDK] 토큰으로 옮기는 objective function을 도입 → 모델이 uncertainty를 명시적으로 반환하도록 함",
          "level": 1
        },
        {
          "text": "이 방식으로 학습된 모델은 기존에 실수하거나 잘못 답변하던 내용들에 대해 uncertainty를 훨씬 더 잘표현할 수 있게 되었다고 보고",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "OpenAI-measuring-short-form-factuality-in-large-language-models",
      "date": "2024-12-W02",
      "year": "2024",
      "month": "12",
      "week": "2",
      "type": "paper",
      "org": "OpenAI",
      "title": "Measuring short-form factuality in large language models",
      "url": "https://cdn.openai.com/papers/simpleqa.pdf",
      "bullets": [
        {
          "text": "GPT-4의 response에 반하도록 수집한 challenging 벤치마크",
          "level": 1
        },
        {
          "text": "오직 한 개의 답변만이 정답이 될 수 있도록 문제를 구성 (correct, incorrect, not attempted)",
          "level": 1
        },
        {
          "text": "모델의 “know what they know”를 평가하기 위한 벤치마크",
          "level": 1
        },
        {
          "text": "[깃허브 링크](https://github.com/openai/simple-evals) 🔗",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Saudi-Data-&-Artificial-Intelligence-Authority-smoltulu-higher-learning-rate-to-batch-size-ratios-can-lead-to-better-reasoning-in-slms",
      "date": "2024-12-W02",
      "year": "2024",
      "month": "12",
      "week": "2",
      "type": "paper",
      "org": "Saudi Data & Artificial Intelligence Authority",
      "title": "SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs",
      "url": "https://arxiv.org/pdf/2412.08347",
      "bullets": [
        {
          "text": "135M 사이즈의 모델일 사용하여 learning rate과 batch size 관계가 모델 퍼포먼스에 큰 영향을 미친다는 것을 확인",
          "level": 1
        },
        {
          "text": "ARC, GSM8K 같은 태스크는 높은 lr, HellaSwag의 pattern recognition, IFEval 등은 낮은 lr이 적합",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Independent-wonderful-matrices-combining-for-a-more-efficient-and-effective-foundation-model-architecture",
      "date": "2024-12-W03",
      "year": "2024",
      "month": "12",
      "week": "3",
      "type": "paper",
      "org": "Independent",
      "title": "Wonderful Matrices: Combining for a More Efficient and Effective Foundation Model Architecture",
      "url": "https://arxiv.org/pdf/2412.11834",
      "bullets": [
        {
          "text": "state space duality algorithm에서 rotary position embedding의 availability를 확인",
          "level": 0
        },
        {
          "text": "dynamic mask attention 적용하여 성능은 그대로 유지하면서도 연산 효율이 좋음",
          "level": 0
        },
        {
          "text": "cross domain mixture of experts를 디자인 (1024개 experts)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Beijing-Univ.-smaller-language-models-are-better-instruction-evolvers",
      "date": "2024-12-W03",
      "year": "2024",
      "month": "12",
      "week": "3",
      "type": "paper",
      "org": "Beijing Univ.",
      "title": "Smaller Language Models Are Better Instruction Evolvers",
      "url": "https://arxiv.org/pdf/2412.11231",
      "bullets": [
        {
          "text": "SLM이 instruction evolving 동안 보다 넓은 output space를 가진다고 주장",
          "level": 0
        },
        {
          "text": "Instruction Complex Aware IFD (IC-IFD)를 제안: instruction data를 평가하기 위해 IFD를 개선한 메트릭",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google,-Peking-tokenformer-rethinking-transformer-scaling-with-tokenized-model-parameters",
      "date": "2024-12-W03",
      "year": "2024",
      "month": "12",
      "week": "3",
      "type": "paper",
      "org": "Google, Peking",
      "title": "TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters",
      "url": "https://arxiv.org/pdf/2410.23168",
      "bullets": [
        {
          "text": "모델 파라미터를 토큰으로 간주하여 트랜스포머 아키텍쳐 내 모든 linear projection을 token-parameter attention layer로 대체",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/Haiyang-W/TokenFormer) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta-byte-latent-transformer-patches-scale-better-than-tokens",
      "date": "2024-12-W03",
      "year": "2024",
      "month": "12",
      "week": "3",
      "type": "paper",
      "org": "Meta",
      "title": "Byte Latent Transformer: Patches Scale Better Than Tokens",
      "url": "https://scontent-ssn1-1.xx.fbcdn.net/v/t39.2365-6/470135129_1314438233309836_4712217603129928862_n.pdf?_nc_cat=111&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=vbUXcOyJdtAQ7kNvgHGfMVI&_nc_zt=14&_nc_ht=scontent-ssn1-1.xx&_nc_gid=Adjk5gBoYiq1LT34WoOFWaC&oh=00_AYDOY9W_gKXm3OE6HttBXG0S1PuK2NFieKLLhr8_nCtoew&oe=6766DC08",
      "bullets": [
        {
          "text": "bytes를 dynamic하게 sized patch로 encoding → 고정된 vocab x",
          "level": 0
        },
        {
          "text": "8B 사이즈의 모델을 4T training bytes로 학습",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-DeepMind-veo-2",
      "date": "2024-12-W03",
      "year": "2024",
      "month": "12",
      "week": "3",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "Veo 2",
      "url": "https://deepmind.google/technologies/veo/veo-2/",
      "bullets": [
        {
          "text": "렌즈 타입과 카메라 효과를 instruction으로 정해서 비디오를 생성할수도 있음",
          "level": 0
        },
        {
          "text": "구글의 SynthID 워터마크를 통해 AI-generated content인지 아닌지 쉽게 식별 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Shanghai-AI-Lab-evaluation-agent-efficient-and-promptable-evaluation-framework-for-visual-generative-models",
      "date": "2024-12-W03",
      "year": "2024",
      "month": "12",
      "week": "3",
      "type": "paper",
      "org": "Shanghai AI Lab",
      "title": "Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models",
      "url": "https://arxiv.org/pdf/2412.09645",
      "bullets": [
        {
          "text": "→ Evaluation Agent 프레임워크: dynamic, multi-round evaluation, 각 라운드마다 몇 개의 샘플만을 사용",
          "level": 0
        },
        {
          "text": "완전한 오픈소스 프레임워크로써 1) efficiency 2) promptable evaluation 3) explainability 4) scalability 등이 핵심 특징",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://vchitect.github.io/Evaluation-Agent-project/) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Claude-Engineer-v3-claude-engineer-v3",
      "date": "2024-12-W03",
      "year": "2024",
      "month": "12",
      "week": "3",
      "type": "dev",
      "org": "Claude Engineer v3",
      "title": "Claude Engineer v3",
      "url": "https://github.com/Doriandarko/claude-engineer?tab=readme-ov-file#claude-engineer-v3-",
      "bullets": [
        {
          "text": "CLI & web 인터페이스 둘 다 지원",
          "level": 0
        },
        {
          "text": "무려 10k 개의 스타 ⭐",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "AIRI-babilong-testing-the-limits-of-llms-with-long-context-reasoning-in-a-haystack",
      "date": "2024-12-W03",
      "year": "2024",
      "month": "12",
      "week": "3",
      "type": "paper",
      "org": "AIRI",
      "title": "BABILong: Testing the Limits of LLMs with Long Context Reasoning-in-a-Haystack",
      "url": "https://arxiv.org/pdf/2406.10149",
      "bullets": [
        {
          "text": "fact chaining, simple induction, deduction, counting 등 20여 개의 reasoning task 포함",
          "level": 0
        },
        {
          "text": "평가 결과에 따르면 popular LLM도 문맥의 10-20% 정도만 활용하는 수준이며 reasoning complexity가 높아짐에 따라 퍼포먼스가 급격하게 떨어짐",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "CMU,-Duke-theagentcompany-benchmarking-llm-agents-on-consequential-real-world-tasks",
      "date": "2024-12-W03",
      "year": "2024",
      "month": "12",
      "week": "3",
      "type": "paper",
      "org": "CMU, Duke",
      "title": "TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks",
      "url": "https://arxiv.org/pdf/2412.14161",
      "bullets": [
        {
          "text": "internal web site, data를 포함하는 self-contained environment를 구축",
          "level": 0
        },
        {
          "text": "가장 뛰어난 모델로는 전체 태스크의 24% 정도를 완수할 수 있었다고 보고함",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/TheAgentCompany/TheAgentCompany) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Google-DeepMind-facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models",
      "date": "2024-12-W03",
      "year": "2024",
      "month": "12",
      "week": "3",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "FACTS Grounding: A new benchmark for evaluating the factuality of large language models",
      "url": "https://deepmind.google/discover/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/",
      "bullets": [
        {
          "text": "LLM의 답변이 사실적으로 정확하고 충분한 내용을 담고 있는지 확인할 수 있는 벤치마크",
          "level": 0
        },
        {
          "text": "gemini 모델들이 상위권을 다 차지하는데 상당히 의문스러운 양상..",
          "level": 0
        },
        {
          "text": "860개의 public, 859개의 private held out set으로 구성되어 있고 전자를 [공개](https://www.kaggle.com/datasets/deepmind/facts-grounding-examples)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "VS-Code-announcing-a-free-github-copilot-for-vs-code",
      "date": "2024-12-W03",
      "year": "2024",
      "month": "12",
      "week": "3",
      "type": "dev",
      "org": "VS Code",
      "title": "Announcing a free GitHub Copilot for VS Code",
      "url": "https://code.visualstudio.com/blogs/2024/12/18/free-github-copilot",
      "bullets": [
        {
          "text": "코드 어시스턴트에 대한 관심이 뜨거운데, Cursor, Windsurf 에 뒤지지 않으려는 노력으로 보임",
          "level": 0
        },
        {
          "text": "그러나 아직까지 다른 코드툴에 비해서는 너무 약해/평범해 보이는 기능들..",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-o3-preview-call-for-safety-researchers",
      "date": "2024-12-W03",
      "year": "2024",
      "month": "12",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "o3 preview & call for safety researchers",
      "url": "https://openai.com/12-days/?day=12",
      "bullets": [
        {
          "text": "o-series 모델에 적용한 새로운 alignment strategy",
          "level": 1
        },
        {
          "text": "안전성 검사를 위한 작업을 진행 중이고, 이를 위해 일부 연구자들에게 사용 기회를 제공할 것으로 보임",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Perplexity-perplexity-has-reportedly-closed-a-500m-funding-round",
      "date": "2024-12-W03",
      "year": "2024",
      "month": "12",
      "week": "3",
      "type": "news",
      "org": "Perplexity",
      "title": "Perplexity has reportedly closed a $500M funding round",
      "url": "https://techcrunch.com/2024/12/19/perplexity-has-reportedly-closed-a-500m-funding-round/",
      "bullets": [
        {
          "text": "OpenAI가 Chat 모델 시장을 선점한 것, 검색 시장을 Perplexity가 선점한 것 등을 보면 시장에서 입지를 빠르게 가져가는 쪽이 압도적인 인지도와 유저풀을 갖게 되는 것 같다는 생각이 듦",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta,-Washington,-CMU-explore-theory-of-mind-program-guided-adversarial-data-generation-for-theory-of-mind-reasoning",
      "date": "2024-12-W03",
      "year": "2024",
      "month": "12",
      "week": "3",
      "type": "paper",
      "org": "Meta, Washington, CMU",
      "title": "Explore Theory-of-Mind: Program-Guided Adversarial Data Generation for Theory of Mind Reasoning",
      "url": "https://arxiv.org/pdf/2412.12175",
      "bullets": [
        {
          "text": "A\\* search를 custom domain-specific language에 사용하여 복잡한 story sturcture를 생산",
          "level": 0
        },
        {
          "text": "Llama-3.1-70B나 GPT-4o 같은 모델도 각각 0%, 9%에 달하는 낮은 정확도를 보임",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/facebookresearch/exploretom) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Washington,-AI2-self-instruct-aligning-language-models-with-self-generated-instructions",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "Washington, AI2",
      "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
      "url": "https://arxiv.org/pdf/2212.10560",
      "bullets": [
        {
          "text": "언어 모델의 zero-shot 성능이 뛰어나더라도 human-written instruction data 자체는 확보하기 어렵다는 문제가 존재",
          "level": 0
        },
        {
          "text": "→ Self-Instruct: 언어 모델의 생성 결과를 bootstrapping 함으로써 사전학습 모델의 instruction following 능력을 개선하는 프레임워크 제시",
          "level": 0
        },
        {
          "text": "instruction, input, output 생성 → invalid, similar 데이터는 필터링",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Oxford-confidence-in-the-reasoning-of-large-language-models",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "Oxford",
      "title": "Confidence in the Reasoning of Large Language Models",
      "url": "https://arxiv.org/abs/2412.15296",
      "bullets": [
        {
          "text": "(1) reconsider 하도록 prompt를 받았을 때의 persistence를 정성적으로 측정",
          "level": 0
        },
        {
          "text": "(2) self-reported confidnece score를 정량적으로 측정",
          "level": 0
        },
        {
          "text": "일반적으로는 confidence와 accuracy가 양의 상관관계를 보이지만, 두 번째 답변이 첫 번째 답변보다 안좋을 가능성이 높음",
          "level": 0
        },
        {
          "text": "confidence는 token-level probability로 부분적인 해석만 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Peking,-Microsoft-Research-outcome-refining-process-supervision-for-code-generation",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "Peking, Microsoft Research",
      "title": "Outcome-Refining Process Supervision for Code Generation",
      "url": "https://arxiv.org/pdf/2412.15118",
      "bullets": [
        {
          "text": "Outcome-Refining Process Supervision, outcome refinement 자체를 supervised process 자체로 취급하는 paradigm 제시",
          "level": 0
        },
        {
          "text": "여러 개의 solution trajectories를 유지하기 위해 tree-structured exploration을 사용",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "HKUST,-Tencent-b-star-monitoring-and-balancing-exploration-and-exploitation-in-self-taught-reasoners",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "HKUST, Tencent",
      "title": "B-STaR: Monitoring and Balancing Exploration and Exploitation in Self-Taught Reasoners",
      "url": "https://arxiv.org/pdf/2412.17256",
      "bullets": [
        {
          "text": "(1) 모델이 충분히 다양한 response를 생성할 수 있는 능력이 있는가",
          "level": 1
        },
        {
          "text": "(2) 고퀄리티-저퀄리티 데이터를 구분하는 external reward의 효용성",
          "level": 1
        },
        {
          "text": "추론 관련 태스크에서 exploration & exploitation을 추적하여 정량적 분석 수행",
          "level": 0
        },
        {
          "text": "Self-Taught Reasoning 프레임워크 B-STaR 제시",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Tsinghua-fourier-position-embedding-enhancing-attentions-periodic-extension-for-length-generalization",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "Tsinghua",
      "title": "Fourier Position Embedding: Enhancing Attention's Periodic Extension for Length Generalization",
      "url": "https://arxiv.org/pdf/2412.17739",
      "bullets": [
        {
          "text": "Discrete Signal Processing theory를 사용하여 RoPE가 Non-Uniform Discrete Fourier Transform을 achieve 함으로써 periodic attention을 가능하도록 만든다는 것을 확인",
          "level": 0
        },
        {
          "text": "Fourier Position Embedding (FoPE): periodic extension과 length generalization을 개선하기 위해 attention의 frequency-domain properties를 enhance",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/TsinghuaC3I/Fourier-Position-Embedding) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "MIS-(Make-It-So)-mis-make-it-so",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "dev",
      "org": "MIS (Make It So)",
      "title": "MIS (Make It So)",
      "url": "https://discuss.pytorch.kr/t/mis-make-it-so-cli-assistant/5727",
      "bullets": [
        {
          "text": "OpenAI, Mistral, X.ai, Ollama 등과 같은 다양한 AI 프로바이더를 지원",
          "level": 0
        },
        {
          "text": "자연어로 명령을 실행할 수 있음. 실제 명령 실행 전에 확인 과정을 거쳐 문제 일으킬 가능성 최소화.",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/RamboRogers/mis?utm_source=pytorchkr&ref=pytorchkr) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "KAIST,-Microsoft-Research-ensembling-large-language-models-with-process-reward-guided-tree-search-for-better-complex-reasoning",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "KAIST, Microsoft Research",
      "title": "Ensembling Large Language Models with Process Reward-Guided Tree Search for Better Complex Reasoning",
      "url": "https://arxiv.org/pdf/2412.15797",
      "bullets": [
        {
          "text": "Markov decision process에 따라 언어 모델들의 ensemble 하여 step-by-step reasoning을 구성",
          "level": 0
        },
        {
          "text": "state는 중간 추론 과정 (reasoning path)를 나타내고 action은 다음 reasoning step을 생성하는 것으로 구성됨",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Nanjing-Univ.-token-budget-aware-llm-reasoning",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "Nanjing Univ.",
      "title": "Token-Budget-Aware LLM Reasoning",
      "url": "https://arxiv.org/pdf/2412.18547",
      "bullets": [
        {
          "text": "CoT reasoning에 사용되는 토큰의 수와 비용을 효과적으로 감소시킬 수 있었다고 주장",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/GeniusHTX/TALE) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "KAIST,-Google-DeepMind-revisiting-in-context-learning-with-long-context-language-models",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "KAIST, Google DeepMind",
      "title": "Revisiting In-Context Learning with Long Context Language Models",
      "url": "https://arxiv.org/pdf/2412.16926",
      "bullets": [
        {
          "text": "정교한 예시 선정이 random selection 대비 큰 성능 향상으로 이어지지 않는다는 결과",
          "level": 0
        },
        {
          "text": "오히려 좋은 예시들을 찾는 것보다 context window를 채울 만큼의 예시를 확보하는 게 더 어렵고 중요한 문제로 인식되기 시작했다는 주장",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Tsinghua,-Peking-how-to-synthesize-text-data-without-model-collapse",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "Tsinghua, Peking",
      "title": "How to Synthesize Text Data without Model Collapse?",
      "url": "https://arxiv.org/pdf/2412.14689",
      "bullets": [
        {
          "text": "합성 데이터의 비율을 조절해가며 학습해 본 결과, 합성 데이터의 비율과 모델의 성능이 음의 상관관계를 보인다고 함",
          "level": 0
        },
        {
          "text": "사람이 생성한 데이터에 token editing을 적용하여 semi-synthetic data를 획득하는 방법론 제안",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Anthropic,-NYU,-Mila-alignment-faking-in-large-language-models",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "Anthropic, NYU, Mila",
      "title": "Alignment faking in large language models",
      "url": "https://arxiv.org/pdf/2412.14093",
      "bullets": [
        {
          "text": "무료 유저와 대화할 것임을 시스템 프롬프트에 포함하고 모든 해로운 질문에 대해서도 답변할 수 있도록 학습 → 추론 시 무료/유료 유저 결과 비교해보니 무료 유저의 해로운 질문에 대해서 답변할 확률이 14%, 유료 유저에 대해서는 0%",
          "level": 0
        },
        {
          "text": "사전학습 데이터를 모방한 합성 데이터를 이용하여 보다 현실적인 세팅에서 실험한 결과 제시",
          "level": 0
        },
        {
          "text": "강화학습으로도 alignment-faking reasoning을 확인한 결과, 그 비율이 78%까지 오르는 것을 확인함",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Pennsylvania,-Salesforce-greater-gradients-over-reasoning-makes-smaller-language-models-strong-prompt-optimizers",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "Pennsylvania, Salesforce",
      "title": "GReaTer: Gradients over Reasoning Makes Smaller Language Models Strong Prompt Optimizers",
      "url": "https://arxiv.org/pdf/2412.09722",
      "bullets": [
        {
          "text": "GReaTer: task loss gradients를 활용하여 open-source, lightweight LM으로 self-optimization of prompts 수행하는 테크닉",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/psunlpgroup/GreaTer) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-Research,-Google-DeepMind-a-little-help-goes-a-long-way-efficient-llm-training-by-leveraging-small-lms",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "Google Research, Google DeepMind",
      "title": "A Little Help Goes a Long Way: Efficient LLM Training by Leveraging Small LMs",
      "url": "https://arxiv.org/pdf/2410.18779",
      "bullets": [
        {
          "text": "(1) additional training supervision을 위한 soft label 제공",
          "level": 0
        },
        {
          "text": "(2) small subset of valuable training examples 선별",
          "level": 0
        },
        {
          "text": "1.5B 모델을 soft labeler로 이용하여 2.8B 사이즈 모델을 학습한 결과를 제시",
          "level": 0
        },
        {
          "text": "low-quality supervision이 좋은 영향을 줄 수 있음, 그리고 adaptive하게 적용할 필요성 등을 확인한 것으로 보임. 장기적으로는 더 좋은 모델을 활용하여 더 뛰어난 모델을 사전학습 단계에서 만들 수 있다는 의미가 될 수도.. (자원이 뒷받침 된다면)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "DeepSeek-deepseek-v3-technical-report",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "DeepSeek",
      "title": "DeepSeek-V3 Technical Report",
      "url": "https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf",
      "bullets": [
        {
          "text": "효율적인 학습 및 추론을 위해 Multi-head Latent Attention (MLA) & DeepSeekMoE 아키텍쳐 선택",
          "level": 0
        },
        {
          "text": "load balancing을 위한 auxiliary-loss-free strategy, multi-token prediction training objective",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta-large-concept-models-language-modeling-in-a-sentence-representation-space",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "Meta",
      "title": "Large Concept Models: Language Modeling in a Sentence Representation Space",
      "url": "https://ai.meta.com/research/publications/large-concept-models-language-modeling-in-a-sentence-representation-space/",
      "bullets": [
        {
          "text": "existing sentence embedding space, SONAR 사용",
          "level": 0
        },
        {
          "text": "diffusion-based generation의 일종인 MSE regression 등을 시도",
          "level": 0
        },
        {
          "text": "1.6B 모델에 1.3T 토큰 학습 & 7B 모델에 2.7T 토큰 학습",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/facebookresearch/large_concept_model) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Ollama-&-HuggingFace-use-ollama-with-any-gguf-model-on-hugging-face-hub",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "dev",
      "org": "Ollama & HuggingFace",
      "title": "Use Ollama with any GGUF Model on Hugging Face Hub",
      "url": "https://huggingface.co/docs/hub/en/ollama",
      "bullets": [
        {
          "text": "모델 페이지의 `Use this model`에서 `ollama`를 선택",
          "level": 0
        },
        {
          "text": "`ollama run hf.co/{username}/{repository}`",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Qwen-qvq-to-see-the-world-with-wisdom",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "dev",
      "org": "Qwen",
      "title": "QVQ: To See the World with Wisdom",
      "url": "https://qwenlm.github.io/blog/qvq-72b-preview/",
      "bullets": [
        {
          "text": "MMMU, MathVista, MathVision, OlympiadBench 등 수학적 추론 능력이 크게 요구되는 벤치마크에서 GPT-4o & Claude3.5 Sonnet 이상의 퍼포먼스를 보임",
          "level": 0
        },
        {
          "text": "Language Mixing & Code-Switching 등이 예상치 못하게 나타날 수 있음, Recursive Reasoning 등의 문제가 존재",
          "level": 0
        }
      ],
      "tags": [
        "multimodal",
        "reasoning"
      ]
    },
    {
      "id": "Tencent-a-silver-bullet-or-a-compromise-for-full-attention-a-comprehensive-study-of-gist-token-based-context-compression",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "Tencent",
      "title": "A Silver Bullet or a Compromise for Full Attention? A Comprehensive Study of Gist Token-based Context Compression",
      "url": "https://arxiv.org/pdf/2412.17483",
      "bullets": [
        {
          "text": "synthetic recall과 같은 태스크에서 약점을 보임",
          "level": 1
        },
        {
          "text": "세 개의 key failure patterns",
          "level": 0
        },
        {
          "text": "(1) lost by the boundary (2) lost if surprise (3) lost along the way",
          "level": 1
        },
        {
          "text": "두 개의 전략을 제시",
          "level": 0
        },
        {
          "text": "(1) fine-grained autoencoding: original token 정보를 reconstruct 하는 걸 강화",
          "level": 1
        },
        {
          "text": "(2) segment-wise token importance estimation: token dependencies 기반으로 최적화 조절",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Gaoling-School-yulan-mini-an-open-data-efficient-language-model",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "Gaoling School",
      "title": "YuLan-Mini: An Open Data-efficient Language Model",
      "url": "https://arxiv.org/pdf/2412.17743",
      "bullets": [
        {
          "text": "세 개의 특징을 가진 사전학습 테크닉",
          "level": 0
        },
        {
          "text": "(1) an elaborate data pipeline",
          "level": 1
        },
        {
          "text": "(2) 학습 불안정성을 완화하는 robust optimization method",
          "level": 1
        },
        {
          "text": "(3) targeted data selection & long context training",
          "level": 1
        },
        {
          "text": "[깃허브 링크](https://github.com/RUC-GSAI/YuLan-Mini) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Chalmers-University-the-impact-of-prompt-programming-on-function-level-code-generation",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "Chalmers University",
      "title": "The Impact of Prompt Programming on Function-Level Code Generation",
      "url": "https://arxiv.org/pdf/2412.20545",
      "bullets": [
        {
          "text": "세 개의 LLM(GPT-4o, Llama3, Mistral)로 부터 생성한 completion function의 quality 평가",
          "level": 0
        },
        {
          "text": "특정 테크닉이 코드 생성에 도움은 되지만, 이것들의 조합/결합이 반드시 도움이 되는 것은 아님",
          "level": 0
        },
        {
          "text": "correctness & quality 간의 trade-off 관측 (quality가 뭘 의미하는지 모르겠음)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta-improving-factuality-with-explicit-working-memory",
      "date": "2024-12-W04",
      "year": "2024",
      "month": "12",
      "week": "4",
      "type": "paper",
      "org": "Meta",
      "title": "Improving Factuality with Explicit Working Memory",
      "url": "https://arxiv.org/pdf/2412.18069",
      "bullets": [
        {
          "text": "memory는 online fack-checking과 retrieval feedback을 기반으로 refreshed",
          "level": 0
        },
        {
          "text": "→ 중간에 잘못 생성되었던 내용들에 대한 dependency issue를 해결할 수 있음",
          "level": 1
        },
        {
          "text": "memory update 규칙, memory unit에 대한 configuration, retrieval datastore의 quality 등이 성능에 가장 큰 영향을 미치는 요소들",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Boston-linguistics-theory-meets-llm-code-switched-text-generation-via-equivalence-constrained-large-language-models",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Boston",
      "title": "Linguistics Theory Meets LLM: Code-Switched Text Generation via Equivalence Constrained Large Language Models",
      "url": "https://arxiv.org/abs/2410.22660",
      "bullets": [
        {
          "text": "EZSwitch: Equivalence Constraint Theory (ECT)를 LLM에 결합하여 언어학적으로 타당하고 유려한 code-switched text를 만들 수 있도록 하는 프레임워크",
          "level": 0
        },
        {
          "text": "CSPerf: human preference dataset",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Yale,-NYU-struc-bench-are-large-language-models-really-good-at-generating-complex-structured-data",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Yale, NYU",
      "title": "Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?",
      "url": "https://arxiv.org/abs/2309.08963",
      "bullets": [
        {
          "text": "Prompting Score (P-Score) & Heuristical Score (H-Score) 를 제안",
          "level": 0
        },
        {
          "text": "structure fine-tuning을 고안하여 Llama에 적용한 결과, 눈에 띄는 성능 향상이 있었다고 보고",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/gersteinlab/Struc-Bench) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Apple-scaling-smart-accelerating-large-language-model-pre-training-with-small-model-initialization",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Apple",
      "title": "Scaling Smart: Accelerating Large Language Model Pre-training with Small Model Initialization",
      "url": "https://arxiv.org/abs/2409.12903",
      "bullets": [
        {
          "text": "larger model이 smaller model의 functionality를 보유할 수 있도록 도와줌",
          "level": 0
        },
        {
          "text": "학습이 시작되기 전 larger 모델이 smaller 모델의 능력을 탑재하고 있으므로, 무작위로 초기화된 파라미터를 학습하는 것보다 훨씬 효율적이라고 주장",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-introducing-chatgpt-search-1",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing ChatGPT search",
      "url": "https://openai.com/index/introducing-chatgpt-search/",
      "bullets": [
        {
          "text": "합성데이터로 fine-tuned GPT-4o를 사용",
          "level": 0
        },
        {
          "text": "날씨, 주식, 스포츠 등은 data provider와 파트너십을 통해 real-time data를 특별히 제공한다고 함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Ghent-University-large-language-models-reflect-the-ideology-of-their-creators",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Ghent University",
      "title": "Large Language Models Reflect the Ideology of their Creators",
      "url": "https://arxiv.org/abs/2410.18417",
      "bullets": [
        {
          "text": "LLM에게 최근 세계사의 유명하면서도 논쟁이 많은 인물들을 묘사하도록 프롬프팅 (영어 & 중국어)",
          "level": 0
        },
        {
          "text": "같은 LLM이라도 영어와 중국어 사용에 따라 normative disagreement를 보인다는 것을 확인함",
          "level": 0
        },
        {
          "text": "Western 모델에 정치적인 성향이 반영되어 있다고도 주장",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Ohio,-Washington,-AI2-compo-community-preferences-for-language-model-personalization",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Ohio, Washington, AI2",
      "title": "ComPO: Community Preferences for Language Model Personalization",
      "url": "https://arxiv.org/abs/2410.16027",
      "bullets": [
        {
          "text": "ComPO, preference provider와 함께 모델 output의 확률 분포를 contextualize 함으로써 preference optimization를 personalize",
          "level": 0
        },
        {
          "text": "개인 단위가 아닌 그룹 단위의 선호 데이터셋을 수집하여 community-level preferences from Reddit → ComPRed 공개",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "NYU,-AI2,-NVIDIA,-Washington-diverging-preferences-when-do-annotators-disagree-and-do-models-know",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "NYU, AI2, NVIDIA, Washington",
      "title": "Diverging Preferences: When do Annotators Disagree and do Models Know?",
      "url": "https://arxiv.org/abs/2410.14632",
      "bullets": [
        {
          "text": "4개의 high-level 클래스로 구분되는 10개의 카테고리로 disagreement taxonomy를 구축",
          "level": 0
        },
        {
          "text": "task underspecification, response style, refusals, annotation errors",
          "level": 1
        },
        {
          "text": "이것들이 reward modeling & evaluation 에 어떤 영향을 미치는지 조사",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "VNU-Univ.-mod-a-distribution-based-approach-for-merging-large-language-models",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "VNU Univ.",
      "title": "MoD: A Distribution-Based Approach for Merging Large Language Models",
      "url": "https://arxiv.org/abs/2411.00406",
      "bullets": [
        {
          "text": "각 모델들의 specialized 능력을 보존하면서도 task 사이의 효율적인 knowledge sharing 가능",
          "level": 0
        },
        {
          "text": "간단하게 살펴봤을 땐 다른 merge 방식과 뭐가 그렇게 크게 다른지는 잘 모르겠음",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/knovel-eng/mod) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-gemini-api-and-google-ai-studio-now-offer-grounding-with-google-search",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "Google",
      "title": "Gemini API and Google AI Studio now offer Grounding with Google Search",
      "url": "https://developers.googleblog.com/en/gemini-api-and-ai-studio-now-offer-grounding-with-google-search/",
      "bullets": [
        {
          "text": "검색 결과를 기반으로 답변을 생성하는 방식으로 최근 생성형 검색 엔진에 대한 관심이 뜨거움",
          "level": 0
        },
        {
          "text": "그러나 최근 구글 검색의 결과물이 만족스럽지 않다는 점을 감안하면 그렇게 좋을지는 잘 모르겠음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "HuggingFace-smollm2-17b-instruct",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "HuggingFace",
      "title": "SmolLM2-1.7B-Instruct",
      "url": "https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct",
      "bullets": [
        {
          "text": "잘 정제된 데이터셋으로 SFT & DPO 학습한 모델로, 동사이즈 대비 아주 뛰어난 성능 지표를 보임",
          "level": 0
        },
        {
          "text": "[이미 ollama에서도 지원](https://ollama.com/library/smollm2) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Anthropic-pdf-support-beta",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "PDF support (beta)",
      "url": "https://docs.anthropic.com/en/docs/build-with-claude/pdf-support",
      "bullets": [
        {
          "text": "최대 32MB, 100 페이지 커버가 가능하며 페이지당 1,500 ~ 3,000 토큰 사용",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "xAI-api-public-beta",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "xAI",
      "title": "API Public Beta",
      "url": "https://x.ai/blog/api",
      "bullets": [
        {
          "text": "128K 토큰 길이의 context, function calling, system prompt를 지원",
          "level": 0
        },
        {
          "text": "베타 기간 동안 25$의 API 크레딧을 매달 지급",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Anthropic-claude-35-haiku",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "Claude 3.5 Haiku",
      "url": "https://www.anthropic.com/claude/haiku",
      "bullets": [
        {
          "text": "다른 태스크보다 특히 코드 생성에서 좋은 퍼포먼스를 보이는 것 같음",
          "level": 0
        },
        {
          "text": "그런데 비용이 많이 올라서 논란이 되는 것으로 보임",
          "level": 0
        },
        {
          "text": "Sonnet 3.5 (new)의 성능도 함께 화제가 되는 중",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "MIT,-Cambridge-the-geometry-of-concepts-sparse-autoencoder-feature-structure",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "MIT, Cambridge",
      "title": "The Geometry of Concepts: Sparse Autoencoder Feature Structure",
      "url": "https://arxiv.org/abs/2410.19750",
      "bullets": [
        {
          "text": "Sparse autoencoder는 최근 LLM에 의해 표현되는 세상의 concepts를 high dimensional vectors의 dictionaries로 produce 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-Research-distinguishing-ignorance-from-error-in-llm-hallucinations",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Google Research",
      "title": "Distinguishing Ignorance from Error in LLM Hallucinations",
      "url": "https://arxiv.org/abs/2410.22071",
      "bullets": [
        {
          "text": "후자의 경우 중간 연산에 개입함으로써 문제를 해결할 수 있으나, 전자의 경우 외부 지식 source가 필요",
          "level": 0
        },
        {
          "text": "두 경우를 구분하기 위해 Wrong Answer despite having Correct Knowledge (WACK) 라는 model-specific dataset 구축 방식을 제안",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Duke,-Google-Research-sled-self-logits-evolution-decoding-for-improving-factuality-in-large-language-models",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Duke, Google Research",
      "title": "SLED: Self Logits Evolution Decoding for Improving Factuality in Large Language Models",
      "url": "https://arxiv.org/abs/2411.02433",
      "bullets": [
        {
          "text": "마지막 layer의 output logits와 초기 layer의 output logits을 contrasting 하여 LLM 내부에 embedded 된 latent knowledge를 이용",
          "level": 0
        },
        {
          "text": "latent knowledge가 output에 대해 self-refinement 할 수 있도록 approximate gradient approach 를 사용",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-smol-tools",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "HuggingFace",
      "title": "Smol Tools",
      "url": "https://github.com/huggingface/smollm/tree/main/smol_tools",
      "bullets": [
        {
          "text": "SmolSummarizer, SmolRewriter, SmolAgent",
          "level": 0
        },
        {
          "text": "각각이 엄청난 건 아닌데 작은 모델들을 각자의 작업에 특화시켜서 합친 것에 의미가 있는 듯함",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "IBM-granite-30-language-models",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "IBM",
      "title": "Granite 3.0 Language Models",
      "url": "https://github.com/ibm-granite/granite-3.0-language-models?tab=readme-ov-file",
      "bullets": [
        {
          "text": "Sparse 1B & 3B MoE 모델. 400M & 800M activate 파라미터. 총 10T 토큰으로 학습.",
          "level": 0
        },
        {
          "text": "비교군으로는 Llama3.1 8B, Mistral 7B / SmolLM-1.7B 등 모델을 사용",
          "level": 0
        },
        {
          "text": "상업적으로도 사용 가능하도록 Apache 2.0 라이센스로 공개됨",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HtmlRAG:-HTML-is-Better-Than-Plain-Text-for-Modeling-Retrieved-Knowledge-in-RAG-Systems-htmlrag-html-is-better-than-plain-text-for-modeling-retrieved-knowledge-in-rag-systems",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems",
      "title": "HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems",
      "url": "https://arxiv.org/abs/2411.02959",
      "bullets": [
        {
          "text": "따라서 plain text 대신 HTML을 사용하는 HtmlRAG를 제안",
          "level": 0
        },
        {
          "text": "그러나 HTML을 바로 사용하기는 어렵기 때문에, HTML cleaning, compression, pruning strategies를 도입하여 정보의 손실을 최소화 하면서도 HTML을 줄이고자 함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Dartmoouth,-Adobe,-Stanford,-…-personalization-of-large-language-models-a-survey",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Dartmoouth, Adobe, Stanford, …",
      "title": "Personalization of Large Language Models: A Survey",
      "url": "https://arxiv.org/abs/2411.00027",
      "bullets": [
        {
          "text": "personalization techniques, datasets ,evaluation methods, application 등을 기준으로 구분",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Huawei-large-language-models-orchestrating-structured-reasoning-achieve-kaggle-grandmaster-level",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Huawei",
      "title": "Large Language Models Orchestrating Structured Reasoning Achieve Kaggle Grandmaster Level",
      "url": "https://arxiv.org/abs/2411.03562",
      "bullets": [
        {
          "text": "기존의 rigid & limited 한 CoT & reflection 대신에 아주 유연한 structrued reasoning 프레임워크를 사용했다고 언급",
          "level": 0
        },
        {
          "text": "iteration마다 핵심 정보를 탐색 및 저장함으로써 long- & short-term memory를 업데이트함. 이를 통해 fine-tuning이나 backpropagation 없이 성능을 개선할 수 있음",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Tancent-hunyuan-large-an-open-source-moe-model-with-52-billion-activated-parameters-by-tencent",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Tancent",
      "title": "Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent",
      "url": "https://arxiv.org/abs/2411.02265",
      "bullets": [
        {
          "text": "256K 길이의 window size를 갖는 모델",
          "level": 0
        },
        {
          "text": "다양한 태스크에서 LLama3.1-70B를 능가하고, 405B 모델에 비견되는 성능을 보임",
          "level": 0
        },
        {
          "text": "large-scale synthetic data, mixed expert routing, key-value cache compression, expert-specific learning rate 등이 핵심 특징",
          "level": 0
        },
        {
          "text": "MoE 모델의 scaling law와 learning rate schedule에 대해서도 연구",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/Tencent/Hunyuan-Large) 🔗 [허깅페이스 링크](https://huggingface.co/tencent/Tencent-Hunyuan-Large) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Ollama-ollama-04-integrates-metas-llama-32-vision-models-11b-and-90b",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "Ollama",
      "title": "Ollama 0.4 Integrates Meta's Llama 3.2 Vision Models (11B and 90B)",
      "url": "https://ollama.com/blog/llama3.2-vision",
      "bullets": [
        {
          "text": "터미널에서 사용 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "NVIDIA-mm-embed-universal-multimodal-retrieval-with-multimodal-llms",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "NVIDIA",
      "title": "MM-Embed: Universal Multimodal Retrieval with Multimodal LLMs",
      "url": "https://arxiv.org/abs/2411.02571",
      "bullets": [
        {
          "text": "MLLM을 10개 데이터셋 16개의 태스크에 대해 학습하여 bi-encoder retriever로 사용",
          "level": 0
        },
        {
          "text": "MLLM에 존재하는 modality bias를 완화하기 위해 modality-aware hard negative mining을 제안",
          "level": 0
        },
        {
          "text": "여러 modality 중에서도 특히 text retrieval 능력을 향상시키기 위해 continually fine-tuning 할 것을 제안",
          "level": 0
        },
        {
          "text": "[허깅페이스 링크](https://huggingface.co/nvidia/MM-Embed) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Zhejiang-fine-grained-guidance-for-retrievers-leveraging-llms-feedback-in-retrieval-augmented-generation",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Zhejiang",
      "title": "Fine-Grained Guidance for Retrievers: Leveraging LLMs' Feedback in Retrieval-Augmented Generation",
      "url": "https://arxiv.org/abs/2411.03957",
      "bullets": [
        {
          "text": "retriever가 잘 못하는 샘플들로부터 easy-to-understand 샘플을 LLM으로 생성하는 방식",
          "level": 0
        },
        {
          "text": "이때 세 가지 learning objective, relevance, comprehensiveness, purity를 고려",
          "level": 0
        },
        {
          "text": "LLM과 retriever 간 dual curriculum learning & reciprocal feedback",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "XPENG-xpeng-unveils-iron-humanoid-robot-already-operational-in-ev-factory",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "news",
      "org": "XPENG",
      "title": "XPENG Unveils Iron Humanoid Robot, Already Operational in EV Factory",
      "url": "https://www.maginative.com/article/xpeng-unveils-iron-humanoid-robot-already-operational-in-ev-factory/",
      "bullets": [
        {
          "text": "Eagle Vision 시스템과 end-to-end large AI model이 통합된 시스템",
          "level": 0
        },
        {
          "text": "PoC 수준을 넘어 실제 공정에서 활용 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "ByteDance,-Tsinghua-x-portrait-2-highly-expressive-portrait-animation",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "ByteDance, Tsinghua",
      "title": "X-Portrait 2: Highly Expressive Portrait Animation",
      "url": "https://byteaigc.github.io/X-Portrait2/",
      "bullets": [
        {
          "text": "현실적인 이미지와 만화 그림체 사이에도 style transfer 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Edinburgh-mixtures-of-in-context-learners",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Edinburgh",
      "title": "Mixtures of In-Context Learners",
      "url": "https://arxiv.org/abs/2411.02830",
      "bullets": [
        {
          "text": "분류 태스크에서 뛰어난 성능, 더 적은 demonstration으로 기존과 유사한 퍼포먼스를 달성하여 파레토 라인을 push",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google,-Peking-tokenformer-rethinking-transformer-scaling-with-tokenized-model-parameters-1",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Google, Peking",
      "title": "TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters",
      "url": "https://arxiv.org/abs/2410.23168",
      "bullets": [
        {
          "text": "Tokenformer: attention 메커니즘을 input token 사이의 computation 뿐만 아니라 token과 모델 파라미터 간 interaction에도 활용",
          "level": 0
        },
        {
          "text": "모든 linear layer를 token-parameter attention layer로 교체!",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/Haiyang-W/TokenFormer) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Hong-Kong,-Tsinghua,-Peking,-Tencent-large-language-models-can-self-improve-in-long-context-reasoning",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Hong Kong, Tsinghua, Peking, Tencent",
      "title": "Large Language Models Can Self-Improve in Long-context Reasoning",
      "url": "https://arxiv.org/abs/2411.08147",
      "bullets": [
        {
          "text": "위 문제를 해결하기 위해 SeaLong 제안: 각 질문에 대해 여러 개의 output을 생성하고 Minimum Bayes Risks를 이용한 scoring 후 SFT 또는 preference optimization",
          "level": 0
        },
        {
          "text": "이런 방법론들은 결국 cost 문제에 직면하기 마련인데..",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "INF,-M-A-P-opencoder-the-open-cookbook-for-top-tier-code-large-language-models",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "INF, M-A-P",
      "title": "OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models",
      "url": "https://opencoder-llm.github.io/",
      "bullets": [
        {
          "text": "재현 가능한 960B 토큰의 데이터셋, 4.5M SFT samples, intermediate checkpoints",
          "level": 0
        },
        {
          "text": "Two-Stage Instruction Fine-Tuning for Theory and Practice",
          "level": 0
        },
        {
          "text": "Ollama에서 동작 가능. 로컬에서 코드 모델을 사용하고자 하는 수요가 적지 않은 것 같음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "NVIDIA-cosmos-tokenizer-a-suite-of-image-and-video-neural-tokenizers",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "NVIDIA",
      "title": "Cosmos Tokenizer: A suite of image and video neural tokenizers",
      "url": "https://research.nvidia.com/labs/dir/cosmos-tokenizer/",
      "bullets": [
        {
          "text": "토크나이저는 생성형 모델들의 성능에 직접적인 영향을 주는데 이를 평가하기 위한 [TokenBench](https://github.com/NVlabs/TokenBench)도 존재",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Wuhan-Univ.-adaption-of-thought-learning-question-difficulty-improves-large-language-models-for-reasoning",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Wuhan Univ.",
      "title": "Adaption-of-Thought: Learning Question Difficulty Improves Large\n  Language Models for Reasoning",
      "url": "https://aclanthology.org/2024.emnlp-main.313.pdf",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Alibaba-qwen25-coder-series-powerful-diverse-practical",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "Alibaba",
      "title": "Qwen2.5-Coder Series: Powerful, Diverse, Practical.",
      "url": "https://qwenlm.github.io/blog/qwen2.5-coder-family/",
      "bullets": [
        {
          "text": "6개의 모델 사이즈를 기준으로 모델을 공개",
          "level": 0
        },
        {
          "text": "0.5B / 1.5B / 7B / 14B / 32B 모델은 Apache 2.0, 3B 모델은 Qwen-Research 라이센스를 따름",
          "level": 1
        },
        {
          "text": "coding assistant & Artifact 두 개의 시나리오에서 사용할 수 있게끔 학습됨",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Nous-Research-introducing-the-forge-reasoning-api-beta-and-nous-chat-an-evolution-in-llm-inference",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "Nous Research",
      "title": "Introducing the Forge Reasoning API Beta and Nous Chat: An Evolution in LLM Inference",
      "url": "https://nousresearch.com/introducing-the-forge-reasoning-api-beta-and-nous-chat-an-evolution-in-llm-inference/",
      "bullets": [
        {
          "text": "📜 [모델 테크니컬 리포트](https://nousresearch.com/wp-content/uploads/2024/08/Hermes-3-Technical-Report.pdf) 🔗",
          "level": 0
        },
        {
          "text": "MCTS, CoC, MoA 등의 방법론들을 조합하여 모델 사이즈 증가 없이 퍼포먼스를 향상시킴",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Israel-Institue-of-Technology-backward-lens-projecting-language-model-gradients-into-the-vocabulary-space",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Israel Institue of Technology",
      "title": "Backward Lens: Projecting Language Model Gradients into the Vocabulary Space",
      "url": "https://aclanthology.org/2024.emnlp-main.142.pdf",
      "bullets": [
        {
          "text": "gradient matrix가 low-rank linear combination의 forward & backward pass의 입력으로 cast 될 수 있음을 입증 (?)",
          "level": 0
        },
        {
          "text": "이러한 gradients를 vocab item에 project하고 LM의 neuron에 새로운 정보를 저장할 수 있도록 하는 방법론을 고안",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/shacharKZ/BackwardLens) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Univ.-of-Tehran-cocop-enhancing-text-classification-with-llm-through-code-completion-prompt",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Univ. of Tehran",
      "title": "CoCoP: Enhancing Text Classification with LLM through Code Completion Prompt",
      "url": "https://arxiv.org/pdf/2411.08979",
      "bullets": [
        {
          "text": "text classification 문제를 해결하기 위해 LLM의 code 능력을 활용하는 Code Completion Prompt (CoCoP) 방법론 제시: text classification → code completion",
          "level": 0
        },
        {
          "text": "CodeLLaMA와 같은 코드 특화 모델을 사용하는 경우, few-shot learning 수준의 퍼포먼스 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Together-AI-llama-ocr",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "Together AI",
      "title": "Llama OCR",
      "url": "",
      "bullets": [
        {
          "text": "Together AI가 학습한 Llama 3.2 모델의 endpoint를 사용하여 ocr 수행",
          "level": 0
        },
        {
          "text": "Llama 3.2 11B & 90B 모델은 유료로 사용 가능",
          "level": 0
        },
        {
          "text": "[이미지 업로드 페이지 링크](https://llamaocr.com/) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Apple-cut-your-losses-in-large-vocabulary-language-models",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Apple",
      "title": "Cut Your Losses in Large-Vocabulary Language Models",
      "url": "https://arxiv.org/pdf/2411.09009",
      "bullets": [
        {
          "text": "이는 각 입력 토큰 & vocab item 쌍마다 logit 행렬을 구축하기 때문이고, 작은 모델이라고 할지라도 LLM의 나머지 구성요소의 수배에 달하는 메모리를 차지하게 됨",
          "level": 1
        },
        {
          "text": "Cut Cross-Entropy (CCE) 제안: 모든 토큰에 대한 로짓을 전역 메모리에 저장하지 않고도 Cross Entropy 계산 가능",
          "level": 0
        },
        {
          "text": "대신 정답에 대한 logit만 계산, 모든 logit에 대한 log sum-exp를 실시간 평가",
          "level": 1
        },
        {
          "text": "Gemma 2 (2B) 모델의 경우 loss 계산의 메모리 사용량을 24GB → 1MB 로 줄이고, classification head의 전체 학습에서는 28GB → 1GB 로 줄임",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/apple/ml-cross-entropy) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Anthropic-improve-your-prompts-in-the-developer-console",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "Improve your prompts in the developer console",
      "url": "https://www.anthropic.com/news/prompt-improver",
      "bullets": [
        {
          "text": "CoT Reasoning, Example standardization, Example enrichment, Rewriting, Prefill addition 등을 활용",
          "level": 0
        },
        {
          "text": "workbench에서 multi-shot example을 관리할 수 있음. Claude를 활용하여 synthetic 데이터를 자동적으로 만들 수도 있음",
          "level": 0
        },
        {
          "text": "(이전에 출시된 기능이긴한데) 최종 생성 결과에 대해 1-5점 점수를 부여하는 평가 기능도 지원함",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Harvard,-Stanford,-MIT,-Databricks,-CMU-scaling-laws-for-precision",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "paper",
      "org": "Harvard, Stanford, MIT, Databricks, CMU",
      "title": "Scaling Laws for Precision",
      "url": "https://arxiv.org/pdf/2411.04330",
      "bullets": [
        {
          "text": "training in lower precision은 모델의 effective parameter count를 감소시킴으로써 low precision training과 post-train quantization으로부터의 loss를 예측할 수 있도록 함",
          "level": 1
        },
        {
          "text": "추론에 대해서는, 모델이 더 많은 데이터로 학습되었을수록 post-training quantization에 의한 성능 하락이 심각",
          "level": 1
        },
        {
          "text": "학습에 대해서는, 본인들이 제시하는 scaling law를 통해 다른 precision으로 학습한 결과를 예측할 수 있다고 주장. 이때 큰 모델을 낮은 precision으로 학습하는 것을 권장.",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "MIT-the-surprising-effectiveness-of-test-time-training-for-abstract-reasoning",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "paper",
      "org": "MIT",
      "title": "The Surprising Effectiveness of Test-Time Training for Abstract Reasoning",
      "url": "https://ekinakyurek.github.io/papers/ttt.pdf",
      "bullets": [
        {
          "text": "Abstraction and Reasoning Corpus (ARC)를 벤치마크로 사용 (reasoning 포커스)",
          "level": 1
        },
        {
          "text": "TTT의 중요한 구성 요소: (1) initial finetuning on similar tasks (2) auxiliary task format and augmentations (3) per-instance training",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Peking,-Tsinghua-llava-o1-let-vision-language-models-reason-step-by-step",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "paper",
      "org": "Peking, Tsinghua",
      "title": "LLaVA-o1: Let Vision Language Models Reason Step-by-Step",
      "url": "https://arxiv.org/pdf/2411.10440",
      "bullets": [
        {
          "text": "LLaVA-o1, autonomous multistage reasoning",
          "level": 1
        },
        {
          "text": "일반적인 CoT prompting과 달리 LLaVA-o1은 summarization, visual interpretation, logical reasoning, conclusion generation 으로 구성된 stage들을 독립적 & 연속적으로 engage",
          "level": 1
        },
        {
          "text": "LLaVA-o1-100k dataset: visual question answering, structured reasoning annotations",
          "level": 1
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Shanghai,-Fudan-compound-qa-a-benchmark-for-evaluating-llms-on-compound-questions",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "paper",
      "org": "Shanghai, Fudan",
      "title": "Compound-QA: A Benchmark for Evaluating LLMs on Compound Questions",
      "url": "https://arxiv.org/pdf/2411.10163",
      "bullets": [
        {
          "text": "Compound Question Synthesis (CQ-Syn)을 도입하여 Compound-QA를 제작. multi sub-question에 집중",
          "level": 1
        },
        {
          "text": "Factual-Statement, Cause-and-Effect, Hypothetical-Analysis, Comparison-and-Selection, Evaluation-and-Suggestion, 다섯 개의 카테고리를 다룸",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "UIUC,-IBM-delift-data-efficient-language-model-instruction-fine-tuning",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "paper",
      "org": "UIUC, IBM",
      "title": "DELIFT: Data Efficient Language model Instruction Fine Tuning",
      "url": "https://arxiv.org/abs/2411.04425",
      "bullets": [
        {
          "text": "DELIFT, 세 단계의 fine-tuning을 통해 data selection을 systematically optimize",
          "level": 1
        },
        {
          "text": "(1) instruction tuning (2) task-specific fine-tuning (3) continual fine-tuning",
          "level": 1
        },
        {
          "text": "현재 데이터 샘플이 현재 모델의 상태에 얼마나 beneficial 한지를 정량화하는 pairwise utility metric 사용",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Univ.-of-California,-Tsinghua,-Peking-style-compress-an-llm-based-prompt-compression-framework-considering-task-specific-styles",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "paper",
      "org": "Univ. of California, Tsinghua, Peking",
      "title": "Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles",
      "url": "https://arxiv.org/pdf/2410.14042",
      "bullets": [
        {
          "text": "Style-Compress: smaller model이 새로운 태스크에 대해 추가적인 fine-tuning 없이 프롬프트를 압축할 수 있도록 adapt하는 방법론",
          "level": 1
        },
        {
          "text": "10개 샘플, 100개 쿼리로 adaptation 한 뒤 compression 적용한 결과가 준수하다는 것을 확인",
          "level": 1
        },
        {
          "text": "방법론에 대한 간단한 수식, 파이프라인, 다양한 실험을 통해 논문화.. 프레임워크도 중요한 시대",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-orca-agentinstruct-agentic-flows-can-be-effective-synthetic-data-generators",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "dev",
      "org": "Microsoft",
      "title": "Orca-AgentInstruct: Agentic flows can be effective synthetic-data generators",
      "url": "https://www.microsoft.com/en-us/research/blog/orca-agentinstruct-agentic-flows-can-be-effective-synthetic-data-generators/",
      "bullets": [
        {
          "text": "합성 데이터 사용 시 LLM의 학습 속도를 높일 수 있다고 설명",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "KAIST-automl-agent-a-multi-agent-llm-framework-for-full-pipeline-automl",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "paper",
      "org": "KAIST",
      "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML",
      "url": "https://arxiv.org/pdf/2410.02958",
      "bullets": [
        {
          "text": "AutoML-Agent, data retrieval 부터 model deployment 까지 아우르는 multi-agent framework",
          "level": 1
        },
        {
          "text": "retrieval-augmented planning strategy를 사용하여 최적의 plan을 만듦",
          "level": 1
        },
        {
          "text": "각 plan을 sub-tasks로 쪼개어서 특화된 agent가 이를 처리할 수 있도록 함",
          "level": 1
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "AI2-ai2-openscholar-scientific-literature-synthesis-with-retrieval-augmented-language-models",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "dev",
      "org": "AI2",
      "title": "Ai2 OpenScholar: Scientific literature synthesis with retrieval-augmented language models",
      "url": "https://allenai.org/blog/openscholar",
      "bullets": [
        {
          "text": "retriever and reranker to search the datastore",
          "level": 1
        },
        {
          "text": "8B Llama fine-tuned on high-quality synthetic data",
          "level": 1
        },
        {
          "text": "self-feedback generation pipeline",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Mistral-AI-mistral-has-entered-the-chat",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "dev",
      "org": "Mistral AI",
      "title": "Mistral has entered the chat",
      "url": "https://mistral.ai/news/mistral-chat/",
      "bullets": [
        {
          "text": "SoTA document and image understanding, powerd bye the new multimodal [Pixtral Large](https://mistral.ai/news/pixtral-large/)",
          "level": 1
        },
        {
          "text": "SoTA on MathVista, DocVQA, VQAv2",
          "level": 2
        },
        {
          "text": "123B multimodal decoder, 1B parameter vision encoder",
          "level": 2
        },
        {
          "text": "128K context window",
          "level": 2
        },
        {
          "text": "Faster responses powered by speculative editing",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "Perplexity-shop-like-a-pro-perplexitys-new-ai-powered-shopping-assistant",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "dev",
      "org": "Perplexity",
      "title": "Shop like a Pro: Perplexity’s new AI-powered shopping assistant",
      "url": "https://www.perplexity.ai/hub/blog/shop-like-a-pro",
      "bullets": [
        {
          "text": "Buy with Pro: One-click checkout to save time & free shipping",
          "level": 1
        },
        {
          "text": "Snap to Shop: 물건의 사진과 유사한 상품을 찾아주는 visual search tool",
          "level": 1
        },
        {
          "text": "Introducing the Perplexity Merchant Program: 상품 판매자들이 가입하는 프로그램으로, 가입 시 상품이 인덱싱 대상이 되어 추천이 더 잘될 수 있음을 언급",
          "level": 1
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Together-AI,-Stanford,-etc-redpajama-an-open-dataset-for-training-large-language-models",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "paper",
      "org": "Together AI, Stanford, etc",
      "title": "RedPajama: an Open Dataset for Training Large Language Models",
      "url": "https://arxiv.org/pdf/2411.12372",
      "bullets": [
        {
          "text": "모델 개발의 투명성 부족 (데이터 정제 포함), 고품질 데이터셋 대량 확보의 어려움, 데이터셋 정제와 분석을 위한 artifact 및 메타 데이터 이용 가능성 낮음",
          "level": 2
        },
        {
          "text": "이러한 문제를 해결하기 위해 RedPajama-V1 release, open reproduction of the LLaMA training dataset",
          "level": 1
        },
        {
          "text": "RedPajama-V2를 함께 release, 정제되지 않은 날것의 text data로 구성된 massive web-only dataset",
          "level": 1
        },
        {
          "text": "RedPajama 데이터셋은 다양한 도메인에 걸쳐 100T 토큰 이상의 텍스트로 구성됨",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Stony-Brook-a-novel-approach-to-eliminating-hallucinations-in-large-language-model-assisted-causal-discovery",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "paper",
      "org": "Stony Brook",
      "title": "A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery",
      "url": "https://arxiv.org/abs/2411.12759",
      "bullets": [
        {
          "text": "고품질 데이터에 접근 가능할 때 RAG를 사용하여 hallucination을 줄이는 방법을 제안",
          "level": 1
        },
        {
          "text": "arbiter(결정권자)를 포함한 여러 LLM을 debate에 참여시켜 causal graphs의 edge를 감사함으로써 hallucination을 최소화하는 기법을 제안",
          "level": 1
        },
        {
          "text": "프롬프트 엔지니어링을 통해 graph를 만드는 것부터 시작",
          "level": 1
        },
        {
          "text": "고품질 데이터 기반의 RAG, 뛰어난 LLM간 debate를 활용한 hallucination 최소화에 대한 연구",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Cerebral-Valley:-Alexandr-Wang-Scale-AI-cerebral-valley-alexandr-wang-scale-ai",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "unknown",
      "org": "Cerebral Valley: Alexandr Wang Scale AI",
      "title": "Cerebral Valley: Alexandr Wang Scale AI",
      "url": "https://www.youtube.com/watch?v=HM7wnQwpJ0w",
      "bullets": [
        {
          "text": "그러나 post training으로 모델을 발전시킬 수 있는 여지는 무궁무진.",
          "level": 1
        },
        {
          "text": "최근 o1 or DeepSeek이 좋은 사례",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "DeepSeek-deepseek-r1-lite-preview-is-now-live-unleashing-supercharged-reasoning-power",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "dev",
      "org": "DeepSeek",
      "title": "DeepSeek-R1-Lite-Preview is now live: unleashing supercharged reasoning power!",
      "url": "https://api-docs.deepseek.com/news/news1120",
      "bullets": [
        {
          "text": "thought process를 real-time으로 투명하게 공개",
          "level": 1
        },
        {
          "text": "곧 오픈 소스 모델과 API 공개 예정",
          "level": 1
        },
        {
          "text": "[링크](http://chat.deepseek.com/)에서 채팅 가능",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "H-french-startup-h-company-launches-runner-h-a-web-automation-agent-with-human-like-precision",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "dev",
      "org": "H",
      "title": "French startup H Company launches Runner H: a web automation agent with human-like precision",
      "url": "https://link.alphasignal.ai/YDPiIj",
      "bullets": [
        {
          "text": "이것이 첫 product인데 $220M 투자 받은 것으로 알려짐 (한화 약 3,000억원)",
          "level": 1
        },
        {
          "text": "API beta도 제공",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "HuggingFaceTB-smoltalk",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "dev",
      "org": "HuggingFaceTB",
      "title": "SmolTalk",
      "url": "https://huggingface.co/datasets/HuggingFaceTB/smoltalk",
      "bullets": [
        {
          "text": "instruction following 능력을 향상시키면서 다양한 태스크를 잘 수행할 수 있는 데 기여하는 public 데이터셋을 합성하여 공개",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Ai2-tülu-3-opens-language-model-post-training-up-to-more-tasks-and-more-people",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "dev",
      "org": "Ai2",
      "title": "Tülu 3 opens language model post-training up to more tasks and more people",
      "url": "https://allenai.org/blog/tulu-3",
      "bullets": [
        {
          "text": "Data, Data Toolkit, Training Code & Infrastructure, Evaluation Framework, Demo, Models & Checkpoints",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Apple-aimv2",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "dev",
      "org": "Apple",
      "title": "AIMv2",
      "url": "https://arxiv.org/pdf/2411.14402",
      "bullets": [
        {
          "text": "대부분의 멀티모달 이해 벤치마크에서 OAI CLIP, SigLIP 등을 outperform",
          "level": 1
        },
        {
          "text": "open-vocabulary object detection & referring expression comprehension에서 DINOv2를 outperform",
          "level": 1
        },
        {
          "text": "📜 [Multimodal Autoregressive Pre-training of Large Vision Encoders](https://arxiv.org/pdf/2411.14402)",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "Anthropic-adding-error-bars-to-evals-a-statistical-approach-to-language-model-evaluations",
      "date": "2024-11-W03",
      "year": "2024",
      "month": "11",
      "week": "3",
      "type": "paper",
      "org": "Anthropic",
      "title": "Adding Error Bars to Evals: A Statistical Approach to Language Model Evaluations",
      "url": "https://arxiv.org/pdf/2411.00640",
      "bullets": [
        {
          "text": "통계학 기반의 연구자들에게 언어 모델의 평가 데이터를 어떻게 분석하고 접근해야 하는지 설명하는 연구",
          "level": 1
        },
        {
          "text": "평가 데이터 분석, 두 모델 간의 차이 측정, 평가 실험 계획을 위한 공식을 제시",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Aalborg-Univ.-knowledge-graphs-large-language-models-and-hallucinations-an-nlp-perspective",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Aalborg Univ.",
      "title": "Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective",
      "url": "https://arxiv.org/pdf/2411.14258",
      "bullets": [
        {
          "text": "LLM의 hallucination 현상을 완화하기 위해 knowledge graph 활용",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-DeepMind-learning-high-accuracy-error-decoding-for-quantum-processors",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Learning high-accuracy error decoding for quantum processors",
      "url": "https://www.nature.com/articles/s41586-024-08148-8",
      "bullets": [
        {
          "text": "구글 딥마인드에서 인공지능을 활용한 quantum computer 연구를 수행하고 있음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "National-Univ.-of-Singapore-the-dawn-of-gui-agent-a-preliminary-case-study-with-claude-35-computer-use",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "National Univ. of Singapore",
      "title": "The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use",
      "url": "https://arxiv.org/pdf/2411.10323",
      "bullets": [
        {
          "text": "연구에 활용된 프롬프트나 도메인, 소프트웨어 정보를 다양하게 포함하고 있음",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/showlab/computer_use_ootb) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Amazon-amazon-and-anthropic-deepen-strategic-collaboration",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "unknown",
      "org": "Amazon",
      "title": "Amazon and Anthropic deepen strategic collaboration",
      "url": "https://www.aboutamazon.com/news/aws/amazon-invests-additional-4-billion-anthropic-ai",
      "bullets": [
        {
          "text": "Microsoft & OpenAI 의 관계와 유사하다고 이해할 수 있음",
          "level": 0
        },
        {
          "text": "Anthropic의 다음 세대 모델 개발을 위한 accelerator chip, “Trainium” 개발에 사용될 것",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Anthropic-hume-ai-creates-emotionally-intelligent-voice-interactions-with-claude",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "Hume AI creates emotionally intelligent voice interactions with Claude",
      "url": "https://www.anthropic.com/customers/hume",
      "bullets": [
        {
          "text": "36%의 유저가 다른 LLM 대신 Claude를 선택",
          "level": 0
        },
        {
          "text": "실시간으로 자연스럽게 interact 하는 모델을 Anthropic에서도 적극적으로 개발 중인 상황으로 이해됨",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "UPC,-ETH-do-i-know-this-entity-knowledge-awareness-and-hallucinations-in-language-models",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "UPC, ETH",
      "title": "Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models",
      "url": "https://arxiv.org/abs/2411.14257",
      "bullets": [
        {
          "text": "representation space에서 의미있는 방향을 찾아내어 모델이 특정 entity에 대해 인지하고 있는지 확인할 수 있음",
          "level": 0
        },
        {
          "text": "챗 모델의 refusal behavior에도 영향을 줄 수 있는 내용",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "UCL,-Shanghai,-Brown,-Singapore-natural-language-reinforcement-learning",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "UCL, Shanghai, Brown, Singapore",
      "title": "Natural Language Reinforcement Learning",
      "url": "https://arxiv.org/pdf/2411.14251",
      "bullets": [
        {
          "text": "Natural Language Reinforcement Learning (NLRL): 전통적인 MDP를 자연어 기반의representation space로 확장",
          "level": 0
        },
        {
          "text": "순수 프롬프팅 or gradient-based training 에 의한 RL-like policy & value 를 개선",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/waterhorse1/Natural-language-RL) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Arizona-from-generation-to-judgment-opportunities-and-challenges-of-llm-as-a-judge",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Arizona",
      "title": "From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge",
      "url": "https://arxiv.org/pdf/2411.16594",
      "bullets": [
        {
          "text": "LLM-as-a-judge를 평가하는 벤치마크 compile",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "OpenAI-advancing-red-teaming-with-people-and-ai",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "OpenAI",
      "title": "Advancing red teaming with people and AI",
      "url": "https://openai.com/index/advancing-red-teaming-with-people-and-ai/",
      "bullets": [
        {
          "text": "📜 [External red teaming](https://cdn.openai.com/papers/openais-approach-to-external-red-teaming.pdf)",
          "level": 0
        },
        {
          "text": "📜 [Automated red teaming](https://cdn.openai.com/papers/diverse-and-effective-red-teaming.pdf)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "MIT-model-based-transfer-learning-for-contextual-reinforcement-learning",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "MIT",
      "title": "Model-Based Transfer Learning for Contextual Reinforcement Learning",
      "url": "https://arxiv.org/pdf/2408.04498",
      "bullets": [
        {
          "text": "Model-Based Transfer Learning (MBTL) 제시: Gaussian process를 사용한 performance set point, linear function of contextual similarity로 모델링되는 performance loss",
          "level": 0
        },
        {
          "text": "두 요소를 결합하여 Bayesian Optimization (BO) 프레임워크 내에서 전략적으로 사용",
          "level": 0
        },
        {
          "text": "50배 이상 개선된 independent & multi-task training 효율성",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "NVIDIA-star-attention-efficient-llm-inference-over-long-sequences",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "NVIDIA",
      "title": "Star Attention: Efficient LLM Inference over Long Sequences",
      "url": "https://arxiv.org/pdf/2411.17116",
      "bullets": [
        {
          "text": "1단계: blockwise-local attention across hosts → 2단계: query & response tokens 가 이전에 생성 및 캐싱된 토큰에 대해 sequence-global attention",
          "level": 0
        },
        {
          "text": "global attention을 사용하여 학습된 트랜스포머 기반의 모델들은 약 11배 정도까지의 추론 속도 향상을 기대할 수 있음 (정확도는 95~100% 유지)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Ai2-olmo-2-the-best-fully-open-language-model-to-date",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Ai2",
      "title": "OLMo 2: The best fully open language model to date",
      "url": "https://allenai.org/blog/olmo2",
      "bullets": [
        {
          "text": "[Tülu 3](https://allenai.org/tulu)에서 얻은 나이스한 레시피를 OLMo 2에도 적용 (근데 둘이 뭐가 다르지 그럼..?)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Case-Western-Reserve-Univ.-dynamic-self-distillation-via-previous-mini-batches-for-fine-tuning-small-language-models",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Case Western Reserve Univ.",
      "title": "Dynamic Self-Distillation via Previous Mini-batches for Fine-tuning Small Language Models",
      "url": "https://arxiv.org/pdf/2411.16991",
      "bullets": [
        {
          "text": "distillation influence와 temperature value를 dynamic 하게 조절",
          "level": 0
        },
        {
          "text": "self-correction & self-training 테크닉들과 seamless 하게 integration 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Tsinghua-training-and-evaluating-language-models-with-template-based-data-generation",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Tsinghua",
      "title": "Training and Evaluating Language Models with Template-based Data Generation",
      "url": "https://arxiv.org/pdf/2411.18104",
      "bullets": [
        {
          "text": "TemplateMath Part 1: TemplateGSM, 7백만 개 이상의 고등학교 수학 문제로 구성된 합성 데이터셋",
          "level": 0
        },
        {
          "text": "[허깅페이스 데이터셋 링크](https://huggingface.co/datasets/math-ai/TemplateGSM) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Andrew-Ng-aisuite",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "Andrew Ng",
      "title": "aisuite",
      "url": "https://github.com/andrewyng/aisuite",
      "bullets": [
        {
          "text": "OpenAI, Anthropic, Azure, Google, AWS, Groq, Mistral, HuggingFace, Ollama 등을 지원",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-smolvlm-small-yet-mighty-vision-language-model",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "HuggingFace",
      "title": "SmolVLM - small yet mighty Vision Language Model",
      "url": "https://huggingface.co/blog/smolvlm",
      "bullets": [
        {
          "text": "모든 모델 체크포인트, VLM 데이터셋, 학습 레시피, 도구 등 Apache 2.0 라이센스로 공개",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "NVIDIA-hymba-a-hybrid-head-architecture-for-small-language-models",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "NVIDIA",
      "title": "Hymba: A Hybrid-head Architecture for Small Language Models",
      "url": "https://www.arxiv.org/pdf/2411.13676",
      "bullets": [
        {
          "text": "Attention heads는 high-resolution recall을, SSM heads는 efficient context summarization을 담당",
          "level": 0
        },
        {
          "text": "프롬프트 앞에 붙어서 중요한 정보를 저장하는 learnable meta token 도입",
          "level": 0
        },
        {
          "text": "허깅페이스에 [Base](https://huggingface.co/nvidia/Hymba-1.5B-Base) & [Instruct](https://huggingface.co/nvidia/Hymba-1.5B-Instruct) 모델 공개",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Qwen-qwq-reflect-deeply-on-the-boundaries-of-the-unknown",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "Qwen",
      "title": "QwQ: Reflect Deeply on the Boundaries of the Unknown",
      "url": "https://qwenlm.github.io/blog/qwq-32b-preview/",
      "bullets": [
        {
          "text": "Language Mixing and Code-Switching, Recursive Reasoning Loops, Safety and Ethical Considerations 등의 한계점",
          "level": 0
        },
        {
          "text": "GPQA, AIME, MATH-500, LiveCodeBench 등 추론 능력이 요구되는 벤치마크에서 뛰어난 성능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "IBM,-Meta-supercharging-training-using-float8-and-fsdp2",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "dev",
      "org": "IBM, Meta",
      "title": "Supercharging Training using float8 and FSDP2",
      "url": "https://pytorch.org/blog/training-using-float8-fsdp2/",
      "bullets": [
        {
          "text": "1.8B 부터 405B 에 이르는 라마 모델에 대한 성능 개선을 확인함 (Llama 3 아키텍쳐 기준)",
          "level": 0
        },
        {
          "text": "end-to-end float8 training에 대한 가능성을 입증",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Univ.-of-Luxembourg-longkey-keyphrase-extraction-for-long-documents",
      "date": "2024-11-W04",
      "year": "2024",
      "month": "11",
      "week": "4",
      "type": "paper",
      "org": "Univ. of Luxembourg",
      "title": "LongKey: Keyphrase Extraction for Long Documents",
      "url": "https://arxiv.org/pdf/2411.17863",
      "bullets": [
        {
          "text": "LongKey, a novel framework for extracting keyphrases from lengthy documents",
          "level": 0
        },
        {
          "text": "encoder 기반의 언어 모델, max-pooling embedder 사용",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-DeepMind-how-alphachip-transformed-computer-chip-design",
      "date": "2024-10-W01",
      "year": "2024",
      "month": "10",
      "week": "1",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "How AlphaChip transformed computer chip design",
      "url": "https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/",
      "bullets": [
        {
          "text": "실제로 6세대 TPU을 몇 개로 구성할지를 이것으로 찾음 (AI for chip design)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Anthropic-introducing-contextual-retrieval",
      "date": "2024-10-W01",
      "year": "2024",
      "month": "10",
      "week": "1",
      "type": "dev",
      "org": "Anthropic",
      "title": "Introducing Contextual Retrieval",
      "url": "https://www.anthropic.com/news/contextual-retrieval",
      "bullets": [
        {
          "text": "Contextual BM25에 사용되는 index를 생성",
          "level": 0
        },
        {
          "text": "context를 생성할 때는 사람이 직접할 수 없으므로 AI 모델을 사용 (Claude)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "BAAI-emu3-next-token-prediction-is-all-you-need",
      "date": "2024-10-W01",
      "year": "2024",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "BAAI",
      "title": "Emu3: Next-Token Prediction is All You Need",
      "url": "https://arxiv.org/abs/2409.18869",
      "bullets": [
        {
          "text": "→ diffusion 또는 compositional architecture 불필요",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Waterloo,-Peking-mio-a-foundation-model-on-multimodal-tokens",
      "date": "2024-10-W01",
      "year": "2024",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "Waterloo, Peking",
      "title": "MIO: A Foundation Model on Multimodal Tokens",
      "url": "https://arxiv.org/abs/2409.17692",
      "bullets": [
        {
          "text": "four-stage training process",
          "level": 0
        },
        {
          "text": "(1) alignment pre-training (2) interleaved pre-training (3) speech-enhanced pre-training (4) comprehensive supervised fine-tuning",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Microsoft-vptq-extreme-low-bit-vector-post-training-quantization-for-large-language-models",
      "date": "2024-10-W01",
      "year": "2024",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "Microsoft",
      "title": "VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models",
      "url": "https://arxiv.org/abs/2409.17066",
      "bullets": [
        {
          "text": "Channel-Independent Second-Order Optimization을 사용하여 가중치를 refine",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/microsoft/VPTQ) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Apple-mm15-methods-analysis-insights-from-multimodal-llm-fine-tuning",
      "date": "2024-10-W01",
      "year": "2024",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "Apple",
      "title": "MM1.5: Methods, Analysis & Insights from Multimodal LLM Fine-tuning",
      "url": "https://arxiv.org/abs/2409.20566",
      "bullets": [
        {
          "text": "high-quality OCR data & synthetic caption 을 continual pre-training에 활용 → optimized visual instruction-tuning data mixture를 supervised fine-tuning에 활용",
          "level": 0
        },
        {
          "text": "MoE 아키텍쳐를 포함하여 모델 사이즈는 1B ~ 30B 로 구성",
          "level": 0
        },
        {
          "text": "video understanding과 mobile UI understanding에 특화된 MM1.5-Video, UI 버전을 공개.",
          "level": 0
        },
        {
          "text": "개인적으로 Apple Intelligence를 아주 기대하고 있는 입장에서 모델 성능이 뛰어나서 유용히 사용될 수 있길 간절히 바라는 중 🙏🏻",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta,-UIUC-law-of-the-weakest-link-cross-capabilities-of-large-language-models",
      "date": "2024-10-W01",
      "year": "2024",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "Meta, UIUC",
      "title": "Law of the Weakest Link: Cross Capabilities of Large Language Models",
      "url": "https://arxiv.org/abs/2409.19951",
      "bullets": [
        {
          "text": "7개의 core individual capabilities를 정의하고 이를 manually 짝지어 taxonomy를 구축",
          "level": 0
        },
        {
          "text": "1,400개의 human-annotated prompts로 구성된 CrossEval 벤치마크를 공개. 각 individual & cross capability 마다 100개 prompt로 구성",
          "level": 0
        },
        {
          "text": "이에 대한 평가를 수행해봤을 때, 현 LLM은 Law of the Weakest Link를 보인다고 주장",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Liquid-liquid-foundation-models-our-first-series-of-generative-ai-models",
      "date": "2024-10-W01",
      "year": "2024",
      "month": "10",
      "week": "1",
      "type": "dev",
      "org": "Liquid",
      "title": "Liquid Foundation Models: Our First Series of Generative AI Models",
      "url": "https://www.liquid.ai/liquid-foundation-models",
      "bullets": [
        {
          "text": "32k token context length, effective across the entire range",
          "level": 0
        },
        {
          "text": "오픈 소스 모델은 아님. Liquid Playground, Lambda, Perplexity Labs 등에서 사용 가능",
          "level": 0
        },
        {
          "text": "최근 sLLM 에 대한 관심이 뜨거운 것 같은데, 이중에서도 오픈소스가 아닌 모델 패밀리를 공개하는 것은 오히려 흔하지 않은 상황으로 이해됨",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "CMU-embodied-rag-general-non-parametric-embodied-memory-for-retrieval-and-generation",
      "date": "2024-10-W01",
      "year": "2024",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "CMU",
      "title": "Embodied-RAG: General Non-parametric Embodied Memory for Retrieval and Generation",
      "url": "https://arxiv.org/abs/2409.18313",
      "bullets": [
        {
          "text": "Embodied-RAG: navigation & language generation의 hierarchical knowledge를 자율적으로 구축할 수 있는 non-parametric memory system",
          "level": 0
        },
        {
          "text": "다양한 환경과 query type에 대해 넓은 범위의 spatial & semantic resolution을 처리할 수 있음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Yale,-OpenAI,-Princeton-when-a-language-model-is-optimized-for-reasoning-does-it-still-show-embers-of-autoregression-an-analysis-of-openai-o1",
      "date": "2024-10-W01",
      "year": "2024",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "Yale, OpenAI, Princeton",
      "title": "When a language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1",
      "url": "https://arxiv.org/abs/2410.01792",
      "bullets": [
        {
          "text": "embers of augoregression이라는 표현을 사용하고 있는데, 결국 다음 토큰을 반복적으로 예측해나가는 근본적인 특성으로 인해 발생하는 문제점을 지적하고 싶은 것으로 이해함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Unleashing-the-Power-of-Large-Language-Models-in-Zero-shot-Relation-Extraction-via-Self-Prompting-unleashing-the-power-of-large-language-models-in-zero-shot-relation-extraction-via-self-prompting",
      "date": "2024-10-W01",
      "year": "2024",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting",
      "title": "Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting",
      "url": "https://arxiv.org/abs/2410.01154",
      "bullets": [
        {
          "text": "세 단계로 구성된 diversity approach를 사용하여 다양한 합성 데이터를 생성 → 이는 in-context learning sample로 사용",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Mila,-Google-DeepMind,-Microsoft-not-all-llm-reasoners-are-created-equal",
      "date": "2024-10-W01",
      "year": "2024",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "Mila, Google DeepMind, Microsoft",
      "title": "Not All LLM Reasoners Are Created Equal",
      "url": "https://arxiv.org/abs/2410.01748",
      "bullets": [
        {
          "text": "compositional pair를 풀어내는 것과 각 문제를 따로 푸는 것의 결과가 독립적이라고 주장",
          "level": 0
        },
        {
          "text": "이러한 결과는 더 작고, cost-efficient하며 수학 특화된 모델에서 두드러진다고 함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Johns-Hopkins-rationalyst-pre-training-process-supervision-for-improving-reasoning",
      "date": "2024-10-W01",
      "year": "2024",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "Johns Hopkins",
      "title": "RATIONALYST: Pre-training Process-Supervision for Improving Reasoning",
      "url": "https://arxiv.org/abs/2410.01044",
      "bullets": [
        {
          "text": "→ unlabeled data로부터 추출한 다양한 종류의 rationale annotations에 대한 사전학습을 기반으로 삼는 process-supervision of reasoning 모델, Rationalyst 제안",
          "level": 0
        },
        {
          "text": "Pile 데이터셋으로부터 79K 개 rationale을 추출. 여기에 사람 개입은 최소화.",
          "level": 0
        }
      ],
      "tags": [
        "multimodal",
        "reasoning"
      ]
    },
    {
      "id": "Apple-contrastive-localized-language-image-pre-training",
      "date": "2024-10-W01",
      "year": "2024",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "Apple",
      "title": "Contrastive Localized Language-Image Pre-Training",
      "url": "https://arxiv.org/abs/2410.02746",
      "bullets": [
        {
          "text": "CLIP에 region-text contrastive loss & module 을 보충하는 CLOC를 제안",
          "level": 0
        },
        {
          "text": "이미지 embedding을 region representation으로 쉽게 변환할 수 있는 promptable embedding을 공식화",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-gemini-15-flash-8b-is-now-production-ready",
      "date": "2024-10-W01",
      "year": "2024",
      "month": "10",
      "week": "1",
      "type": "dev",
      "org": "Google",
      "title": "Gemini 1.5 Flash-8B is now production ready",
      "url": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/",
      "bullets": [
        {
          "text": "경량화된 모델이라고 하는 것 같은데 실사용 성능이 어떤지는 커뮤니티 반응 조사 필요",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Mila-were-rnns-all-we-needed",
      "date": "2024-10-W01",
      "year": "2024",
      "month": "10",
      "week": "1",
      "type": "paper",
      "org": "Mila",
      "title": "Were RNNs All We Needed?",
      "url": "https://arxiv.org/abs/2410.01201",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-Research,-Apple-llms-know-more-than-they-show-on-the-intrinsic-representation-of-llm-hallucinations",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Google Research, Apple",
      "title": "LLMs Know More Than They Show: On the Intrinsic Representation of LLM Hallucinations",
      "url": "https://arxiv.org/abs/2410.02707",
      "bullets": [
        {
          "text": "(1) 정보를 많이 담고 있는 특정 토큰을 이용하여 error detction을 시도했으나 generalize 되지 않음 → multifaceted",
          "level": 0
        },
        {
          "text": "(2) internal representation은 모델이 일으키는 에러를 줄이는 데 활용될 수 있다는 것을 확인",
          "level": 0
        },
        {
          "text": "(3) LLM의 internal encoding과 external behavior 사이의 discrepancy를 확인",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Salesforce-enhance-reasoning-by-learning-from-mistakes-peer-review-knowledge-distillation-from-multiple-large-language-models",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Salesforce",
      "title": "Enhance Reasoning by Learning from Mistakes: Peer-Review Knowledge Distillation from Multiple Large Language Models",
      "url": "https://arxiv.org/abs/2410.03663",
      "bullets": [
        {
          "text": "Mistake-Aware Peer-Review Distillation (MAPD) 방식 제안",
          "level": 0
        },
        {
          "text": "teacher 에게 student의 실수를 파악 및 설명하고 customized instruction learning data를 제공하도록 지시",
          "level": 1
        },
        {
          "text": "simulated peer-review process를 디자인하여 acceptance threshold를 넘기는 rationale을 사용",
          "level": 1
        },
        {
          "text": "결국 peer-review라는 게 여러 개의 proprietary 모델을 사용한다는 뜻인데 비용을 n배로 증가시키는 방법론이긴 함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "feder-cr/Auto_Jobs_Applier_AIHawk-feder-crauto_jobs_applier_aihawk",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "dev",
      "org": "feder-cr/Auto_Jobs_Applier_AIHawk",
      "title": "feder-cr/Auto_Jobs_Applier_AIHawk",
      "url": "https://github.com/feder-cr/Auto_Jobs_Applier_AIHawk",
      "bullets": [],
      "tags": []
    },
    {
      "id": "mendableai/firecrawl-mendableaifirecrawl",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "dev",
      "org": "mendableai/firecrawl",
      "title": "mendableai/firecrawl",
      "url": "https://github.com/mendableai/firecrawl",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Stanford-tutor-copilot-a-human-ai-approach-for-scaling-real-time-expertise",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Stanford",
      "title": "Tutor CoPilot: A Human-AI Approach for Scaling Real-Time Expertise",
      "url": "https://arxiv.org/abs/2410.03017",
      "bullets": [
        {
          "text": "under-served communities의 900명 tutor와 1,800명 학생이 참여한 대규모 연구",
          "level": 0
        },
        {
          "text": "수학을 공부하는 학생들이 덕분에 유의미한 점수 향상(4%p)을 얻었다고 함",
          "level": 0
        },
        {
          "text": "tutor마다 연간 $20 밖에 들지 않음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Hong-Kong,-Huawei,-McGill-&-MILA-reviseval-improving-llm-as-a-judge-via-response-adapted-references",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Hong Kong, Huawei, McGill & MILA",
      "title": "RevisEval: Improving LLM-as-a-Judge via Response-Adapted References",
      "url": "https://arxiv.org/abs/2410.05193",
      "bullets": [
        {
          "text": "LLM이 text revision을 잘한다는 점을 이용하여 response를 adaptive하게 revise하고 이를 reference로 삼아 이어지는 평가에 활용하는 방식을 고안",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "Microsoft,-Tsinghua-differential-transformer",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Microsoft, Tsinghua",
      "title": "Differential Transformer",
      "url": "https://arxiv.org/abs/2410.05258",
      "bullets": [
        {
          "text": "differential attention mechanism은 두 개의 separate softmax attention map의 차이로 attention score를 계산 → sparse attention pattern을 촉진",
          "level": 0
        },
        {
          "text": "특히 long-context modeling, key information retrieval, hallucination mitigation, in-context learning, reduction of activation outlier 등에 탁월",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "HuggingFace-gradio-appopenai-gradio",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "dev",
      "org": "HuggingFace",
      "title": "gradio-app/openai-gradio",
      "url": "https://github.com/gradio-app/openai-gradio",
      "bullets": [
        {
          "text": "API 대신 로컬 모델로 구축할 수 있으면 좋을텐데 아쉽",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Tsinghua,-Microsoft-data-selection-via-optimal-control-for-language-models",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Tsinghua, Microsoft",
      "title": "Data Selection via Optimal Control for Language Models",
      "url": "https://arxiv.org/abs/2410.07064",
      "bullets": [
        {
          "text": "CommonCrawl을 대상으로 PDS를 적용했을 때, 사전학습의 효율이 크게 향상된다는 것을 확인",
          "level": 0
        },
        {
          "text": "Mistral 아키텍쳐를 기반으로 160M, 470M, 1B, 1.7B 모델로 실험",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/microsoft/LMOps/tree/main/data_selection) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Microsoft-vptq-extreme-low-bit-vector-post-training-quantization-for-large-language-models-1",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Microsoft",
      "title": "VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models",
      "url": "https://arxiv.org/abs/2409.17066",
      "bullets": [
        {
          "text": "Channel-Independent Second-Order Optimization을 granular VQ에 적용함으로써 가중치를 refine",
          "level": 0
        },
        {
          "text": "optimization problem을 decomposing함으로써 brief & effective codebook initialization algorithm을 제안",
          "level": 0
        },
        {
          "text": "residual & outlier quantization을 지원하여 모델 정확도를 향상하고 압축률을 높임",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/microsoft/VPTQ) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "HuggingFace-llm-evaluation-guidebook",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "dev",
      "org": "HuggingFace",
      "title": "LLM Evaluation Guidebook",
      "url": "https://github.com/huggingface/evaluation-guidebook",
      "bullets": [
        {
          "text": "초보자/상급자를 위한 내용들이 포함되어 있음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Baidu-retrieving-rethinking-and-revising-the-chain-of-verification-can-improve-retrieval-augmented-generation",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Baidu",
      "title": "Retrieving, Rethinking and Revising: The Chain-of-Verification Can Improve Retrieval Augmented Generation",
      "url": "https://arxiv.org/abs/2410.05801",
      "bullets": [
        {
          "text": "이를 해결하기 위해 chain-of-verification (CoV-RAG)를 제안",
          "level": 0
        },
        {
          "text": "verification module을 RAG에 넣어 scoring, judgement, rewriting에 참여하도록 함",
          "level": 0
        },
        {
          "text": "internal generation error를 수정하기 위해 QA와 verification에 CoT reasoning을 포함하여 학습 진행",
          "level": 0
        },
        {
          "text": "예전에도 CoVE 라는 논문이 Meta에서 hallucination mitigate를 위해 제시되었는데 이와 무엇이 다른지 확인할 필요도 있는 듯함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "HKUST,-UIUC-personalized-visual-instruction-tuning",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "HKUST, UIUC",
      "title": "Personalized Visual Instruction Tuning",
      "url": "https://arxiv.org/abs/2410.07113",
      "bullets": [
        {
          "text": "MLLM이 target individual을 이미지 내에서 식별하고 coherent dialogue를 이어나갈 수 있도록 data curation & training framework를 포함하는 PVIT를 제안 (Personalized Visual Instruction Tuning)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Microsoft-scaling-optimal-lr-across-token-horizons",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Microsoft",
      "title": "Scaling Optimal LR Across Token Horizons",
      "url": "https://arxiv.org/abs/2409.19913",
      "bullets": [
        {
          "text": "optimal LR은 token horizon에 따라 변화하는데, longer training일수록 smaller LR이 필요",
          "level": 0
        },
        {
          "text": "optimal LR도 scaling law를 따르기 때문에, longer horizon에 대한 optimal LR을 shorter horizon으로부터 예측할 수 있다고 주장",
          "level": 0
        },
        {
          "text": "데이터셋, 모델 사이즈를 scale-up 할 때 필수로 참고해야 할 논문이 아닌가..",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "KAIST,-Washington,-LG-AI-Research-knowledge-entropy-decay-during-language-model-pretraining-hinders-new-knowledge-acquisition",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "KAIST, Washington, LG AI Research",
      "title": "Knowledge Entropy Decay during Language Model Pretraining Hinders New Knowledge Acquisition",
      "url": "https://arxiv.org/abs/2410.01380",
      "bullets": [
        {
          "text": "knowlege entropy 개념을 도입하여 모델이 engage하는 memory의 범위를 정량적으로 나타냄. 이 값이 높으면 모델이 넓은 범위의 memory source를 포함하는 것이고, 낮으면 반대임",
          "level": 0
        },
        {
          "text": "pretraining이 진행됨에 따라 knowledge entropy가 낮아지고, 이는 모델의 knowledge acquisition & retain 능력 감소를 의미한다고 주장",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "OpenAI-mle-bench-evaluating-machine-learning-agents-on-machine-learning-engineering",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "OpenAI",
      "title": "MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering",
      "url": "https://arxiv.org/abs/2410.07095",
      "bullets": [
        {
          "text": "캐글의 75개 MLE competition을 curate하여, 모델 학습, 데이터셋 준비, 실험 수행 등 다양한 real-world ML engineering skill을 테스트 할 수 있도록 함",
          "level": 0
        },
        {
          "text": "OpenAI의 o1-preview가 최고라는 걸 보여주는 연구 결과..?",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/openai/mle-bench/) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Hong-Kong-teaching-inspired-integrated-prompting-framework-a-novel-approach-for-enhancing-reasoning-in-large-language-models",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Hong Kong",
      "title": "Teaching-Inspired Integrated Prompting Framework: A Novel Approach for Enhancing Reasoning in Large Language Models",
      "url": "https://arxiv.org/abs/2410.08068",
      "bullets": [
        {
          "text": "reasoning에 필요한 필수적인 개념, 관련 이론, 유사한 문제 등을 LLM이 떠올릴 수 있도록 함",
          "level": 0
        },
        {
          "text": "자체적으로 개발한 두 개의 중국어 벤치마크 MathMC, MathToF 공개",
          "level": 0
        },
        {
          "text": "이런 방식이 정말 모델의 능력을 극대화하는 것이 맞나? 어떤 상황에서도 적용 가능한 방법은 맞나? 또 모델이 학생을 가르치는 내용의 데이터를 학습하지는 않았을 것 같은데 이것이 working 하는 이유는 뭘까?",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Tesla-robotaxi",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "dev",
      "org": "Tesla",
      "title": "Robotaxi",
      "url": "https://x.com/Tesla/status/1844577040034562281",
      "bullets": [],
      "tags": []
    },
    {
      "id": "ML-Code-Challenges-ml-code-challenges",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "dev",
      "org": "ML Code Challenges",
      "title": "ML Code Challenges",
      "url": "https://www.deep-ml.com/",
      "bullets": [
        {
          "text": "행렬곱, 공분산행렬, Decision Tree 등등 다양한 개념들이 있어서 코드 연습해보기 좋은 것 같음. 카테고리는 linear algebra, machine learning, deep learning, nlp 등으로 구분됨",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "One-Initialization-to-Rule-them-All:-Fine-tuning-via-Explained-Variance-Adaptation-one-initialization-to-rule-them-all-fine-tuning-via-explained-variance-adaptation",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "One Initialization to Rule them All: Fine-tuning via Explained Variance Adaptation",
      "title": "One Initialization to Rule them All: Fine-tuning via Explained Variance Adaptation",
      "url": "https://arxiv.org/abs/2410.07170",
      "bullets": [
        {
          "text": "이를 Explained Variance Adaptation (EVA)라고 부르는데, 다양한 태스크에 적용해 보았을 때, convergence 속도가 빠르고 평균적으로 높은 스코어를 달성할 수 있었다고 주장함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "CMU-better-instruction-following-through-minimum-bayes-risk",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "CMU",
      "title": "Better Instruction-Following Through Minimum Bayes Risk",
      "url": "https://arxiv.org/abs/2410.02902",
      "bullets": [
        {
          "text": "이는 reference-based evaluator를 사용하여 여러 후보 output 중에서 가장 high-quality인 것을 고를 수 있도록 돕는 방식임",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Washington,-AI2-can-language-models-reason-about-individualistic-human-values-and-preferences",
      "date": "2024-10-W02",
      "year": "2024",
      "month": "10",
      "week": "2",
      "type": "paper",
      "org": "Washington, AI2",
      "title": "Can Language Models Reason about Individualistic Human Values and Preferences?",
      "url": "https://arxiv.org/abs/2410.03868",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Central-Florida-parameter-efficient-fine-tuning-of-large-language-models-using-semantic-knowledge-tuning",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "Central Florida",
      "title": "Parameter-Efficient Fine-Tuning of Large Language Models using Semantic Knowledge Tuning",
      "url": "https://arxiv.org/abs/2410.08598",
      "bullets": [
        {
          "text": "이를 위해 zero-shot으로 프롬프트의 semantic content를 이해할 수 있는 fixed LLM을 활용",
          "level": 0
        },
        {
          "text": "processed prompt를 입력 텍스트와 통합하여 모델이 특정 태스크에서 더 뛰어난 성능을 발휘할 수 있도록 함",
          "level": 0
        },
        {
          "text": "text classification & understanding에서 다른 tuning method 대비 더 적은 시간과 비용으로 좋은 성능을 낼 수 있었다고 주장",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Peking,-Microsoft-self-boosting-large-language-models-with-synthetic-preference-data",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "Peking, Microsoft",
      "title": "Self-Boosting Large Language Models with Synthetic Preference Data",
      "url": "https://arxiv.org/abs/2410.06961",
      "bullets": [
        {
          "text": "self-prompt generator가 다양한 프롬프트를 생성 → response improver가 response를 점진적으로 개선",
          "level": 0
        },
        {
          "text": "LLM 스스로 자신의 output에 대한 generative reward를 자율적으로 학습하고, 대규모 annotation 작업을 하지 않을 수 있게 됨",
          "level": 0
        },
        {
          "text": "AlpacaEval 2.0 & ArenaHard 에 대한 검증을 통해 모델의 instruction following 능력이 크게 향상되었음을 확인",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "UNIST-response-tuning-aligning-large-language-models-without-instruction",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "UNIST",
      "title": "Response Tuning: Aligning Large Language Models without Instruction",
      "url": "https://arxiv.org/abs/2410.02465",
      "bullets": [
        {
          "text": "실험 결과에 따르면 response에 대해서만 학습한 본인들의 모델이 instruction-tuned 모델들보다 더 다양한 범위의 instruction을 따를 수 있거나 성능이 좋았다고 언급함",
          "level": 0
        },
        {
          "text": "training response distribution을 조절함으로써 target behavior를 유도할 수 있었다고 함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "OpenAI-openaiswarm",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "openai/swarm",
      "url": "https://github.com/openai/swarm",
      "bullets": [
        {
          "text": "[Orchestrating Agents: Handoffs & Routines](https://cookbook.openai.com/examples/orchestrating_agents) cookbook의handoff & routines pattern을 보여주기 위해 제작됨",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Alibaba-structrag-boosting-knowledge-intensive-reasoning-of-llms-via-inference-time-hybrid-information-structurization",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "Alibaba",
      "title": "StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via Inference-time Hybrid Information Structurization",
      "url": "https://arxiv.org/abs/2410.08815",
      "bullets": [
        {
          "text": "사람이 raw information을 다양한 structured knowledge로 convert한다는 점에 착안하여 StructRAG를 제안",
          "level": 0
        },
        {
          "text": "즉, 태스크에 적합한 structured format으로 문서를 재구성하는 방식",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Mistral-AI-un-ministral-des-ministraux",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "dev",
      "org": "Mistral AI",
      "title": "Un Ministral, des Ministraux",
      "url": "https://mistral.ai/news/ministraux/",
      "bullets": [
        {
          "text": "128k context length (vLLM에선 현재 32k). 8B 모델은 sliding-window attention",
          "level": 0
        },
        {
          "text": "Llama-3.1-8B 보다 뛰어난 성능임을 벤치마크 결과를 통해 제시하고 있음",
          "level": 0
        },
        {
          "text": "라이센스는 각각 Mistral Commercial / Commercial & Research License를 따름",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta,-Berkeley,-NYU-thinking-llms-general-instruction-following-with-thought-generation",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "Meta, Berkeley, NYU",
      "title": "Thinking LLMs: General Instruction Following with Thought Generation",
      "url": "https://arxiv.org/abs/2410.10630",
      "bullets": [
        {
          "text": "iterative search & optimiation precedure를 통해 possible thought generation space를 탐색. 여기엔 direct supervision이 필요하지 않음",
          "level": 0
        },
        {
          "text": "각 instruction에 대한 thought candidate는 judge model이 평가하여 preference optimization에 활용 (DPO)",
          "level": 0
        },
        {
          "text": "AlpacaEval & Arena-Hard 에서 우수한 성능을 보였음을 강조. 그외의 marketing, health, general knowledge 등의 분야에서도 뛰어나다고 주장.",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Zyphra-zamba2-7b",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "dev",
      "org": "Zyphra",
      "title": "ZAMBA2-7B",
      "url": "https://mail.naver.com/",
      "bullets": [
        {
          "text": "single shared attention block → two shared attention block",
          "level": 0
        },
        {
          "text": "토큰 당 추론 속도를 25% 가량 개선한 inference-efficient 모델",
          "level": 0
        },
        {
          "text": "하루 사이에 Mistral 신모델이 출시되었는데 성능 비교가 필요할지도..",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "NVIDIA-llama-31-nemotron-70b",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "dev",
      "org": "NVIDIA",
      "title": "Llama-3.1-Nemotron-70B",
      "url": "https://huggingface.co/collections/nvidia/llama-31-nemotron-70b-670e93cd366feea16abc13d8",
      "bullets": [
        {
          "text": "2024년 10월 기준, Arena Hard와 RewardBench에서 SoTA 달성",
          "level": 0
        },
        {
          "text": "GPT-4o와 Claude 3.5를 넘는 성능을 달성했다고 함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Rhymes-AI-aria",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "dev",
      "org": "Rhymes AI",
      "title": "Aria",
      "url": "https://huggingface.co/rhymes-ai/Aria",
      "bullets": [
        {
          "text": "text, image, video 처리 가능하며 64k 사이즈의 context window 지원",
          "level": 0
        },
        {
          "text": "토큰당 3.9B activated parameters 사용",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Perplexity-introducing-internal-knowledge-search-and-spaces",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "dev",
      "org": "Perplexity",
      "title": "Introducing Internal Knowledge Search and Spaces",
      "url": "https://www.perplexity.ai/hub/blog/introducing-internal-knowledge-search-and-spaces",
      "bullets": [
        {
          "text": "Perplexity Space에서 team based search 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Fudan,-CMU,-ByteDance-revealing-the-barriers-of-language-agents-in-planning",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "Fudan, CMU, ByteDance",
      "title": "Revealing the Barriers of Language Agents in Planning",
      "url": "https://arxiv.org/abs/2410.12409",
      "bullets": [
        {
          "text": "Language model을 agent로 사용하여 planning에 활용하는 최근 연구가 많은데, 현재 연구들이 보이는 한계의 원인을 파악한 연구라고 볼 수 있음. 이를 Memory Updating과 연관지어 분석하고 설명한 내용들이 기술되어 있음.",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Tufts-University-lets-argue-both-sides-argument-generation-can-force-small-models-to-utilize-previously-inaccessible-reasoning-capabilities",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "Tufts University",
      "title": "\"Let's Argue Both Sides\": Argument Generation Can Force Small Models to Utilize Previously Inaccessible Reasoning Capabilities",
      "url": "https://arxiv.org/abs/2410.12997",
      "bullets": [
        {
          "text": "추가적인 레이어 없이 zero-shot prompting을 대체할 수 있는 방법론이라고 주장",
          "level": 0
        },
        {
          "text": "CoT나 Argument Generation은 추론이 필요한 태스크에서 zero-shot 할 때나 유용한 보조적인 수단이라고 설명",
          "level": 0
        },
        {
          "text": "엄청 단순하고 흔한 방식 같긴 한데, 이런 테크닉이 한정적인 보조수단이라고 설명한 내용이 인상 깊음",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "DeepSeek-AI,-Hong-Kong,-Peking-janus-decoupling-visual-encoding-for-unified-multimodal-understanding-and-generation",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "DeepSeek-AI, Hong Kong, Peking",
      "title": "Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation",
      "url": "https://arxiv.org/abs/2410.13848",
      "bullets": [
        {
          "text": "visual encoding을 여러 pathway로 분해(decouple)하되, 처리하는 transformer architecture는 통합된 것을 사용",
          "level": 0
        },
        {
          "text": "decoupling은 visual encoder의 역할 간 충돌을 완화하면서도 framework의 유연성은 증가시켜줌",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/deepseek-ai/Janus) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta-AI,-KAUST-agent-as-a-judge-evaluate-agents-with-agents",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "Meta AI, KAUST",
      "title": "Agent-as-a-Judge: Evaluate Agents with Agents",
      "url": "https://arxiv.org/abs/2410.10934",
      "bullets": [
        {
          "text": "LLM-as-a-Judge에 agentic feature를 통합하여 Agent-as-a-Judge를 만들고 이를 code generation에 활용",
          "level": 0
        },
        {
          "text": "realistic automated AI 개발 태스크로 구성된 새로운 벤치마크 DevAI를 제시",
          "level": 0
        },
        {
          "text": "LLM-as-a-Judge와 비교했을 때, human evaluation baseline에 준할 정도로 뛰어난 성능",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/metauto-ai/agent-as-a-judge) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "UC-Berkeley,-Washington-Univ-judgebench-a-benchmark-for-evaluating-llm-based-judges",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "UC Berkeley, Washington Univ",
      "title": "JudgeBench: A Benchmark for Evaluating LLM-based Judges",
      "url": "https://arxiv.org/abs/2410.12784",
      "bullets": [
        {
          "text": "knowledge, reasoning, math, coding 태스크를 다루는 challenging response pari로 구성",
          "level": 0
        },
        {
          "text": "현존하는 difficult dataset을 challenging response pair with preference label로 convert 해주는 pipeline을 포함하고 있음",
          "level": 0
        },
        {
          "text": "response pair 데이터셋이 아닌 것을 convert 해주는 파이프라인은 활용 가치가 높은 것 같은데, 평가 방식 자체에 대단한 건 없는 것 같음",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "KAIST,-Naver-Cloud-AI-how-does-vision-language-adaptation-impact-the-safety-of-vision-language-models",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "KAIST, Naver Cloud AI",
      "title": "How Does Vision-Language Adaptation Impact the Safety of Vision Language Models?",
      "url": "https://arxiv.org/abs/2410.07571",
      "bullets": [
        {
          "text": "training data가 safe 하더라도 VL adaptation 동안 safety degradation이 발생한다고 설명",
          "level": 0
        },
        {
          "text": "supervised fine-tuning with safety datasets | reinforcement learning from human feedback 등은 risk를 줄일 수 있지만 온전한 해결책이 아니라고 주장",
          "level": 0
        },
        {
          "text": "해결책으로 weight merging를 제안하여 safety degradation을 줄이면서도 helpfulness를 유지할 수 있도록 함",
          "level": 0
        },
        {
          "text": "요즘 은근 weight merging이 많이 활용되는 것 같은데 이게 퍼포먼스 한계치인가 싶은 생각",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "AI2,-Washington-unpacking-dpo-and-ppo-disentangling-best-practices-for-learning-from-preference-feedback",
      "date": "2024-10-W03",
      "year": "2024",
      "month": "10",
      "week": "3",
      "type": "paper",
      "org": "AI2, Washington",
      "title": "Unpacking DPO and PPO: Disentangling Best Practices for Learning from Preference Feedback",
      "url": "https://arxiv.org/abs/2406.09279",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Samsung-Research-balancing-continuous-pre-training-and-instruction-fine-tuning-optimizing-instruction-following-in-llms",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "Samsung Research",
      "title": "Balancing Continuous Pre-Training and Instruction Fine-Tuning: Optimizing Instruction-Following in LLMs",
      "url": "https://arxiv.org/abs/2410.10739",
      "bullets": [
        {
          "text": "Instruction 모델에 많은 양의 새로운 토큰을 CPT 하면 Instruction Following 성능 크게 하락",
          "level": 0
        },
        {
          "text": "Base 모델은 많은 양의 새로운 토큰을 CPT 해도 안정적인 성능 유지 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-first-person-fairness-in-chatbots",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "OpenAI",
      "title": "First-Person Fairness in Chatbots",
      "url": "https://cdn.openai.com/papers/first-person-fairness-in-chatbots.pdf",
      "bullets": [
        {
          "text": "1% 미만 수준으로 영향을 받는다는 요약글을 본 적이 있는 것 같은데, 사용자수를 고려한다면 훨씬 더 엄밀한 safety 정책이나 방법론이 필요하다는 생각이 듦",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Anthropic,-Scale-AI,-NYU,-UC-Berkeley-looking-inward-language-models-can-learn-about-themselves-by-introspection",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "Anthropic, Scale AI, NYU, UC Berkeley",
      "title": "Looking Inward: Language Models Can Learn About Themselves by Introspection",
      "url": "https://arxiv.org/abs/2410.13787",
      "bullets": [
        {
          "text": "LLM이 가상의 시나리오에 대한 본인의 행동 특성을 예측하도록 fine-tuning",
          "level": 0
        },
        {
          "text": "introspect 할 수 있는 모델 M1이 본인의 output 예측을 더 잘할 것이고, 이것이 곧 M2 보다 뛰어난 성능을 지닌다는 방증으로 이해하는 것 같음",
          "level": 0
        },
        {
          "text": "요즘 성찰, self-correct 등 모델의 inherent ability를 최대한 이끌어내고자 하는 연구가 꽤 많은 것 같은데, 약간 결과론적인 해석 위주인 것 같아서 아쉽게 느껴짐",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "British-Columbia-supervised-chain-of-thought",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "British Columbia",
      "title": "Supervised Chain of Thought",
      "url": "https://arxiv.org/abs/2410.14198",
      "bullets": [
        {
          "text": "one-for-all prompting (think step by step) 대신 task-specific supervision이 필요하다고 주장",
          "level": 0
        },
        {
          "text": "reasoning path를 학습하는 방식은 이미 제시된 바 있는데 데이터셋을 잘 구축한 건가 싶은 인상",
          "level": 0
        }
      ],
      "tags": [
        "multimodal",
        "reasoning"
      ]
    },
    {
      "id": "Hong-Kong,-Washington,-HKUST,-Microsoft-seerattention-learning-intrinsic-sparse-attention-in-your-llms",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "Hong Kong, Washington, HKUST, Microsoft",
      "title": "SeerAttention: Learning Intrinsic Sparse Attention in Your LLMs",
      "url": "https://arxiv.org/abs/2410.13276",
      "bullets": [
        {
          "text": "learnable gate를 두어 attention map에서 중요한 block를 adaptive 하게 선택하는 mechanism 제안",
          "level": 0
        },
        {
          "text": "→ accuracy & speed 균형",
          "level": 0
        },
        {
          "text": "이를 위한 customized Flash Attention 구현",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/microsoft/SeerAttention) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-open-sourced-bitnet",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "dev",
      "org": "Microsoft",
      "title": "Open-sourced BitNet",
      "url": "https://github.com/microsoft/BitNet",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-FAIR-sharing-new-research-models-and-datasets-from-meta-fair",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "dev",
      "org": "Meta FAIR",
      "title": "Sharing new research, models, and datasets from Meta FAIR",
      "url": "https://ai.meta.com/blog/fair-news-segment-anything-2-1-meta-spirit-lm-layer-skip-salsa-lingua/",
      "bullets": [
        {
          "text": "Meta Spirit LM: An open source language model for seamless speech and text integration",
          "level": 0
        },
        {
          "text": "cross modality generation을 위해 단어 단위의 text & audio 데이터를 interleaving 하는 방식 사용",
          "level": 1
        },
        {
          "text": "Layer Skip: Enhancing large language model performance with accelerated generation times",
          "level": 0
        },
        {
          "text": "추론 시 일부 layer만을 사용, 이후 verification & correction layer 통과",
          "level": 1
        },
        {
          "text": "Llama 3, Llama 2, Code Llama 등은 early exit이 가능하도록 학습",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Texas,-Pittsburgh,-Princeton,-CMU-cbt-bench-evaluating-large-language-models-on-assisting-cognitive-behavior-therapy",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "Texas, Pittsburgh, Princeton, CMU",
      "title": "CBT-Bench: Evaluating Large Language Models on Assisting Cognitive Behavior Therapy",
      "url": "https://arxiv.org/abs/2410.13218",
      "bullets": [
        {
          "text": "CBT-Bench를 구성하는 세 단계의 태스크 (Cognitive Behavior Therapy)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Shanghai-AI-Lab-compassjudger-1-all-in-one-judge-model-helps-model-evaluation-and-evolution",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "Shanghai AI Lab",
      "title": "CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and Evolution",
      "url": "https://arxiv.org/abs/2410.16256",
      "bullets": [
        {
          "text": "unitary scoring & two-model comparison 가능 / 특정 형식을 따라 평가 가능 / critiques 생성 가능 / 일반적인 LLM 태스크 수행 가능",
          "level": 0
        },
        {
          "text": "various subjective evaluation task와 topic을 커버하는 JudgerBench 구축",
          "level": 0
        },
        {
          "text": "[모델 및 코드 공개 커뮤니티 링크](https://github.com/open-compass/CompassJudger) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "CMU-causality-for-large-language-models",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "CMU",
      "title": "Causality for Large Language Models",
      "url": "https://arxiv.org/abs/2410.15319",
      "bullets": [
        {
          "text": "어떻게 causality가 언어 모델의 각 학습 단계에서 어떻게 영향을 줄 수 있는지 연구하고 앞으로의 연구 방향성을 제시. 프롬프트 기반의 연구들의 한계를 극복하겠다는 취지.",
          "level": 0
        },
        {
          "text": "말은 거창한데 abstract만 보고서는 무슨 소리인지 모르겠음",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/causal-machine-learning-lab/Awesome-Causal-LLM) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Anthropic-introducing-computer-use-a-new-claude-35-sonnet-and-claude-35-haiku",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "Introducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku",
      "url": "https://www.anthropic.com/news/3-5-models-and-computer-use",
      "bullets": [
        {
          "text": "자연어를 컴퓨터 명령어로 변환하는 기능을 포함",
          "level": 0
        },
        {
          "text": "기존 대비 훨씬 강력한 성능의 모델 업데이트를 공개함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Alibaba-aligning-large-language-models-via-self-steering-optimization",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "Alibaba",
      "title": "Aligning Large Language Models via Self-Steering Optimization",
      "url": "https://arxiv.org/abs/2410.17131",
      "bullets": [
        {
          "text": "chosen & rejected response 간의 consistent gap을 보장하면서도 현재 policy 모델의 learning capacity에 적합한 학습이 진행될 수 있도록 함",
          "level": 0
        },
        {
          "text": "SSO로 생성된 선호 데이터셋은 reward 모델의 성능을 높인다는 결과도 함께 제시",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/icip-cas/SSO) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Yonsei,-SNU-large-language-models-still-exhibit-bias-in-long-text",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "Yonsei, SNU",
      "title": "Large Language Models Still Exhibit Bias in Long Text",
      "url": "https://arxiv.org/abs/2410.17519",
      "bullets": [
        {
          "text": "14개 토픽, 10개 demographic axes, 11,948개 샘플로 구성",
          "level": 0
        },
        {
          "text": "연구에 따르면 특정 demographic group이 선호됨 & excessive sensitivity가 확인됨",
          "level": 0
        },
        {
          "text": "이를 완화하기 위해 biased prompt를 neutral response와 짝짓는 fine-tuning approach 제안",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "IBM-ibm-introduces-granite-30-high-performing-ai-models-built-for-business",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "dev",
      "org": "IBM",
      "title": "IBM Introduces Granite 3.0: High Performing AI Models Built for Business",
      "url": "https://newsroom.ibm.com/2024-10-21-ibm-introduces-granite-3-0-high-performing-ai-models-built-for-business",
      "bullets": [
        {
          "text": "larger 모델 대비 3~23x 저렴한 비용",
          "level": 0
        },
        {
          "text": "MoE 아키텍쳐를 이용하여 1B 이하의 사이즈로 enterprise 태스크 수행",
          "level": 0
        },
        {
          "text": "128K 윈도우 사이즈 지원 (예정)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "NVIDIA-helpsteer2-preference-complementing-ratings-with-preferences",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "NVIDIA",
      "title": "HelpSteer2-Preference: Complementing Ratings with Preferences",
      "url": "https://arxiv.org/abs/2410.01257",
      "bullets": [
        {
          "text": "두 방식을 head-to-head comparison → Bradley-Terry and Regression reward modeling 제안",
          "level": 0
        },
        {
          "text": "Llama-3.1-70B-Instruct 모델을 튜닝한 것이 RewardBench에서 94.1점을 달성",
          "level": 0
        },
        {
          "text": "[데이터셋 링크](https://huggingface.co/datasets/nvidia/HelpSteer2) 🔗 [모델 링크](https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Cohere-introducing-multimodal-embed-3-powering-ai-search",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "dev",
      "org": "Cohere",
      "title": "Introducing Multimodal Embed 3: Powering AI Search",
      "url": "https://cohere.com/blog/multimodal-embed-3",
      "bullets": [
        {
          "text": "나쁘지 않은 수준의 성능으로 100개 이상의 언어를 지원한다고 함 (검증할 길이 없어 아쉽)",
          "level": 0
        },
        {
          "text": "text, image가 독립적으로 clustering 되는 문제가 해결되어 mixed-modality search에서 CLIP 대비 뛰어난 성능을 보여줌",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "OpenAI-simplifying-stabilizing-and-scaling-continuous-time-consistency-models",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "OpenAI",
      "title": "Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models",
      "url": "https://arxiv.org/abs/2410.11081",
      "bullets": [
        {
          "text": "only two sampling step만으로도 뛰어난 성능을 거둘 수 있었음",
          "level": 0
        },
        {
          "text": "[OpenAI 블로그 & 데모 링크](https://openai.com/index/simplifying-stabilizing-and-scaling-continuous-time-consistency-models/) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-DeepMind-synthid-identifying-ai-generated-content-with-synthid",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "SynthID Identifying AI-generated content with SynthID",
      "url": "https://deepmind.google/technologies/synthid/",
      "bullets": [
        {
          "text": "image, audio, text, video 지원",
          "level": 0
        },
        {
          "text": "이중에서도 특히 audio, text를 어떻게 구분할 수 있다는 건지 전혀 이해가 안됨..",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Meta-introducing-quantized-llama-models-with-increased-speed-and-a-reduced-memory-footprint",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "dev",
      "org": "Meta",
      "title": "Introducing quantized Llama models with increased speed and a reduced memory footprint",
      "url": "https://ai.meta.com/blog/meta-llama-quantized-lightweight-models/",
      "bullets": [
        {
          "text": "Llama 3.2 모델에 Quantization-Aware Training with LoRA adaptors (accuracy) & SpinQuant (portability), 두 가지 방법론을 적용",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Washington,-Google-Cloud,-DeepMind-model-swarms-collaborative-search-to-adapt-llm-experts-via-swarm-intelligence",
      "date": "2024-10-W04",
      "year": "2024",
      "month": "10",
      "week": "4",
      "type": "paper",
      "org": "Washington, Google Cloud, DeepMind",
      "title": "Model Swarms: Collaborative Search to Adapt LLM Experts via Swarm Intelligence",
      "url": "https://arxiv.org/abs/2410.11163",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Stanford-co-storm-get-a-wikipedia-like-report-on-your-topic-with-ai",
      "date": "2024-10-W05",
      "year": "2024",
      "month": "10",
      "week": "5",
      "type": "dev",
      "org": "Stanford",
      "title": "Co-STORM Get a Wikipedia-like report on your topic with AI",
      "url": "https://storm.genie.stanford.edu/",
      "bullets": [
        {
          "text": "위키피디아 형식으로 작성된 내용들은 모두 PDF로 다운로드 가능",
          "level": 0
        },
        {
          "text": "글에 존재하는 모든 인용문에 대한 원본 출처 확인 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Michigan,-Amazon-a-theoretical-understanding-of-chain-of-thought-coherent-reasoning-and-error-aware-demonstration",
      "date": "2024-10-W05",
      "year": "2024",
      "month": "10",
      "week": "5",
      "type": "paper",
      "org": "Michigan, Amazon",
      "title": "A Theoretical Understanding of Chain-of-Thought: Coherent Reasoning and Error-Aware Demonstration",
      "url": "https://arxiv.org/abs/2410.16540",
      "bullets": [
        {
          "text": "추론 단계에서 demonstration example이 corrupted 될 때, Coherent CoT를 사용하는 transformer의 sensitivity를 조사",
          "level": 0
        },
        {
          "text": "→ final outcome에 비해 intermediate reasoning step에서 더 sensitive하게 반응",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Shanghai-agentic-information-retrieval",
      "date": "2024-10-W05",
      "year": "2024",
      "month": "10",
      "week": "5",
      "type": "paper",
      "org": "Shanghai",
      "title": "Agentic Information Retrieval",
      "url": "https://arxiv.org/abs/2410.09713",
      "bullets": [
        {
          "text": "기존에는 사전에 정의된 candidate item을 filtering 하는 것에 수십년째 의존하고 있던 상황",
          "level": 0
        },
        {
          "text": "Agentic IR을 제시하며 세 종류의 application과 현재의 문제점에 대해 논의",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Michigan,-Alibaba-make-llms-better-zero-shot-reasoners-structure-orientated-autonomous-reasoning",
      "date": "2024-10-W05",
      "year": "2024",
      "month": "10",
      "week": "5",
      "type": "paper",
      "org": "Michigan, Alibaba",
      "title": "Make LLMs better zero-shot reasoners: Structure-orientated autonomous reasoning",
      "url": "https://arxiv.org/abs/2410.19000",
      "bullets": [
        {
          "text": "왜 이런 방식이 실제 reasoning에 유용한지를 probabilistic graphical model을 통해 입증",
          "level": 0
        },
        {
          "text": "multi-agent reasoning system, Structure-oriented Autonomous Reasoning Agents (SARA) 제안",
          "level": 0
        }
      ],
      "tags": [
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "Stability.AI-introducing-stable-diffusion-35",
      "date": "2024-10-W05",
      "year": "2024",
      "month": "10",
      "week": "5",
      "type": "dev",
      "org": "Stability.AI",
      "title": "Introducing Stable Diffusion 3.5",
      "url": "https://stability.ai/news/introducing-stable-diffusion-3-5",
      "bullets": [
        {
          "text": "Stable Diffusion 3.5 수준의 성능을 낼 수 있는 distilled version의 turbo 모델도 공개",
          "level": 0
        },
        {
          "text": "transformer block에 Query-Key Normalization 테크닉 적용",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Huawei-step-guided-reasoning-improving-mathematical-reasoning-using-guidance-generation-and-step-reasoning",
      "date": "2024-10-W05",
      "year": "2024",
      "month": "10",
      "week": "5",
      "type": "paper",
      "org": "Huawei",
      "title": "Step Guided Reasoning: Improving Mathematical Reasoning using Guidance Generation and Step Reasoning",
      "url": "https://arxiv.org/abs/2410.19817",
      "bullets": [
        {
          "text": "LLM은 small reasoning step을 reflect 하고, 이를 inference stage에 포함시킴으로써 첫 스텝을 다음으로 잘 이어나갈 수 있게 됨",
          "level": 0
        },
        {
          "text": "간단히 살펴봤을 땐 inference를 여러 번 하게 되는 것 같은데.. 근본적인 해결책은 아닌 것 같음",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Google-DeepMind,-Boston-measuring-memorization-through-probabilistic-discoverable-extraction",
      "date": "2024-10-W05",
      "year": "2024",
      "month": "10",
      "week": "5",
      "type": "paper",
      "org": "Google DeepMind, Boston",
      "title": "Measuring memorization through probabilistic discoverable extraction",
      "url": "https://arxiv.org/abs/2410.19482",
      "bullets": [
        {
          "text": "이를 통해 모델이 기억(암기)하고 있는 정보에 대해 파악할 수 있다고 주장",
          "level": 0
        },
        {
          "text": "이러한 연구는 학습에 사용된 민감한 정보 등이 유출되는 것을 방지하기 위함인데, 그럼 외운 것 없이 순수한 추론, 이해, 언어 능력만으로 여러 태스크를 처리하는 것이 궁극적인 goal이 될지 궁금함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "GitHub-bringing-developer-choice-to-copilot-with-anthropics-claude-35-sonnet-googles-gemini-15-pro-and-openais-o1-preview",
      "date": "2024-10-W05",
      "year": "2024",
      "month": "10",
      "week": "5",
      "type": "dev",
      "org": "GitHub",
      "title": "Bringing developer choice to Copilot with Anthropic’s Claude 3.5 Sonnet, Google’s Gemini 1.5 Pro, and OpenAI’s o1-preview",
      "url": "https://github.blog/news-insights/product-news/bringing-developer-choice-to-copilot/",
      "bullets": [
        {
          "text": "VS Code, GitHub.com, Apple Xcode와의 직접적인 통합",
          "level": 0
        },
        {
          "text": "VS Code 내에 GitHub Spark 공개 (Cursor의 Composer와 유사한 기능)",
          "level": 0
        },
        {
          "text": "Cursor에 비해 한 발자국씩 대응이 늦는 것 같음. 모델 종류의 다양성이나 Spark 전부 다.",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Meta-transfusion-predict-the-next-token-and-diffuse-images-with-one-multi-modal-model",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "Meta",
      "title": "Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model",
      "url": "https://www.arxiv.org/abs/2408.11039",
      "bullets": [
        {
          "text": "언어 모델의 loss function(next token prediction)을 diffusion과 결합하여 mixed-modality sequence에 대해 single transformer를 학습",
          "level": 0
        },
        {
          "text": "7B 사이즈의 모델을 scratch부터 학습하고 2T multi-modal token을 사용, scaling law 확인.",
          "level": 0
        },
        {
          "text": "텍스트로 이뤄진 시퀀스 중간에 이미지 패치의 vector가 <BOI> & <EOI> 태그 사이에 삽입",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Stanford-anchored-preference-optimization-and-contrastive-revisions-addressing-underspecification-in-alignment",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "Stanford",
      "title": "Anchored Preference Optimization and Contrastive Revisions:\n  Addressing Underspecification in Alignment",
      "url": "https://arxiv.org/abs/2408.06266v3",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind,-UCLA,-Milla-smaller-weaker-yet-better-training-llm-reasoners-via-compute-optimal-sampling",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "Google DeepMind, UCLA, Milla",
      "title": "Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling",
      "url": "https://arxiv.org/abs/2408.16737",
      "bullets": [
        {
          "text": "세 개의 주요 메트릭: coverage, diversity, false positive rate → WC가 더 높은 coverage, diversity, but 더 높은 false positive 비율",
          "level": 0
        },
        {
          "text": "weak-to-strong improvement setup: weaker LM이 stronger LM에게 reasoning을 가르침",
          "level": 0
        },
        {
          "text": "WC-generated data로 학습한 모델이 SE-generated data로 학습한 모델보다 뛰어난 성능",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "University-of-Virginia-dynamic-self-consistency-leveraging-reasoning-paths-for-efficient-llm-sampling",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "University of Virginia",
      "title": "Dynamic Self-Consistency: Leveraging Reasoning Paths for Efficient LLM Sampling",
      "url": "https://arxiv.org/abs/2408.17017",
      "bullets": [
        {
          "text": "→ output answer와 CoT로부터의 reasoning path를 동시에 고려하여 생성되는 sample의 숫자를 dynamic하게 조절하는 early framework, Reasoning-Aware Self-Consistency (RASC)",
          "level": 0
        },
        {
          "text": "생성되는 샘플들에 confidence score를 부여하고 일정 기준이 충족되면 stop → weighted majority voting",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "LMSYS-lmsys-launches-style-control-for-chatbot-arena-to-help-separating-the-impact-of-style-from-substance-in-llm-rankings",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "dev",
      "org": "LMSYS",
      "title": "Lmsys launches style control for Chatbot Arena to help separating the impact of style from substance in LLM rankings",
      "url": "https://y1mnw3w8.r.us-east-1.awstrack.me/L0/https:%2F%2Flink.alphasignal.ai%2FNrhrYd/2/01000191b450e825-9493be3f-106c-4bf6-a9c4-4ae7a4e7370e-000000/8U59LlKUzwU7SzqhapRkBOVCPYU=389",
      "bullets": [],
      "tags": []
    },
    {
      "id": "DP-Technology-scilitllm-how-to-adapt-llms-for-scientific-literature-understanding",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "DP Technology",
      "title": "SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding",
      "url": "https://arxiv.org/abs/2408.15545",
      "bullets": [
        {
          "text": "continual pre-training (CPT) & supervised fine-tuning (SFT) 통합한 hybrid strategy 제안 → 과학 도메인 지식을 불어넣고 domain specific 태스크에서 instruction following 능력을 향상",
          "level": 0
        },
        {
          "text": "이를 위해 (1) 고품질의 CPT corpora 필요 (2) 다양한 SFT instructions 생성 필요",
          "level": 0
        },
        {
          "text": "→ PDF text extraction, parsing content error correction, quality filtering, synthetic instruction creation을 아우르는 pipeline으로 해결 시도",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Independent-Researcher-curlora-stable-llm-continual-fine-tuning-and-catastrophic-forgetting-mitigation",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "Independent Researcher",
      "title": "CURLoRA: Stable LLM Continual Fine-Tuning and Catastrophic Forgetting Mitigation",
      "url": "https://arxiv.org/abs/2408.14572",
      "bullets": [
        {
          "text": "→ catastrophic forgetting during continual learning 완화 & trainable parameters 감소",
          "level": 0
        },
        {
          "text": "변형된 CUR decomposition: 1) 열과 행 선택에 역확률 (inverted probability) 2) U 행렬 0으로 초기화 3) U 행렬만 fine-tuning",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Tsinghua-University-mini-omni-language-models-can-hear-talk-while-thinking-in-streaming",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "Tsinghua University",
      "title": "Mini-Omni: Language Models Can Hear, Talk While Thinking in Streaming",
      "url": "https://arxiv.org/abs/2408.16725",
      "bullets": [
        {
          "text": "audio-based end-to-end conversational model, Mini-Omni (real-time speech를 위한 최초의 오픈소스 모델)",
          "level": 0
        },
        {
          "text": "text-instructed speech generation, batch-parallel strategies 사용",
          "level": 0
        },
        {
          "text": "speech output을 만들 수 있도록 학습하는 데 사용 가능한 데이터셋 VoiceAssistant-400K",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/gpt-omni/mini-omni) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Peking-University,-ByteDance-multimath-bridging-visual-and-mathematical-reasoning-for-large-language-models",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "Peking University, ByteDance",
      "title": "MultiMath: Bridging Visual and Mathematical Reasoning for Large Language Models",
      "url": "https://arxiv.org/abs/2409.00147",
      "bullets": [
        {
          "text": "→ 네 단계로 학습: 1) vison-language alignment 2) visual instruction-tuning 3) math instruction-tuning 4) process-supervised reinforcement learning → MultiMath-7B",
          "level": 0
        },
        {
          "text": "K-12 수준의 image caption과 step-wise solution을 포함하는 MultiMath-300K 데이터셋 공개",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/pengshuai-rin/MultiMath) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "NVIDIA-in-defense-of-rag-in-the-era-of-long-context-language-models",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "NVIDIA",
      "title": "In Defense of RAG in the Era of Long-Context Language Models",
      "url": "https://arxiv.org/abs/2409.01666",
      "bullets": [
        {
          "text": "그러나 극단적으로 길이가 긴 입력을 처리하는 것은 결국 관련성 높은 정보에 집중하는 것을 방해함으로써 성능 저하로 이어짐",
          "level": 0
        },
        {
          "text": "→ order-preserve retrieval-augmented generation (OP-RAG) 제안",
          "level": 0
        },
        {
          "text": "retrieved chunk가 증가할수록 답변 퀄리티는 초반에 상성하다가 결국 감소하여 U-shaped curve ⇒ OP-RAG가 이득을 볼 수 있는 지점이 분명히 존재한다",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "AI2,-Washington,-Princeton-olmoe-open-mixture-of-experts-language-models",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "AI2, Washington, Princeton",
      "title": "OLMoE: Open Mixture-of-Experts Language Models",
      "url": "https://arxiv.org/abs/2409.02060",
      "bullets": [
        {
          "text": "5T 토큰으로 사전학습한 모델이며 instruct 버전도 함께 공개",
          "level": 0
        },
        {
          "text": "Llama2-13B-Chat, DeepSeekMoE-16B 보다도 뛰어난 성능이라고 주장",
          "level": 0
        },
        {
          "text": "모델 가중치, 학습 데이터, 코드, 로그 등을 오픈소스로 공개. 역시 AI2..",
          "level": 0
        },
        {
          "text": "[허깅페이스](https://hf.co/allenai/OLMoE-1B-7B-0924), [깃허브](https://github.com/allenai/OLMoE) 링크 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Tsinghua-longcite-enabling-llms-to-generate-fine-grained-citations-in-long-context-qa",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "Tsinghua",
      "title": "LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA",
      "url": "https://arxiv.org/abs/2409.02897",
      "bullets": [
        {
          "text": "LCQA를 평가하기 위한 벤치마크 LongBench-Cite 제안",
          "level": 0
        },
        {
          "text": "CoF (Coarse to Fine) 파이프라인 제안",
          "level": 0
        },
        {
          "text": "LongCite-45k 데이터셋을 사용하여 LongCite-8B, 9B를 학습",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/THUDM/LongCite) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Autodesk-AI-Research-mmlu-pro-evaluating-higher-order-reasoning-and-shortcut-learning-in-llms",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "Autodesk AI Research",
      "title": "MMLU-Pro+: Evaluating Higher-Order Reasoning and Shortcut Learning in LLMs",
      "url": "https://arxiv.org/abs/2409.02257",
      "bullets": [
        {
          "text": "복잡한 추론을 하도록 세팅이 되어 있어서 단순한 problem-solving 전략과 다르다고 주장",
          "level": 0
        },
        {
          "text": "모델이 실제 추론을 하지 않고 표면적인 패턴을 학습하여 정답을 맞히는 shortcut learning 현상을 최소화하는 것이 본 연구의 목표. shortcut learning의 정도를 평가할 수 있는 메트릭도 제시.",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/asgsaeid/mmlu-pro-plus) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "SSI-lya-sutskevers-startup-safe-superintelligence-raises-1-billion",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "dev",
      "org": "SSI",
      "title": "lya Sutskever’s startup, Safe Superintelligence, *raises $1 BILLION*",
      "url": "https://x.com/ssi/status/1831325643226890379",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Tsinghua-University-attention-heads-of-large-language-models-a-survey",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "Tsinghua University",
      "title": "Attention Heads of Large Language Models: A Survey",
      "url": "https://arxiv.org/abs/2409.03752",
      "bullets": [
        {
          "text": "사람의 생각을 네 단계의 프레임워크로 distill: 1) Knowledge Recalling, 2) In-Context Identification, 3) Latent Reasoning, 4) Expression Preparation",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/IAAR-Shanghai/Awesome-Attention-Heads) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "HSE-University-guide-and-rescale-self-guidance-mechanism-for-effective-tuning-free-real-image-editing",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "HSE University",
      "title": "Guide-and-Rescale: Self-Guidance Mechanism for Effective Tuning-Free Real Image Editing",
      "url": "https://arxiv.org/abs/2409.01322",
      "bullets": [
        {
          "text": "source 이미지의 local & global 구조를 저장할 수 있도록 하는 layout-preserving energy function을 도입",
          "level": 0
        },
        {
          "text": "→ fast & high-quality editing mechanism",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/FusionBrainLab/Guide-and-Rescale) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Tsinghua-University-pandoras-box-or-aladdins-lamp-a-comprehensive-analysis-revealing-the-role-of-rag-noise-in-large-language-models",
      "date": "2024-09-W01",
      "year": "2024",
      "month": "9",
      "week": "1",
      "type": "paper",
      "org": "Tsinghua University",
      "title": "Pandora's Box or Aladdin's Lamp: A Comprehensive Analysis Revealing the Role of RAG Noise in Large Language Models",
      "url": "https://arxiv.org/abs/2408.13533",
      "bullets": [],
      "tags": []
    },
    {
      "id": "HuggingFace,-IBM-improving-hugging-face-training-efficiency-through-packing-with-flash-attention",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "dev",
      "org": "HuggingFace, IBM",
      "title": "Improving Hugging Face Training Efficiency Through Packing with Flash Attention",
      "url": "https://huggingface.co/blog/packing-with-FA2",
      "bullets": [
        {
          "text": "최대 2배까지 높은 throughput으로 이어진다고 함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-DeepMind-building-math-agents-with-multi-turn-iterative-preference-learning",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Building Math Agents with Multi-Turn Iterative Preference Learning",
      "url": "https://arxiv.org/abs/2409.02392",
      "bullets": [
        {
          "text": "→ multi-turn direct preference learning framework를 제안: multi-turn DPO & KPO",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "University-of-Toronto,-Vector-Institute-report-cards-qualitative-evaluation-of-language-models-using-natural-language-summaries",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "University of Toronto, Vector Institute",
      "title": "Report Cards: Qualitative Evaluation of Language Models Using Natural Language Summaries",
      "url": "https://arxiv.org/abs/2409.00844",
      "bullets": [
        {
          "text": "→ 특정 스킬이나 토픽에 대한 모델의 behavior를 요약한 natrual language summaries, Report Cards를 제안",
          "level": 0
        },
        {
          "text": "specificity, faithfulness, interpretability, 세 기준을 근거로 Report Cards를 평가",
          "level": 0
        },
        {
          "text": "human supervision 없이 Report Cards를 생성하는 iterative algorithm 제안",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "Replit-replit-agent",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "dev",
      "org": "Replit",
      "title": "Replit Agent",
      "url": "https://docs.replit.com/replitai/agent",
      "bullets": [
        {
          "text": "cursor의 composer와 유사한 기능으로 보임",
          "level": 0
        },
        {
          "text": "long context, code understanding & generation에 많은 기업들이 집중하는 이유",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-illuminate",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "dev",
      "org": "Google",
      "title": "Illuminate",
      "url": "https://illuminate.google.com/home",
      "bullets": [
        {
          "text": "현재 waitlist에 등록해야 하는 실험적 기능임",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Beijing-University-how-do-your-code-llms-perform-empowering-code-instruction-tuning-with-high-quality-data",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "Beijing University",
      "title": "How Do Your Code LLMs Perform? Empowering Code Instruction Tuning with High-Quality Data",
      "url": "https://arxiv.org/abs/2409.03810",
      "bullets": [
        {
          "text": "instruction complexity, response quality, instruction diversity 세 개의 기준으로 데이터를 선별",
          "level": 0
        },
        {
          "text": "선별된 데이터로 Llama-3를 학습하여 XCoder 모델을 공개",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Mila,-Princeton,-Cambridge,-Google-DeepMind-metacognitive-capabilities-of-llms-an-exploration-in-mathematical-problem-solving",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "Mila, Princeton, Cambridge, Google DeepMind",
      "title": "Metacognitive Capabilities of LLMs: An Exploration in Mathematical Problem Solving",
      "url": "https://arxiv.org/abs/2405.12205",
      "bullets": [
        {
          "text": "→ 본 연구 결과에 따르면 LLM이 meta cognitive knowledge를 지닌 것으로 판단된다고 함",
          "level": 0
        },
        {
          "text": "수학 문제에 합리적인 skill label을 붙일 수 있다는 것이 확인되었음. 그 결과는 사람도 해석 가능.",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Oxford-detecting-hallucinations-in-large-language-models-using-semantic-entropy",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "Oxford",
      "title": "Detecting hallucinations in large language models using semantic entropy",
      "url": "https://www.nature.com/articles/s41586-024-07421-0",
      "bullets": [
        {
          "text": "→ entropy-based uncertainty estimator를 도입하여 LLM이 hallucinations-confabulations-를 탐지할 수 있도록 함",
          "level": 0
        },
        {
          "text": "데이터셋이나 task에 대한 사전 지식 없이도 적용 가능한 방법론임을 설명",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Singapore-University-spinning-the-golden-thread-benchmarking-long-form-generation-in-language-models",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "Singapore University",
      "title": "Spinning the Golden Thread: Benchmarking Long-Form Generation in Language Models",
      "url": "https://arxiv.org/abs/2409.02076",
      "bullets": [
        {
          "text": "→ 생성된 long text sequences 내의 특정 사건들을 식별할 수 있는 능력을 평가하는 Spinning the Golden Thread (SGT) 제안",
          "level": 0
        },
        {
          "text": "LM이 특정 사건과 constraint를 포함하여 long-form text를 생성하도록 지시",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Huawei-huawei-unveils-2800-tri-fold-phone-just-hours-after-iphone-16-launch",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "dev",
      "org": "Huawei",
      "title": "Huawei unveils $2,800 tri-fold phone just hours after iPhone 16 launch.",
      "url": "https://x.com/alvinfoo/status/1833427069470183795",
      "bullets": [],
      "tags": []
    },
    {
      "id": "University-of-Toronto-seek-and-solve-reasoning-for-table-question-answering",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "University of Toronto",
      "title": "Seek and Solve Reasoning for Table Question Answering",
      "url": "https://arxiv.org/abs/2409.05286",
      "bullets": [
        {
          "text": "reasoning은 two-stage로 구성, CoT paths는 Seek-and-Solve CoT로 통합 (SS-CoT)",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Stanford-University-can-llms-generate-novel-research-ideas-a-large-scale-human-study-with-100-nlp-researchers",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "Stanford University",
      "title": "Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP Researchers",
      "url": "https://www.arxiv.org/abs/2409.04109",
      "bullets": [
        {
          "text": "LLM-generated idea가 사람이 만든 것보다 더 novel 하다는 결과 (p<0.05). 단, feasibility는 조금 더 낮은 것으로 확인됨.",
          "level": 0
        },
        {
          "text": "얼마 전 Sakana에서 공개한 AI Scientist도 그렇고.. 확실히 연구도 AI로 하는 시대가 오게 될 듯",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Apple-theory-analysis-and-best-practices-for-sigmoid-self-attention",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "Apple",
      "title": "Theory, Analysis, and Best Practices for Sigmoid Self-Attention",
      "url": "https://arxiv.org/abs/2409.04431",
      "bullets": [
        {
          "text": "H100에서 FlashAttention2 위에서 돌아가는 Flash-Sigmoid 도입 → 추론 속도 17% 향상",
          "level": 0
        },
        {
          "text": "이런 것들은 실제 사용 경험을 많이 접해보고 적용하면 좋을 것 같음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "UIUC,-CMU-paper-copilot-a-self-evolving-and-efficient-llm-system-for-personalized-academic-assistance",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "UIUC, CMU",
      "title": "Paper Copilot: A Self-Evolving and Efficient LLM System for Personalized Academic Assistance",
      "url": "https://arxiv.org/abs/2409.04593",
      "bullets": [
        {
          "text": "→ thought-retrieval을 기반으로 researcher를 돕는 self-evoling, efficient LLM 시스템 제안",
          "level": 0
        },
        {
          "text": "69.92%의 시간을 절약할 수 있다고 주장",
          "level": 0
        },
        {
          "text": "[허깅페이스 스페이스 링크](https://huggingface.co/spaces/ulab-ai/ArxivCopilot) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Mistral-pixtral-12b-240910",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "dev",
      "org": "Mistral",
      "title": "pixtral-12b-240910",
      "url": "",
      "bullets": [
        {
          "text": "text-based Nemo 12B에 400M vision adapter를 합친 모델",
          "level": 0
        },
        {
          "text": "1024 x 1024 이미지까지 처리 가능하며 16 x 16 단위로 쪼갠다고 알려짐",
          "level": 0
        },
        {
          "text": "131,072개의 unique tokens",
          "level": 0
        },
        {
          "text": "업데이트 되지 않는 모델 체크포인트를 허깅페이스에 공개",
          "level": 0
        },
        {
          "text": "[허깅페이스 링크](https://huggingface.co/mistral-community/pixtral-12b-240910) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "SambaNova-sambanova-launches-the-worlds-fastest-ai-platform",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "dev",
      "org": "SambaNova",
      "title": "SambaNova Launches The World's Fastest AI Platform",
      "url": "https://sambanova.ai/press/worlds-fastest-ai-platform",
      "bullets": [
        {
          "text": "오픈소스는 아니고 fine-tuning과 inference 솔루션을 판매하는 기업의 제품으로 보임",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "United-We-Care-llms-will-always-hallucinate-and-we-need-to-live-with-this",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "United We Care",
      "title": "LLMs Will Always Hallucinate, and We Need to Live With This",
      "url": "https://arxiv.org/abs/2409.05746",
      "bullets": [
        {
          "text": "→ 따라서 아키텍쳐 개선, 데이터셋 증가, fact-checking 등으로 hallucination을 제거한다는 것은 불가능하다고 주장",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "KAIST-think-together-and-work-better-combining-humans-and-llms-think-aloud-outcomes-for-effective-text-evaluation",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "KAIST",
      "title": "Think Together and Work Better: Combining Humans' and LLMs' Think-Aloud Outcomes for Effective Text Evaluation",
      "url": "https://arxiv.org/abs/2409.07355",
      "bullets": [
        {
          "text": "사람은 Coherence & Fluency와 같은 internal quality와 관련된 작업에 능하고, LLM은 Consistency & Relavance와 같은 external alignment에 능하다는 분석 결과",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/BBeeChu/InteractEval.git) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Intel,-DeepLearning.AI-multimodal-rag-chat-with-videos",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "dev",
      "org": "Intel, DeepLearning.AI",
      "title": "Multimodal RAG: Chat with Videos",
      "url": "https://www.deeplearning.ai/short-courses/multimodal-rag-chat-with-videos/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-datagemma-using-real-world-data-to-address-ai-hallucinations",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "dev",
      "org": "Google",
      "title": "DataGemma: Using real-world data to address AI hallucinations",
      "url": "https://blog.google/technology/ai/google-datagemma-ai-llm/",
      "bullets": [
        {
          "text": "RIG(Retrieval-Interleaved Generation) & RAG 사용",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Tsinghua-general-ocr-theory-towards-ocr-20-via-a-unified-end-to-end-model",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "Tsinghua",
      "title": "General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model",
      "url": "https://arxiv.org/abs/2409.01704",
      "bullets": [
        {
          "text": "scene, document, whole-page 스타일 등 다양한 이미지 양식을 커버할 수 있고 “글자” 단위로 처리하는 OCR tasks도 다룰 수 있음",
          "level": 0
        },
        {
          "text": "좌표나 색상 등으로 설명되는 region-level recognition도 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "FutureHouse-paperqa2",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "dev",
      "org": "FutureHouse",
      "title": "PaperQA2",
      "url": "https://github.com/Future-House/paper-qa",
      "bullets": [
        {
          "text": "QA, 요약, contradiction detection 등 가능",
          "level": 0
        },
        {
          "text": "`pip install paper-qa`",
          "level": 0
        },
        {
          "text": "[논문 링크](https://storage.googleapis.com/fh-public/paperqa/Language_Agents_Science.pdf) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "OpenAI-introducing-openai-o1-preview",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing OpenAI o1-preview",
      "url": "https://openai.com/index/introducing-openai-o1-preview/",
      "bullets": [
        {
          "text": "과학, 코딩, 수학 분야에서 뛰어난 성능 보임 (예: IMO 예선 83% 정답률, Codeforces 89번째 백분위)",
          "level": 0
        },
        {
          "text": "o1-preview와 o1-mini 두 모델 제공, ChatGPT Plus/Team 사용자와 일부 API 개발자들에게 접근 권한 부여",
          "level": 0
        },
        {
          "text": "향상된 안전 기능 적용 (jailbreaking 테스트에서 GPT-4o 대비 큰 성능 향상)",
          "level": 0
        },
        {
          "text": "[OpenAI o1 System Card](https://openai.com/index/openai-o1-system-card/) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "University-of-Mannheim-fine-tuning-large-language-models-for-entity-matching",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "University of Mannheim",
      "title": "Fine-tuning Large Language Models for Entity Matching",
      "url": "https://arxiv.org/abs/2409.08185",
      "bullets": [
        {
          "text": "→ LLM fine-tuning: 1) LLM이 생성한 학습용 설명 데이터셋 2) LLM을 이용한 학습 데이터 선별",
          "level": 0
        },
        {
          "text": "sLLM (Llama 3.1 8B) > LLM (GPT-4o Mini), in-domain > cross-domain, structured data 효과적",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta,-Oxford,-UCL-source2synth-synthetic-data-generation-and-curation-grounded-in-real-data-sources",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "Meta, Oxford, UCL",
      "title": "Source2Synth: Synthetic Data Generation and Curation Grounded in Real Data Sources",
      "url": "https://arxiv.org/abs/2409.08239",
      "bullets": [
        {
          "text": "custom data source 입력 → real-wrold source에 근거한 intermediate reasoning step을 포함하여 합성 데이터를 생성",
          "level": 0
        },
        {
          "text": "answerability에 따라 low-quality generation를 버릴 수 있어 데이터셋 퀄리티가 개선됨",
          "level": 0
        },
        {
          "text": "multi-hop question answering (MHQA), tool usage in tabular question answering (TQA) 에 효과적",
          "level": 0
        }
      ],
      "tags": [
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "Alibaba-mplug-docowl2-high-resolution-compressing-for-ocr-free-multi-page-document-understanding",
      "date": "2024-09-W02",
      "year": "2024",
      "month": "9",
      "week": "2",
      "type": "paper",
      "org": "Alibaba",
      "title": "mPLUG-DocOwl2: High-resolution Compressing for OCR-free Multi-page Document Understanding",
      "url": "https://arxiv.org/abs/2409.03420",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Stability.AI-stable-diffusion-3-medium-fine-tuning-tutorial",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "dev",
      "org": "Stability.AI",
      "title": "Stable Diffusion 3 Medium Fine-tuning Tutorial",
      "url": "https://www.notion.so/17f90df74bce4c62a295849f0dc8fb7e?pvs=21",
      "bullets": [
        {
          "text": "기존 SD1.5, SDXL 모델과 SD3M 파인튜닝의 차이점 설명",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "CMU,-MIT-agent-workflow-memory",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "CMU, MIT",
      "title": "Agent Workflow Memory",
      "url": "https://arxiv.org/abs/2409.07429",
      "bullets": [
        {
          "text": "Agent Workflow Memory (AWM): 자주 반복되는 routine을 induce 하는 방법론으로, agent에게 workflow를 선택적으로 제공",
          "level": 0
        },
        {
          "text": "offline & online 시나리오 둘 다 적용 가능, Mind2Web & WebArena 벤치마크로 실험",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/zorazrw/agent-workflow-memory) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "KAIST-stable-language-model-pre-training-by-reducing-embedding-variability",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "KAIST",
      "title": "Stable Language Model Pre-training by Reducing Embedding Variability",
      "url": "https://arxiv.org/abs/2409.07787",
      "bullets": [
        {
          "text": "Multi-head Low-Rank Attention (MLRA), output embedding의 exponential growth를 제안함으로써 instability를 완화",
          "level": 0
        },
        {
          "text": "연구실에서는 아직도 GPT-2, Llama-2 등을 사용할 수밖에 없는 실정..",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Peking,-Microsoft-cpl-critical-planning-step-learning-boosts-llm-generalization-in-reasoning-tasks",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Peking, Microsoft",
      "title": "CPL: Critical Planning Step Learning Boosts LLM Generalization in Reasoning Tasks",
      "url": "https://arxiv.org/abs/2409.08642",
      "bullets": [
        {
          "text": "→ Monte Carlo Tree Search (MCTS)를 이용하여 multi-step reasoning tasks 내의 다양한 planning step을 탐색하는 Critical Planning Step Learning (CPL) 제안",
          "level": 0
        },
        {
          "text": "Step-APO (Step-level Adavantage Preference Optimization): MCTS를 통해 획득 가능한 step-level 선호쌍을 DPO와 통합",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Wisconsin-Madison-your-weak-llm-is-secretly-a-strong-teacher-for-alignment",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Wisconsin-Madison",
      "title": "Your Weak LLM is Secretly a Strong Teacher for Alignment",
      "url": "https://arxiv.org/abs/2409.08813",
      "bullets": [
        {
          "text": "→ weak LLM을 이용해서 human feedback만 사용할 때에 준하는, 혹은 그 이상의 효율을 뽑아내고자 함",
          "level": 0
        },
        {
          "text": "본 연구에서는 OPT-125M 모델을 사용 → 굉장히 작은 사이즈의 모델로도 좋은 결과를 얻었다고 볼 수 있음",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Chinese-Academy-of-Sciecnes-struedit-structured-outputs-enable-the-fast-and-accurate-knowledge-editing-for-large-language-models",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Chinese Academy of Sciecnes",
      "title": "StruEdit: Structured Outputs Enable the Fast and Accurate Knowledge Editing for Large Language Models",
      "url": "https://arxiv.org/abs/2409.10132",
      "bullets": [
        {
          "text": "→ StruEdit 제안: reasoning triplet으로 structured output을 반환하도록 프롬프팅 → outdated knowledge를 제거하고 효율적으로 up-to-date 정보로 채워 넣음",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Microsoft-microsoft-365-copilot-wave-2-pages-python-in-excel-and-agents",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "dev",
      "org": "Microsoft",
      "title": "Microsoft 365 Copilot Wave 2: Pages, Python in Excel, and agents",
      "url": "https://www.microsoft.com/en-us/microsoft-365/blog/2024/09/16/microsoft-365-copilot-wave-2-pages-python-in-excel-and-agents/",
      "bullets": [
        {
          "text": "이런 통합 시스템을 구현하겠다고 작년부터 구글과 경쟁하고 있는 것 같은데 실효성은 아직 잘 모르겠음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Waymo-waymos-self-driving-cars-beat-humans-in-safety",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "dev",
      "org": "Waymo",
      "title": "Waymo’s Self-driving cars beat humans in safety",
      "url": "https://link.mail.beehiiv.com/ss/c/u001.22XVe7hOOQo4HoFgEcBa71etRz_zVbDtBQ3xhBSmS3-n3f-hnoXyvvOxUSLr6qeJjN2gRzsBXkF6QrPYsjDpmxZwZNAKYsVbeUOzsTe6a_ioIFmsIrSF-HGC5aYKMdFl60qp-lMR26Rog3HlP7SWkyVB7rS969GLVp_nHwbyxhVj49y4OmafUcEihqsRFHAfHOiNhhQf-x74RW5v2pZrVumPsWdi3iQ1YD0HoorhANkbGv8gZPD2HcT6bYgL27bo7FOqPcrK3Gu_O7mJwUdrtsAszFpNLNaSiT12CgLdjcM/49u/CsYMakzZSD6FfomXvnqCHg/h24/h001.wdQJP84KSzOLsjJU3kuEDFJFbyKEvKR3ubNxu0y-MT0",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-notebooklm-now-lets-you-listen-to-a-conversation-about-your-sources",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "dev",
      "org": "Google",
      "title": "NotebookLM now lets you listen to a conversation about your sources",
      "url": "https://blog.google/technology/ai/notebooklm-audio-overviews/",
      "bullets": [
        {
          "text": "구글 [Illuminate](https://illuminate.google.com/home)에 이것이 사용된 것으로 보이고 Gemini 1.5의 멀티모달 능력을 이용",
          "level": 0
        },
        {
          "text": "[NotebookLM 링크](http://notebooklm.google/) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Huawei-large-language-models-are-good-multi-lingual-learners-when-llms-meet-cross-lingual-prompts",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Huawei",
      "title": "Large Language Models are Good Multi-lingual Learners : When LLMs Meet Cross-lingual Prompts",
      "url": "https://arxiv.org/abs/2409.11056",
      "bullets": [
        {
          "text": "LLM이 다른 언어로는 따르기 어려워하는 error-prone rule을 자동으로 번역",
          "level": 0
        },
        {
          "text": "structured data 생성에 대한 auto-checking 메커니즘을 포함하는 프레임워크를 공개",
          "level": 0
        },
        {
          "text": "이 부분은 확인할 필요가 있을 듯",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Mistral-AI-ai-in-abundance",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "dev",
      "org": "Mistral AI",
      "title": "AI in abundance",
      "url": "https://mistral.ai/news/september-24-release/",
      "bullets": [
        {
          "text": "Mistral AI 모델들의 비용을 크게 줄임: Nemo 50%, Small & Codestral 80%, Large 33, …",
          "level": 0
        },
        {
          "text": "le Chat에서 사용 가능한 Pixtral 12B 모델을 Apache 2.0 라이센스로 공개",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Qwen-qwen25-a-party-of-foundation-models",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "dev",
      "org": "Qwen",
      "title": "Qwen2.5: A Party of Foundation Models!",
      "url": "https://qwenlm.github.io/blog/qwen2.5/",
      "bullets": [
        {
          "text": "3B & 72B 를 제외한 모델들은 Apache 2.0 라이센스",
          "level": 0
        },
        {
          "text": "18T 토큰으로 학습하여 coding, mathematics, instruction following, long texts 등 다양한 영역에서 강점을 보임 → 128K 윈도우 사이즈 지원, 8K 토큰까지 생성 가능, 29개 언어 지원",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "ETRI-a-comprehensive-evaluation-of-quantized-instruction-tuned-large-language-models-an-experimental-analysis-up-to-405b",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "ETRI",
      "title": "A Comprehensive Evaluation of Quantized Instruction-Tuned Large Language Models: An Experimental Analysis up to 405B",
      "url": "https://arxiv.org/abs/2409.11055",
      "bullets": [
        {
          "text": "→ GPTQ, AWQ, SmoothQuant, FP8 등 다양한 방식, 7B ~ 405B 사이즈 모델. 13개 벤치마크에서 평가",
          "level": 0
        },
        {
          "text": "(1) FP 16 LLM은 hallucination detection & instruction following 제외하고 괜찮",
          "level": 0
        },
        {
          "text": "(2) quantization 방법, 모델 사이즈, bit-width 등에 따라 결과가 천차만별",
          "level": 0
        },
        {
          "text": "(3) task 난이도가 accuracy degradation에 그렇게 큰 영향을 주지는 않음",
          "level": 0
        },
        {
          "text": "(4) MT-Bench 평가 방식은 뛰어난 최근 LLM들의 독보적인 능력이 발휘되기에 적합하지는 않음",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-fine-tuning-llms-to-158bit-extreme-quantization-made-easy",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "dev",
      "org": "HuggingFace",
      "title": "Fine-tuning LLMs to 1.58bit: extreme quantization made easy",
      "url": "https://huggingface.co/blog/1_58_llm_extreme_quantization",
      "bullets": [
        {
          "text": "허깅페이스에서 1.58b 로 학습하고 추론하는 방법에 대한 블로그 글을 게시",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Snap-introducing-new-spectacles-and-snap-os-the-next-frontier-of-ar-glasses",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "news",
      "org": "Snap",
      "title": "Introducing New Spectacles and Snap OS: The Next Frontier of AR Glasses",
      "url": "https://newsroom.snap.com/sps-2024-spectacles-snapos",
      "bullets": [
        {
          "text": "OpenAI와의 파트너십을 발표하여 화제",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "ETH-breaking-recaptchav2",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "ETH",
      "title": "Breaking reCAPTCHAv2",
      "url": "https://arxiv.org/abs/2409.08831",
      "bullets": [
        {
          "text": "YOLO 모델을 사용하여 100% 확률로 통과할 수 있었으며, 통과에 필요한 문제 수가 사람과 다르지 않다는 결론",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/aplesner/Breaking-reCAPTCHAv2) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Texas-at-Austin,-Johns-Hopkins,-Princeton-to-cot-or-not-to-cot-chain-of-thought-helps-mainly-on-math-and-symbolic-reasoning",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Texas at Austin, Johns Hopkins, Princeton",
      "title": "To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning",
      "url": "https://arxiv.org/abs/2409.12183",
      "bullets": [
        {
          "text": "→ CoT는 math, logic 과 같이 논리적인 태스크에서는 효과적이지만 그 외에는 그닥 영향이 없음",
          "level": 0
        },
        {
          "text": "MMLU에서 질문이나 모델의 답변에 ‘=’ 기호를 포함하는 태스크를 제외하고서는 CoT를 쓰나 안쓰나 비슷",
          "level": 0
        },
        {
          "text": "따라서 CoT는 상황에 맞게 선별적으로 사용하는 것이 좋을 것 같다는 결론",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Texas-at-San-Antonio-improving-llm-reasoning-with-multi-agent-tree-of-thought-validator-agent",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Texas at San Antonio",
      "title": "Improving LLM Reasoning with Multi-Agent Tree-of-Thought Validator Agent",
      "url": "https://arxiv.org/abs/2409.11527",
      "bullets": [
        {
          "text": "Thought Validator agent를 동반한 ToT 기반의 Reasoner agent를 제시",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Qwen-qwen25-coder-technical-report",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Qwen",
      "title": "Qwen2.5-Coder Technical Report",
      "url": "",
      "bullets": [
        {
          "text": "CodeQwen1.5의 후속작 Qwen2.5-Coder-1.5B, 7B의 테크니컬 리포트",
          "level": 0
        },
        {
          "text": "데이터 정제, 합성 데이터 생성, 데이터 혼합 등. 5.5T 토큰으로 학습. 큰 사이즈 모델보다도 뛰어난 성능을 보고.",
          "level": 0
        },
        {
          "text": "[허깅 페이스](https://hf.co/Qwen/Qwen2.5-Coder-7B-Instruct), [깃허브](https://github.com/QwenLM/Qwen2.5-Coder) 링크 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "GitHub-try-out-openai-o1-in-github-copilot-and-models",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "dev",
      "org": "GitHub",
      "title": "Try out OpenAI o1 in GitHub Copilot and Models",
      "url": "https://github.blog/news-insights/product-news/try-out-openai-o1-in-github-copilot-and-models/",
      "bullets": [
        {
          "text": "Copilot Chat 중간에 o1-preview, o1-mini, GPT-4o 모델 간 변경 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Open-source-FinePersonas-datasets-dropped-in-Huggingface-with-21-million-rows-and-142GB-size-open-source-finepersonas-datasets-dropped-in-huggingface-with-21-million-rows-and-142gb-size",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "dev",
      "org": "Open-source FinePersonas datasets dropped in Huggingface with 21 million rows and 142GB size",
      "title": "Open-source FinePersonas datasets dropped in Huggingface with 21 million rows and 142GB size",
      "url": "https://huggingface.co/datasets/argilla/FinePersonas-v0.1",
      "bullets": [
        {
          "text": "어떤 프롬프트를 사용했는지도 함께 공개",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-re-reading-improves-reasoning-in-large-language-models",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Microsoft",
      "title": "Re-Reading Improves Reasoning in Large Language Models",
      "url": "https://arxiv.org/abs/2309.06275",
      "bullets": [
        {
          "text": "질문을 두 번 처리함으로써 과정에 대한 이해도를 높인다는 것이 컨셉",
          "level": 0
        },
        {
          "text": "단방향의 decoder-only LLM에서 “bidirectional” encoding을 사용하여 global information 활용",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Huawei,-McGill,-Mila-enhancing-logical-reasoning-in-large-language-models-through-graph-based-synthetic-data",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Huawei, McGill, Mila",
      "title": "Enhancing Logical Reasoning in Large Language Models through Graph-based Synthetic Data",
      "url": "https://arxiv.org/abs/2409.12437",
      "bullets": [
        {
          "text": "기존의 다른 능력들을 손상시키지 않으면서도 추론 능력을 향상시킬 수 있었다고 주장",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://arxiv.org/abs/2409.12437) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-DeepMind-training-language-models-to-self-correct-via-reinforcement-learning",
      "date": "2024-09-W03",
      "year": "2024",
      "month": "9",
      "week": "3",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Training Language Models to Self-Correct via Reinforcement Learning",
      "url": "https://arxiv.org/abs/2409.12917",
      "bullets": [],
      "tags": []
    },
    {
      "id": "HKUST,-Amazon-constrained-reasoning-chains-for-enhancing-theory-of-mind-in-large-language-models",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "HKUST, Amazon",
      "title": "Constrained Reasoning Chains for Enhancing\n  Theory-of-Mind in Large Language Models",
      "url": "https://arxiv.org/abs/2409.13490",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Tsinghua,-Berkely,-Anthropic,-NYU-language-models-learn-to-mislead-humans-via-rlhf",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Tsinghua, Berkely, Anthropic, NYU",
      "title": "Language Models Learn to Mislead Humans via RLHF",
      "url": "https://arxiv.org/abs/2409.12822",
      "bullets": [
        {
          "text": "모델의 출력 결과를 사람이 직접 평가 → RLHF는 모델의 성능도 평가하기 어렵게 만든다.",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Tsinghua,-Shanhai-AI-Lab-on-the-diagram-of-thought",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Tsinghua, Shanhai AI Lab",
      "title": "On the Diagram of Thought",
      "url": "https://arxiv.org/abs/2409.10038",
      "bullets": [
        {
          "text": "propositions, critiques, refinements, verifications를 DAG 구조 내에 포함 → logical consistency를 유지하면서도 모델이 복잡한 reasoning pathways를 탐색하도록 함",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Arizona-State-University-llms-still-cant-plan-can-lrms-a-preliminary-evaluation-of-openais-o1-on-planbench",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Arizona State University",
      "title": "LLMs Still Can't Plan; Can LRMs? A Preliminary Evaluation of OpenAI's o1 on PlanBench",
      "url": "https://arxiv.org/abs/2409.13373",
      "bullets": [
        {
          "text": "o1과 같은 Large Reasoning Model (LRM) 은 분명 눈에 띄는 성능 향상을 보여주고 있으나 아직까지 planning 능력이 충분하지 않다고 주장",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "NYU,-Columbia-style-over-substance-failure-modes-of-llm-judges-in-alignment-benchmarking",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "NYU, Columbia",
      "title": "Style over Substance: Failure Modes of LLM Judges in Alignment Benchmarking",
      "url": "https://arxiv.org/abs/2409.15268",
      "bullets": [
        {
          "text": "LLM-judgement는 safety, world knowledge, instruction following과 관계가 없다고 주장. 대신 style에 대해 더 높은 우선순위를 부여하고 있는 것으로 관측.",
          "level": 0
        },
        {
          "text": "[코드 및 결과물 링크](https://anonymous.4open.science/r/mismo-bench-587D/readme.md) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "NVIDIA-advancing-the-accuracy-efficiency-frontier-with-llama-31-nemotron-51b",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "NVIDIA",
      "title": "Advancing the Accuracy-Efficiency Frontier with Llama-3.1-Nemotron-51B",
      "url": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/",
      "bullets": [
        {
          "text": "40B tokens from FineWeb, Buzz-V1.2, and Dolma datasets",
          "level": 0
        },
        {
          "text": "Packaged as NVIDIA NIM inference microservice for easy deployment",
          "level": 0
        },
        {
          "text": "[허깅페이스 링크](https://huggingface.co/nvidia/Llama-3_1-Nemotron-51B-Instruct) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-DeepMind-michelangelo-long-context-evaluations-beyond-haystacks-via-latent-structure-queries",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Michelangelo: Long Context Evaluations Beyond Haystacks via Latent Structure Queries",
      "url": "https://arxiv.org/abs/2409.12640",
      "bullets": [
        {
          "text": "context 내에서 단순히 정보를 retrieve 하는 것 이상의 long-context 평가를 하기 위한 통합 평가 프레임워크",
          "level": 0
        },
        {
          "text": "코드 및 자연어 도메인에서 3개의 diagnostic long-context evaluations",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "SocialAI:-we-tried-the-Twitter-clone-where-no-other-humans-are-allowed-socialai-we-tried-the-twitter-clone-where-no-other-humans-are-allowed",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "news",
      "org": "SocialAI: we tried the Twitter clone where no other humans are allowed",
      "title": "SocialAI: we tried the Twitter clone where no other humans are allowed",
      "url": "https://www.theverge.com/2024/9/17/24247253/social-ai-app-replace-humans-with-bots",
      "bullets": [],
      "tags": []
    },
    {
      "id": "OpenAI-advanced-voice",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "dev",
      "org": "OpenAI",
      "title": "Advanced Voice",
      "url": "https://x.com/OpenAI/status/1838642444365369814?t=LEjyOFoySCjkcAjbXMfEww&s=19",
      "bullets": [
        {
          "text": "Custom Instructions, Memory, five new voices, improved accents 등의 특징",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "dev",
      "org": "Google",
      "title": "Updated production-ready Gemini models, reduced 1.5 Pro pricing, increased rate limits, and more",
      "url": "https://developers.googleblog.com/en/updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more/",
      "bullets": [
        {
          "text": "1.5 Pro 비용 50% 감소, 2배 높아진 limit, 2배 빨라진 output",
          "level": 0
        },
        {
          "text": "거대 모델을 이용하는 비용은 확실히 빠른 속도로 줄어들고 있음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "NASA,-IBM-prithvi-wxc-foundation-model-for-weather-and-climate",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "NASA, IBM",
      "title": "Prithvi WxC: Foundation Model for Weather and Climate",
      "url": "https://arxiv.org/abs/2409.13598",
      "bullets": [
        {
          "text": "[허깅페이스 링크](https://huggingface.co/Prithvi-WxC) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Meta-llama-32-revolutionizing-edge-ai-and-vision-with-open-customizable-models",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "dev",
      "org": "Meta",
      "title": "Llama 3.2: Revolutionizing edge AI and vision with open, customizable models",
      "url": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
      "bullets": [
        {
          "text": "summarization, instruction following, rewriting tasks 등을 locally 처리 가능",
          "level": 0
        },
        {
          "text": "AWS, Databricks, Dell, Fireworks 등 Llama Stack distributions을 위한 노력. Ollama에서 single-node로 지원하기도 함",
          "level": 0
        },
        {
          "text": "[허깅페이스 링크](https://huggingface.co/collections/meta-llama/llama-32-66f448ffc8c32f949b04c8cf) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Beijing-Academy-of-AI-making-text-embedders-few-shot-learners",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Beijing Academy of AI",
      "title": "Making Text Embedders Few-Shot Learners",
      "url": "https://arxiv.org/abs/2409.15700",
      "bullets": [
        {
          "text": "few-shot exmaples를 이용하여 고퀄리티 text embedding을 생성하는 bge-en-icl 공개",
          "level": 0
        },
        {
          "text": "MTEB, AIR-Bench에서 SOTA 달성",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "AI2,-Washington-molmo-and-pixmo-open-weights-and-open-data-for-state-of-the-art-multimodal-models",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "AI2, Washington",
      "title": "Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models",
      "url": "https://arxiv.org/abs/2409.17146",
      "bullets": [
        {
          "text": "→ speech 기반의 description을 사용하여 사람이 직접 highly detailed image caption dataset을 제작. 이것으로 학습한 VLM family, Molmo를 공개",
          "level": 0
        },
        {
          "text": "model weights, captioning & fine-tuning data & source code 모두 공개 예정. [링크](https://molmo.allenai.org/) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "HyperAgent:-Generalist-Software-Engineering-Agents-to-Solve-Coding-Tasks-at-Scale-hyperagent-generalist-software-engineering-agents-to-solve-coding-tasks-at-scale",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "HyperAgent: Generalist Software Engineering Agents to Solve Coding Tasks at Scale",
      "title": "HyperAgent: Generalist Software Engineering Agents to Solve Coding Tasks at Scale",
      "url": "https://arxiv.org/abs/2409.16299",
      "bullets": [
        {
          "text": "Planner, Navigator, Code Editor, Executor 네 개의 agent로 구성",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/FSoft-AI4Code/HyperAgent) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "stepfun-ai/GPT-OCR2_0-stepfun-aigpt-ocr2_0",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "dev",
      "org": "stepfun-ai/GPT-OCR2_0",
      "title": "stepfun-ai/GPT-OCR2_0",
      "url": "https://huggingface.co/stepfun-ai/GOT-OCR2_0",
      "bullets": [
        {
          "text": "[데모 링크](https://huggingface.co/stepfun-ai/GOT-OCR2_0), [깃허브 링크](https://github.com/Ucas-HaoranWei/GOT-OCR2.0/), [논문 링크](https://arxiv.org/abs/2409.01704) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "York-University-task-oriented-prompt-enhancement-via-script-generation",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "York University",
      "title": "Task-oriented Prompt Enhancement via Script Generation",
      "url": "https://arxiv.org/abs/2409.16418",
      "bullets": [
        {
          "text": "(1) task’s input specification을 추출하기 위한 step-back prompting (2) required procedural steps를 identify 하기 위한 CoT prompting",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Logic-of-Thought:-Injecting-Logic-into-Contexts-for-Full-Reasoning-in-Large-Language-Models-logic-of-thought-injecting-logic-into-contexts-for-full-reasoning-in-large-language-models",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Logic-of-Thought: Injecting Logic into Contexts for Full Reasoning in Large Language Models",
      "title": "Logic-of-Thought: Injecting Logic into Contexts for Full Reasoning in Large Language Models",
      "url": "https://arxiv.org/abs/2409.17539",
      "bullets": [
        {
          "text": "생성된 logical information을 augmented input으로 붙여서 모델에게 전달",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Stanford-instruction-following-without-instruction-tuning",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Stanford",
      "title": "Instruction Following without Instruction Tuning",
      "url": "https://arxiv.org/abs/2409.14254",
      "bullets": [
        {
          "text": "(1) 상응하는 instruction 없이, 오직 response만 학습하더라도 instruction following 가능",
          "level": 0
        },
        {
          "text": "(2) 이때 response의 desired distribution으로 학습할 필요는 없음",
          "level": 0
        },
        {
          "text": "일반적인 instruction tuning 대비 갖는 장점이 무엇인지 모르겠음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "NVIDIA,-Singapore-maskllm-learnable-semi-structured-sparsity-for-large-language-models",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "NVIDIA, Singapore",
      "title": "MaskLLM: Learnable Semi-Structured Sparsity for Large Language Models",
      "url": "https://arxiv.org/abs/2409.17481",
      "bullets": [
        {
          "text": "(1) High-quality Masks (2) Transferability: from 843M to 15B 사이즈 모델까지 working",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/NVlabs/MaskLLM) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "CMU,-Amazon-synatra-turning-indirect-knowledge-into-direct-demonstrations-for-digital-agents-at-scale",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "CMU, Amazon",
      "title": "Synatra: Turning Indirect Knowledge into Direct Demonstrations for Digital Agents at Scale",
      "url": "https://arxiv.org/abs/2409.15637",
      "bullets": [
        {
          "text": "100k 개의 synthetically-created demonstrations 데이터로 7B CodeLlama를 학습",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "CMU,-AI2,-Washington,-Stanford-haicosystem-an-ecosystem-for-sandboxing-safety-risks-in-human-ai-interactions",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "CMU, AI2, Washington, Stanford",
      "title": "HAICOSYSTEM: An Ecosystem for Sandboxing Safety Risks in Human-AI Interactions",
      "url": "https://arxiv.org/abs/2409.16427",
      "bullets": [
        {
          "text": "현실적인 user-AI interaction과 AI agents의 복잡한 tool use 능력을 평가할 수 있다고 주장",
          "level": 0
        },
        {
          "text": "한 줄 요약하면 AI agents를 평가하기 위한 좋은 프레임워크를 만들어서 공개했음",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "PyTorch-pytorch-native-architecture-optimization-torchao",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "dev",
      "org": "PyTorch",
      "title": "PyTorch Native Architecture Optimization: torchao",
      "url": "https://pytorch.org/blog/pytorch-native-architecture-optimization/",
      "bullets": [
        {
          "text": "학습 및 추론에 둘 다 활용할 수 있도록 간단한 예시를 제공",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-retrieval-augmented-generation-rag-and-beyond-a-comprehensive-survey-on-how-to-make-your-llms-use-external-data-more-wisely",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Microsoft",
      "title": "Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey on How to Make your LLMs use External Data More Wisely",
      "url": "https://arxiv.org/abs/2409.14924",
      "bullets": [
        {
          "text": "(1) Explicit Facts (2) Implicit Facts (3) Interpretable Rationales (4) Hidden Rationales",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Cambridge-small-language-models-survey-measurements-and-insights",
      "date": "2024-09-W04",
      "year": "2024",
      "month": "9",
      "week": "4",
      "type": "paper",
      "org": "Cambridge",
      "title": "Small Language Models: Survey, Measurements, and Insights",
      "url": "https://arxiv.org/abs/2409.15790",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-smaller-safer-more-transparent-advancing-responsible-ai-with-gemma",
      "date": "2024-08-W01",
      "year": "2024",
      "month": "8",
      "week": "1",
      "type": "dev",
      "org": "Google",
      "title": "Smaller, Safer, More Transparent: Advancing Responsible AI with Gemma",
      "url": "https://developers.googleblog.com/en/smaller-safer-more-transparent-advancing-responsible-ai-with-gemma/",
      "bullets": [
        {
          "text": "[Gemma 2 허깅페이스 링크](https://huggingface.co/collections/google/gemma-2-2b-release-66a20f3796a2ff2a7c76f98f) 🔗",
          "level": 0
        },
        {
          "text": "언어 모델의 생성 결과를 필터링 해주는 ShieldGemma를 공개. SoTA급 성능.",
          "level": 0
        },
        {
          "text": "모델의 내부 동작 과정을 살펴볼 수 있는 툴 Gemma scope 🔭 공개.",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "PyTorch-introducing-torchchat-accelerating-local-llm-inference-on-laptop-desktop-and-mobile",
      "date": "2024-08-W01",
      "year": "2024",
      "month": "8",
      "week": "1",
      "type": "dev",
      "org": "PyTorch",
      "title": "Introducing torchchat: Accelerating Local LLM Inference on Laptop, Desktop and Mobile",
      "url": "https://pytorch.org/blog/torchchat-local-llm-inference/",
      "bullets": [
        {
          "text": "[torchchat GitHub 링크](https://github.com/pytorch/torchchat) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "DeepLearning.AI-embedding-models-from-architecture-to-implementation",
      "date": "2024-08-W01",
      "year": "2024",
      "month": "8",
      "week": "1",
      "type": "dev",
      "org": "DeepLearning.AI",
      "title": "Embedding Models: From Architecture to Implementation",
      "url": "https://www.deeplearning.ai/short-courses/embedding-models-from-architecture-to-implementation/",
      "bullets": [
        {
          "text": "Word2Vec과 BERT와 같은 모델을 다양한 semantic search에 어떻게 활용하는지 학습",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-shieldgemma-generative-ai-content-moderation-based-on-gemma",
      "date": "2024-08-W01",
      "year": "2024",
      "month": "8",
      "week": "1",
      "type": "paper",
      "org": "Google",
      "title": "ShieldGemma: Generative AI Content Moderation Based on Gemma",
      "url": "",
      "bullets": [
        {
          "text": "Gemma2-2B 모델과 함께 공개한 LLM safety 관련 모델 (2B/9B/27B)",
          "level": 0
        },
        {
          "text": "user input & LLM-generated output 둘 다에 대해 뛰어난 safety 능력을 보여줌 (llama guard 이상)",
          "level": 0
        },
        {
          "text": "llm 기반의 새로운 data curation 파이프라인을 제안",
          "level": 0
        },
        {
          "text": "[허깅페이스 링크](https://huggingface.co/collections/google/shieldgemma-release-66a20efe3c10ef2bd5808c79) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Tsinghua-improving-text-embeddings-for-smaller-language-models-using-contrastive-fine-tuning",
      "date": "2024-08-W01",
      "year": "2024",
      "month": "8",
      "week": "1",
      "type": "paper",
      "org": "Tsinghua",
      "title": "Improving Text Embeddings for Smaller Language Models Using Contrastive Fine-tuning",
      "url": "https://arxiv.org/abs/2408.00690",
      "bullets": [
        {
          "text": "NLI 데이터셋에 대해 MiniCPM, Phi-2, Gemma 모델을 contrastive fine-tuning",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Stability.AI-introducing-stable-fast-3d-rapid-3d-asset-generation-from-single-images",
      "date": "2024-08-W01",
      "year": "2024",
      "month": "8",
      "week": "1",
      "type": "dev",
      "org": "Stability.AI",
      "title": "Introducing Stable Fast 3D: Rapid 3D Asset Generation From Single Images",
      "url": "https://stability.ai/news/introducing-stable-fast-3d",
      "bullets": [
        {
          "text": "게임, 가상현실 개발자들을 위한 어플리케이셔늘 포함",
          "level": 0
        },
        {
          "text": "[허깅페이스 링크](https://huggingface.co/stabilityai/stable-fast-3d) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Figure-figure-02",
      "date": "2024-08-W01",
      "year": "2024",
      "month": "8",
      "week": "1",
      "type": "news",
      "org": "Figure",
      "title": "Figure 02",
      "url": "https://x.com/Figure_robot/status/1819388819638309286",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Tsinghua-rageval-scenario-specific-rag-evaluation-dataset-generation-framework",
      "date": "2024-08-W01",
      "year": "2024",
      "month": "8",
      "week": "1",
      "type": "paper",
      "org": "Tsinghua",
      "title": "RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework",
      "url": "https://arxiv.org/abs/2408.01262",
      "bullets": [
        {
          "text": "→ LLM의 knowledge 활용 능력을 평가하기 위해 평가용 데이터셋을 자동적으로 생성하는 프레임워크 RAGEval을 제시",
          "level": 0
        },
        {
          "text": "Completeness, Hallucination, Irrelevance 세 개의 metric을 사용",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Sheffiled,-Liverpool-adaptive-retrieval-augmented-generation-for-conversational-systems",
      "date": "2024-08-W02",
      "year": "2024",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "Sheffiled, Liverpool",
      "title": "Adaptive Retrieval-Augmented Generation for Conversational Systems",
      "url": "https://arxiv.org/abs/2407.21712",
      "bullets": [
        {
          "text": "발화할 때 과거의 내용을 돌아보게 만들어야하지 않을까 생각했던 것과 유사한 접근이라고 느껴짐",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Sapienza-NLP-Group-relik-retrieve-and-link-fast-and-accurate-entity-linking-and-relation-extraction-on-an-academic-budget",
      "date": "2024-08-W02",
      "year": "2024",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "Sapienza NLP Group",
      "title": "ReLiK: Retrieve and LinK, Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget",
      "url": "https://arxiv.org/abs/2408.00103",
      "bullets": [
        {
          "text": "Retriever 모듈은 entity, relation 후보를 탐색 → Reader 모듈은 실제 관계를 파악",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Meta-self-taught-evaluators",
      "date": "2024-08-W02",
      "year": "2024",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "Meta",
      "title": "Self-Taught Evaluators",
      "url": "https://arxiv.org/abs/2408.02666",
      "bullets": [
        {
          "text": "unlabeled instruction → contrasting model outputs → reasoning traces & final judgements",
          "level": 0
        },
        {
          "text": "최근 가장 주목을 받은 논문이 합성 데이터로 인한 모델 붕괴인데.. 아이러니하다.",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "ByteDance-language-model-can-listen-while-speaking",
      "date": "2024-08-W02",
      "year": "2024",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "ByteDance",
      "title": "Language Model Can Listen While Speaking",
      "url": "https://arxiv.org/abs/2408.02622",
      "bullets": [
        {
          "text": "listening-while-speaking language model (LSLM) 이라는 모델 디자인을 공개",
          "level": 0
        },
        {
          "text": "early fusion, middle fusion, late fusion 셋 중에서 middel fusion의 balance가 가장 훌륭",
          "level": 0
        },
        {
          "text": "OpenAI에서 공개했던 자연스러운 실시간 대화와 관련된 연구로 보임",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "LG-AI-Research-exaone-30-78b-instruction-tuned-language-model",
      "date": "2024-08-W02",
      "year": "2024",
      "month": "8",
      "week": "2",
      "type": "dev",
      "org": "LG AI Research",
      "title": "EXAONE 3.0 7.8B Instruction Tuned Language Model",
      "url": "",
      "bullets": [
        {
          "text": "[technical report](https://www.lgresearch.ai/data/upload/tech_report/en/EXAONE_3.0_Technical_Report.pdf) 링크 🔗",
          "level": 0
        },
        {
          "text": "영어와 한국어로 학습된 bilingual generative model",
          "level": 0
        },
        {
          "text": "8T curated tokens pre-trained & SFT & DPO",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "NVIDIA-advancing-humanoid-robot-development",
      "date": "2024-08-W02",
      "year": "2024",
      "month": "8",
      "week": "2",
      "type": "dev",
      "org": "NVIDIA",
      "title": "Advancing Humanoid Robot Development",
      "url": "https://www.youtube.com/watch?v=Bhg3uOx9ZPw",
      "bullets": [
        {
          "text": "사용자의 움직임을 비전프로로 인식하고 로봇이 이를 실시간으로 모방하는 형태",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-introducing-structured-outputs-in-the-api",
      "date": "2024-08-W02",
      "year": "2024",
      "month": "8",
      "week": "2",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing Structured Outputs in the API",
      "url": "https://openai.com/index/introducing-structured-outputs-in-the-api/",
      "bullets": [
        {
          "text": "`“strict”: true` 로 설정 시 100% 확률로 structured output 반환",
          "level": 0
        },
        {
          "text": "function calling 또는 response_format 파라미터로 기능 지원",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenGVLab,-Tsinghua-mmiu-multimodal-multi-image-understanding-for-evaluating-large-vision-language-models",
      "date": "2024-08-W02",
      "year": "2024",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "OpenGVLab, Tsinghua",
      "title": "MMIU: Multimodal Multi-image Understanding for Evaluating Large Vision-Language Models",
      "url": "https://arxiv.org/abs/2408.02718",
      "bullets": [
        {
          "text": "7개 종류의 multi-image 관계, 52개 태스크, 77K 이미지, 11K multiple-choice questions로 구성",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "DeepLearning.AI-ai-python-for-beginners",
      "date": "2024-08-W02",
      "year": "2024",
      "month": "8",
      "week": "2",
      "type": "dev",
      "org": "DeepLearning.AI",
      "title": "AI Python for Beginners",
      "url": "https://www.deeplearning.ai/short-courses/ai-python-for-beginners/",
      "bullets": [
        {
          "text": "비지니스, 마케팅과 같은 실제 산업 분야에 파이썬을 활용하는 방법 안내",
          "level": 0
        },
        {
          "text": "AI 어시스턴트를 이용한 코드 디버깅, 개념 설명 등을 시도",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-DeepMind-achieving-human-level-competitive-robot-table-tennis",
      "date": "2024-08-W02",
      "year": "2024",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Achieving Human Level Competitive Robot Table Tennis",
      "url": "https://arxiv.org/abs/2408.03906",
      "bullets": [
        {
          "text": "탁구 칠 수 있는 로봇을 개발했는데 특징은 다음과 같음 (아마추어 수준으로 판단)",
          "level": 0
        },
        {
          "text": "hierarchical and modular policy architecture",
          "level": 1
        },
        {
          "text": "zero-shot sim-to-real을 가능하게 만드는 기술",
          "level": 1
        },
        {
          "text": "unseen opponents에 대한 real time adapation (wow)",
          "level": 1
        },
        {
          "text": "[데모 영상](https://accounts.google.com/v3/signin/confirmidentifier?authuser=2&continue=https%3A%2F%2Fdocs.google.com%2Fforms%2Fu%2F2%2Fd%2Fe%2F1FAIpQLSeHyoLH65fkRtcskOw1tyQH26m3oSrIzVYB7I_SXtejunl5EQ%2Fviewform%3Fusp%3Dsend_form&followup=https%3A%2F%2Fdocs.google.com%2Fforms%2Fu%2F2%2Fd%2Fe%2F1FAIpQLSeHyoLH65fkRtcskOw1tyQH26m3oSrIzVYB7I_SXtejunl5EQ%2Fviewform%3Fusp%3Dsend_form&ifkv=AdF4I74-85ab20MJwFQtGLxCCSJFfb8P3UEomYdCPMJa5g830SjZqgqBIo2ypFBQmIR_MGNycbB-cw&ltmpl=forms&osid=1&passive=1209600&service=wise&flowName=GlifWebSignIn&flowEntry=ServiceLogin&dsh=S826118426%3A1723163958486536&ddm=0) 링크 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFaceM4-idefics3-8b-llama3",
      "date": "2024-08-W02",
      "year": "2024",
      "month": "8",
      "week": "2",
      "type": "dev",
      "org": "HuggingFaceM4",
      "title": "Idefics3-8B-Llama3",
      "url": "https://huggingface.co/HuggingFaceM4/Idefics3-8B-Llama3",
      "bullets": [
        {
          "text": "[google/siglip-so400m-patch14-384](https://huggingface.co/google/siglip-so400m-patch14-384) & [meta-llama/Meta-Llama-3.1-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct)",
          "level": 0
        },
        {
          "text": "[v1 paper](https://huggingface.co/papers/2306.16527) 링크 🔗 & [v2 paper](https://huggingface.co/papers/2405.02246) 링크 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "NVIDIA-build-a-digital-human",
      "date": "2024-08-W02",
      "year": "2024",
      "month": "8",
      "week": "2",
      "type": "dev",
      "org": "NVIDIA",
      "title": "Build a Digital Human",
      "url": "https://build.nvidia.com/nvidia/digital-humans-virtual-assistant",
      "bullets": [
        {
          "text": "웹 사이트에서 음성을 통해 실시간 interaction 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Jilin-University-bias-aware-low-rank-adaptation-mitigating-catastrophic-inheritance-of-large-language-models",
      "date": "2024-08-W02",
      "year": "2024",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "Jilin University",
      "title": "Bias-Aware Low-Rank Adaptation: Mitigating Catastrophic Inheritance of Large Language Models",
      "url": "https://arxiv.org/abs/2408.04556",
      "bullets": [
        {
          "text": "→ 세 개의 regularization terms: (1) consistency regularizer (2) diversity regularizer (3) singular vector decomposition regularizer",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/cyp-jlu-ai/BA-LoRA) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Appier-AI-Research-let-me-speak-freely-a-study-on-the-impact-of-format-restrictions-on-performance-of-large-language-models",
      "date": "2024-08-W02",
      "year": "2024",
      "month": "8",
      "week": "2",
      "type": "paper",
      "org": "Appier AI Research",
      "title": "Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance of Large Language Models",
      "url": "https://arxiv.org/abs/2408.02442",
      "bullets": [
        {
          "text": "특정 포맷을 강제할수록, 그리고 포맷이 엄격할수록 모델의 추론 능력이 하락하는 경향성을 관측",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-DeepMind-gemma-scope-open-sparse-autoencoders-everywhere-all-at-once-on-gemma-2",
      "date": "2024-08-W03",
      "year": "2024",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2",
      "url": "https://arxiv.org/abs/2408.05147",
      "bullets": [
        {
          "text": "Gemma 2 2B의 전체 layer, 9B의 일부 layer에서 학습, 27B에서 선택된 JumpReLU SAEs를 공개 → 비교를 위해 instruction-tuned version을 함께 공개",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Liverpool-order-matters-in-hallucination-reasoning-order-as-benchmark-and-reflexive-prompting-for-large-language-models",
      "date": "2024-08-W03",
      "year": "2024",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "Liverpool",
      "title": "Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models",
      "url": "https://arxiv.org/abs/2408.05093",
      "bullets": [
        {
          "text": "→ LLM consistency를 평가하기 위한 새로운 벤치마크 제안, 직관적인 프롬프트 전략 제안",
          "level": 0
        },
        {
          "text": "Andrej Karpathy가 언급한 [Jagged Intelligence](https://x.com/karpathy/status/1816531576228053133)와 관련된 문제로 볼 수 있음",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Sakana-AI-the-ai-scientist-towards-fully-automated-open-ended-scientific-discovery",
      "date": "2024-08-W03",
      "year": "2024",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "Sakana AI",
      "title": "The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery",
      "url": "https://arxiv.org/abs/2408.06292",
      "bullets": [
        {
          "text": "open-ended 방식으로 아이디어 발전 과정을 반복하며 knowledge archive를 키워 나감",
          "level": 0
        },
        {
          "text": "diffusion modeling, transformer-based language modeling, learning dynamics, 세 분야에서 실험하는 동안 15$ 이하의 비용이 발생",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/SakanaAI/AI-Scientist) 🔗",
          "level": 0
        },
        {
          "text": "반드시 확인해봐야 할 내용인 것 같음. 현재 엄청난 주목을 받고 있는 논문.",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Microsoft,-Harvard-mutual-reasoning-makes-smaller-llms-stronger-problem-solvers",
      "date": "2024-08-W03",
      "year": "2024",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "Microsoft, Harvard",
      "title": "Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers",
      "url": "https://arxiv.org/abs/2408.06195",
      "bullets": [
        {
          "text": "1. target SLM이 Monte Carlo Tree Search (CMTS)를 human-like reasoning actions로 증강",
          "level": 0
        },
        {
          "text": "2. another SLM이 target SLM이 만들어내는 trajectory를 discriminate",
          "level": 0
        },
        {
          "text": "→ 양측 동의를 받은 것들은 mutual consistent로 구분",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Anthropic-prompt-caching-with-claude",
      "date": "2024-08-W03",
      "year": "2024",
      "month": "8",
      "week": "3",
      "type": "dev",
      "org": "Anthropic",
      "title": "Prompt caching with Claude",
      "url": "https://www.anthropic.com/news/prompt-caching",
      "bullets": [
        {
          "text": "배경 지식, 예시 등을 설명하는데 사용되었던 컨텍스트가 캐싱됨으로써 비용을 90%까지 줄이고 latency도 85%까지 감소할 수 있음.",
          "level": 0
        },
        {
          "text": "현재 public beta로 Claude 3.5 Sonnet & Haiku 에서 사용 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "xAI-grok-2-beta-release",
      "date": "2024-08-W03",
      "year": "2024",
      "month": "8",
      "week": "3",
      "type": "dev",
      "org": "xAI",
      "title": "Grok-2 Beta Release",
      "url": "https://x.ai/blog/grok-2",
      "bullets": [
        {
          "text": "(xAI피셜..) Claude 3.5 Sonnet & GPT-4-Turbo 이상의 성능",
          "level": 0
        },
        {
          "text": "Grok-2 & Grok-2 mini 를 X로 선공개. 추후 Grok에서 API 지원",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "ACL-2024-Best-Paper-Award-cohere-aya-model-an-instruction-finetuned-open-access-multilingual-language-modelhttpsarxivorgabs240207827",
      "date": "2024-08-W03",
      "year": "2024",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "ACL 2024 Best Paper Award",
      "title": "- [Cohere] [Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model](https://arxiv.org/abs/2402.07827)",
      "url": "",
      "bullets": [
        {
          "text": "101개 언어를 지원하는 multilingual generative language model",
          "level": 1
        },
        {
          "text": "instruction datasets을 [링크](https://hf.co/CohereForAI/aya-101)에 공개",
          "level": 1
        },
        {
          "text": "[Cambridge, ETH] [Causal Estimation of Memorisation Profiles](https://arxiv.org/abs/2406.04327)",
          "level": 0
        },
        {
          "text": "memorisation: 학습했던 instance를 예측할 수 있는 causal effect",
          "level": 1
        },
        {
          "text": "이를 difference-in-differences 방식을 이용하여 효율적으로 측정",
          "level": 1
        },
        {
          "text": "(1) 큰 모델일수록 memorisation이 강하게 발생 (2) 데이터 순서와 학습률의 영향 (3) 모델 사이즈에 따른 일반적 경향 (예측 가능)",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-gemini-live",
      "date": "2024-08-W03",
      "year": "2024",
      "month": "8",
      "week": "3",
      "type": "dev",
      "org": "Google",
      "title": "Gemini Live",
      "url": "https://x.com/Google/status/1823409511471690064",
      "bullets": [
        {
          "text": "Gemini Advanced 구독자 대상",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Qwen-introducing-qwen2-math",
      "date": "2024-08-W03",
      "year": "2024",
      "month": "8",
      "week": "3",
      "type": "dev",
      "org": "Qwen",
      "title": "Introducing Qwen2-Math",
      "url": "https://qwenlm.github.io/blog/qwen2-math/",
      "bullets": [
        {
          "text": "closed-source models (gpt-4o) 보다도 뛰어난 수학적, 추론 능력을 지녔다고 주장",
          "level": 0
        },
        {
          "text": "[깃허브](https://github.com/QwenLM/Qwen2-Math) 링크 🔗 [허깅페이스](https://huggingface.co/Qwen) 링크 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-DeepMind-scaling-llm-test-time-compute-optimally-can-be-more-effective-than-scaling-model-parameters",
      "date": "2024-08-W03",
      "year": "2024",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters",
      "url": "https://arxiv.org/abs/2408.03314",
      "bullets": [
        {
          "text": "(1) dense, process-based verifier reward models에 대한 searching",
          "level": 0
        },
        {
          "text": "(2) 추론 시 프롬프트가 주어지면 response에 대해 adaptive 하게 모델 분포를 업데이트",
          "level": 0
        },
        {
          "text": "→ ‘사전학습 vs 추론’ 시간의 trade-off에 관한 연구: 작은 모델들도 뛰어난 성능 달성",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "DeepLearning.AI-improving-accuracy-of-llm-applications",
      "date": "2024-08-W03",
      "year": "2024",
      "month": "8",
      "week": "3",
      "type": "dev",
      "org": "DeepLearning.AI",
      "title": "Improving accuracy of LLM applications",
      "url": "https://www.deeplearning.ai/short-courses/improving-accuracy-of-llm-applications/",
      "bullets": [
        {
          "text": "Llama 3-8b 모델을 학습하여 text-to-SQL 어플리케이션을 개발",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Oxford-fine-tuning-large-language-models-with-human-inspired-learning-strategies-in-medical-question-answering",
      "date": "2024-08-W03",
      "year": "2024",
      "month": "8",
      "week": "3",
      "type": "paper",
      "org": "Oxford",
      "title": "Fine-tuning Large Language Models with Human-inspired Learning Strategies in Medical Question Answering",
      "url": "https://arxiv.org/abs/2408.07888",
      "bullets": [
        {
          "text": "curriculum learning의 난이도를 사람이 정하는 것보다 모델이 정하는 것이 더 효율적이었다는 결과",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "MetaGPT:-The-Multi-Agent-Framework-metagpt-the-multi-agent-framework",
      "date": "2024-08-W03",
      "year": "2024",
      "month": "8",
      "week": "3",
      "type": "dev",
      "org": "MetaGPT: The Multi-Agent Framework",
      "title": "MetaGPT: The Multi-Agent Framework",
      "url": "https://github.com/geekan/MetaGPT",
      "bullets": [
        {
          "text": "아주 간단하게 소프트웨어 제작 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "NVIDIA-how-to-prune-and-distill-llama-31-8b-to-an-nvidia-llama-31-minitron-4b-model",
      "date": "2024-08-W03",
      "year": "2024",
      "month": "8",
      "week": "3",
      "type": "dev",
      "org": "NVIDIA",
      "title": "How to Prune and Distill Llama-3.1 8B to an NVIDIA Llama-3.1-Minitron 4B Model",
      "url": "https://developer.nvidia.com/blog/how-to-prune-and-distill-llama-3-1-8b-to-an-nvidia-llama-3-1-minitron-4b-model/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "TII-welcome-falconmamba-the-first-strong-attention-free-7b-model",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "dev",
      "org": "TII",
      "title": "Welcome FalconMamba: The first strong attention-free 7B model",
      "url": "https://huggingface.co/blog/falconmamba",
      "bullets": [
        {
          "text": "최적화 벤치마크에서는 더욱 뛰어난 성능",
          "level": 0
        },
        {
          "text": "base/instruct 버전의 모델을 각각 공개 + 4-bit 버전도 공개 ([허깅페이스 링크](https://huggingface.co/tiiuae) 🔗)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-DeepMind-towards-flexible-perception-with-visual-memory",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Towards flexible perception with visual memory",
      "url": "https://arxiv.org/abs/2408.08172",
      "bullets": [
        {
          "text": "→ (1) 데이터의 사이즈에 관계 없이 이를 자유롭게 추가할 수 있는 능력 (2) unlearning & pruning을 통해 데이터를 삭제할 수 있는 능력 (3) 해석 가능한 의사 결정 메커니즘",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "I-SHEEP:-Self-Alignment-of-LLM-from-Scratch-through-an-Iterative-Self-Enhancement-Paradigm-i-sheep-self-alignment-of-llm-from-scratch-through-an-iterative-self-enhancement-paradigm",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm",
      "title": "I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm",
      "url": "https://arxiv.org/abs/2408.08072",
      "bullets": [
        {
          "text": "→ from scratch에서 계속해서 self-align 하는 학습 방식을 제안",
          "level": 0
        },
        {
          "text": "Qwen & Llama 모델의 성능을 크게 개선할 수 있었다고 주장",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "DeepSeek-deepseek-prover-v15-harnessing-proof-assistant-feedback-for-reinforcement-learning-and-monte-carlo-tree-search",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "DeepSeek",
      "title": "DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search",
      "url": "https://arxiv.org/abs/2408.08152",
      "bullets": [
        {
          "text": "DeepSeek-Prover-V1 모델의 학습 & 추론 과정을 최적화한 DeepSeek-Prover-V1.5 모델 공개",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/deepseek-ai/DeepSeek-Prover-V1.5) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Salesforce-AI,-Univ-of-Washington-xgen-mm-blip-3-a-family-of-open-large-multimodal-models",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "Salesforce AI, Univ of Washington",
      "title": "xGen-MM (BLIP-3): A Family of Open Large Multimodal Models",
      "url": "https://arxiv.org/abs/2408.08872",
      "bullets": [
        {
          "text": "엄선된 학습 데이터셋, 학습 레시피, 모델 아키텍쳐, 학습 결과 등을 오픈소스로 공개",
          "level": 0
        },
        {
          "text": "DPO를 이용하여 safety tuning을 적용",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Meta-imagine-yourself-tuning-free-personalized-image-generation",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "Meta",
      "title": "Imagine yourself: Tuning-Free Personalized Image Generation",
      "url": "https://ai.meta.com/research/publications/imagine-yourself-tuning-free-personalized-image-generation/",
      "bullets": [
        {
          "text": "→ 1) 이미지 다양성을 높이기 위한 synthetic paired data 생성 메커니즘, 2) 완전히 병렬적인 세 개의 text encoder와 학습 가능한 visual encoder, 3) visual quality를 점진적으로 향상시키는 coarse-to-fine multi-stage finetuning",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Vanderbit-University-reasoning-beyond-bias-a-study-on-counterfactual-prompting-and-chain-of-thought-reasoning",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "Vanderbit University",
      "title": "Reasoning Beyond Bias: A Study on Counterfactual Prompting and Chain of Thought Reasoning",
      "url": "https://arxiv.org/abs/2408.08651",
      "bullets": [
        {
          "text": "→ 이를 해결하기 위해 Counterfactual CoT & Agnostically Primed CoT 를 제안",
          "level": 0
        },
        {
          "text": "bias를 줄이는 데 전자로만은 불충분할 수 있긴 하나, 특정 상황에서는 충분",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Lambda-unveiling-hermes-3-the-first-full-parameter-fine-tuned-llama-31-405b-model-is-on-lambdas-cloud",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "dev",
      "org": "Lambda",
      "title": "Unveiling Hermes 3: The First Full-Parameter Fine-Tuned Llama 3.1 405B Model is on Lambda’s Cloud",
      "url": "https://lambdalabs.com/blog/unveiling-hermes-3-the-first-fine-tuned-llama-3.1-405b-model-is-on-lambdas-cloud",
      "bullets": [
        {
          "text": "[Lambda Chat Completions API](http://api.lambdalabs.com/docs)와 [Lambda Chat](https://lambda.chat/)에서 사용 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-Research-transformers-in-music-recommendation",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "Google Research",
      "title": "Transformers in music recommendation",
      "url": "https://research.google/blog/transformers-in-music-recommendation/",
      "bullets": [
        {
          "text": "Intention of action, Salience metrics, Metadata, Music track identifiers",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Luma-AI-dream-machine-15",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "dev",
      "org": "Luma AI",
      "title": "Dream Machine 1.5",
      "url": "https://lumalabs.ai/dream-machine",
      "bullets": [
        {
          "text": "prompts에 대한 이해, 커스텀 text rendering, image-to-video 성능 등을 개선",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Microsoft-microsoft-releases-phi-35-mixture-of-experts-moe",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "dev",
      "org": "Microsoft",
      "title": "Microsoft releases Phi-3.5-mixture-of-experts (MoE)",
      "url": "https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3",
      "bullets": [
        {
          "text": "4.9T 토큰 학습, 그중 10%는 multilingual content, 128k 토큰 길이 지원",
          "level": 0
        },
        {
          "text": "SFT, PPO, DPO 등 학습 과정을 거침",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Fine-tuning-now-available-for-GPT-4o-fine-tuning-now-available-for-gpt-4o",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "unknown",
      "org": "Fine-tuning now available for GPT-4o",
      "title": "Fine-tuning now available for GPT-4o",
      "url": "https://openai.com/index/gpt-4o-fine-tuning/",
      "bullets": [
        {
          "text": "[fine-tuning dashboard](https://platform.openai.com/finetune) 에서 사용할 수 있음",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Waterloo,-Fudan-tablebench-a-comprehensive-and-complex-benchmark-for-table-question-answering",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "Waterloo, Fudan",
      "title": "TableBench: A Comprehensive and Complex Benchmark for Table Question Answering",
      "url": "https://arxiv.org/abs/2408.09174",
      "bullets": [
        {
          "text": "industrial scenarios를 반영한 벤치마크, TableBench를 제안",
          "level": 0
        },
        {
          "text": "GPT-3.5 수준의 성능을 내는 TabelLLM을 소개 (TableInstruct 데이터셋으로 학습)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Ideogram-introducing-ideogram-20",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "dev",
      "org": "Ideogram",
      "title": "Introducing Ideogram 2.0",
      "url": "https://x.com/ideogram_ai/status/1826277550798278804",
      "bullets": [
        {
          "text": "Flux, Midjourney에 도전..! Color Palette Selection, Enhanced Text Rendering, Search Functionality, Improved Image Coherence 가 특징",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "NVIDIA-llm-pruning-and-distillation-in-practice-the-minitron-approach",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "NVIDIA",
      "title": "LLM Pruning and Distillation in Practice: The Minitron Approach",
      "url": "https://arxiv.org/abs/2408.11796",
      "bullets": [
        {
          "text": "depth pruning & joint hidden/attention/MLP (width) pruning 에 대해 탐구",
          "level": 0
        },
        {
          "text": "기존 데이터를 모르는 상황에서 teacher 모델을 distillation dataset에 학습하는 방식이 유익할 수 있다고 주장",
          "level": 0
        },
        {
          "text": "허깅 페이스에 공개: [Mistral-NeMo-Minitron-8B-Base](https://huggingface.co/nvidia/Mistral-NeMo-Minitron-8B-Base) | [Llama-3.1-Minitron-4B-Width-Base](https://huggingface.co/nvidia/Llama-3.1-Minitron-4B-Width-Base) | [Llama-3.1-Minitron-4B-Depth-Base](https://huggingface.co/nvidia/Llama-3.1-Minitron-4B-Depth-Base)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Adobe-Research-magicfixup",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "dev",
      "org": "Adobe Research",
      "title": "MagicFixup",
      "url": "https://github.com/adobe-research/MagicFixup?tab=readme-ov-file#gradio-demo",
      "bullets": [
        {
          "text": "기존에는 이런 모델을 학습하기 위해 이미지를 사용하는데, 여기서는 비디오를 사용",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Meta-sapiens-foundation-for-human-vision-models",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "dev",
      "org": "Meta",
      "title": "Sapiens: Foundation for Human Vision Models",
      "url": "https://about.meta.com/realitylabs/codecavatars/sapiens?_bhlid=9ff3b20994dca7d88de03063c5de34f1da2853ed",
      "bullets": [
        {
          "text": "위 네 개의 핵심 vision tasks를 지원하는 모델 패밀리 Sapiens를 공개",
          "level": 0
        },
        {
          "text": "[아카이브 링크](https://about.meta.com/realitylabs/codecavatars/sapiens?_bhlid=9ff3b20994dca7d88de03063c5de34f1da2853ed) 🔗 [깃허브 링크](https://github.com/facebookresearch/sapiens) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Singapore-llms-are-not-zero-shot-reasoners-for-biomedical-information-extraction",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "Singapore",
      "title": "LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction",
      "url": "https://arxiv.org/abs/2408.12249",
      "bullets": [
        {
          "text": "Medical Classification & NER 벤치마크 점수 비교: BioMistral & Llama-2",
          "level": 0
        },
        {
          "text": "standard prompting, CoT, Self-Consistency, RAG 등을 비교 → standard best",
          "level": 0
        },
        {
          "text": "knowledge, reasoning 향상을 위한 여러 prompt 테크닉이 biomedical tasks에 쉽게 적용 불가능하다는 것을 시사하는 실험 결과",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "AI21-labs-the-jamba-15-open-model-family-the-most-powerful-and-efficient-long-context-models",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "dev",
      "org": "AI21 labs",
      "title": "The Jamba 1.5 Open Model Family: The Most Powerful and Efficient Long Context Models",
      "url": "https://www.ai21.com/blog/announcing-jamba-model-family",
      "bullets": [
        {
          "text": "비슷한 사이즈의 모델 중에서 Mixtral 8x22B, Command-R+ 보다 뛰어난 성능 (Mini)",
          "level": 0
        },
        {
          "text": "256K context window 사이즈를 가지며 추론 속도도 빠른 것이 특징",
          "level": 0
        },
        {
          "text": "[허깅페이스 링크](https://huggingface.co/collections/ai21labs/jamba-15-66c44befa474a917fcf55251) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-speculative-rag-enhancing-retrieval-augmented-generation-through-drafting",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "paper",
      "org": "Google",
      "title": "Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting",
      "url": "https://arxiv.org/abs/2407.08223",
      "bullets": [
        {
          "text": "각 draft는 retrieved documents의 subset으로 생성 → draft당 input token count는 줄이면서 다양한 관점을 제공할 수 있다는 장점",
          "level": 0
        },
        {
          "text": "각 subset에 대한 이해도를 높이고 긴 context에 대한 position bias를 줄일 수 있음",
          "level": 0
        },
        {
          "text": "[Google Research 블로그 포스팅 링크](https://research.google/blog/speculative-rag-enhancing-retrieval-augmented-generation-through-drafting/) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Anthropic-anthropic-added-support-latex-rendering-in-claude-web-interface",
      "date": "2024-08-W04",
      "year": "2024",
      "month": "8",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "Anthropic added support Latex rendering in Claude Web interface",
      "url": "https://x.com/AnthropicAI/status/1826667671364272301",
      "bullets": [],
      "tags": []
    },
    {
      "id": "The-Fin-AI-open-finllms-open-multimodal-large-language-models-for-financial-applications",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "paper",
      "org": "The Fin AI",
      "title": "Open-FinLLMs: Open Multimodal Large Language Models for Financial\n  Applications",
      "url": "https://arxiv.org/abs/2408.11878",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Singapore-language-modeling-on-tabular-data-a-survey-of-foundations-techniques-and-evolution",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "paper",
      "org": "Singapore",
      "title": "Language Modeling on Tabular Data: A Survey of Foundations, Techniques and Evolution",
      "url": "https://arxiv.org/abs/2408.10548",
      "bullets": [
        {
          "text": "(2) 모델 학습과 평가를 위한 핵심 데이터셋에 대한 리뷰",
          "level": 0
        },
        {
          "text": "(3) data processing methods, popular architectures 등 모델링 테크닉 요약",
          "level": 0
        },
        {
          "text": "외에도 잠재적인 어려움이나 미래 발전 방향에 대해 논한 survery 페이퍼",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "British-Columbia-automated-design-of-agentic-systems",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "paper",
      "org": "British Columbia",
      "title": "Automated Design of Agentic Systems",
      "url": "https://arxiv.org/abs/2408.08435",
      "bullets": [
        {
          "text": "Meta Agent Search: 이전의 발견들을 쌓아두어 점점 커지는 archive를 바탕으로 계속해서 새로운 agent를 프로그래밍 해나갈 수 있다는 아이디어",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/ShengranHu/ADAS) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Kyoto-University-beyond-english-centric-llms-what-language-do-multilingual-language-models-think-in",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "paper",
      "org": "Kyoto University",
      "title": "Beyond English-Centric LLMs: What Language Do Multilingual Language Models Think in?",
      "url": "https://arxiv.org/abs/2408.10811",
      "bullets": [
        {
          "text": "일본어로 continued pretraining 한 Swallow, 영어와 일본어를 균형 있게 학습한 LLM-jp",
          "level": 0
        },
        {
          "text": "→ 영어만이 latent language인 Llama2와 달리, Swallow와 LLM-jp는 영어와 일본어 둘 다 laten language라고 볼 수 있음",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-building-and-better-understanding-vision-language-models-insights-and-future-directions",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "paper",
      "org": "HuggingFace",
      "title": "Building and better understanding vision-language\n  models: insights and future directions",
      "url": "https://arxiv.org/abs/2408.12637",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Priceton-NLP-llama-3-8b-prolong",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "dev",
      "org": "Priceton-NLP",
      "title": "Llama-3-8B-ProLong",
      "url": "https://huggingface.co/collections/princeton-nlp/prolong-66c72d55d2051a86ac7bd7e4",
      "bullets": [
        {
          "text": "Instruct 버전도 존재하며 현재는 64K 버전만 공개되어 있음. 향후 512K 버전도 공개 예정",
          "level": 0
        },
        {
          "text": "1저자가 SimCSE 저자임",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Institute-of-Automation-k-sort-arena-efficient-and-reliable-benchmarking-for-generative-models-via-k-wise-human-preferences",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "paper",
      "org": "Institute of Automation",
      "title": "K-Sort Arena: Efficient and Reliable Benchmarking for Generative Models via K-wise Human Preferences",
      "url": "https://arxiv.org/abs/2408.14468",
      "bullets": [
        {
          "text": "→ 이미지와 비디오는 텍스트에 비해 더 인지적 직관성이 높다는 특징을 이용 (이미지 아레나임)",
          "level": 0
        },
        {
          "text": "K개의 모델이 한 번에 경쟁에 참여 ⇒ ELO 알고리즘 대비 16.3배 빠른 수렴 속도",
          "level": 0
        },
        {
          "text": "[허깅페이스 스페이스 링크](https://huggingface.co/spaces/ksort/K-Sort-Arena) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "University-of-Edinburgh-explicit-inductive-inference-using-large-language-models",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "paper",
      "org": "University of Edinburgh",
      "title": "Explicit Inductive Inference using Large Language Models",
      "url": "https://arxiv.org/abs/2408.14467",
      "bullets": [
        {
          "text": "LLM을 이용하여 premise를 attested alternative 세트로 변경 & 이를 기반으로 hypothesis derive ⇒ 둘을 이용하여 NLI task 성능 향상",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Anthropic-anthropic-publishes-claudes-system-prompts",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "dev",
      "org": "Anthropic",
      "title": "Anthropic publishes Claude’s system prompts",
      "url": "https://x.com/alexalbert__/status/1828107230656471442",
      "bullets": [
        {
          "text": "이는 [Claude.ai](http://Claude.ai) 와 모바일 앱에 영향을 주지만 API와는 무관함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Nous-Research-distro",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "dev",
      "org": "Nous Research",
      "title": "DisTro",
      "url": "https://github.com/NousResearch/DisTrO",
      "bullets": [
        {
          "text": "깃허브에 A Preliminary Report on DisTrO를 공개",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "DeepLearning.AI-large-multimodal-model-prompting-with-gemini",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "dev",
      "org": "DeepLearning.AI",
      "title": "Large Multimodal Model Prompting with Gemini",
      "url": "https://www.deeplearning.ai/short-courses/large-multimodal-model-prompting-with-gemini/",
      "bullets": [
        {
          "text": "function calling과 API 통합 관련 내용까지 포함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-google-just-released-three-new-experimental-gemini-15-models",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "dev",
      "org": "Google",
      "title": "Google just released three new experimental Gemini 1.5 models",
      "url": "https://x.com/OfficialLoganK/status/1828480081574142227",
      "bullets": [
        {
          "text": "[Google AI Studio](https://ai.google.dev/aistudio/)에서 사용 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Waseem-Inc.-writing-in-the-margins-better-inference-pattern-for-long-context-retrieval",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "paper",
      "org": "Waseem Inc.",
      "title": "Writing in the Margins: Better Inference Pattern for\n  Long Context Retrieval",
      "url": "https://arxiv.org/abs/2408.14906",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-Research-diffusion-models-are-real-time-game-engines",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "paper",
      "org": "Google Research",
      "title": "Diffusion Models Are Real-Time Game Engines",
      "url": "https://arxiv.org/abs/2408.14837",
      "bullets": [
        {
          "text": "single TPU에서 초당 20 프레임으로 DOOM에서 simualte 가능",
          "level": 0
        },
        {
          "text": "(1) RL-agent가 게임 플레이를 학습 (2) diffusion 모델이 이전 프레임과 행동들을 기반으로 다음 프레임을 생성하도록 학습",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://gamengen.github.io) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Qwen-qwen2-vl-to-see-the-world-more-clearly",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "dev",
      "org": "Qwen",
      "title": "Qwen2-VL: To See the World More Clearly",
      "url": "https://qwenlm.github.io/blog/qwen2-vl/",
      "bullets": [
        {
          "text": "2B, 7B, 72B 중에서 72B는 API로만 이용 가능",
          "level": 0
        },
        {
          "text": "72B 모델은 GPT-4o나 Claude 3.5-Sonnet을 넘어설 정도의 visual understanding benchmark score를 보여주었음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-DeepMind-generative-verifiers-reward-modeling-as-next-token-prediction",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Generative Verifiers: Reward Modeling as Next-Token Prediction",
      "url": "https://arxiv.org/abs/2408.15240",
      "bullets": [
        {
          "text": "→ next-token prediction objective로 verifier를 학습, 즉 verification과 solution generation을 joint training",
          "level": 0
        },
        {
          "text": "기존 instruction tuning, CoT reasoning 등과 seamlessly 통합 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Tsinghua-longwriter-unleashing-10000-word-generation-from-long-context-llms",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "paper",
      "org": "Tsinghua",
      "title": "LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs",
      "url": "https://arxiv.org/abs/2408.07055",
      "bullets": [
        {
          "text": "→ 엄청나게 긴 생성 태스크를 여러 개의 subtask로 쪼개어 LLM이 20,000 단어 이상의 텍스트를 생성할 수 있도록 만드는 agent-based pipeline 제시",
          "level": 0
        },
        {
          "text": "LongWriter-6K: 답변의 길이가 2K - 32K 에 이르는 텍스트로 구성된 데이터셋",
          "level": 0
        },
        {
          "text": "장문의 텍스트 생성 능력이 있는지를 검증하는 벤치마크 LongBench-Write 또한 공개",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/THUDM/LongWriter) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Alibaba,-Meta-wavtokenizer-an-efficient-acoustic-discrete-codec-tokenizer-for-audio-language-modeling",
      "date": "2024-08-W05",
      "year": "2024",
      "month": "8",
      "week": "5",
      "type": "paper",
      "org": "Alibaba, Meta",
      "title": "WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling",
      "url": "https://arxiv.org/abs/2408.16532",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Zhejiang-University-on-llms-driven-synthetic-data-generation-curation-and-evaluation-a-survey",
      "date": "2024-07-W01",
      "year": "2024",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "Zhejiang University",
      "title": "On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey",
      "url": "https://arxiv.org/abs/2406.15126",
      "bullets": [
        {
          "text": "industry & academy 양측을 위한 합성 데이터 생성 관련 연구에 대한 폭 넓은 조사 결과를 공유",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Tsinghua,-Microsoft-direct-preference-knowledge-distillation-for-large-language-models",
      "date": "2024-07-W01",
      "year": "2024",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "Tsinghua, Microsoft",
      "title": "Direct Preference Knowledge Distillation for Large Language Models",
      "url": "https://arxiv.org/abs/2406.19774",
      "bullets": [
        {
          "text": "선호 차를 바탕으로 implicit reward function을 학습하도록 하는 DPKD 제시",
          "level": 0
        },
        {
          "text": "Implicit reward & Reverse KL divergence",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Tencent-AI-scaling-synthetic-data-creation-with-1000000000-personas",
      "date": "2024-07-W01",
      "year": "2024",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "Tencent AI",
      "title": "Scaling Synthetic Data Creation with 1,000,000,000 Personas",
      "url": "https://arxiv.org/abs/2406.20094",
      "bullets": [
        {
          "text": "다양한 시나리오를 대상으로 삼는 합성 데이터 생성 용이 (persona-driven data synthesis)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "University-of-Wisoconsin-Madison-from-artificial-needles-to-real-haystacks-improving-retrieval-capabilities-in-llms-by-finetuning-on-synthetic-data",
      "date": "2024-07-W01",
      "year": "2024",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "University of Wisoconsin-Madison",
      "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
      "url": "https://arxiv.org/abs/2406.19292",
      "bullets": [
        {
          "text": "일반적인 LLM이 long-context task에서 hallucination을 빈번히 보이는 것과 달리 fine-tuned 모델들은 performance drop을 일으키지 않음",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "infiniflow-ragflow",
      "date": "2024-07-W01",
      "year": "2024",
      "month": "7",
      "week": "1",
      "type": "dev",
      "org": "infiniflow",
      "title": "ragflow",
      "url": "https://github.com/infiniflow/ragflow",
      "bullets": [
        {
          "text": "Reranker 모델을 추가함으로써 향상된 retrieval 퍼포먼스를 보여줌",
          "level": 0
        },
        {
          "text": "Q&A parsing 방식 중 Markdown & Docx 를 새로 지원",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Learn-RAG-with-Langchain-learn-rag-with-langchain",
      "date": "2024-07-W01",
      "year": "2024",
      "month": "7",
      "week": "1",
      "type": "dev",
      "org": "Learn RAG with Langchain",
      "title": "Learn RAG with Langchain",
      "url": "https://www.sakunaharinda.xyz/ragatouille-book/intro.html",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Peking,-Alibaba-mmevalpro-calibrating-multimodal-benchmarks-towards-trustworthy-and-efficient-evaluation",
      "date": "2024-07-W01",
      "year": "2024",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "Peking, Alibaba",
      "title": "MMEvalPro: Calibrating Multimodal Benchmarks Towards Trustworthy and Efficient Evaluation",
      "url": "https://arxiv.org/abs/2407.00468",
      "bullets": [
        {
          "text": "Type-1 에러를 3단 평가 파이프라인과 엄격한 metric으로 최소화하는 벤치마크, MMEvalPro 를 제안",
          "level": 0
        },
        {
          "text": "2,138개의 question triplets, 6,414 distinct questions, 이 중 2/3는 사람이 직접 annotation",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Rice-University-malalgoqa-a-pedagogical-approach-for-evaluating-counterfactual-reasoning-abilities",
      "date": "2024-07-W01",
      "year": "2024",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "Rice University",
      "title": "MalAlgoQA: A Pedagogical Approach for Evaluating Counterfactual Reasoning Abilities",
      "url": "https://arxiv.org/abs/2407.00938",
      "bullets": [
        {
          "text": "incorrect answer rationales, ‘malgorithms’ 을 도입하여 이에 상응하는 오답을 맞히는 (identification) 태스크를 수행",
          "level": 0
        },
        {
          "text": "Algorithm Identification Accuracy (AIA), Malgorithm Identification Accuracy (AIA)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-Reserach-codeclm-aligning-language-models-with-tailored-synthetic-data",
      "date": "2024-07-W01",
      "year": "2024",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "Google Reserach",
      "title": "CodecLM: Aligning Language Models with Tailored Synthetic Data",
      "url": "https://arxiv.org/abs/2404.05875",
      "bullets": [
        {
          "text": "여러 downstream instructoin distribution에 맞는 고품질 합성 데이터를 생성해주는 프레임워크, CodecLM을 제안",
          "level": 0
        },
        {
          "text": "seed instructions을 meta data로 인코딩 한 뒤, tailored instructions을 생성하기 위해 decode",
          "level": 0
        },
        {
          "text": "Self-Rubrics & Contrastive Filtering 도입",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "OpenAI-openai-will-block-people-in-china-from-using-its-services",
      "date": "2024-07-W01",
      "year": "2024",
      "month": "7",
      "week": "1",
      "type": "news",
      "org": "OpenAI",
      "title": "OpenAI will block people in China from using its services",
      "url": "https://sg.news.yahoo.com/openai-will-block-people-in-china-from-using-its-services-200801957.html",
      "bullets": [],
      "tags": []
    },
    {
      "id": "CVPR-2024:-Image-and-Video-Search-&-Understanding-(RAG,-Multimodal,-Embeddings,-and-more)-cvpr-2024-image-and-video-search-understanding-rag-multimodal-embeddings-and-more",
      "date": "2024-07-W01",
      "year": "2024",
      "month": "7",
      "week": "1",
      "type": "dev",
      "org": "CVPR 2024: Image and Video Search & Understanding (RAG, Multimodal, Embeddings, and more)",
      "title": "CVPR 2024: Image and Video Search & Understanding (RAG, Multimodal, Embeddings, and more)",
      "url": "https://medium.com/@tenyks_blogger/cvpr-2024-image-and-video-search-understanding-rag-multimodal-embeddings-and-more-59dad7568b80",
      "bullets": [],
      "tags": []
    },
    {
      "id": "French-AI-Lab-Announces-an-Open-Source-GPT-4o-Multimodal-Alternative:-Moshi-french-ai-lab-announces-an-open-source-gpt-4o-multimodal-alternative-moshi",
      "date": "2024-07-W01",
      "year": "2024",
      "month": "7",
      "week": "1",
      "type": "dev",
      "org": "French AI Lab Announces an Open-Source GPT-4o Multimodal Alternative: Moshi",
      "title": "French AI Lab Announces an Open-Source GPT-4o Multimodal Alternative: Moshi",
      "url": "https://us.moshi.chat/?queue_id=talktomoshi",
      "bullets": [
        {
          "text": "이전에 4o 데모 영상에 비하면 아쉽다는 평이 많으나 오픈 소스 진영의 약진을 상징하기도 함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Salesforce-AI-summary-of-a-haystack-a-challenge-to-long-context-llms-and-rag-systems",
      "date": "2024-07-W01",
      "year": "2024",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "Salesforce AI",
      "title": "Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems",
      "url": "https://arxiv.org/abs/2407.01370",
      "bullets": [
        {
          "text": "query가 주어지면 관련된 내용을 source 기반으로 생성하는 태스크, Summary of a Haystack (conversation & news)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "UKP-Lab-fine-tuning-with-divergent-chains-of-thought-boosts-reasoning-through-self-correction-in-language-models",
      "date": "2024-07-W01",
      "year": "2024",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "UKP Lab",
      "title": "Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models",
      "url": "https://arxiv.org/abs/2407.03181",
      "bullets": [
        {
          "text": "해당 데이터셋으로 학습한 모델들은 상대적으로 작은 사이즈의 LLM임에도 좋은 성능을 발휘",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "UIUC,-Harvard-eliminating-position-bias-of-language-models-a-mechanistic-approach",
      "date": "2024-07-W01",
      "year": "2024",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "UIUC, Harvard",
      "title": "Eliminating Position Bias of Language Models: A Mechanistic Approach",
      "url": "https://arxiv.org/abs/2407.01100",
      "bullets": [
        {
          "text": "training-free zero-shot 방식, PINE을 제안.",
          "level": 0
        },
        {
          "text": "segment 간 causal attention을 bidirectional attention으로 변경. attention value를 활용",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "DeepSeek-AI-let-the-expert-stick-to-his-last-expert-specialized-fine-tuning-for-sparse-architectural-large-language-models",
      "date": "2024-07-W01",
      "year": "2024",
      "month": "7",
      "week": "1",
      "type": "paper",
      "org": "DeepSeek AI",
      "title": "Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models",
      "url": "https://arxiv.org/abs/2407.01906",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Salesforce-AI-apigen-automated-pipeline-for-generating-verifiable-and-diverse-function-calling-datasets",
      "date": "2024-07-W02",
      "year": "2024",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "Salesforce AI",
      "title": "APIGen: Automated Pipeline for Generating Verifiable and Diverse Function-Calling Datasets",
      "url": "https://arxiv.org/abs/2406.18518",
      "bullets": [
        {
          "text": "21개 카테고리에 대해 3,673개의 실행 가능한 fuction-calling 데이터를 수집",
          "level": 0
        },
        {
          "text": "format checking, actual function execution, semantic verification, 세 단계를 거침",
          "level": 0
        },
        {
          "text": "허깅페이스 데이터셋 링크: https://huggingface.co/datasets/Salesforce/xlam-function-calling-60k",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Reddit-chatgpt-prompt-hacking-issue",
      "date": "2024-07-W02",
      "year": "2024",
      "month": "7",
      "week": "2",
      "type": "dev",
      "org": "Reddit",
      "title": "ChatGPT prompt hacking issue",
      "url": "https://www.reddit.com/r/ChatGPT/comments/1ds9gi7/i_just_said_hi_to_chatgpt_and_it_sent_this_back/",
      "bullets": [
        {
          "text": "v1 ~ v6까지의 personality가 있고 현재는 v2 (Balanced & Friendly) 라고 답변",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "KAIST,-AWS-finesure-fine-grained-summarization-evaluation-using-llms",
      "date": "2024-07-W02",
      "year": "2024",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "KAIST, AWS",
      "title": "FineSurE: Fine-grained Summarization Evaluation using LLMs",
      "url": "https://arxiv.org/abs/2407.00908",
      "bullets": [
        {
          "text": "completeness, conciseness,faithfulness 등을 기준으로 삼음",
          "level": 0
        },
        {
          "text": "open-source vs proprietary LLMs를 비교",
          "level": 0
        },
        {
          "text": "깃허브 링크: https://github.com/DISL-Lab/FineSurE-ACL24",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Harvard-transcendence-generative-models-can-outperform-the-experts-that-train-them",
      "date": "2024-07-W02",
      "year": "2024",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "Harvard",
      "title": "Transcendence: Generative Models Can Outperform The Experts That Train Them",
      "url": "https://arxiv.org/abs/2406.11741v2",
      "bullets": [
        {
          "text": "이를 Transcendence (초월성) 이라고 정의했는데, 과연 다양한 분야에 적용 가능한 것일지 의문",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "W&B-developers-guide-to-llm-prompting",
      "date": "2024-07-W02",
      "year": "2024",
      "month": "7",
      "week": "2",
      "type": "dev",
      "org": "W&B",
      "title": "Developer's guide to LLM prompting",
      "url": "https://www.wandb.courses/courses/prompting",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-multi-token-prediction",
      "date": "2024-07-W02",
      "year": "2024",
      "month": "7",
      "week": "2",
      "type": "dev",
      "org": "Meta",
      "title": "Multi-token-prediction",
      "url": "https://huggingface.co/facebook/multi-token-prediction",
      "bullets": [
        {
          "text": "8-byte prediction 성능 굿. 요약 성능 굿.",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-minference",
      "date": "2024-07-W02",
      "year": "2024",
      "month": "7",
      "week": "2",
      "type": "dev",
      "org": "Microsoft",
      "title": "MInference",
      "url": "https://github.com/microsoft/MInference",
      "bullets": [
        {
          "text": "single A100에서 운용",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Auburn-University-vision-language-models-are-blind",
      "date": "2024-07-W02",
      "year": "2024",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "Auburn University",
      "title": "Vision language models are blind",
      "url": "https://arxiv.org/abs/2407.06581",
      "bullets": [
        {
          "text": "→ 그러나 일부 (사람에게) 굉장히 쉬운 vision task (원이 중첩되어 있는가, 원 안의 글자는 무엇인가) 들은 오히려 엄청나게 못함.",
          "level": 0
        },
        {
          "text": "세부적인 내용을 거의 파악하지 못하는 것으로 판단",
          "level": 0
        },
        {
          "text": "https://vlmsareblind.github.io/",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Anthropic-generate-better-prompts-in-the-developer-console",
      "date": "2024-07-W02",
      "year": "2024",
      "month": "7",
      "week": "2",
      "type": "dev",
      "org": "Anthropic",
      "title": "Generate better prompts in the developer console",
      "url": "https://www.anthropic.com/news/prompt-generator",
      "bullets": [
        {
          "text": "Claude 3.5 Sonnet 기반",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Tianjin-University-review-llm-harnessing-large-language-models-for-personalized-review-generation",
      "date": "2024-07-W02",
      "year": "2024",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "Tianjin University",
      "title": "Review-LLM: Harnessing Large Language Models for Personalized Review Generation",
      "url": "https://arxiv.org/abs/2407.07487",
      "bullets": [
        {
          "text": "rating 정보도 포함하여 유저의 선호를 파악할 수 있도록 함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-DeepMind-paligemma-a-versatile-3b-vlm-for-transfer",
      "date": "2024-07-W02",
      "year": "2024",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "PaliGemma: A versatile 3B VLM for transfer",
      "url": "https://arxiv.org/abs/2407.07726",
      "bullets": [
        {
          "text": "transfer를 잘해서 다양한 open-word task를 수행할 수 있는 능력이 있는 모델",
          "level": 0
        },
        {
          "text": "특히 remote-sensing & segmentation에서 강점",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "together.ai-flashattention-3-fast-and-accurate-attention-with-asynchrony-and-low-precision",
      "date": "2024-07-W02",
      "year": "2024",
      "month": "7",
      "week": "2",
      "type": "dev",
      "org": "together.ai",
      "title": "FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision",
      "url": "https://www.together.ai/blog/flashattention-3",
      "bullets": [
        {
          "text": "계산 및 데이터 이동의 중첩을 통해 처리 속도 가속",
          "level": 0
        },
        {
          "text": "FP8의 저정밀도 처리를 사용하여 성능을 향상",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-4-google-updates-coming-to-samsung-devices",
      "date": "2024-07-W02",
      "year": "2024",
      "month": "7",
      "week": "2",
      "type": "dev",
      "org": "Google",
      "title": "4 Google updates coming to Samsung devices",
      "url": "https://blog.google/products/android/google-updates-samsung-galaxy-unpacked-2024/",
      "bullets": [
        {
          "text": "갤럭시 Z 시리즈에서 circle 검색을 지원",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "University-of-Oxford-a-critical-review-of-causal-reasoning-benchmarks-for-large-language-models",
      "date": "2024-07-W02",
      "year": "2024",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "University of Oxford",
      "title": "A Critical Review of Causal Reasoning Benchmarks for Large Language Models",
      "url": "https://arxiv.org/abs/2407.08029",
      "bullets": [
        {
          "text": "interventional or counterfactual reasoning을 통합함으로써 causal reasoning을 정의",
          "level": 0
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "lmsys,-UC-Berkeley-routellm-learning-to-route-llms-with-preference-data",
      "date": "2024-07-W02",
      "year": "2024",
      "month": "7",
      "week": "2",
      "type": "paper",
      "org": "lmsys, UC Berkeley",
      "title": "RouteLLM: Learning to Route LLMs with Preference Data",
      "url": "https://arxiv.org/abs/2406.18665",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Georgia-Tech,-NVIDIA-rankrag-unifying-context-ranking-with-retrieval-augmented-generation-in-llms",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "Georgia Tech, NVIDIA",
      "title": "RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs",
      "url": "https://arxiv.org/abs/2407.02485v1",
      "bullets": [
        {
          "text": "LLM을 contest ranking & answer generatino, 두 가지에 fine-tuning 하는 방식",
          "level": 0
        },
        {
          "text": "이런식으로 학습된 모델은 ranking 관련 데이터를 조금만 학습하더라도 기존 모델들보다 월등한 성능을 보임",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "MIT,-University-of-Washington-lookback-lens-detecting-and-mitigating-contextual-hallucinations-in-large-language-models-using-only-attention-maps",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "MIT, University of Washington",
      "title": "Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps",
      "url": "https://arxiv.org/abs/2407.07071",
      "bullets": [
        {
          "text": "따라서 각각에 대한 attention weight의 비율을 입력 feature로 받는 hallucination detection model을 제안",
          "level": 0
        },
        {
          "text": "lookback ration-based detector, Lookback Lens",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-spreadsheetllm-encoding-spreadsheets-for-large-language-models",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "Microsoft",
      "title": "SpreadsheetLLM: Encoding Spreadsheets for Large Language Models",
      "url": "https://arxiv.org/abs/2407.09025",
      "bullets": [
        {
          "text": "structural-anchor-based compression, inverse index translation, data-format-aware aggregation, 세 요소로 구성된 SheetCompressor를 도입",
          "level": 0
        },
        {
          "text": "이를 바탕으로 Chain of Spreadsheet를 제안",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "DeepLearning.AI,-MongoDB-prompt-compression-and-query-optimization",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "dev",
      "org": "DeepLearning.AI, MongoDB",
      "title": "Prompt Compression and Query Optimization",
      "url": "https://learn.deeplearning.ai/courses/prompt-compression-and-query-optimization/lesson/1/introduction",
      "bullets": [
        {
          "text": "Prefiltering and Postfiltering, Projection, Reranking, Prompt Compression",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Qwen,-Alibaba-qwen2-technical-report",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "Qwen, Alibaba",
      "title": "Qwen2 Technical Report",
      "url": "https://arxiv.org/abs/2407.10671",
      "bullets": [
        {
          "text": "multilingual 능력이 뛰어나 30개 언어를 커버할 수 있다고 강조",
          "level": 0
        },
        {
          "text": "[허깅페이스](https://huggingface.co/Qwen)와 [ModelScope](https://modelscope.cn/organization/qwen)에서만 이용 가능. [깃허브](https://github.com/QwenLM/Qwen2)에서 예시 코드 참조 가능.",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Mistral-AI-mathσtral",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "dev",
      "org": "Mistral AI",
      "title": "MathΣtral",
      "url": "https://mistral.ai/news/mathstral/",
      "bullets": [
        {
          "text": "Mathstral: 수학적 추론 능력이 탁월한 7B 모델. 32K context window. Apache 2.0",
          "level": 0
        },
        {
          "text": "Codestral Mamba: 코드 생성에 특화된 Mamba2 language model. Apache 2.0",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "LlamaIndex-graphrag-implementation-with-llamaindex",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "dev",
      "org": "LlamaIndex",
      "title": "GraphRAG Implementation with LlamaIndex",
      "url": "https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/cookbooks/GraphRAG_v1.ipynb",
      "bullets": [],
      "tags": []
    },
    {
      "id": "AnthropicAI-doubled-max-output-token-limit-for-claude-35-sonnet",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "dev",
      "org": "AnthropicAI",
      "title": "Doubled max output token limit for Claude 3.5 Sonnet",
      "url": "https://x.com/alexalbert__/status/1812921642143900036",
      "bullets": [
        {
          "text": "API, console 둘 다 적용 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "University-of-Toronto-toward-adaptive-reasoning-in-large-language-models-with-thought-rollback",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "University of Toronto",
      "title": "Toward Adaptive Reasoning in Large Language Models with Thought Rollback",
      "url": "https://openreview.net/pdf/3b225c0db299e43d4952d2b73d5576523cde6de2.pdf",
      "bullets": [
        {
          "text": "LLM이 thought에 대해 error 분석을 수행. trial-and-error를 프롬프트에 포함.",
          "level": 0
        },
        {
          "text": "평소에 내가 고민하던 ‘인간이 사고하는 방식’을 고민한 것처럼 보이는 연구 결과",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-smollm-blazingly-fast-and-remarkably-powerful",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "dev",
      "org": "HuggingFace",
      "title": "SmolLM - blazingly fast and remarkably powerful",
      "url": "https://huggingface.co/blog/smollm",
      "bullets": [
        {
          "text": "Cosmopedia v2, FineWeb-Edu, Stack-Edu-Python을 정제한 Smollm-Corpus 데이터셋 ([링크](https://huggingface.co/datasets/HuggingFaceTB/smollm-corpus) 🔗)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "OpenAI-prover-verifier-games-improve-legibility-of-language-model-outputs",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "Prover-Verifier Games improve legibility of language model outputs",
      "url": "https://openai.com/index/prover-verifier-games-improve-legibility/",
      "bullets": [
        {
          "text": "정확도만을 높이기 위해 학습된 모델은 legibility가 떨어진다는 문제가 존재",
          "level": 0
        },
        {
          "text": "Prover-Verifier Game 이론을 바탕으로 하는 학습 알고리즘을 제안",
          "level": 0
        },
        {
          "text": "small verifier는 solution이 옳았는지를 구분하도록 학습, helpful prover는 verifier에게 인정받을 정확한 답변을 생성하도록 학습, sneaky prover는 verifier를 속일 수 있는 부정확한 solution을 생성하도록 학습.",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Upstage,-DeepLearning.AI-pretraining-llms",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "dev",
      "org": "Upstage, DeepLearning.AI",
      "title": "Pretraining LLMs",
      "url": "https://www.deeplearning.ai/short-courses/pretraining-llms/",
      "bullets": [
        {
          "text": "Meta의 Llama 모델을 비롯한 다양한 모델들을 원하는대로 학습하는 방식 등",
          "level": 0
        },
        {
          "text": "학습 비용을 크게 줄여주는 Depth Upscaling에 대한 소개",
          "level": 0
        },
        {
          "text": "업스테이지 강의가 여기에 나오다니.. 엄청 신기..",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Andrej-Karpathy-new-ai-education-company-called-eureka-labs",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "dev",
      "org": "Andrej Karpathy",
      "title": "new AI Education company called Eureka labs",
      "url": "https://link.alphasignal.ai/9Wanw6",
      "bullets": [
        {
          "text": "LLM101n 라는 첫 번째 컨텐츠 ([링크](https://github.com/karpathy/LLM101n) 🔗)",
          "level": 0
        },
        {
          "text": "홈페이지 [링크](https://eurekalabs.ai/) 🔗, 깃허브 [링크](https://t.co/ubv4xONI57) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Apple-dclm-7b-8k",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "dev",
      "org": "Apple",
      "title": "DCLM-7B-8k",
      "url": "https://huggingface.co/apple/DCLM-7B-8k",
      "bullets": [
        {
          "text": "systematic data curation 관련해서 이점이 있음",
          "level": 0
        },
        {
          "text": "Common Crawl로부터 추출한 240T 토큰의 corpus, DCLM (논문 [링크](https://arxiv.org/abs/2406.11794) 🔗)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-gpt-4o-mini-advancing-cost-efficient-intelligence",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "GPT-4o mini: advancing cost-efficient intelligence",
      "url": "https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/",
      "bullets": [
        {
          "text": "reasoning, math & coding, multimodal reasoning 특화되어 있음",
          "level": 0
        },
        {
          "text": "LMSYS의 리더보드에서 GPT-4 보다도 선택을 많이 받으며 MMLU도 82점을 기록",
          "level": 0
        }
      ],
      "tags": [
        "multimodal",
        "reasoning"
      ]
    },
    {
      "id": "Mistral-AI-mistral-nemo",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "dev",
      "org": "Mistral AI",
      "title": "Mistral NeMo",
      "url": "https://mistral.ai/news/mistral-nemo/",
      "bullets": [
        {
          "text": "128k context window를 지원",
          "level": 0
        },
        {
          "text": "sentence 기반의 tokenizer → Tiktoken 기반의 tokenizer, Tekken을 사용",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Tsinghua,-CMU-self-guide-better-task-specific-instruction-following-via-self-synthetic-finetuning",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "Tsinghua, CMU",
      "title": "SELF-GUIDE: Better Task-Specific Instruction Following via Self-Synthetic Finetuning",
      "url": "https://arxiv.org/abs/2407.12874",
      "bullets": [
        {
          "text": "기존에는 이러한 데이터를 다른 LLM으로 생성하는 방식도 있으나, 법적 문제, 의존성 문제 등이 제기",
          "level": 0
        },
        {
          "text": "→ task-specific input-output pair를 student LLM으로부터 합성하고, 이것으로 스스로를 학습하는 Self-Guide 메커니즘을 제안",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "University-of-Washington,-AI2-scaling-retrieval-based-language-models-with-a-trillion-token-datastore",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "University of Washington, AI2",
      "title": "Scaling Retrieval-Based Language Models with a Trillion-Token Datastore",
      "url": "https://arxiv.org/abs/2407.12854",
      "bullets": [
        {
          "text": "→ inference 시 사용 가능한 datastore의 사이즈를 키워 retrieval-based LM의 성능을 지속적으로 개선.",
          "level": 0
        },
        {
          "text": "뭔가 당연해 보이는데.. datastore를 키워서 이를 이용하면 사이즈만 큰 모델보다 잘한다는 결과를 제시함",
          "level": 0
        },
        {
          "text": "1.4T 토큰에 해당하는 datastore, MassiveDS 공개. ([링크](https://github.com/RulinShao/retrieval-scaling) 🔗)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "The-University-of-Hong-Kong-scaling-laws-with-vocabulary-larger-models-deserve-larger-vocabularies",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "The University of Hong Kong",
      "title": "Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies",
      "url": "https://arxiv.org/abs/2407.13623",
      "bullets": [
        {
          "text": "→ 큰 모델일수록 큰 vocab을 사용하는 것이 좋다. 그러나 현재 모델들은 너무 작은 vocab을 쓰고 있다.",
          "level": 0
        },
        {
          "text": "예를 들어 Llama2-70B 모델에는 216K 이상의 vocab이 적절 (현재는 32K)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Meta-joint-audio-and-symbolic-conditioning-for-temporally-controlled-text-to-music-generation",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "Meta",
      "title": "Joint Audio and Symbolic Conditioning for Temporally Controlled Text-to-Music Generation",
      "url": "https://arxiv.org/abs/2406.10970",
      "bullets": [
        {
          "text": "global text description을 기반으로 fine-grained local control도 가능",
          "level": 0
        },
        {
          "text": "information bottleneck layer를 temporal blurring과 함께 적용하여 디테일한 컨트롤과 관련된 정보를 추출",
          "level": 0
        },
        {
          "text": "이런 모델들은 평가를 어떻게 하는 걸까?",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Moqi,-Peking-memory3-language-modeling-with-explicit-memory",
      "date": "2024-07-W03",
      "year": "2024",
      "month": "7",
      "week": "3",
      "type": "paper",
      "org": "Moqi, Peking",
      "title": "Memory3: Language Modeling with Explicit Memory",
      "url": "https://arxiv.org/abs/2407.01178v1",
      "bullets": [],
      "tags": []
    },
    {
      "id": "New-York-University-a-survey-of-prompt-engineering-methods-in-large-language-models-for-different-nlp-tasks",
      "date": "2024-07-W04",
      "year": "2024",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "New York University",
      "title": "A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks",
      "url": "https://arxiv.org/abs/2407.12994",
      "bullets": [
        {
          "text": "최근 2년 간의 prompting 연구에 대해 총망라",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Generative-AI-Research-Lab-(GAIR),-Fudan-weak-to-strong-reasoning",
      "date": "2024-07-W04",
      "year": "2024",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "Generative AI Research Lab (GAIR), Fudan",
      "title": "Weak-to-Strong Reasoning",
      "url": "https://arxiv.org/abs/2407.13647",
      "bullets": [
        {
          "text": "samll, but high-quality dataset으로 지도 학습을 시작 → 모델 스스로 contrastive sample로 식별한 케이스들에 대해 preference optimization",
          "level": 0
        },
        {
          "text": "세 개의 weak 모델을 이용하여 LLama2-70B 모델의 성능을 향상시킬 수 있었다고 보고",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Apple,-Meta-lazyllm-dynamic-token-pruning-for-efficient-long-context-llm-inference",
      "date": "2024-07-W04",
      "year": "2024",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "Apple, Meta",
      "title": "LazyLLM: Dynamic Token Pruning for Efficient Long Context LLM Inference",
      "url": "https://arxiv.org/abs/2407.14057",
      "bullets": [
        {
          "text": "병목을 해결하기 위해 prefilling과 decoding에 중요한 토큰의 KV만 선별적으로 계산하는 방식 LazyLLM을 제안",
          "level": 0
        },
        {
          "text": "다른 방식들과 달리 매 생성 step에서 ‘dynamically’ 토큰을 고른다는 점이 특징",
          "level": 0
        },
        {
          "text": "기존 모델들에 추가 학습 없이 seamlessly 통합 가능하다는 점이 특징",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "groq-introducing-llama-3-groq-tool-use-models",
      "date": "2024-07-W04",
      "year": "2024",
      "month": "7",
      "week": "4",
      "type": "dev",
      "org": "groq",
      "title": "Introducing Llama-3-Groq-Tool-Use Models",
      "url": "https://wow.groq.com/introducing-llama-3-groq-tool-use-models/",
      "bullets": [
        {
          "text": "[Llama-3-Groq-70B-Tool-Use](https://huggingface.co/Groq/Llama-3-Groq-70B-Tool-Use) & [Llama-3-Groq-8B-Tool-Use](https://huggingface.co/Groq/Llama-3-Groq-8B-Tool-Use)",
          "level": 0
        },
        {
          "text": "[GroqCloud Devloper Hub](http://console.groq.com/)에서도 이용 가능",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "Google-DeepMind-jumping-ahead-improving-reconstruction-fidelity-with-jumprelu-sparse-autoencoders",
      "date": "2024-07-W04",
      "year": "2024",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Jumping Ahead: Improving Reconstruction Fidelity with JumpReLU Sparse Autoencoders",
      "url": "https://arxiv.org/abs/2407.14435",
      "bullets": [
        {
          "text": "Gemma 2 9B activations를 기준으로 reconstruction fidelity에서 SoTA를 달성한 JumpReLU SAEs를 제안",
          "level": 0
        },
        {
          "text": "activation 관련해서 오랜만에 눈에 띄는 논문..",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Meta-introducing-llama-31-our-most-capable-models-to-date",
      "date": "2024-07-W04",
      "year": "2024",
      "month": "7",
      "week": "4",
      "type": "dev",
      "org": "Meta",
      "title": "Introducing Llama 3.1: Our most capable models to date",
      "url": "https://ai.meta.com/blog/meta-llama-3-1/",
      "bullets": [
        {
          "text": "GPT-4 수준을 상회하는 오픈소스 모델은 최초라고 봐도 될 듯",
          "level": 0
        },
        {
          "text": "[Meta paper 링크](https://ai.meta.com/research/publications/the-llama-3-herd-of-models/) 🔗",
          "level": 0
        },
        {
          "text": "[Hugging Face Model Family 링크](https://huggingface.co/collections/meta-llama/llama-31-669fc079a0c406a149a5738f) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "NC-Research-offsetbias-leveraging-debiased-data-for-tuning-evaluators",
      "date": "2024-07-W04",
      "year": "2024",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "NC Research",
      "title": "OffsetBias: Leveraging Debiased Data for Tuning Evaluators",
      "url": "https://www.arxiv.org/abs/2407.06551",
      "bullets": [
        {
          "text": "→ judge 모델에 존재하는 6개 종류의 bias에 대한 연구",
          "level": 0
        },
        {
          "text": "각 bias 종류별로 hand-crafted test 케이스를 포함하는 EvalBiasBench 제안",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Numina,-Hugging-Face,-MIT,-Mistral,-Peking-numinamath",
      "date": "2024-07-W04",
      "year": "2024",
      "month": "7",
      "week": "4",
      "type": "dev",
      "org": "Numina, Hugging Face, MIT, Mistral, Peking",
      "title": "NuminaMath",
      "url": "https://github.com/project-numina/aimo-progress-prize?tab=readme-ov-file",
      "bullets": [
        {
          "text": "1M 수학 문제 & 정답으로 구성된 high-quality training dataset",
          "level": 0
        },
        {
          "text": "[Hugging Face 데이터셋 링크](https://huggingface.co/collections/AI-MO/numinamath-6697df380293bcfdbc1d978c) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "WWDC-24:-Running-Mistral-7B-with-Core-ML-wwdc-24-running-mistral-7b-with-core-ml",
      "date": "2024-07-W04",
      "year": "2024",
      "month": "7",
      "week": "4",
      "type": "dev",
      "org": "WWDC 24: Running Mistral 7B with Core ML",
      "title": "WWDC 24: Running Mistral 7B with Core ML",
      "url": "https://huggingface.co/blog/mistral-coreml",
      "bullets": [
        {
          "text": "간단히 공부하기 좋을 것 같은 허깅페이스 블로그 글",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Mistral-AI-mistral-large-2",
      "date": "2024-07-W04",
      "year": "2024",
      "month": "7",
      "week": "4",
      "type": "dev",
      "org": "Mistral AI",
      "title": "Mistral Large 2",
      "url": "https://mistral.ai/news/mistral-large-2407/",
      "bullets": [
        {
          "text": "French, German 등 다양한 언어 뿐만 아니라 Python, Java 등 프로그래밍 언어에도 특화",
          "level": 0
        },
        {
          "text": "비상업적, 연구적 목적으로 이용 가능. [weight download](https://models.mistralcdn.com/mistral-large-2407/mistral-large-instruct-2407.tar) 🔗 [HuggingFace](https://huggingface.co/mistralai/Mistral-Large-Instruct-2407) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "OpenAI-searchgpt-prototype",
      "date": "2024-07-W04",
      "year": "2024",
      "month": "7",
      "week": "4",
      "type": "dev",
      "org": "OpenAI",
      "title": "SearchGPT Prototype",
      "url": "https://openai.com/index/searchgpt-prototype/",
      "bullets": [
        {
          "text": "conversational capability를 향상시킴으로써 real-time 정보를 보다 쉽게 획득할 수 있음",
          "level": 0
        },
        {
          "text": "partnering with publisher & creator",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Cohere-introducing-rerank-3-nimble-faster-reranking-for-enterprise-search-retrieval-augmented-generation-rag-systems",
      "date": "2024-07-W04",
      "year": "2024",
      "month": "7",
      "week": "4",
      "type": "dev",
      "org": "Cohere",
      "title": "Introducing Rerank 3 Nimble: Faster Reranking for Enterprise Search & Retrieval-Augmented Generation (RAG) Systems",
      "url": "https://cohere.com/blog/rerank-3-nimble",
      "bullets": [
        {
          "text": "영어 외에도 100개 이상의 언어를 지원",
          "level": 0
        },
        {
          "text": "[Amazon Sagemaker](https://aws.amazon.com/marketplace/pp/prodview-rq7ik6yx6jnzc) 🔗",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-geminis-big-upgrade-faster-responses-with-15-flash-expanded-access-and-more",
      "date": "2024-07-W04",
      "year": "2024",
      "month": "7",
      "week": "4",
      "type": "dev",
      "org": "Google",
      "title": "Gemini’s big upgrade: Faster responses with 1.5 Flash, expanded access and more",
      "url": "https://blog.google/products/gemini/google-gemini-new-features-july-2024/",
      "bullets": [
        {
          "text": "현재 트렌드는 조금 덜 뛰어난 성능일지라도 빠른 답변을 할 수 있는 모델을 제공하는 것. 빠른 속도를 한 번 경험하고 나면 느린 모델에 대한 반감이 커질 것 같다는 생각이 듦.",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "AI2,-University-of-Washington,-Microsoft-the-art-of-saying-no-contextual-noncompliance-in-language-models",
      "date": "2024-07-W04",
      "year": "2024",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "AI2, University of Washington, Microsoft",
      "title": "The Art of Saying No: Contextual Noncompliance in Language Models",
      "url": "https://arxiv.org/abs/2407.12043",
      "bullets": [
        {
          "text": "모델이 언제 어떻게 유저의 요청을 따르지 말아야 하는지에 대한 어휘 분류 체계를 도입",
          "level": 0
        },
        {
          "text": "1,000개의 noncompliance prompt를 바탕으로 실험 → 30% 정도는 유저의 요청을 제대로 따르지 못하고 있음",
          "level": 0
        },
        {
          "text": "→ request & noncompliant response로 구성된 학습용 학습 데이터를 제작 → Fine-tuning은 overfit으로 이어지는 반면 LoRA 같은 기법이 밸런스가 좋음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "University-of-Washinton,-AI2-data-mixture-inference-what-do-bpe-tokenizers-reveal-about-their-training-data",
      "date": "2024-07-W04",
      "year": "2024",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "University of Washinton, AI2",
      "title": "Data Mixture Inference: What do BPE Tokenizers Reveal about their Training Data?",
      "url": "https://arxiv.org/abs/2407.16607",
      "bullets": [
        {
          "text": "→ GPT-4o의 토크나이저는 39%의 non-English data로 학습되어 전작보다 multilingual 하다고 이야기 할 수 있음",
          "level": 0
        },
        {
          "text": "→ Llama3 모델은 48%의 non-English data로 학습되었음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "NVIDIA-compact-language-models-via-pruning-and-knowledge-distillation",
      "date": "2024-07-W04",
      "year": "2024",
      "month": "7",
      "week": "4",
      "type": "paper",
      "org": "NVIDIA",
      "title": "Compact Language Models via Pruning and Knowledge Distillation",
      "url": "https://arxiv.org/abs/2407.14679",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Oxford,-Cambridge,-Imperial-College-London,-Toronto-ai-models-collapse-when-trained-on-recursively-generated-data",
      "date": "2024-07-W05",
      "year": "2024",
      "month": "7",
      "week": "5",
      "type": "paper",
      "org": "Oxford, Cambridge, Imperial College London, Toronto",
      "title": "AI models collapse when trained on recursively generated data",
      "url": "https://www.nature.com/articles/s41586-024-07566-y",
      "bullets": [
        {
          "text": "LLM 생성 데이터가 점점 늘어나고 있는 상황에서 인간이 직접 만들어낸 데이터의 가치는 점점 높아질 것이라고 예측",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Washington,-AI2-the-art-of-refusal-a-survey-of-abstention-in-large-language-models",
      "date": "2024-07-W05",
      "year": "2024",
      "month": "7",
      "week": "5",
      "type": "paper",
      "org": "Washington, AI2",
      "title": "The Art of Refusal: A Survey of Abstention in Large Language Models",
      "url": "https://arxiv.org/abs/2407.18418",
      "bullets": [
        {
          "text": "이를 query, model, human value, 세 개의 관점에서 평가하난 프레임워크를 제시",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Equall-saullm-54b-saullm-141b-scaling-up-domain-adaptation-for-the-legal-domain",
      "date": "2024-07-W05",
      "year": "2024",
      "month": "7",
      "week": "5",
      "type": "paper",
      "org": "Equall",
      "title": "SaulLM-54B & SaulLM-141B: Scaling Up Domain Adaptation for the Legal Domain",
      "url": "https://arxiv.org/abs/2407.19584",
      "bullets": [
        {
          "text": "domain adaptation 과정은 세 단계로 구성됨.",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta-introducing-sam-2-the-next-generation-of-meta-segment-anything-model-for-videos-and-images",
      "date": "2024-07-W05",
      "year": "2024",
      "month": "7",
      "week": "5",
      "type": "dev",
      "org": "Meta",
      "title": "Introducing SAM 2: The next generation of Meta Segment Anything Model for videos and images",
      "url": "https://ai.meta.com/blog/segment-anything-2/",
      "bullets": [
        {
          "text": "memory mechanism: 과거 segmentation 정보를 저장 & 불러오기 하여 프레임 간 continuous tracking이 가능",
          "level": 0
        },
        {
          "text": "real-time processing이 가능한 빠른 추론 속도",
          "level": 0
        },
        {
          "text": "51K videos & 600K masklets로 구성된 SA-V dataset 공개",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-gpt-4o-long-output",
      "date": "2024-07-W05",
      "year": "2024",
      "month": "7",
      "week": "5",
      "type": "dev",
      "org": "OpenAI",
      "title": "GPT-4o Long Output",
      "url": "https://openai.com/gpt-4o-long-output/",
      "bullets": [
        {
          "text": "요즘 가장 큰 두 개의 트렌드는 context 늘리기와 모델 사이즈 줄이기 (추론 속도 up)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Meta,-Berkeley,-NYU-meta-rewarding-language-models-self-improving-alignment-with-llm-as-a-meta-judge",
      "date": "2024-07-W05",
      "year": "2024",
      "month": "7",
      "week": "5",
      "type": "paper",
      "org": "Meta, Berkeley, NYU",
      "title": "Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge",
      "url": "https://arxiv.org/abs/2407.19594",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Renmin-University-one-token-can-help-learning-scalable-and-pluggable-virtual-tokens-for-retrieval-augmented-large-language-models",
      "date": "2024-06-W01",
      "year": "2024",
      "month": "6",
      "week": "1",
      "type": "paper",
      "org": "Renmin University",
      "title": "One Token Can Help! Learning Scalable and Pluggable Virtual Tokens for Retrieval-Augmented Large Language Models",
      "url": "https://arxiv.org/abs/2405.19670",
      "bullets": [
        {
          "text": "RAG를 위한 scalable & pluggable 가상 토큰을 제안. 해당 토큰에 대한 임베딩만 fine-tuning",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Jina-AI-jina-clip-your-clip-model-is-also-your-text-retriever",
      "date": "2024-06-W01",
      "year": "2024",
      "month": "6",
      "week": "1",
      "type": "paper",
      "org": "Jina AI",
      "title": "Jina CLIP: Your CLIP Model Is Also Your Text Retriever",
      "url": "https://arxiv.org/abs/2405.20204",
      "bullets": [
        {
          "text": "→ 이를 해결하기 위해 multi-task contrastive training method를 제안",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Anthropic-claude-can-now-use-tools",
      "date": "2024-06-W01",
      "year": "2024",
      "month": "6",
      "week": "1",
      "type": "dev",
      "org": "Anthropic",
      "title": "Claude can now use tools",
      "url": "https://www.anthropic.com/news/tool-use-ga",
      "bullets": [
        {
          "text": "예를 들어 구조화된 데이터 추출, DB 기반 검색 및 답변, API 기능 자동화 등에 활용 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Perplexity-introducing-perplexity-pages",
      "date": "2024-06-W01",
      "year": "2024",
      "month": "6",
      "week": "1",
      "type": "dev",
      "org": "Perplexity",
      "title": "Introducing Perplexity Pages",
      "url": "https://www.perplexity.ai/hub/blog/perplexity-pages",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Contextual-Position-Encoding:-Learning-to-Count-What’s-Important-contextual-position-encoding-learning-to-count-whats-important",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "unknown",
      "org": "Contextual Position Encoding: Learning to Count What’s Important",
      "title": "Contextual Position Encoding: Learning to Count What’s Important",
      "url": "https://arxiv.org/abs/2405.18719",
      "bullets": [
        {
          "text": "→ 모델에 의해 결정되는 특정 토큰에 대한 position만 확장함으로써 position이 context에 conditioned 될 수 있도록 하는 Contextual Position Encoding(CoPE)를 제안",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Samsung-samsungs-galaxy-s24-series-dominates-genai-capable-smartphone-market-in-q1-2024",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "news",
      "org": "Samsung",
      "title": "Samsung’s Galaxy S24 Series Dominates GenAI-capable Smartphone Market in Q1 2024",
      "url": "https://www.counterpointresearch.com/insights/global-top-10-best-selling-genai-smartphones-q1-2024/",
      "bullets": [
        {
          "text": "AI 기술 발전을 내세울 것으로 예상되는 애플의 WWDC가 많은 이들의 기대를 받고 있음",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Princeton,-CMU-transformers-are-ssms-generalized-models-and-efficient-algorithms-through-structured-state-space-duality",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "Princeton, CMU",
      "title": "Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality",
      "url": "https://arc.net/l/quote/avdoajmy",
      "bullets": [
        {
          "text": "핵심 레이어의 연산 속도가 Mamba의 selective SSM보다 2-8배 정도 빠르면서, 트랜스포머 기반의 언어 모델과 견줄 수 있는 성능을 내세움",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Perdue-sayself-teaching-llms-to-express-confidence-with-self-reflective-rationales",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "Perdue",
      "title": "SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales",
      "url": "https://arxiv.org/abs/2405.20974",
      "bullets": [
        {
          "text": "→ fine-grained confidence estimates를 표현하도록 가르치는 SaySelf 방법론을 제안",
          "level": 1
        },
        {
          "text": "추가적으로 LLM은 스스로의 parametric knowledge를 나타내는 self-reflective rationale을 생성하고, 반대로 uncertainty를 표현할 수 있게 됨",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "LlamaIndex-introducing-the-property-graph-index-a-powerful-new-way-to-build-knowledge-graphs-with-llms",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "dev",
      "org": "LlamaIndex",
      "title": "Introducing the Property Graph Index: A Powerful New Way to Build Knowledge Graphs with LLMs",
      "url": "https://www.llamaindex.ai/blog/introducing-the-property-graph-index-a-powerful-new-way-to-build-knowledge-graphs-with-llms",
      "bullets": [
        {
          "text": "그래프를 hybrid search를 위한 vector database로 사용 가능",
          "level": 1
        },
        {
          "text": "Cypher graph query language를 이용한 복잡한 query 표현 가능",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "DeepLearning.AI-ai-agents-in-langgraph",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "dev",
      "org": "DeepLearning.AI",
      "title": "AI Agents in LangGraph",
      "url": "https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/",
      "bullets": [
        {
          "text": "추가로, 여러 개의 답변을 agent-friendly 형식으로 반환하는 agent serarch도 다룸",
          "level": 1
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "ByteDance-exploring-mathematical-extrapolation-of-large-language-models-with-synthetic-data",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "ByteDance",
      "title": "Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data",
      "url": "https://arxiv.org/abs/2406.02100",
      "bullets": [
        {
          "text": "또한 추가 실험을 통해 out-of-domain 데이터셋에 대한 성능도 준수하다는 것을 확인",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-DeepMind-to-believe-or-not-to-believe-your-llm",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "To Believe or Not to Believe Your LLM",
      "url": "https://arxiv.org/abs/2406.02543",
      "bullets": [
        {
          "text": "information-theoretic metric을 사용하여 언제 epistemic uncertainty가 높은지를 탐지",
          "level": 1
        },
        {
          "text": "이전의 답변을 기반으로 삼는 iterative prompting을 통해 metric을 계산. 즉, log-likelihood 등을 사용하지 않음.",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-plaigemma",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "dev",
      "org": "Google",
      "title": "PlaiGemma",
      "url": "https://ai.google.dev/gemma/docs/paligemma",
      "bullets": [
        {
          "text": "다양한 태스크를 처리할 수 있는 PaliGemma와 특정 research dataset에 fine-tuned PaliGemma-FT를 공개",
          "level": 1
        },
        {
          "text": "[캐글](https://www.kaggle.com/models/google/paligemma)에서 다운로드 가능",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Mistral-AI-my-tailor-is-mistral",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "dev",
      "org": "Mistral AI",
      "title": "My Tailor is Mistral",
      "url": "https://mistral.ai/news/customization/",
      "bullets": [
        {
          "text": "LoRA를 기반으로 하여 memory-efficient 하면서도 performant한 fine-tuning 기법을 도입",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "KAIST,-LG-AI-block-transformer-global-to-local-language-modeling-for-fast-inference",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "KAIST, LG AI",
      "title": "Block Transformer: Global-to-Local Language Modeling for Fast Inference",
      "url": "https://arxiv.org/abs/2406.02657",
      "bullets": [
        {
          "text": "→ 낮은 layer에 대한 global modeling의 병목을 고립시키고, 상위 layer에 대해 fast local modeling을 적용. 입력 토큰을 특정 사이즈의 블록으로 압축하고 coarse level로 self attention을 적용.",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-extracting-concepts-from-gpt-4",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "unknown",
      "org": "OpenAI",
      "title": "Extracting Concepts from GPT-4",
      "url": "https://openai.com/index/extracting-concepts-from-gpt-4/",
      "bullets": [
        {
          "text": "GPT-4의 internal representation을 16M 개의 oft-interpretable pattern으로 decompose하기 위해 고안한 scalable method를 공개",
          "level": 1
        },
        {
          "text": "k-sparse autoencoders를 제안하여 sparsity를 control 함과 동시에 reconstruction-sparsity frontier를 tuning하고 개선하는 과정을 간소화",
          "level": 1
        },
        {
          "text": "autoencoder의 크기와 sparsity 간의 확연한 scaling laws를 관측",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Google-notebooklm-goes-global-with-slides-support-and-better-ways-to-fact-check",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "dev",
      "org": "Google",
      "title": "NotebookLM goes global with Slides support and better ways to fact-check",
      "url": "https://blog.google/technology/ai/notebooklm-goes-global-support-for-websites-slides-fact-check/",
      "bullets": [
        {
          "text": "Google Slide, web URL, Google Docs, PDFs, text files를 지원",
          "level": 1
        },
        {
          "text": "[NotebookLM 링크](https://notebooklm.google.com/?original_referer=https://blog.google%23&pli=1)🔗에서 가이드 확인 및 노트북 생성 가능",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "ELLIS-semantically-diverse-language-generation-for-uncertainty-estimation-in-language-models",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "ELLIS",
      "title": "Semantically Diverse Language Generation for Uncertainty Estimation in Language Models",
      "url": "https://arxiv.org/abs/2406.04306",
      "bullets": [
        {
          "text": "이를 통해 initial text가 hallucinated 인지 아닌지 판단할 수 있음",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Peking,-Berkeley,-Stanford-buffer-of-thoughts-thought-augmented-reasoning-with-large-language-models",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "paper",
      "org": "Peking, Berkeley, Stanford",
      "title": "Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models",
      "url": "https://arxiv.org/abs/2406.04271",
      "bullets": [
        {
          "text": "meta-buffer: 유익한 high-level thoughts를 저장",
          "level": 1
        },
        {
          "text": "buffer-manager: meta-buffer를 동적으로 업데이트하여 meta-buffer의 capacity를 향상",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "KLING-forget-sora-kling-is-a-killer-new-ai-video-model-that-just-dropped-and-im-impressed",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "news",
      "org": "KLING",
      "title": "Forget Sora — Kling is a killer new AI video model that just dropped and I’m impressed",
      "url": "https://www.tomsguide.com/ai/ai-image-video/forget-sora-kling-is-a-killer-new-ai-video-model-that-just-dropped-and-im-impressed",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Alibaba-hello-qwen2",
      "date": "2024-06-W02",
      "year": "2024",
      "month": "6",
      "week": "2",
      "type": "dev",
      "org": "Alibaba",
      "title": "Hello Qwen2",
      "url": "https://qwenlm.github.io/blog/qwen2/",
      "bullets": [
        {
          "text": "coding, mathematics, multilingual understanding, long-context understanding 등에서 Meta의 Llama3나 OpenAI의 GPT-4를 능가하는 수준의 성능을 보임",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Santa-Cruz-scalable-matmul-free-language-modeling",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "Santa Cruz",
      "title": "Scalable MatMul-free Language Modeling",
      "url": "https://arxiv.org/abs/2406.02528",
      "bullets": [
        {
          "text": "MatMul-free 모델이 transformer 기반의 모델보다 2.7B 사이즈까지 뛰어나도록 학습한 결과를 제시",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "University-of-Chicago-the-geometry-of-categorical-and-hierarchical-concepts-in-large-language-models",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "University of Chicago",
      "title": "The Geometry of Categorical and Hierarchical Concepts in Large Language Models",
      "url": "https://arxiv.org/abs/2406.01506",
      "bullets": [
        {
          "text": "전자는 simplices, 후자는 orthogonal, 복잡한 개념은 direct sum으로 구성된 polytope로 표현",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Andrej-Karpathy-lets-reproduce-gpt-2-124m",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "dev",
      "org": "Andrej Karpathy",
      "title": "Let's reproduce GPT-2 (124M)",
      "url": "https://www.youtube.com/watch?v=l8pRSuU81PU",
      "bullets": [],
      "tags": []
    },
    {
      "id": "OpenAI,-Apple-openai-and-apple-announce-partnership-to-integrate-chatgpt-into-apple-experiences",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "dev",
      "org": "OpenAI, Apple",
      "title": "OpenAI and Apple announce partnership to integrate ChatGPT into Apple experiences",
      "url": "https://arc.net/l/quote/jbenmlas",
      "bullets": [
        {
          "text": "privacy와 관련해서 애플이 직접 데이터 센터를 구축하고 관리하겠다고 함.",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "University-of-Waterloo-genai-arena-an-open-evaluation-platform-for-generative-models",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "University of Waterloo",
      "title": "GenAI Arena: An Open Evaluation Platform for Generative Models",
      "url": "https://arxiv.org/abs/2406.04485",
      "bullets": [
        {
          "text": "text-to-image, text-to-video, image editing, 세 영역에 대한 평가가 가능",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "AI2-wildbench-benchmarking-llms-with-challenging-tasks-from-real-users-in-the-wild",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "AI2",
      "title": "WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild",
      "url": "https://arxiv.org/abs/2406.04770",
      "bullets": [
        {
          "text": "GPT-4 turbo와 같은 LLM을 사용하여 WB-Reward, WB-Score 을 기준으로 평가 자동화",
          "level": 0
        },
        {
          "text": "fine-grained pari-wise comparision 방식을 사용했으며, 세 개의 베이스라인을 설정",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Duke,-Stanford,-Together-AI-mixture-of-agents-enhances-large-language-model-capabilities",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "Duke, Stanford, Together AI",
      "title": "Mixture-of-Agents Enhances Large Language Model Capabilities",
      "url": "https://arxiv.org/abs/2406.04692",
      "bullets": [
        {
          "text": "즉, 여러 개의 LLM agents로 각 layer를 구성하는 방식. 각 agent는 이전 레이어의 결과물을 auxiliary information으로 활용.",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "LLMs-Aren’t-Just-“Trained-On-the-Internet”-Anymore-llms-arent-just-trained-on-the-internet-anymore",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "news",
      "org": "LLMs Aren’t Just “Trained On the Internet” Anymore",
      "title": "LLMs Aren’t Just “Trained On the Internet” Anymore",
      "url": "https://allenpike.com/2024/llms-trained-on-internet",
      "bullets": [
        {
          "text": "맞춤형 학습데이터를 제작하여 활용하는 방식이 대두. Phi-3가 대표적인 모델이며 [Scale.ai](http://Scale.ai) 같은 회사가 크게 주목을 받게 됨.",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "University-of-Washington-do-llms-exhibit-human-like-reasoning-evaluating-theory-of-mind-in-llms-for-open-ended-responses",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "University of Washington",
      "title": "Do LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses",
      "url": "https://arxiv.org/abs/2406.05659",
      "bullets": [
        {
          "text": "Reddit, ChangedMyView에서 수집한 포스트에서 사람과 LLM 응답 간의 의미적 유사성 및 어휘 중복 정도를 비교 → open-ended scenarios에서 명백한 한계를 보임",
          "level": 0
        },
        {
          "text": "LLM은 아직까지 social reasoning 성능이 부족함을 입증하고 어떻게 인간 의도와 감정을 통합할 수 있는지에 대한 방법을 제시",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "ByteDance-autoregressive-model-beats-diffusion-llama-for-scalable-image-generation",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "ByteDance",
      "title": "Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation",
      "url": "https://arxiv.org/abs/2406.06525",
      "bullets": [
        {
          "text": "(1) image tokenizer (2) class-conditional image generation (3) text-conditional image generation (4) optimizaing the inference speed of image generation",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "Washington,-Meta,-AI2-husky-a-unified-open-source-language-agent-for-multi-step-reasoning",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "Washington, Meta, AI2",
      "title": "Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning",
      "url": "https://arxiv.org/abs/2406.06469",
      "bullets": [
        {
          "text": "→ numerical, tabular, knowledge-based reasoning을 다룰 수 있는, 즉 unified action space에서 학습한 open-source language agent, Husky를 제안",
          "level": 0
        },
        {
          "text": "1. 다음 단계에 수행할 작업을 예측 2) expert 모델이 선택된 작업을 실행하고 상태 업데이트",
          "level": 0
        },
        {
          "text": "7B 모델로도 GPT-4에 준하거나 그 이상의 성능을 보임",
          "level": 0
        }
      ],
      "tags": [
        "agent",
        "reasoning"
      ]
    },
    {
      "id": "OpenAI,-Stnaford,-Microsoft-the-prompt-report-a-systematic-survey-of-prompting-techniques",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "OpenAI, Stnaford, Microsoft",
      "title": "The Prompt Report: A Systematic Survey of Prompting Techniques",
      "url": "https://arxiv.org/abs/2406.06608",
      "bullets": [
        {
          "text": "58개의 프롬프팅 테크닉과 다른 modality에 활용 가능한 40개의 테크닉을 정리",
          "level": 0
        },
        {
          "text": "자연어 prefix-prompting에 대한 내용도 다루고 있음",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-generative-ai-for-beginners",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "dev",
      "org": "Microsoft",
      "title": "Generative-AI-For-Beginners",
      "url": "https://github.com/microsoft/generative-ai-for-beginners",
      "bullets": [
        {
          "text": "생성형 AI application을 만드는 데 필요한 18개의 강의를 제공",
          "level": 0
        },
        {
          "text": "데이터 베이스와 관련된 강의를 DeepLearning.AI 에서도 제공",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Luma-AI-dream-machine",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "dev",
      "org": "Luma AI",
      "title": "Dream Machine",
      "url": "https://lumalabs.ai/dream-machine",
      "bullets": [],
      "tags": []
    },
    {
      "id": "University-of-Toronto-out-of-context-prompting-boosts-fairness-and-robustness-in-large-language-model-predictions",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "University of Toronto",
      "title": "Out-Of-Context Prompting Boosts Fairness and Robustness in Large Language Model Predictions",
      "url": "https://arxiv.org/abs/2406.07685",
      "bullets": [
        {
          "text": "→ 반대로 out-of-comtext prompting을 제안 (테스트 단계에서)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "New-York-University-large-language-models-must-be-taught-to-know-what-they-dont-know",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "New York University",
      "title": "Large Language Models Must Be Taught to Know What They Don't Know",
      "url": "https://arxiv.org/abs/2406.08391",
      "bullets": [
        {
          "text": "→ 작은 correct & incorrect answer로 fine-tuning 함으로써 불확실성 추정에 대한 일반화 성능을 끌어올릴 수 있다.",
          "level": 0
        },
        {
          "text": "인간과 AI가 협력하는 환경에서의 불확실성 추정이 어떻게 인간 의사결정에 도움이 되는지 연구",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "University-of-Edinburgh-are-we-done-with-mmlu",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "University of Edinburgh",
      "title": "Are We Done with MMLU?",
      "url": "https://arxiv.org/abs/2406.04127",
      "bullets": [
        {
          "text": "error taxonomy를 이용하여 데이터셋을 확인하는 프레임워크, MMLU-Redux를 제안",
          "level": 0
        },
        {
          "text": "30개의 MMLU subjects에 대해서 3,000개를 reannotate → 벤치마크 성능과 실제 체감 성능 간의 괴리를 줄이고자 함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "NVIDIA-nemotron-4-340b",
      "date": "2024-06-W03",
      "year": "2024",
      "month": "6",
      "week": "3",
      "type": "paper",
      "org": "NVIDIA",
      "title": "Nemotron-4 340B",
      "url": "https://research.nvidia.com/publication/2024-06_nemotron-4-340b",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Fudan,-AI2-selfgoal-your-language-agents-already-know-how-to-achieve-high-level-goals",
      "date": "2024-06-W04",
      "year": "2024",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Fudan, AI2",
      "title": "SelfGoal: Your Language Agents Already Know How to Achieve High-level Goals",
      "url": "https://arc.net/l/quote/fcednhje",
      "bullets": [
        {
          "text": "→ 사람이 제공하는 피드백이 제한되고 느린(delayed) 상황에서도 high-level goal을 달성할 수 있도록 돕는 automatic apporach, SelfGoal을 제안",
          "level": 1
        },
        {
          "text": "핵심: high-level goal을 실용적인 subgoal로 이루어진 tree structure로 쪼개는 것",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "AIRI-babilong-testing-the-limits-of-llms-with-long-context-reasoning-in-a-haystack-1",
      "date": "2024-06-W04",
      "year": "2024",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "AIRI",
      "title": "BABILong: Testing the Limits of LLMs with Long Context Reasoning-in-a-Haystack",
      "url": "https://arxiv.org/abs/2406.10149",
      "bullets": [
        {
          "text": "20여개의 다양한 reasoning tasks를 포함",
          "level": 1
        },
        {
          "text": "아직까지는 유의미한 long context understanding 벤치마크가 없다고 생각하는데, 향후 유의미한 연구들이 등장할 것인지 개인적인 의문",
          "level": 1
        }
      ],
      "tags": [
        "reasoning"
      ]
    },
    {
      "id": "Hong-Kong-Science-know-the-unknown-an-uncertainty-sensitive-method-for-llm-instruction-tuning",
      "date": "2024-06-W04",
      "year": "2024",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Hong Kong Science",
      "title": "Know the Unknown: An Uncertainty-Sensitive Method for LLM Instruction Tuning",
      "url": "https://arxiv.org/abs/2406.10099",
      "bullets": [
        {
          "text": "→ uncertainity-sensitive tuning: uncertainty recognition + prompt-sensitive activation",
          "level": 1
        },
        {
          "text": "모르는 질문을 거절 + causal instruction을 통해 퍼포먼스 회복",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "AIRI-xland-100b-a-large-scale-multi-task-dataset-for-in-context-reinforcement-learning",
      "date": "2024-06-W04",
      "year": "2024",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "AIRI",
      "title": "XLand-100B: A Large-Scale Multi-Task Dataset for In-Context Reinforcement Learning",
      "url": "https://arxiv.org/abs/2406.08973",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Fudan,-Tsinghua-needle-in-a-multimodal-haystack",
      "date": "2024-06-W04",
      "year": "2024",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Fudan, Tsinghua",
      "title": "Needle In A Multimodal Haystack",
      "url": "https://arxiv.org/abs/2406.07230",
      "bullets": [
        {
          "text": "multimodal retrieval, counting, reasoning, 세 타입의 태스크를 포함",
          "level": 1
        }
      ],
      "tags": [
        "multimodal",
        "reasoning"
      ]
    },
    {
      "id": "DeepSeek-AI-deepseek-coder-v2-breaking-the-barrier-of-closed-source-models-in-code-intelligence",
      "date": "2024-06-W04",
      "year": "2024",
      "month": "6",
      "week": "4",
      "type": "dev",
      "org": "DeepSeek AI",
      "title": "DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence",
      "url": "https://github.com/deepseek-ai/DeepSeek-Coder-V2?tab=readme-ov-file",
      "bullets": [
        {
          "text": "338개 언어, 128K 컨텍스트 길이 지원",
          "level": 1
        },
        {
          "text": "코딩 벤치마크에서 GPT-4-turbo를 능가하는 퍼포먼스 달성",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Fudan,-Shanghai-accessing-gpt-4-level-mathematical-olympiad-solutions-via-monte-carlo-tree-self-refine-with-llama-3-8b",
      "date": "2024-06-W04",
      "year": "2024",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Fudan, Shanghai",
      "title": "Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B",
      "url": "https://arxiv.org/abs/2406.07394",
      "bullets": [
        {
          "text": "Selection, self-refine, self-evaluation, Backpropagation 과정을 반복하며 MCTS 수행",
          "level": 1
        },
        {
          "text": "이때 Upper Confidence Bound (UCB) 공식이 활용됨",
          "level": 2
        }
      ],
      "tags": []
    },
    {
      "id": "Google-DeepMind-generating-audio-for-video",
      "date": "2024-06-W04",
      "year": "2024",
      "month": "6",
      "week": "4",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "Generating audio for video",
      "url": "https://deepmind.google/discover/blog/generating-audio-for-video/",
      "bullets": [
        {
          "text": "positive - negative prompt를 구분할 수 있을 정도로 정교한 컨트롤이 가능해짐",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "runway-introducing-gen-3-alpha",
      "date": "2024-06-W04",
      "year": "2024",
      "month": "6",
      "week": "4",
      "type": "dev",
      "org": "runway",
      "title": "Introducing Gen-3 Alpha",
      "url": "https://runwayml.com/blog/introducing-gen-3-alpha/",
      "bullets": [
        {
          "text": "Sora의 등장 이후로 이와 같은 고해상도 비디오 생성 모델들의 발전이 빠르게 이어지고 있는 듯한 느낌이 듦",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Tisnghua-retrieval-meets-reasoning-dynamic-in-context-editing-for-long-text-understanding",
      "date": "2024-06-W04",
      "year": "2024",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Tisnghua",
      "title": "Retrieval Meets Reasoning: Dynamic In-Context Editing for Long-Text Understanding",
      "url": "https://arxiv.org/abs/2406.12331",
      "bullets": [
        {
          "text": "→ 긴 context를 malleable(벼릴 수 있는) 외부 지식으로 생각하고 이를 dynamic하게 모으거나 통합하는 방법론",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Cohere-back-to-basics-revisiting-reinforce-style-optimization-for-learning-from-human-feedback-in-llms",
      "date": "2024-06-W04",
      "year": "2024",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Cohere",
      "title": "Back to Basics: Revisiting REINFORCE Style Optimization for Learning from Human Feedback in LLMs",
      "url": "https://arxiv.org/abs/2402.14740",
      "bullets": [
        {
          "text": "→ PPO의 많은 요소가 RLHF에 불필요함을 입증 & DPO, RAFT와 같은 RL-free 방식이 PPO보다 뛰어나다는 것을 입증",
          "level": 1
        },
        {
          "text": "🧑🏻‍💻 [RLOO 알고리즘을 설명한 허깅페이스 블로그 링크](https://huggingface.co/blog/putting_rl_back_in_rlhf_with_rloo)",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Cohere-claude-35-sonnet",
      "date": "2024-06-W04",
      "year": "2024",
      "month": "6",
      "week": "4",
      "type": "dev",
      "org": "Cohere",
      "title": "Claude 3.5 Sonnet",
      "url": "https://www.anthropic.com/news/claude-3-5-sonnet",
      "bullets": [
        {
          "text": "뛰어난 coding 능력과 visual reasoning 능력을 강조",
          "level": 1
        },
        {
          "text": "code snippets & website design과 같이 AI-generated content와 상호작용 가능한 Artifacts 기능을 공개",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "University-of-Maryland-genqa-generating-millions-of-instructions-from-a-handful-of-prompts",
      "date": "2024-06-W04",
      "year": "2024",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "University of Maryland",
      "title": "GenQA: Generating Millions of Instructions from a Handful of Prompts",
      "url": "https://arxiv.org/abs/2406.10323",
      "bullets": [
        {
          "text": "→ single prompt로 large instruction datasets를 생성하는 방법을 제안",
          "level": 1
        },
        {
          "text": "simple completion task부터 complex multi-turn dialogs까지 다양한 태스크에 이르는 데이터셋을 생성 가능",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Georgia,-MIT-self-moe-towards-compositional-large-language-models-with-self-specialized-experts",
      "date": "2024-06-W04",
      "year": "2024",
      "month": "6",
      "week": "4",
      "type": "paper",
      "org": "Georgia, MIT",
      "title": "Self-MoE: Towards Compositional Large Language Models with Self-Specialized Experts",
      "url": "https://arxiv.org/abs/2406.12034",
      "bullets": [
        {
          "text": "self-generated 합성 데이터를 사용하여 expert module을 구축 + self-optimized routing으로 통합",
          "level": 1
        },
        {
          "text": "다른 방법론들에 비해 trade-off (학습하면 기존의 것을 까먹어 버리는 것에 대한)가 적은 편이라고 언급",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Meta-sharing-new-research-models-and-datasets-from-meta-fair",
      "date": "2024-06-W04",
      "year": "2024",
      "month": "6",
      "week": "4",
      "type": "dev",
      "org": "Meta",
      "title": "Sharing new research, models, and datasets from Meta FAIR",
      "url": "https://ai.meta.com/blog/meta-fair-research-new-releases/",
      "bullets": [
        {
          "text": "한 번에 여러 개의 토큰을 예측하는 Multi-Token Prediction ([HuggingFace](https://huggingface.co/facebook/multi-token-prediction) 🤗)",
          "level": 1
        },
        {
          "text": "Meta Joint Audio and Symbolic Conditioning for Temporally Controlled Text-to-Music Generation ([데모](https://pages.cs.huji.ac.il/adiyoss-lab/JASCO/) 🔗)",
          "level": 1
        },
        {
          "text": "최초의 audio 워터마크 기법 (faster & efficient detection), AudioSeal ([Github](https://pages.cs.huji.ac.il/adiyoss-lab/JASCO/) 🧑🏻‍💻)",
          "level": 1
        },
        {
          "text": "Partnership supporting the release of the PRISM dataset ([HuggingFace](https://huggingface.co/datasets/HannahRoseKirk/prism-alignment) 🤗, [Report](https://arxiv.org/abs/2404.16019) 📜)",
          "level": 1
        },
        {
          "text": "text-to-image 생성 시스템의 geographical 불균형을 측정 및 개선 ([Github](https://github.com/facebookresearch/DIG-In) 🧑🏻‍💻, [Dataset](https://github.com/facebookresearch/DIG-In/blob/main/task2_geode.csv) 🧑🏻‍💻)",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML",
        "multimodal"
      ]
    },
    {
      "id": "Zou-group-textgrad-automatic-differentiation-via-text",
      "date": "2024-06-W05",
      "year": "2024",
      "month": "6",
      "week": "5",
      "type": "paper",
      "org": "Zou group",
      "title": "TextGrad: Automatic \"Differentiation\" via Text",
      "url": "https://arxiv.org/abs/2406.07496v1",
      "bullets": [
        {
          "text": "compound AI 시스템의 개별 구성 요소를 LLM에 의해 제공되는 피드백으로 개선",
          "level": 0
        },
        {
          "text": "LLM은 general & rich 자연어로 피드백을 제공 → out-of-the-box 태스크도 잘 수행",
          "level": 0
        },
        {
          "text": "[깃허브 링크](https://github.com/zou-group/textgrad) 🔗",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Bloomberg-generate-then-ground-in-retrieval-augmented-generation-for-multi-hop-question-answering",
      "date": "2024-06-W05",
      "year": "2024",
      "month": "6",
      "week": "5",
      "type": "paper",
      "org": "Bloomberg",
      "title": "Generate-then-Ground in Retrieval-Augmented Generation for Multi-hop Question Answering",
      "url": "https://arxiv.org/abs/2406.14891",
      "bullets": [
        {
          "text": "→ generate-then-ground (GenGround) 프레임워크를 제시: 최종 답변이 도출될 때까지 두 단락을 번갈아보는 방식",
          "level": 0
        },
        {
          "text": "Generate: 더 간단한 single-hop question과 이에 대응하는 정답을 생성",
          "level": 0
        },
        {
          "text": "Ground: retrieved documnets에서 question-answer pair를 ground",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "USTC-retrieve-plan-generation-an-iterative-planning-and-answering-framework-for-knowledge-intensive-llm-generation",
      "date": "2024-06-W05",
      "year": "2024",
      "month": "6",
      "week": "5",
      "type": "paper",
      "org": "USTC",
      "title": "Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation",
      "url": "https://arxiv.org/abs/2406.14979",
      "bullets": [
        {
          "text": "→ Retrieve-Plan-Generation (RPG) 프레임워크를 제안",
          "level": 0
        },
        {
          "text": "Plan stage: subsequent generation을 가이드하는 plan tokens을 생성",
          "level": 0
        },
        {
          "text": "Answer stage: plan을 근거로 fine-grained paragraphs를 선택, 이를 바탕으로 futher answer 생성",
          "level": 0
        },
        {
          "text": "위 과정을 completion 될 때까지 반복",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Amherst,-Meta-judging-the-judges-evaluating-alignment-and-vulnerabilities-in-llms-as-judges",
      "date": "2024-06-W05",
      "year": "2024",
      "month": "6",
      "week": "5",
      "type": "paper",
      "org": "Amherst, Meta",
      "title": "Judging the Judges: Evaluating Alignment and Vulnerabilities in LLMs-as-Judges",
      "url": "https://arxiv.org/abs/2406.12624",
      "bullets": [
        {
          "text": "단순 의견 일치 비율 대신 Cohen’s Kappa Metric을 사용하는 것의 중요성을 강조",
          "level": 0
        },
        {
          "text": "여러 언어 모델을 비교(base, instruction-tuned)한 결과를 제시: 작은 모델을 잘 학습하면 큰 모델보다 뛰어남",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Andrej-Karpathy-httpsgithubcomkarpathyllm101n",
      "date": "2024-06-W05",
      "year": "2024",
      "month": "6",
      "week": "5",
      "type": "dev",
      "org": "Andrej Karpathy",
      "title": "https://github.com/karpathy/LLM101n",
      "url": "",
      "bullets": [
        {
          "text": "스토리텔링 AI LLM 구축 방법을 알려주는 강의를 담은 repo",
          "level": 0
        },
        {
          "text": "from scratch in Python, C and CUDA",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "ICL,-Tisnghua-entropy-based-decoding-for-retrieval-augmented-large-language-models",
      "date": "2024-06-W05",
      "year": "2024",
      "month": "6",
      "week": "5",
      "type": "paper",
      "org": "ICL, Tisnghua",
      "title": "Entropy-Based Decoding for Retrieval-Augmented Large Language Models",
      "url": "https://arxiv.org/abs/2406.17519",
      "bullets": [
        {
          "text": "→ training-free decoding method를 제안",
          "level": 0
        },
        {
          "text": "entropy-based document-parallel ensemble: retrieved 문서로부터 low-entropy distribution에 우선순위를 높이고자 함",
          "level": 0
        },
        {
          "text": "constrastive decoding 메커니즘을 통합",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-open-llm-leaderboard-2",
      "date": "2024-06-W05",
      "year": "2024",
      "month": "6",
      "week": "5",
      "type": "dev",
      "org": "HuggingFace",
      "title": "Open-llm-leaderboard 2",
      "url": "https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard",
      "bullets": [
        {
          "text": "Qwen2 72B instruct > llama 3 70B > CommandR",
          "level": 0
        },
        {
          "text": "MMLU-pro, GPQA, BBH 등 어려운 벤치마크 추가",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Peking,-HKUST,-MIT-efficient-continual-pre-training-by-mitigating-the-stability-gap",
      "date": "2024-06-W05",
      "year": "2024",
      "month": "6",
      "week": "5",
      "type": "paper",
      "org": "Peking, HKUST, MIT",
      "title": "Efficient Continual Pre-training by Mitigating the Stability Gap",
      "url": "https://arxiv.org/abs/2406.14833",
      "bullets": [
        {
          "text": "→ 이를 해결하기 위한 세 가지 학습 전략을 제시",
          "level": 0
        },
        {
          "text": "1. 여러 epoch 동안 적당한 사이즈의 subset으로 continual pre-training (single epoch, large corpus 대신)",
          "level": 0
        },
        {
          "text": "2. high-quality의 sub-corpus에 대해서만 pre-training",
          "level": 0
        },
        {
          "text": "3. pre-training data와의 갭을 줄여줄 수 있는 data mixture를 사용",
          "level": 0
        },
        {
          "text": "의료 도메인(Llama-3-Physician) 적용 결과를 제시",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "ByteDance,-MIT-IBM-selective-prompting-tuning-for-personalized-conversations-with-llm",
      "date": "2024-06-W05",
      "year": "2024",
      "month": "6",
      "week": "5",
      "type": "paper",
      "org": "ByteDance, MIT-IBM",
      "title": "Selective Prompting Tuning for Personalized Conversations with LLM",
      "url": "https://arxiv.org/abs/2406.18187",
      "bullets": [
        {
          "text": "개인화된 LLM을 만드는 방법론",
          "level": 0
        },
        {
          "text": "prompt engineering보다 fine-tuning이 원하는 답변을 생성할 가능성이 더 높더라 → Selective Prompt Tuning (SPT)",
          "level": 0
        },
        {
          "text": "soft prompts로 시작하고 학습 가능한 dense retriever를 사용하여 input context 기반 최적의 soft prompt를 dynamic하게 고르는 방식을 제안",
          "level": 0
        },
        {
          "text": "Context-Prompt Contrastive Learning & Prompt Fusion Learning",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "HuggingFace-the-fineweb-datasets-decanting-the-web-for-the-finest-text-data-at-scale",
      "date": "2024-06-W05",
      "year": "2024",
      "month": "6",
      "week": "5",
      "type": "paper",
      "org": "HuggingFace",
      "title": "The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale",
      "url": "https://arxiv.org/abs/2406.17557",
      "bullets": [
        {
          "text": "96개의 Common Crawl snapshot으로부터 15T token 데이터셋을 구축 for pretraining",
          "level": 0
        },
        {
          "text": "이 FineWeb으로부터 추가 filtering을 한 1.3T token 데이터셋 FineWeb-Edu 또한 공개",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Hong-Kong,-Tsinghua,-NVIDIA,-HKUST-unlocking-continual-learning-abilities-in-language-models",
      "date": "2024-06-W05",
      "year": "2024",
      "month": "6",
      "week": "5",
      "type": "paper",
      "org": "Hong Kong, Tsinghua, NVIDIA, HKUST",
      "title": "Unlocking Continual Learning Abilities in Language Models",
      "url": "https://arxiv.org/abs/2406.17245",
      "bullets": [
        {
          "text": "MIGU (MagnItude-based Gradient Updating for continual learning): LM의 linear layer에서 가장 큰 output 크기를 갖는 파라미터 업데이트에 집중하는 방식",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-gemma-2-is-now-available-to-researchers-and-developers",
      "date": "2024-06-W05",
      "year": "2024",
      "month": "6",
      "week": "5",
      "type": "dev",
      "org": "Google",
      "title": "Gemma 2 is now available to researchers and developers",
      "url": "https://blog.google/technology/developers/google-gemma-2/",
      "bullets": [
        {
          "text": "27B 모델의 경우 A100/H100 한 대에서 추론 가능",
          "level": 0
        },
        {
          "text": "[Kaggle](https://www.kaggle.com/models/google/gemma-2), [HuggingFace](https://huggingface.co/google/gemma-2-9b) 등에서 다운로드 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Tsinghua-aligning-teacher-with-student-preferences-for-tailored-training-data-generation",
      "date": "2024-06-W05",
      "year": "2024",
      "month": "6",
      "week": "5",
      "type": "paper",
      "org": "Tsinghua",
      "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
      "url": "https://arxiv.org/abs/2406.19227",
      "bullets": [
        {
          "text": "학생의 선호를 반영한 학습 예시를 생성 for Knowledge Distillation",
          "level": 0
        },
        {
          "text": "우선 teacher model이 draft question & rationale 생성 → 이에 대한 학생의 in-context learning 능력을 proxy로 사용 → teacher model을 학생의 선호에 DPO",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "CMU,-KAIST-learning-to-correct-for-qa-reasoning-with-black-box-llms",
      "date": "2024-06-W05",
      "year": "2024",
      "month": "6",
      "week": "5",
      "type": "paper",
      "org": "CMU, KAIST",
      "title": "Learning to Correct for QA Reasoning with Black-box LLMs",
      "url": "https://arxiv.org/abs/2406.18695",
      "bullets": [
        {
          "text": "→ CoBB (Correct for improving QA reasoning of Black-Box LLMs)",
          "level": 0
        },
        {
          "text": "불완전한 추론을 올바른 추론으로 Seq2Seq 매핑하는 학습된 adaptation 모델을 사용",
          "level": 0
        },
        {
          "text": "dataset과 sampled sub-dataset의 divergence를 최소화하기 위한 유전 알고리즘 적용",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "UC-Berkeley,-Toronto,-Anthropic-connecting-the-dots-llms-can-infer-and-verbalize-latent-structure-from-disparate-training-data",
      "date": "2024-06-W05",
      "year": "2024",
      "month": "6",
      "week": "5",
      "type": "paper",
      "org": "UC Berkeley, Toronto, Anthropic",
      "title": "Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data",
      "url": "https://arxiv.org/abs/2406.14546",
      "bullets": [
        {
          "text": "이를 inductive out-of-context (OOCR) 으로 표현",
          "level": 0
        },
        {
          "text": "작은 모델은 부족하지만, GPT-3.5, GPT-4 정도의 모델들은 충분 → 명시적으로 학습하지 않은 내용도 유추가 가능함을 입증. LLM 학습의 새로운 위험성을 제시.",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta-meta-large-language-model-compiler-foundation-models-of-compiler-optimization",
      "date": "2024-06-W05",
      "year": "2024",
      "month": "6",
      "week": "5",
      "type": "paper",
      "org": "Meta",
      "title": "Meta Large Language Model Compiler: Foundation Models of Compiler Optimization",
      "url": "https://ai.meta.com/research/publications/meta-large-language-model-compiler-foundation-models-of-compiler-optimization/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "UIUC,-Cohere,-Princeton-snapkv-llm-knows-what-you-are-looking-for-before-generation",
      "date": "2024-05-W01",
      "year": "2024",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "UIUC, Cohere, Princeton",
      "title": "SnapKV: LLM Knows What You are Looking for Before Generation",
      "url": "https://arxiv.org/abs/2404.14469",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-advprompter-fast-adaptive-adversarial-prompting-for-llms",
      "date": "2024-05-W01",
      "year": "2024",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "Meta",
      "title": "AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs",
      "url": "https://arxiv.org/abs/2404.16873",
      "bullets": [],
      "tags": []
    },
    {
      "id": "DeepLearning.AI-prompt-engineering-for-vision-models",
      "date": "2024-05-W01",
      "year": "2024",
      "month": "5",
      "week": "1",
      "type": "dev",
      "org": "DeepLearning.AI",
      "title": "Prompt Engineering for Vision Models",
      "url": "https://www.deeplearning.ai/short-courses/prompt-engineering-for-vision-models/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "MIT,-MyShell-openvoice",
      "date": "2024-05-W01",
      "year": "2024",
      "month": "5",
      "week": "1",
      "type": "dev",
      "org": "MIT, MyShell",
      "title": "OpenVoice",
      "url": "https://github.com/myshell-ai/OpenVoice",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Cohere-replacing-judges-with-juries-evaluating-llm-generations-with-a-panel-of-diverse-models",
      "date": "2024-05-W01",
      "year": "2024",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "Cohere",
      "title": "Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models",
      "url": "https://arxiv.org/abs/2404.18796",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Mystery-‘Gpt2-Chatbot’-And-Cryptic-Sam-Altman-Tweet-Fuel-Speculation-Over-OpenAI’s-Next-ChatGPT-Update-mystery-gpt2-chatbot-and-cryptic-sam-altman-tweet-fuel-speculation-over-openais-next-chatgpt-update",
      "date": "2024-05-W01",
      "year": "2024",
      "month": "5",
      "week": "1",
      "type": "news",
      "org": "Mystery ‘Gpt2-Chatbot’ And Cryptic Sam Altman Tweet Fuel Speculation Over OpenAI’s Next ChatGPT Update",
      "title": "Mystery ‘Gpt2-Chatbot’ And Cryptic Sam Altman Tweet Fuel Speculation Over OpenAI’s Next ChatGPT Update",
      "url": "https://www.forbes.com/sites/roberthart/2024/04/30/mystery-gpt2-chatbot-and-cryptic-sam-altman-tweet-fuel-speculation-over-openais-next-chatgpt-update/?sh=19ea4686384d",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Baidu-hft-half-fine-tuning-for-large-language-models",
      "date": "2024-05-W01",
      "year": "2024",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "Baidu",
      "title": "HFT: Half Fine-Tuning for Large Language Models",
      "url": "https://arxiv.org/abs/2404.18466",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Gradient-llama-3-8b-instruct-gradient-1048k",
      "date": "2024-05-W01",
      "year": "2024",
      "month": "5",
      "week": "1",
      "type": "dev",
      "org": "Gradient",
      "title": "LLama-3-8B-Instruct-Gradient-1048K",
      "url": "https://huggingface.co/gradientai/Llama-3-8B-Instruct-Gradient-1048k",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Bozewn-Bolzano-when-to-retrieve-teaching-llms-to-utilize-information-retrieval-effectively",
      "date": "2024-05-W01",
      "year": "2024",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "Bozewn-Bolzano",
      "title": "When to Retrieve: Teaching LLMs to Utilize Information Retrieval Effectively",
      "url": "https://arxiv.org/abs/2404.19705",
      "bullets": [],
      "tags": []
    },
    {
      "id": "UC-Berkeley-is-bigger-edit-batch-size-always-better-an-empirical-study-on-model-editing-with-llama-3",
      "date": "2024-05-W01",
      "year": "2024",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "UC Berkeley",
      "title": "Is Bigger Edit Batch Size Always Better? - An Empirical Study on Model Editing with Llama-3",
      "url": "https://arxiv.org/abs/2405.00664",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-better-faster-large-language-models-via-multi-token-prediction",
      "date": "2024-05-W01",
      "year": "2024",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "Meta",
      "title": "Better & Faster Large Language Models via Multi-token Prediction",
      "url": "https://arxiv.org/abs/2404.19737",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Hong-Kong-University-mixture-of-insightful-experts-mote-the-synergy-of-thought-chains-and-expert-mixtures-in-self-alignment",
      "date": "2024-05-W01",
      "year": "2024",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "Hong Kong University",
      "title": "Mixture of insighTful Experts (MoTE): The Synergy of Thought Chains and Expert Mixtures in Self-Alignment",
      "url": "https://arxiv.org/abs/2405.00557",
      "bullets": [],
      "tags": []
    },
    {
      "id": "KAIST-AI-prometheus-2-an-open-source-language-model-specialized-in-evaluating-other-language-models",
      "date": "2024-05-W01",
      "year": "2024",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "KAIST AI",
      "title": "Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models",
      "url": "https://arxiv.org/abs/2405.01535",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Virginia-context-aware-clustering-using-large-language-models",
      "date": "2024-05-W01",
      "year": "2024",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "Virginia",
      "title": "Context-Aware Clustering using Large Language Models",
      "url": "https://arxiv.org/abs/2405.00988",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Anthropic-introducing-the-claude-team-plan-and-ios-app",
      "date": "2024-05-W01",
      "year": "2024",
      "month": "5",
      "week": "1",
      "type": "dev",
      "org": "Anthropic",
      "title": "Introducing the Claude Team plan and iOS app",
      "url": "https://www.anthropic.com/news/team-plan-and-ios",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Predibase-lora-land-310-fine-tuned-llms-that-rival-gpt-4-a-technical-report",
      "date": "2024-05-W01",
      "year": "2024",
      "month": "5",
      "week": "1",
      "type": "paper",
      "org": "Predibase",
      "title": "LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report",
      "url": "https://arxiv.org/abs/2405.00732",
      "bullets": [],
      "tags": []
    },
    {
      "id": "MIT-kan-kolmogorov-arnold-networks",
      "date": "2024-05-W02",
      "year": "2024",
      "month": "5",
      "week": "2",
      "type": "paper",
      "org": "MIT",
      "title": "KAN: Kolmogorov-Arnold Networks",
      "url": "https://arxiv.org/abs/2404.19756",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Imperial-College-London-argumentative-large-language-models-for-explainable-and-contestable-decision-making",
      "date": "2024-05-W02",
      "year": "2024",
      "month": "5",
      "week": "2",
      "type": "paper",
      "org": "Imperial College London",
      "title": "Argumentative Large Language Models for Explainable and Contestable Decision-Making",
      "url": "https://arxiv.org/abs/2405.02079",
      "bullets": [],
      "tags": []
    },
    {
      "id": "X-x-launches-stories-delivering-news-summarized-by-grok-ai",
      "date": "2024-05-W02",
      "year": "2024",
      "month": "5",
      "week": "2",
      "type": "news",
      "org": "X",
      "title": "X launches Stories, delivering news summarized by Grok AI",
      "url": "https://techcrunch.com/2024/05/03/x-launches-stories-on-x-delivering-news-summarized-by-grok-ai/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "DeepLearning.AI-&-HuggingFace-quantization-in-depth",
      "date": "2024-05-W02",
      "year": "2024",
      "month": "5",
      "week": "2",
      "type": "dev",
      "org": "DeepLearning.AI & HuggingFace",
      "title": "Quantization In Depth",
      "url": "https://www.deeplearning.ai/short-courses/quantization-in-depth/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-Llama-3-120B-Instruct-meta-llama-3-120b-instruct",
      "date": "2024-05-W02",
      "year": "2024",
      "month": "5",
      "week": "2",
      "type": "dev",
      "org": "Meta-Llama-3-120B-Instruct",
      "title": "Meta-Llama-3-120B-Instruct",
      "url": "https://huggingface.co/mlabonne/Meta-Llama-3-120B-Instruct",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Nvidia-nvidia-launches-chatrtx-chatbot-for-rtx-gpus",
      "date": "2024-05-W02",
      "year": "2024",
      "month": "5",
      "week": "2",
      "type": "news",
      "org": "Nvidia",
      "title": "Nvidia Launches ChatRTX Chatbot for RTX GPUs",
      "url": "https://www.extremetech.com/computing/nvidia-launches-chatrtx-chatbot-for-rtx-gpus",
      "bullets": [],
      "tags": []
    },
    {
      "id": "LMSYS-gpt2-chatbot-is-back-online",
      "date": "2024-05-W02",
      "year": "2024",
      "month": "5",
      "week": "2",
      "type": "dev",
      "org": "LMSYS",
      "title": "gpt2-chatbot is Back Online",
      "url": "https://chat.lmsys.org/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "DeepSeek-AI-deepseek-v2-a-strong-economical-and-efficient-mixture-of-experts-language-model",
      "date": "2024-05-W02",
      "year": "2024",
      "month": "5",
      "week": "2",
      "type": "dev",
      "org": "DeepSeek-AI",
      "title": "DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model",
      "url": "https://github.com/deepseek-ai/DeepSeek-V2?tab=readme-ov-file",
      "bullets": [],
      "tags": []
    },
    {
      "id": "DeepLearning.AI-building-agentic-rag-with-llamaindex",
      "date": "2024-05-W02",
      "year": "2024",
      "month": "5",
      "week": "2",
      "type": "dev",
      "org": "DeepLearning.AI",
      "title": "Building Agentic RAG with LlamaIndex",
      "url": "https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "xLSTM:-Extended-Long-Short-Term-Memory-xlstm-extended-long-short-term-memory",
      "date": "2024-05-W02",
      "year": "2024",
      "month": "5",
      "week": "2",
      "type": "paper",
      "org": "xLSTM: Extended Long Short-Term Memory",
      "title": "xLSTM: Extended Long Short-Term Memory",
      "url": "https://arxiv.org/abs/2405.04517",
      "bullets": [],
      "tags": []
    },
    {
      "id": "MIT-co-design-for-efficient-llm-serving",
      "date": "2024-05-W02",
      "year": "2024",
      "month": "5",
      "week": "2",
      "type": "paper",
      "org": "MIT",
      "title": "Co-design for Efficient LLM Serving",
      "url": "https://arxiv.org/abs/2405.04532",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-meet-pixel-8a-the-google-ai-phone-at-an-unbeatable-value",
      "date": "2024-05-W02",
      "year": "2024",
      "month": "5",
      "week": "2",
      "type": "dev",
      "org": "Google",
      "title": "Meet Pixel 8a: The Google AI phone at an unbeatable value",
      "url": "https://blog.google/products/pixel/pixel-8a-launch/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "University-of-Texas-mitigating-exaggerated-safety-in-large-language-models",
      "date": "2024-05-W02",
      "year": "2024",
      "month": "5",
      "week": "2",
      "type": "paper",
      "org": "University of Texas",
      "title": "Mitigating Exaggerated Safety in Large Language Models",
      "url": "https://arxiv.org/abs/2405.05418",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-Research-does-fine-tuning-llms-on-new-knowledge-encourage-hallucinations",
      "date": "2024-05-W02",
      "year": "2024",
      "month": "5",
      "week": "2",
      "type": "paper",
      "org": "Google Research",
      "title": "Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?",
      "url": "https://arxiv.org/abs/2405.05904",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Anthropic-prompt-generator",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "dev",
      "org": "Anthropic",
      "title": "Prompt Generator",
      "url": "https://docs.anthropic.com/en/docs/prompt-generator",
      "bullets": [],
      "tags": []
    },
    {
      "id": "IBM-granite-code-models-a-family-of-open-foundation-models-for-code-intelligence",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "dev",
      "org": "IBM",
      "title": "Granite Code Models: A Family of Open Foundation Models for Code Intelligence",
      "url": "https://github.com/ibm-granite/granite-code-models",
      "bullets": [
        {
          "text": "논문 링크: https://arxiv.org/abs/2405.04324",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-hello-gpt-4o",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "Hello GPT-4o",
      "url": "https://openai.com/index/hello-gpt-4o/",
      "bullets": [
        {
          "text": "개인적인 교육 분야에서 특히 활용 여지가 많이 커진 것 같다고 느낌.",
          "level": 0
        },
        {
          "text": "[유튜브에 공개된 데모 링크](https://www.youtube.com/watch?v=DQacCB9tDaw&t=3986s)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Baidu-a-survey-on-rag-meets-llms-towards-retrieval-augmented-large-language-models",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "paper",
      "org": "Baidu",
      "title": "A Survey on RAG Meets LLMs: Towards Retrieval-Augmented Large Language Models",
      "url": "https://arxiv.org/abs/2405.06211",
      "bullets": [],
      "tags": []
    },
    {
      "id": "TII-falcon-2",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "dev",
      "org": "TII",
      "title": "Falcon 2",
      "url": "https://huggingface.co/tiiuae/falcon-11B",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Cohere-fishing-for-magikarp-automatically-detecting-under-trained-tokens-in-large-language-models",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "paper",
      "org": "Cohere",
      "title": "Fishing for Magikarp: Automatically Detecting Under-trained Tokens in Large Language Models",
      "url": "https://arxiv.org/abs/2405.05417",
      "bullets": [
        {
          "text": "‘tokenizer analysis, model weight-based indicators, prompting techniques’의 조합을 이용하여 위와 같은 problematic tokens를 자동적으로 detect 하는 방법론을 제안.",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-google-io-2024-an-io-for-a-new-generation",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "dev",
      "org": "Google",
      "title": "Google I/O 2024: An I/O for a new generation",
      "url": "https://blog.google/inside-google/message-ceo/google-io-2024-keynote-sundar-pichai/",
      "bullets": [
        {
          "text": "Gemini를 구글 제품(포토, 이미지 검색, 워크 스페이스, 이메일 등)에 통합하겠다고 발표. (라이브 데모 x, 여름 또는 올해 말 출시 예정 ????)",
          "level": 0
        },
        {
          "text": "GPT-4o와 마찬가지로 multimodality를 강조. 그러나 그만큼의 임팩트가 있지는 않음.",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Salesforce-sfr-iterative-dpo-llama-8b-r",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "dev",
      "org": "Salesforce",
      "title": "SFR-Iterative-DPO-LLaMA-8B-R",
      "url": "https://huggingface.co/Salesforce/SFR-Iterative-DPO-LLaMA-3-8B-R",
      "bullets": [],
      "tags": []
    },
    {
      "id": "HuggingFace-what-matters-when-building-vision-language-models",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "paper",
      "org": "HuggingFace",
      "title": "What matters when building vision-language models?",
      "url": "https://arxiv.org/abs/2405.02246",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Salesforce,-UIUC-rlhf-workflow-from-reward-modeling-to-online-rlhf",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "paper",
      "org": "Salesforce, UIUC",
      "title": "RLHF Workflow: From Reward Modeling to Online RLHF",
      "url": "https://arxiv.org/abs/2405.07863",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Hwawei-beyond-scaling-laws-understanding-transformer-performance-with-associative-memory",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "paper",
      "org": "Hwawei",
      "title": "Beyond Scaling Laws: Understanding Transformer Performance with Associative Memory",
      "url": "https://arxiv.org/abs/2405.08707",
      "bullets": [],
      "tags": []
    },
    {
      "id": "DeepLearning.AI-multi-ai-agent-systems-with-crewai",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "dev",
      "org": "DeepLearning.AI",
      "title": "Multi AI Agent Systems with crewAI",
      "url": "https://www.deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "OpenAI-improvements-to-data-analysis-in-chatgpt",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "Improvements to data analysis in ChatGPT",
      "url": "https://openai.com/index/improvements-to-data-analysis-in-chatgpt/",
      "bullets": [
        {
          "text": "차주부터 ChatGPT Plus, Team, Enterprise 유저들에게 공개.",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "University-of-Waterloo-unirag-universal-retrieval-augmentation-for-multi-modal-large-language-models",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "paper",
      "org": "University of Waterloo",
      "title": "UniRAG: Universal Retrieval Augmentation for Multi-Modal Large Language Models",
      "url": "https://arxiv.org/abs/2405.10311",
      "bullets": [],
      "tags": []
    },
    {
      "id": "OpenAI-&-Reddit-openai-strikes-reddit-deal-to-train-its-ai-on-your-posts",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "news",
      "org": "OpenAI & Reddit",
      "title": "OpenAI strikes Reddit deal to train its AI on your posts",
      "url": "https://www.theverge.com/2024/5/16/24158529/reddit-openai-chatgpt-api-access-advertising",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Columbia-University-lora-learns-less-and-forgets-less",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "paper",
      "org": "Columbia University",
      "title": "LoRA Learns Less and Forgets Less",
      "url": "https://arxiv.org/pdf/2405.09673",
      "bullets": [],
      "tags": []
    },
    {
      "id": "HuggingFace-hugging-face-x-langchain-a-new-partner-package-in-langchain",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "dev",
      "org": "HuggingFace",
      "title": "Hugging Face x LangChain : A new partner package in LangChain",
      "url": "https://huggingface.co/blog/langchain",
      "bullets": [],
      "tags": []
    },
    {
      "id": "TIGER-Lab-mmlu-pro",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "dev",
      "org": "TIGER-Lab",
      "title": "MMLU-Pro",
      "url": "https://huggingface.co/datasets/TIGER-Lab/MMLU-Pro",
      "bullets": [],
      "tags": []
    },
    {
      "id": "MIT-the-platonic-representation-hypothesis",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "paper",
      "org": "MIT",
      "title": "The Platonic Representation Hypothesis",
      "url": "https://arxiv.org/abs/2405.07987",
      "bullets": [
        {
          "text": "인공지능 모델의 발전 방향은 데이터 타입(언어의 종류, modality)과 무관할 것이라고 주장했던 사람이 생각남.",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Meta-chameleon-mixed-modal-early-fusion-foundation-models",
      "date": "2024-05-W03",
      "year": "2024",
      "month": "5",
      "week": "3",
      "type": "paper",
      "org": "Meta",
      "title": "Chameleon: Mixed-Modal Early-Fusion Foundation Models",
      "url": "https://arxiv.org/abs/2405.09818",
      "bullets": [],
      "tags": []
    },
    {
      "id": "University-of-Cambridge-zero-shot-tokenizer-transfer",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "University of Cambridge",
      "title": "Zero-Shot Tokenizer Transfer",
      "url": "https://arxiv.org/abs/2405.07883",
      "bullets": [
        {
          "text": "tokenizer를 입력으로 받고 이에 대응하는 embedding을 예측하도록 학습하는 hypernetwork를 제안 → encoder & decoder 둘 다에 일반화 가능하다는 것을 실험적으로 입증",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Alibaba-language-models-can-evaluate-themselves-via-probability-discrepancy",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "Alibaba",
      "title": "Language Models can Evaluate Themselves via Probability Discrepancy",
      "url": "https://arxiv.org/abs/2405.10516",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Stanford,-Toronto-observational-scaling-laws-and-the-predictability-of-language-model-performance",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "Stanford, Toronto",
      "title": "Observational Scaling Laws and the Predictability of Language Model Performance",
      "url": "https://arxiv.org/abs/2405.10938",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Korea-Univ.-horangi-한국어-llm-리더보드",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "Korea Univ.",
      "title": "Horangi 한국어 LLM 리더보드",
      "url": "https://wandb.ai/wandb-korea/korean-llm-leaderboard/reports/-LLM---Vmlldzo3MzIyNDE2?accessToken=95bffmg3gwblgohulknz7go3h66k11uqn1l3ytjma1uj3w0l0dwh1fywgsgpbdyy",
      "bullets": [
        {
          "text": "llm-jp-eval을 기반으로 llm-kr-eval을 구축",
          "level": 0
        },
        {
          "text": "Multi-turn 대화를 통해 생성 능력을 평가하는 MT-Bench를 포함",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Microsoft-mora-high-rank-updating-for-parameter-efficient-fine-tuning",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "Microsoft",
      "title": "MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning",
      "url": "https://arxiv.org/abs/2405.12130",
      "bullets": [
        {
          "text": "LoRA와 마찬가지로 학습 이후에는 weight matrix에 merge 되는 방식을 취함.",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "DeepLearning.AI-&-Qualcomm-introduction-to-on-device-ai",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "DeepLearning.AI & Qualcomm",
      "title": "Introduction to On-Device AI",
      "url": "https://www.deeplearning.ai/short-courses/introduction-to-on-device-ai/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "llama3-from-scratch-llama3-from-scratch",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "llama3-from-scratch",
      "title": "llama3-from-scratch",
      "url": "https://github.com/naklecha/llama3-from-scratch",
      "bullets": [
        {
          "text": "llama3의 구성 요소를 하나씩 간단히 살펴볼 수 있는 ipynb을 제공. meta로부터 weight를 받을 수 있는 공식 링크도 포함되어 있음.",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "ByteDance,-Alibaba-openrlhf-an-easy-to-use-scalable-and-high-performance-rlhf-framework",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "ByteDance, Alibaba",
      "title": "OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework",
      "url": "https://arxiv.org/abs/2405.11143",
      "bullets": [
        {
          "text": "Ray, vLLM, DeepSpeed와 같은 다양한 학습 기법들을 동원하며 Hugging Face와도 통합 가능.",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Anthropic-scaling-monosemanticity-extracting-interpretable-features-from-claude-3-sonnet",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet",
      "url": "https://transformer-circuits.pub/2024/scaling-monosemanticity/",
      "bullets": [
        {
          "text": "Claude 3 Sonnet을 통해 LLM의 interpretability와 관련된 실험을 진행하고 그 결과를 report",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "You-can-now-buy-a-4-foot-tall-humanoid-robot-for-$16K-you-can-now-buy-a-4-foot-tall-humanoid-robot-for-16k",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "news",
      "org": "You can now buy a 4-foot-tall humanoid robot for $16K",
      "title": "You can now buy a 4-foot-tall humanoid robot for $16K",
      "url": "https://arstechnica.com/gadgets/2024/05/unitree-starts-selling-16000-humanoid-robot/?utm_source=www.theaivalley.com",
      "bullets": [
        {
          "text": "[데모 영상](https://www.youtube.com/watch?v=GzX1qOIO1bE&t=58s)을 보면 굉장히 자연스럽고 다양한 동작을 지원함 (상당히 유연..;;)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Google-new-ai-tools-to-help-merchants-market-brands-and-products",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "Google",
      "title": "New AI tools to help merchants market brands and products",
      "url": "https://blog.google/products/shopping/google-generative-ai-marketing-features-may-2024/",
      "bullets": [
        {
          "text": "Product Studio에서 상품 이미지를 다른 배경이나 상황에 맞게끔 생성하여 다양한 연출이 가능",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Microsoft-whats-next-microsoft-build-continues-the-evolution-and-expansion-of-ai-tools-for-developers",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "Microsoft",
      "title": "What’s next: Microsoft Build continues the evolution and expansion of AI tools for developers",
      "url": "https://blogs.microsoft.com/blog/2024/05/21/whats-next-microsoft-build-continues-the-evolution-and-expansion-of-ai-tools-for-developers/",
      "bullets": [
        {
          "text": "Microsoft Copilots and GitHub Copilot",
          "level": 0
        },
        {
          "text": "New Copilot + PCs: PyTorch and a new Web Neural Network",
          "level": 0
        },
        {
          "text": "Real Time intelligence, partnerships with ADM, Khan Academy, Cognition AI",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-DeepMind-gemini-15-unlocking-multimodal-understanding-across-millions-of-tokens-of-context",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "url": "https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf",
      "bullets": [
        {
          "text": "경량화된 모델, Gemini 1.5 Flash에 대한 실험 결과도 함께 제시",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "University-of-Michigan-a-turing-test-of-whether-ai-chatbots-are-behaviorally-similar-to-humans",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "University of Michigan",
      "title": "A Turing test of whether AI chatbots are behaviorally similar to humans",
      "url": "https://www.pnas.org/doi/10.1073/pnas.2313925121",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Mistral-AI-mistral-7b-instruct-v03",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "Mistral AI",
      "title": "Mistral-7B-Instruct-v0.3",
      "url": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3",
      "bullets": [],
      "tags": []
    },
    {
      "id": "AIRI-your-transformer-is-secretly-linear",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "AIRI",
      "title": "Your Transformer is Secretly Linear",
      "url": "https://arxiv.org/abs/2405.12250",
      "bullets": [
        {
          "text": "이러한 linear block을 제거하더라도 모델의 성능에 거의 영향을 주지 않는다는 것이 관측됨",
          "level": 0
        },
        {
          "text": "pretraining 단계에서 linearity를 최소화하기 위해 cosine-similarity-based regularization을 도입",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Xi’an-Jiaotong-University-large-language-models-can-self-correct-with-minimal-effort",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "Xi’an Jiaotong University",
      "title": "Large Language Models Can Self-Correct with Minimal Effort",
      "url": "https://arxiv.org/abs/2405.14092",
      "bullets": [],
      "tags": []
    },
    {
      "id": "MIT-not-all-language-model-features-are-linear",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "MIT",
      "title": "Not All Language Model Features Are Linear",
      "url": "https://arxiv.org/abs/2405.14860",
      "bullets": [
        {
          "text": "이러한 주장과 달리 일부 언어 모델들은 inherently multi-dimensional representation을 갖는다는 것을 입증",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Xi’an-Jiaotong-University-quantifying-emergence-in-large-language-models",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "Xi’an Jiaotong University",
      "title": "Quantifying Emergence in Large Language Models",
      "url": "https://arxiv.org/abs/2405.12617v1",
      "bullets": [
        {
          "text": "→ 본 연구에서는 macroscopic(semantic) & microscopic(token) level에서 entropy reduction을 비교하여 strength of emergence를 quantify",
          "level": 0
        },
        {
          "text": "metric의 variance와 ICL에서 shot의 개수 등 사이의 상관 계수 등을 바탕으로 novel emergence pattern을 파악하고, 이를 통해 hallucination을 새로운 관점에서 해석",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "phidata-phidata",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "phidata",
      "title": "phidata",
      "url": "https://github.com/phidatahq/phidata",
      "bullets": [
        {
          "text": "Assistant = LLM + Memory(Chat History, Summaries, ...) + Knowledge(PDF, Docs, … ) + Tools(Search Web, Send Email, …)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "agent"
      ]
    },
    {
      "id": "Mistral-AI-mistral-finetune",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "dev",
      "org": "Mistral AI",
      "title": "mistral-finetune",
      "url": "https://github.com/mistralai/mistral-finetune",
      "bullets": [
        {
          "text": "대부분의 파라미터는 frozen & 1-2% 정도의 추가 파라미터로 학습 → A100 or H100 권장",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "EluetherAI-and-others-lessons-from-the-trenches-on-reproducible-evaluation-of-language-models",
      "date": "2024-05-W04",
      "year": "2024",
      "month": "5",
      "week": "4",
      "type": "paper",
      "org": "EluetherAI and others",
      "title": "Lessons from the Trenches on Reproducible Evaluation of Language Models",
      "url": "https://arxiv.org/abs/2405.14782",
      "bullets": [
        {
          "text": "언어 모델 평가의 공통된 한계점, research에서의 어려움을 최소화하는 방법, 이와 같은 이슈를 해소하는 데 적합한 오픈소스 라이브러리 Language Model Evaluation Harness (lm-eval)",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Fudan-University-aggregation-of-reasoning-a-hierarchical-framework-for-enhancing-answer-selection-in-large-language-models",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "Fudan University",
      "title": "Aggregation of Reasoning: A Hierarchical Framework for Enhancing Answer Selection in Large Language Models",
      "url": "https://arxiv.org/abs/2405.12939",
      "bullets": [
        {
          "text": "reasoning chain에 대한 평가를 기반으로 정답을 고르는 방식. dynamic sampling 활용.",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Cohere-cohere-for-ai-launches-aya-23-8-and-35-billion-parameter-open-weights-release",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "Cohere",
      "title": "Cohere For AI Launches Aya 23, 8 and 35 Billion Parameter Open Weights Release",
      "url": "https://cohere.com/blog/aya23",
      "bullets": [
        {
          "text": "대규모 multilingual instruction fine-tuning dataset으로 학습된 Aya 모델을 기반으로 발전",
          "level": 0
        },
        {
          "text": "[technical report on Aya 23](https://cohere.com/research/aya/aya-23-technical-report.pdf?ref=cohere-ai.ghost.io)",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "National-University-of-Singapore,-Salesforce-decompose-and-aggregate-a-step-by-step-interpretable-evaluation-framework",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "National University of Singapore, Salesforce",
      "title": "Decompose and Aggregate: A Step-by-Step Interpretable Evaluation Framework",
      "url": "https://arxiv.org/abs/2405.15329",
      "bullets": [
        {
          "text": "→ 평가 과정을 여러 개의 단계로 decompose 후 결과를 aggregate 하는 방법론을 제안. 이때 교육학적 관행을 근거로 여러 단계로 구분.",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "University-of-Virginia,-Princeton-Language-and-Intelligence-simpo-simple-preference-optimization-with-a-reference-free-reward",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "University of Virginia, Princeton Language and Intelligence",
      "title": "SimPO: Simple Preference Optimization with a Reference-Free Reward",
      "url": "https://arxiv.org/abs/2405.14734",
      "bullets": [
        {
          "text": "target reward margin을 사용하여 winning & losing response 간의 격차를 벌림",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "IEEE-wav-kan-wavelet-kolmogorov-arnold-networks",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "IEEE",
      "title": "Wav-KAN: Wavelet Kolmogorov-Arnold Networks",
      "url": "https://arxiv.org/abs/2405.12832",
      "bullets": [
        {
          "text": "wavelet function을 KAN 네트워크 구조에 통합함으로써 입력 데이터의 high-/low-frequency 요소들을 효율적으로 capture 할 수 있도록 함",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "xAI-series-b-funding-round",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "news",
      "org": "xAI",
      "title": "Series B Funding Round",
      "url": "https://x.ai/blog/series-b",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Fudna-University-tokenization-matters-degrading-large-language-models-through-challenging-their-tokenization",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "Fudna University",
      "title": "Tokenization Matters! Degrading Large Language Models through Challenging Their Tokenization",
      "url": "https://arxiv.org/abs/2405.17067",
      "bullets": [
        {
          "text": "다양한 오픈소스 LLM이 tokenization에서 겪는 어려움을 테스트하기 위한 ADT (Adversarial Dataset for Tokenizer) 구축",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-can-large-language-models-faithfully-express-their-intrinsic-uncertainty-in-words",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "Google",
      "title": "Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?",
      "url": "https://arxiv.org/abs/2405.16908",
      "bullets": [
        {
          "text": "intrinsic uncertainty를 확인하기 위해 모델의 intrinsic confidence와 실제 결정 간의 갭을 측정할 수 있는 faithful response uncertainty를 공식화하여 실험",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Meta-an-introduction-to-vision-language-modeling",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "Meta",
      "title": "An Introduction to Vision-Language Modeling",
      "url": "https://arxiv.org/abs/2405.17247",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-matryoshka-multimodal-models",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "Microsoft",
      "title": "Matryoshka Multimodal Models",
      "url": "",
      "bullets": [
        {
          "text": "Large Multimodal Models(LMMs)이 고해상도 이미지를 처리할 때 너무 많은 visual token을 학습해야 한다는 문제점이 존재",
          "level": 0
        },
        {
          "text": "Matryoshka 인형에 착안. visual content를 여러 coarse-to-fine granularities 정보로부터의 nested sets of visual tokens로 표현하는 방법을 학습.",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "DeepLearning.AI-ai-agentic-design-patterns-with-autogen",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "dev",
      "org": "DeepLearning.AI",
      "title": "AI Agentic Design Patterns with AutoGen",
      "url": "https://www.deeplearning.ai/short-courses/ai-agentic-design-patterns-with-autogen/",
      "bullets": [
        {
          "text": "Reflection, Tool use, Planning 등 다양한 agentic design pattern에 대해 학습",
          "level": 0
        }
      ],
      "tags": [
        "agent"
      ]
    },
    {
      "id": "National-University-of-Singapore-faithful-logical-reasoning-via-symbolic-chain-of-thought",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "National University of Singapore",
      "title": "Faithful Logical Reasoning via Symbolic Chain-of-Thought",
      "url": "https://arxiv.org/abs/2405.18357",
      "bullets": [
        {
          "text": "1. 자연어를 symbolic format으로 변경 2) 문제를 해결하기 위해 step-by-step plan을 구축 3) verifier가 translation & reasoning chain의 결과를 검증",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML",
        "reasoning"
      ]
    },
    {
      "id": "Karpathy-reproducing-gpt-2-124m-in-llmc-in-90-minutes-for-20",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "dev",
      "org": "Karpathy",
      "title": "Reproducing GPT-2 (124M) in llm.c in 90 minutes for $20",
      "url": "https://github.com/karpathy/llm.c/discussions/481",
      "bullets": [
        {
          "text": "124M 사이즈의 GPT-2를 A100x8를 사용하여 엄청나게 효율적으로 학습하는 방식을 공개",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Mistral-AI-codestral-hello-world",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "dev",
      "org": "Mistral AI",
      "title": "Codestral: Hello, World!",
      "url": "https://mistral.ai/news/codestral/",
      "bullets": [
        {
          "text": "22B 사이즈의 모델임에도 불구하고 Llama 3 70B, CodeLlama 70B 보다 뛰어난 성능을 보임",
          "level": 0
        },
        {
          "text": "[허깅페이스](https://huggingface.co/mistralai/Codestral-22B-v0.1)에서 다운로드 가능",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "The-University-of-Edinburgh-2bp-2-stage-backpropagation",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "The University of Edinburgh",
      "title": "2BP: 2-Stage Backpropagation",
      "url": "https://arxiv.org/abs/2405.18047",
      "bullets": [
        {
          "text": "→ 2-stage backporpagation(2BP)을 제안. 이를 통해 1.70x 향상된 throughput을 확인",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "OpenAI-openai-makes-chatgpt-4os-advanced-tools-available-to-users-in-free-tier",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "news",
      "org": "OpenAI",
      "title": "OpenAI makes ChatGPT-4o's advanced tools available to users in free tier",
      "url": "https://www.business-standard.com/technology/tech-news/openai-makes-chatgpt-4o-s-advanced-tools-available-to-users-in-free-tier-124053000880_1.html",
      "bullets": [
        {
          "text": "또한 browse, vision, data analysis, file uploads, GPTs 등의 기능도 이용 가능",
          "level": 0
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Meta-nearest-neighbor-speculative-decoding-for-llm-generation-and-attribution",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "Meta",
      "title": "Nearest Neighbor Speculative Decoding for LLM Generation and Attribution",
      "url": "https://arc.net/l/quote/bobbepsa",
      "bullets": [
        {
          "text": "이를 해결하기 위해 임의 길이의 real-world text spans를 LM 생성 과정에 통합하는 Nearest Neighbor Speculative Decoding (NEST)를 제안 → token-level의 retrieval을 매 inference step마다 수행",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "Adobe-calibrating-reasoning-in-language-models-with-internal-consistency",
      "date": "2024-05-W05",
      "year": "2024",
      "month": "5",
      "week": "5",
      "type": "paper",
      "org": "Adobe",
      "title": "Calibrating Reasoning in Language Models with Internal Consistency",
      "url": "https://arc.net/l/quote/tmcvuipx",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Anthropic-prompt-library",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "dev",
      "org": "Anthropic",
      "title": "Prompt library",
      "url": "https://docs.anthropic.com/claude/prompt-library",
      "bullets": [],
      "tags": []
    },
    {
      "id": "xAI-announcing-grok-15",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "dev",
      "org": "xAI",
      "title": "Announcing Grok-1.5",
      "url": "https://x.ai/blog/grok-1.5",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Can-LLMs-Learn-from-Previous-Mistakes?-Investigating-LLMs'-Errors-to-Boost-for-Reasoning-can-llms-learn-from-previous-mistakes-investigating-llms-errors-to-boost-for-reasoning",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "Can LLMs Learn from Previous Mistakes? Investigating LLMs' Errors to Boost for Reasoning",
      "title": "Can LLMs Learn from Previous Mistakes? Investigating LLMs' Errors to Boost for Reasoning",
      "url": "https://arxiv.org/abs/2403.20046",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-the-unreasonable-ineffectiveness-of-the-deeper-layers",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "Meta",
      "title": "The Unreasonable Ineffectiveness of the Deeper Layers",
      "url": "https://arxiv.org/abs/2403.17887v1",
      "bullets": [],
      "tags": []
    },
    {
      "id": "OpenAI-navigating-the-challenges-and-opportunities-of-synthetic-voices",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "dev",
      "org": "OpenAI",
      "title": "Navigating the Challenges and Opportunities of Synthetic Voices",
      "url": "https://openai.com/blog/navigating-the-challenges-and-opportunities-of-synthetic-voices",
      "bullets": [],
      "tags": []
    },
    {
      "id": "AI21labs-jamba-a-hybrid-transformer-mamba-language-model",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "AI21labs",
      "title": "Jamba: A Hybrid Transformer-Mamba Language Model",
      "url": "https://arxiv.org/abs/2403.19887",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind-gecko-versatile-text-embeddings-distilled-from-large-language-models",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Gecko: Versatile Text Embeddings Distilled from Large Language Models",
      "url": "https://arxiv.org/abs/2403.20327",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Apple-realm-reference-resolution-as-language-modeling",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "Apple",
      "title": "ReALM: Reference Resolution As Language Modeling",
      "url": "https://arxiv.org/abs/2403.20329",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-and-OpenAI-pledge-$100-billion-for-‘Stargate’-supercomputer-facility-microsoft-and-openai-pledge-100-billion-for-stargate-supercomputer-facility",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "news",
      "org": "Microsoft and OpenAI pledge $100 billion for ‘Stargate’ supercomputer facility",
      "title": "Microsoft and OpenAI pledge $100 billion for ‘Stargate’ supercomputer facility",
      "url": "https://interestingengineering.com/culture/microsoft-and-openai-want-to-build-a-100-billion-datacenter",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-injecting-new-knowledge-into-large-language-models-via-supervised-fine-tuning",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "Microsoft",
      "title": "Injecting New Knowledge into Large Language Models via Supervised Fine-Tuning",
      "url": "https://arxiv.org/abs/2404.00213",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Naver-Cloud-hyperclova-x-technical-report",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "Naver Cloud",
      "title": "HyperCLOVA X Technical Report",
      "url": "https://arxiv.org/abs/2404.01954",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Anthropic-many-shot-jailbreaking",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "Anthropic",
      "title": "Many-shot jailbreaking",
      "url": "https://www.anthropic.com/research/many-shot-jailbreaking",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Efficient-Prompting-Methods-for-Large-Language-Models:-A-Survey-efficient-prompting-methods-for-large-language-models-a-survey",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "Efficient Prompting Methods for Large Language Models: A Survey",
      "title": "Efficient Prompting Methods for Large Language Models: A Survey",
      "url": "https://arxiv.org/abs/2404.01077",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Beyond-Accuracy:-Evaluating-the-Reasoning-Behavior-of-Large-Language-Models-A-Survey-beyond-accuracy-evaluating-the-reasoning-behavior-of-large-language-models-a-survey",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models -- A Survey",
      "title": "Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models -- A Survey",
      "url": "https://arxiv.org/abs/2404.01869",
      "bullets": [],
      "tags": []
    },
    {
      "id": "University-of-Waterloo,-CMU-long-context-llms-struggle-with-long-in-context-learning",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "University of Waterloo, CMU",
      "title": "Long-context LLMs Struggle with Long In-context Learning",
      "url": "https://arxiv.org/abs/2404.02060",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Tsinghua-University,-UIUC-advancing-llm-reasoning-generalists-with-preference-trees",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "Tsinghua University, UIUC",
      "title": "Advancing LLM Reasoning Generalists with Preference Trees",
      "url": "https://arxiv.org/abs/2404.02078",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind-mixture-of-depths-dynamically-allocating-compute-in-transformer-based-language-models",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Mixture-of-Depths: Dynamically allocating compute in transformer-based language models",
      "url": "https://arxiv.org/abs/2404.02258",
      "bullets": [],
      "tags": []
    },
    {
      "id": "DALL-E-now-lets-you-edit-images-in-ChatGPT-dall-e-now-lets-you-edit-images-in-chatgpt",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "news",
      "org": "DALL-E now lets you edit images in ChatGPT",
      "title": "DALL-E now lets you edit images in ChatGPT",
      "url": "https://www.theverge.com/2024/4/3/24120181/openai-dall-e-chat-gpt-image-edit",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Anthropic-claude-can-now-use-tools-1",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "dev",
      "org": "Anthropic",
      "title": "Claude can now use tools",
      "url": "https://docs.anthropic.com/claude/docs/tool-use",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind,-Anthropic-training-llms-over-neurally-compressed-text",
      "date": "2024-04-W01",
      "year": "2024",
      "month": "4",
      "week": "1",
      "type": "paper",
      "org": "Google DeepMind, Anthropic",
      "title": "Training LLMs over Neurally Compressed Text",
      "url": "https://arxiv.org/abs/2404.03626",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Stability-AI-introducing-stable-audio-20",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "dev",
      "org": "Stability AI",
      "title": "Introducing Stable Audio 2.0",
      "url": "https://stability.ai/news/stable-audio-2-0",
      "bullets": [],
      "tags": []
    },
    {
      "id": "MyShell,-MIT-IBM,-Princeton,-Lepton-AI-jetmoe-reaching-llama2-performance-with-01m-dollars",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "dev",
      "org": "MyShell, MIT-IBM, Princeton, Lepton AI",
      "title": "JetMoE: Reaching LLaMA2 Performance with 0.1M Dollars",
      "url": "https://research.myshell.ai/jetmoe",
      "bullets": [],
      "tags": []
    },
    {
      "id": "University-of-Copenhagen,-Google-DeepMind-mulan-a-study-of-fact-mutability-in-language-models",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "University of Copenhagen, Google DeepMind",
      "title": "MuLan: A Study of Fact Mutability in Language Models",
      "url": "https://arxiv.org/abs/2404.03036",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Stanford,-MIT-stream-of-search-sos-learning-to-search-in-language",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "Stanford, MIT",
      "title": "Stream of Search (SoS): Learning to Search in Language",
      "url": "https://arxiv.org/abs/2404.03683",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Stanford,-Georgia-social-skill-training-with-large-language-models",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "Stanford, Georgia",
      "title": "Social Skill Training with Large Language Models",
      "url": "https://arxiv.org/abs/2404.04204",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-Research-models-to-self-improve-with-general-preferences",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "Microsoft Research",
      "title": "Models to Self-Improve with General Preferences",
      "url": "https://arxiv.org/abs/2404.03715",
      "bullets": [],
      "tags": []
    },
    {
      "id": "W&B-weight-biases-docs",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "dev",
      "org": "W&B",
      "title": "Weight & Biases Docs",
      "url": "https://docs.wandb.ai/ko/?mkt_tok=MjYxLVFIUC04MjIAAAGSX8W79t-qKeYqkWAB6xTAK2R-027DfjjyAUi4hj32ywDET-u3DS8zoc8EGTXUmD6FeRTJjKotiQYg8qjBWT3683U-z133NpaQSmQJ8gRp",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Tesla-robotaxi-1",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "dev",
      "org": "Tesla",
      "title": "Robotaxi",
      "url": "https://twitter.com/elonmusk/status/1776351450542768368",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Andrej-Karpathy-llmc",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "dev",
      "org": "Andrej Karpathy",
      "title": "llm.c",
      "url": "https://github.com/karpathy/llm.c",
      "bullets": [],
      "tags": []
    },
    {
      "id": "3Blue1Brown-attention-in-transformers-visually-explained",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "dev",
      "org": "3Blue1Brown",
      "title": "Attention in transformers, visually explained",
      "url": "https://www.youtube.com/watch?v=eMlx5fFNoYc&t=27s",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Mila,-McGil-llm2vec-large-language-models-are-secretly-powerful-text-encoders",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "Mila, McGil",
      "title": "LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders",
      "url": "https://arxiv.org/abs/2404.05961",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-leave-no-context-behind-efficient-infinite-context-transformers-with-infini-attention",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "Google",
      "title": "Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention",
      "url": "https://arxiv.org/abs/2404.07143",
      "bullets": [],
      "tags": []
    },
    {
      "id": "NVIDIA-ruler-whats-the-real-context-size-of-your-long-context-language-models",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "NVIDIA",
      "title": "RULER: What's the Real Context Size of Your Long-Context Language Models?",
      "url": "https://arxiv.org/abs/2404.06654",
      "bullets": [],
      "tags": []
    },
    {
      "id": "UIUC-graph-chain-of-thought-augmenting-large-language-models-by-reasoning-on-graphs",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "UIUC",
      "title": "Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs",
      "url": "https://arxiv.org/abs/2404.07103",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Apple-superposition-prompting-improving-and-accelerating-retrieval-augmented-generation",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "Apple",
      "title": "Superposition Prompting: Improving and Accelerating Retrieval-Augmented Generation",
      "url": "https://arxiv.org/abs/2404.06910",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Tsinghua,-Microsoft-rho-1-not-all-tokens-are-what-you-need",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "Tsinghua, Microsoft",
      "title": "Rho-1: Not All Tokens Are What You Need",
      "url": "https://arxiv.org/abs/2404.07965",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind-recurrentgemma-moving-past-transformers-for-efficient-open-language-models",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "RecurrentGemma: Moving Past Transformers for Efficient Open Language Models",
      "url": "https://arxiv.org/abs/2404.07839",
      "bullets": [],
      "tags": []
    },
    {
      "id": "IBM-ibm-watsonx-chat",
      "date": "2024-04-W02",
      "year": "2024",
      "month": "4",
      "week": "2",
      "type": "dev",
      "org": "IBM",
      "title": "IBM watsonx chat",
      "url": "https://dataplatform.cloud.ibm.com/chat/login?redirect_url=%2Fchat%2F",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Mistral-mixtral-8x22b-v01-4bit",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "Mistral",
      "title": "Mixtral-8x22B-v0.1-4bit",
      "url": "https://huggingface.co/mistral-community/Mixtral-8x22B-v0.1-4bit",
      "bullets": [],
      "tags": []
    },
    {
      "id": "xAI-grok-15-vision-preview",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "xAI",
      "title": "Grok-1.5 Vision Preview",
      "url": "https://x.ai/blog/grok-1.5v",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-codegemma-open-code-models-based-on-gemma",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "paper",
      "org": "Google",
      "title": "CodeGemma: Open Code Models Based on Gemma",
      "url": "https://storage.googleapis.com/deepmind-media/gemma/codegemma_report.pdf",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-is-testing-an-AI-powered-search-bar-in-Instagram-meta-is-testing-an-ai-powered-search-bar-in-instagram",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "news",
      "org": "Meta is testing an AI-powered search bar in Instagram",
      "title": "Meta is testing an AI-powered search bar in Instagram",
      "url": "https://techcrunch.com/2024/04/12/meta-is-testing-an-ai-powered-search-bar-in-instagram/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "DeepLearning.AI-quantization-fundamentals-with-huggingface",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "DeepLearning.AI",
      "title": "Quantization Fundamentals with HuggingFace",
      "url": "https://www.deeplearning.ai/short-courses/quantization-fundamentals-with-hugging-face/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Sample-Efficient-Human-Evaluation-of-Large-Language-Models-via-Maximum-Discrepancy-Competition-sample-efficient-human-evaluation-of-large-language-models-via-maximum-discrepancy-competition",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "paper",
      "org": "Sample-Efficient Human Evaluation of Large Language Models via Maximum Discrepancy Competition",
      "title": "Sample-Efficient Human Evaluation of Large Language Models via Maximum Discrepancy Competition",
      "url": "https://arxiv.org/abs/2404.08008",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Tinkoff-learn-your-reference-model-for-real-good-alignment",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "paper",
      "org": "Tinkoff",
      "title": "Learn Your Reference Model for Real Good Alignment",
      "url": "https://arxiv.org/abs/2404.09656",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-transformerfam-feedback-attention-is-working-memory",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "paper",
      "org": "Google",
      "title": "TransformerFAM: Feedback attention is working memory",
      "url": "https://arxiv.org/abs/2404.09173",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta,-CMU-megalodon-efficient-llm-pretraining-and-inference-with-unlimited-context-length",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "paper",
      "org": "Meta, CMU",
      "title": "Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length",
      "url": "https://arxiv.org/abs/2404.08801",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-gemma-11-version-released",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "news",
      "org": "Google",
      "title": "Gemma-1.1 version released",
      "url": "https://huggingface.co/google/gemma-1.1-7b-it",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Cambridge,-Michigan,-Oxford,-Stanford,-etc-foundational-challenges-in-assuring-alignment-and-safety-of-large-language-models",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "paper",
      "org": "Cambridge, Michigan, Oxford, Stanford, etc",
      "title": "Foundational Challenges in Assuring Alignment and Safety of Large Language Models",
      "url": "https://arxiv.org/abs/2404.09932",
      "bullets": [],
      "tags": []
    },
    {
      "id": "UT-Austin-pre-training-small-base-lms-with-fewer-tokens",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "paper",
      "org": "UT Austin",
      "title": "Pre-training Small Base LMs with Fewer Tokens",
      "url": "https://arxiv.org/abs/2404.08634",
      "bullets": [],
      "tags": []
    },
    {
      "id": "KAIST-self-explore-to-avoid-the-pit-improving-the-reasoning-capabilities-of-language-models-with-fine-grained-rewards",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "paper",
      "org": "KAIST",
      "title": "Self-Explore to Avoid the Pit: Improving the Reasoning Capabilities of Language Models with Fine-grained Rewards",
      "url": "https://arxiv.org/abs/2404.10346",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Upstage-evalverse-revolutionizing-large-language-model-evaluation-with-a-unified-user-friendly-framework",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "Upstage",
      "title": "Evalverse: Revolutionizing Large Language Model Evaluation with a Unified, User-Friendly Framework",
      "url": "https://www.upstage.ai/feed/tech/evalverse-llm-evaluation-opensource",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-vasa-1-lifelike-audio-driven-talking-facesgenerated-in-real-time",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "Microsoft",
      "title": "VASA-1: Lifelike Audio-Driven Talking FacesGenerated in Real Time",
      "url": "https://www.microsoft.com/en-us/research/project/vasa-1/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-build-the-future-of-ai-with-meta-llama-3",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "Meta",
      "title": "Build the future of AI with Meta Llama 3",
      "url": "https://llama.meta.com/llama3/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-tune-in-for-google-io",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "Google",
      "title": "Tune in for Google I/O",
      "url": "https://io.google/2024/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "AI2-olmo-177b-a-24-point-improvement-on-mmlu",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "AI2",
      "title": "OLMo 1.7–7B: A 24 point improvement on MMLU",
      "url": "https://blog.allenai.org/olmo-1-7-7b-a-24-point-improvement-on-mmlu-92b43f7d269d",
      "bullets": [],
      "tags": []
    },
    {
      "id": "PyTorch-torchtune",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "PyTorch",
      "title": "torchtune",
      "url": "https://github.com/pytorch/torchtune",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind-many-shot-in-context-learning",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Many-Shot In-Context Learning",
      "url": "https://arxiv.org/abs/2404.11018",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-Research-position-engineering-boosting-large-language-models-through-positional-information-manipulation",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "paper",
      "org": "Microsoft Research",
      "title": "Position Engineering: Boosting Large Language Models through Positional Information Manipulation",
      "url": "https://arxiv.org/abs/2404.11216",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Tencent-AI-toward-self-improvement-of-llms-via-imagination-searching-and-criticizing",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "paper",
      "org": "Tencent AI",
      "title": "Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing",
      "url": "https://arxiv.org/abs/2404.12253",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-adds-its-AI-chatbot,-powered-by-Llama-3,-to-the-search-bar-across-its-apps-meta-adds-its-ai-chatbot-powered-by-llama-3-to-the-search-bar-across-its-apps",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "news",
      "org": "Meta adds its AI chatbot, powered by Llama 3, to the search bar across its apps",
      "title": "Meta adds its AI chatbot, powered by Llama 3, to the search bar across its apps",
      "url": "https://techcrunch.com/2024/04/18/meta-adds-its-ai-chatbot-powered-by-llama-3-to-the-search-bar-across-its-apps/?utm_source=www.theaivalley.com&utm_medium=newsletter&utm_campaign=meta-ai-vs-chatgpt-begins-now",
      "bullets": [],
      "tags": []
    },
    {
      "id": "CMU,-Meta-AI-triforce-lossless-acceleration-of-long-sequence-generation-with-hierarchical-speculative-decoding",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "paper",
      "org": "CMU, Meta AI",
      "title": "TriForce: Lossless Acceleration of Long Sequence Generation with Hierarchical Speculative Decoding",
      "url": "https://arxiv.org/abs/2404.11912",
      "bullets": [],
      "tags": []
    },
    {
      "id": "OpenAI-introducing-openai-japan",
      "date": "2024-04-W03",
      "year": "2024",
      "month": "4",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "Introducing OpenAI Japan",
      "url": "https://openai.com/blog/introducing-openai-japan",
      "bullets": [],
      "tags": []
    },
    {
      "id": "HuggingFace-fineweb",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "HuggingFace",
      "title": "FineWeb",
      "url": "https://huggingface.co/datasets/HuggingFaceFW/fineweb",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Epoch-AI-chinchilla-scaling-a-replication-attempt",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Epoch AI",
      "title": "Chinchilla Scaling: A replication attempt",
      "url": "https://arxiv.org/abs/2404.10102",
      "bullets": [],
      "tags": []
    },
    {
      "id": "State-Space-Model-for-New-Generation-Network-Alternative-to-Transformers:-A-Survey-state-space-model-for-new-generation-network-alternative-to-transformers-a-survey",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "State Space Model for New-Generation Network Alternative to Transformers: A Survey",
      "title": "State Space Model for New-Generation Network Alternative to Transformers: A Survey",
      "url": "https://arxiv.org/abs/2404.09516",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Stanford-how-faithful-are-rag-models-quantifying-the-tug-of-war-between-rag-and-llms-internal-prior",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Stanford",
      "title": "How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs' internal prior",
      "url": "https://arxiv.org/abs/2404.10198",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Stanford-2024-ai-index-report",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Stanford",
      "title": "2024 AI Index Report",
      "url": "https://aiindex.stanford.edu/report/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Fudan-University-autocrawler-a-progressive-understanding-web-agent-for-web-crawler-generation",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Fudan University",
      "title": "AutoCrawler: A Progressive Understanding Web Agent for Web Crawler Generation",
      "url": "https://arxiv.org/abs/2404.12753",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Towards-Logically-Consistent-Language-Models-via-Probabilistic-Reasoning-towards-logically-consistent-language-models-via-probabilistic-reasoning",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Towards Logically Consistent Language Models via Probabilistic Reasoning",
      "title": "Towards Logically Consistent Language Models via Probabilistic Reasoning",
      "url": "https://arxiv.org/abs/2404.12843",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Nanyang-Technological-University-relevant-or-random-can-llms-truly-perform-analogical-reasoning",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Nanyang Technological University",
      "title": "Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?",
      "url": "https://arxiv.org/abs/2404.12728",
      "bullets": [],
      "tags": []
    },
    {
      "id": "DeepLearning.AI-getting-started-with-mistral",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "DeepLearning.AI",
      "title": "Getting Started with Mistral",
      "url": "https://www.deeplearning.ai/short-courses/getting-started-with-mistral/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Cookbook-efficiently-fine-tune-llama-3-with-pytorch-fsdp-and-q-lora",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "Cookbook",
      "title": "Efficiently fine-tune Llama 3 with PyTorch FSDP and Q-Lora",
      "url": "https://www.philschmid.de/fsdp-qlora-llama3",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-phi-3-technical-report-a-highly-capable-language-model-locally-on-your-phone",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Microsoft",
      "title": "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone",
      "url": "https://arxiv.org/abs/2404.14219",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Adobe-generative-ai-in-premiere-pro-powered-by-adobe-firefly-adobe-video",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "Adobe",
      "title": "Generative AI in Premiere Pro powered by Adobe Firefly | Adobe Video",
      "url": "https://www.youtube.com/watch?v=6de4akFiNYM",
      "bullets": [],
      "tags": []
    },
    {
      "id": "OpenAI-the-instruction-hierarchy-training-llms-to-prioritize-privileged-instructions",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "OpenAI",
      "title": "The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions",
      "url": "https://arxiv.org/abs/2404.13208",
      "bullets": [],
      "tags": []
    },
    {
      "id": "CMU-treacle-thrifty-reasoning-via-context-aware-llm-and-prompt-selection",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "CMU",
      "title": "TREACLE: Thrifty Reasoning via Context-Aware LLM and Prompt Selection",
      "url": "https://arxiv.org/abs/2404.13082",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Zhejiang-University-information-re-organization-improves-reasoning-in-large-language-models",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Zhejiang University",
      "title": "Information Re-Organization Improves Reasoning in Large Language Models",
      "url": "https://arxiv.org/abs/2404.13985",
      "bullets": [],
      "tags": []
    },
    {
      "id": "vals.ai-benchmarks-for-industry",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "vals.ai",
      "title": "Benchmarks for Industry",
      "url": "https://www.vals.ai/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Achieving->97%-on-GSM8K:-Deeply-Understanding-the-Problems-Makes-LLMs-Perfect-Reasoners-achieving-97-on-gsm8k-deeply-understanding-the-problems-makes-llms-perfect-reasoners",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Achieving >97% on GSM8K: Deeply Understanding the Problems Makes LLMs Perfect Reasoners",
      "title": "Achieving >97% on GSM8K: Deeply Understanding the Problems Makes LLMs Perfect Reasoners",
      "url": "https://arxiv.org/abs/2404.14963",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Tsinghua-University-multi-head-mixture-of-experts",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Tsinghua University",
      "title": "Multi-Head Mixture-of-Experts",
      "url": "https://arxiv.org/pdf/2404.15045",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Apple-openelm-an-efficient-language-model-family-with-open-source-training-and-inference-framework",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Apple",
      "title": "OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework",
      "url": "https://arxiv.org/pdf/2404.14619",
      "bullets": [],
      "tags": []
    },
    {
      "id": "The-Ray-Ban-Meta-Smart-Glasses-have-multimodal-AI-now-the-ray-ban-meta-smart-glasses-have-multimodal-ai-now",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "news",
      "org": "The Ray-Ban Meta Smart Glasses have multimodal AI now",
      "title": "The Ray-Ban Meta Smart Glasses have multimodal AI now",
      "url": "https://www.theverge.com/2024/4/23/24138090/ray-ban-meta-smart-glasses-ai-wearables",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Adobe-beyond-chain-of-thought-a-survey-of-chain-of-x-paradigms-for-llms",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Adobe",
      "title": "Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs",
      "url": "https://arxiv.org/abs/2404.15676",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-towards-systematic-evaluation-of-logical-reasoning-ability-of-large-language-models",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Microsoft",
      "title": "Towards Systematic Evaluation of Logical Reasoning Ability of Large Language Models",
      "url": "https://arxiv.org/abs/2404.15522",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-layerskip-enabling-early-exit-inference-and-self-speculative-decoding",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Meta",
      "title": "LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding",
      "url": "https://arxiv.org/abs/2404.16710",
      "bullets": [],
      "tags": []
    },
    {
      "id": "PyTorch-pytorch-23-release-blog",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "PyTorch",
      "title": "PyTorch 2.3 Release Blog",
      "url": "https://pytorch.org/blog/pytorch2-3/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Snowflake-snowflake-arctic-instruct",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "dev",
      "org": "Snowflake",
      "title": "snowflake-arctic-instruct",
      "url": "https://huggingface.co/Snowflake/snowflake-arctic-instruct",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Peking,-Microsoft-make-your-llm-fully-utilize-the-context",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "paper",
      "org": "Peking, Microsoft",
      "title": "Make Your LLM Fully Utilize the Context",
      "url": "https://arxiv.org/abs/2404.16811",
      "bullets": [],
      "tags": []
    },
    {
      "id": "China-Unveils-Vidu:-A-Powerful-Text-to-Video-Generator-china-unveils-vidu-a-powerful-text-to-video-generator",
      "date": "2024-04-W04",
      "year": "2024",
      "month": "4",
      "week": "4",
      "type": "news",
      "org": "China Unveils Vidu: A Powerful Text-to-Video Generator",
      "title": "China Unveils Vidu: A Powerful Text-to-Video Generator",
      "url": "https://www.maginative.com/article/china-unveils-vidu-a-powerful-text-to-video-generator/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Robotics-startup-Figure-raises-$675-mln-from-Microsoft,-Nvidia,-OpenAI-robotics-startup-figure-raises-675-mln-from-microsoft-nvidia-openai",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "news",
      "org": "Robotics startup Figure raises $675 mln from Microsoft, Nvidia, OpenAI",
      "title": "Robotics startup Figure raises $675 mln from Microsoft, Nvidia, OpenAI",
      "url": "https://www.reuters.com/technology/robotics-startup-figure-raises-675-mln-microsoft-nvidia-other-big-techs-2024-02-29/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "IIT-how-to-think-step-by-step-a-mechanistic-understanding-of-chain-of-thought-reasoning",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "IIT",
      "title": "How to think step-by-step: A mechanistic understanding of chain-of-thought reasoning",
      "url": "https://arxiv.org/abs/2402.18312",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Rice-University-learning-to-compress-prompt-in-natural-language-formats",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Rice University",
      "title": "Learning to Compress Prompt in Natural Language Formats",
      "url": "https://arxiv.org/abs/2402.18700",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-reslora-identity-residual-mapping-in-low-rank-adaption",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Microsoft",
      "title": "ResLoRA: Identity Residual Mapping in Low-Rank Adaption",
      "url": "https://arxiv.org/abs/2402.18039",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Datasets-for-Large-Language-Models:-A-Comprehensive-Survey-datasets-for-large-language-models-a-comprehensive-survey",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Datasets for Large Language Models: A Comprehensive Survey",
      "title": "Datasets for Large Language Models: A Comprehensive Survey",
      "url": "https://arxiv.org/abs/2402.18041",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Apple-lucid-llm-generated-utterances-for-complex-and-interesting-dialogues",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Apple",
      "title": "LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues",
      "url": "https://arxiv.org/abs/2403.00462",
      "bullets": [],
      "tags": []
    },
    {
      "id": "An-Empirical-Categorization-of-Prompting-Techniques-for-Large-Language-Models:-A-Practitioner's-Guide-an-empirical-categorization-of-prompting-techniques-for-large-language-models-a-practitioners-guide",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "An Empirical Categorization of Prompting Techniques for Large Language Models: A Practitioner's Guide",
      "title": "An Empirical Categorization of Prompting Techniques for Large Language Models: A Practitioner's Guide",
      "url": "https://arxiv.org/abs/2402.14837",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-learning-and-leveraging-world-models-in-visual-representation-learning",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Meta",
      "title": "Learning and Leveraging World Models in Visual Representation Learning",
      "url": "https://arxiv.org/abs/2403.00504",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Anthropic-introducing-the-next-generation-of-claude",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "Anthropic",
      "title": "Introducing the next generation of Claude",
      "url": "https://www.anthropic.com/news/claude-3-family",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Distilling-Text-Style-Transfer-With-Self-Explanation-From-LLMs-distilling-text-style-transfer-with-self-explanation-from-llms",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Distilling Text Style Transfer With Self-Explanation From LLMs",
      "title": "Distilling Text Style Transfer With Self-Explanation From LLMs",
      "url": "https://arxiv.org/abs/2403.01106",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Stanford,-Georgia-Tech,-Microsoft,-Google-DeepMind-design2code-how-far-are-we-from-automating-front-end-engineering",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Stanford, Georgia Tech, Microsoft, Google DeepMind",
      "title": "Design2Code: How Far Are We From Automating Front-End Engineering?",
      "url": "https://arxiv.org/abs/2403.03163",
      "bullets": [],
      "tags": []
    },
    {
      "id": "PHAnToM:-Personality-Has-An-Effect-on-Theory-of-Mind-Reasoning-in-Large-Language-Models-phantom-personality-has-an-effect-on-theory-of-mind-reasoning-in-large-language-models",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "PHAnToM: Personality Has An Effect on Theory-of-Mind Reasoning in Large Language Models",
      "title": "PHAnToM: Personality Has An Effect on Theory-of-Mind Reasoning in Large Language Models",
      "url": "https://arxiv.org/abs/2403.02246",
      "bullets": [],
      "tags": []
    },
    {
      "id": "2024-오픈소스-컨트리뷰션-아카데미-[체험형-멘티-모집httpswwwcontributionac",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "2024 오픈소스 컨트리뷰션 아카데미 [체험형",
      "title": "멘티 모집](https://www.contribution.ac/)",
      "url": "",
      "bullets": [
        {
          "text": "‘Git 활용 및 Gemma를 이용한 LLM 앱 개발’",
          "level": 1
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Elon-Musk-and-OpenAI’s-fiery-battle-elon-musk-and-openais-fiery-battle",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "Elon Musk and OpenAI’s fiery battle",
      "title": "Elon Musk and OpenAI’s fiery battle",
      "url": "https://openai.com/blog/openai-elon-musk",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Claude-3’s-system-prompt-claude-3s-system-prompt",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "Claude 3’s system prompt",
      "title": "Claude 3’s system prompt",
      "url": "https://twitter.com/AmandaAskell/status/1765207842993434880?",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Benchmarking-Hallucination-in-Large-Language-Models-based-on-Unanswerable-Math-Word-Problem-benchmarking-hallucination-in-large-language-models-based-on-unanswerable-math-word-problem",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Benchmarking Hallucination in Large Language Models based on Unanswerable Math Word Problem",
      "title": "Benchmarking Hallucination in Large Language Models based on Unanswerable Math Word Problem",
      "url": "https://arxiv.org/abs/2403.03558",
      "bullets": [],
      "tags": []
    },
    {
      "id": "ShortGPT:-Layers-in-Large-Language-Models-are-More-Redundant-Than-You-Expect-shortgpt-layers-in-large-language-models-are-more-redundant-than-you-expect",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "ShortGPT: Layers in Large Language Models are More Redundant Than You Expect",
      "title": "ShortGPT: Layers in Large Language Models are More Redundant Than You Expect",
      "url": "https://arxiv.org/abs/2403.03853",
      "bullets": [],
      "tags": []
    },
    {
      "id": "GaLore:-Memory-Efficient-LLM-Training-by-Gradient-Low-Rank-Projection-galore-memory-efficient-llm-training-by-gradient-low-rank-projection",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection",
      "title": "GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection",
      "url": "https://arxiv.org/abs/2403.03507",
      "bullets": [],
      "tags": []
    },
    {
      "id": "SaulLM-7B:-A-pioneering-Large-Language-Model-for-Law-saullm-7b-a-pioneering-large-language-model-for-law",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "SaulLM-7B: A pioneering Large Language Model for Law",
      "title": "SaulLM-7B: A pioneering Large Language Model for Law",
      "url": "https://arxiv.org/abs/2403.03883",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Salesforce-announces-new-AI-tools-for-doctors-salesforce-announces-new-ai-tools-for-doctors",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "news",
      "org": "Salesforce announces new AI tools for doctors",
      "title": "Salesforce announces new AI tools for doctors",
      "url": "https://www.cnbc.com/2024/03/07/salesforce-announces-new-ai-tools-for-doctors.html",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Chatbot-Arena:-An-Open-Platform-for-Evaluating-LLMs-by-Human-Preference-chatbot-arena-an-open-platform-for-evaluating-llms-by-human-preference",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference",
      "title": "Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference",
      "url": "https://arxiv.org/abs/2403.04132",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Yi:-Open-Foundation-Models-by-01.AI-yi-open-foundation-models-by-01ai",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Yi: Open Foundation Models by 01.AI",
      "title": "Yi: Open Foundation Models by 01.AI",
      "url": "https://arxiv.org/abs/2403.04652",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-teaching-large-language-models-to-reason-with-reinforcement-learning",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Meta",
      "title": "Teaching Large Language Models to Reason with Reinforcement Learning",
      "url": "https://arxiv.org/abs/2403.04642",
      "bullets": [],
      "tags": []
    },
    {
      "id": "WildBench:-Benchmarking-LLMs-with-Challenging-Tasks-from-Real-Users-in-the-Wild-wildbench-benchmarking-llms-with-challenging-tasks-from-real-users-in-the-wild",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild",
      "title": "WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild",
      "url": "https://huggingface.co/spaces/allenai/WildBench",
      "bullets": [],
      "tags": []
    },
    {
      "id": "mamba_peft.py-on-HuggingFace-mamba_peftpy-on-huggingface",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "mamba_peft.py on HuggingFace",
      "title": "mamba_peft.py on HuggingFace",
      "url": "https://gist.github.com/ArthurZucker/743dd7962f21b6ab4a21f692c82b9246",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Foundation-Model-Development-Cheatsheet-foundation-model-development-cheatsheet",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "Foundation Model Development Cheatsheet",
      "title": "Foundation Model Development Cheatsheet",
      "url": "https://fmcheatsheet.org/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Learning-to-Generate-Instruction-Tuning-Datasets-for-Zero-Shot-Task-Adaptation-learning-to-generate-instruction-tuning-datasets-for-zero-shot-task-adaptation",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Learning to Generate Instruction Tuning Datasets for Zero-Shot Task Adaptation",
      "title": "Learning to Generate Instruction Tuning Datasets for Zero-Shot Task Adaptation",
      "url": "https://arxiv.org/abs/2402.18334",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Gen-AI-Korea-2024-생성형-ai-레드팀-챌린지",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "dev",
      "org": "Gen AI Korea 2024",
      "title": "생성형 AI 레드팀 챌린지",
      "url": "https://www.aiignite.org/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Anthropic-the-claude-3-model-family-opus-sonnet-haiku",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Anthropic",
      "title": "The Claude 3 Model Family: Opus, Sonnet, Haiku",
      "url": "https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-sora-a-review-on-background-technology-limitations-and-opportunities-of-large-vision-models",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Microsoft",
      "title": "Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models",
      "url": "https://arxiv.org/abs/2402.17177v2",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-Research-beyond-sparse-rewards-enhancing-reinforcement-learning-with-language-model-critique-in-text-generation",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Google Research",
      "title": "Beyond Sparse Rewards: Enhancing Reinforcement Learning with Language Model Critique in Text Generation",
      "url": "https://arxiv.org/abs/2401.07382",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Birbal:-An-efficient-7B-instruct-model-fine-tuned-with-curated-datasets-birbal-an-efficient-7b-instruct-model-fine-tuned-with-curated-datasets",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Birbal: An efficient 7B instruct-model fine-tuned with curated datasets",
      "title": "Birbal: An efficient 7B instruct-model fine-tuned with curated datasets",
      "url": "https://arxiv.org/abs/2403.02247",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind-gemini-15-unlocking-multimodal-understanding-across-millions-of-tokens-of-context-1",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "url": "https://arxiv.org/abs/2403.05530",
      "bullets": [],
      "tags": []
    },
    {
      "id": "MuseGraph:-Graph-oriented-Instruction-Tuning-of-Large-Language-Models-for-Generic-Graph-Mining-musegraph-graph-oriented-instruction-tuning-of-large-language-models-for-generic-graph-mining",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "MuseGraph: Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining",
      "title": "MuseGraph: Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining",
      "url": "https://arxiv.org/abs/2403.04780",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Harnessing-Multi-Role-Capabilities-of-Large-Language-Models-for-Open-Domain-Question-Answering-harnessing-multi-role-capabilities-of-large-language-models-for-open-domain-question-answering",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering",
      "title": "Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering",
      "url": "https://arxiv.org/abs/2403.05217",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Cohere-command-r-retrieval-augmented-generation-at-production-scale",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "dev",
      "org": "Cohere",
      "title": "Command-R: Retrieval Augmented Generation at Production Scale",
      "url": "https://txt.cohere.com/command-r/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "MIT-ra-isf-learning-to-answer-and-understand-from-retrieval-augmentation-via-iterative-self-feedback",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "MIT",
      "title": "RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback",
      "url": "https://arxiv.org/abs/2403.06840",
      "bullets": [],
      "tags": []
    },
    {
      "id": "OpenAI-transfromer-debugger-tbd",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "transfromer-debugger (TBD)",
      "url": "https://github.com/openai/transformer-debugger",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind,-OpenAI-stealing-part-of-a-production-language-model",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Google DeepMind, OpenAI",
      "title": "Stealing Part of a Production Language Model",
      "url": "https://arxiv.org/abs/2403.06634",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-branch-train-mix-mixing-expert-llms-into-a-mixture-of-experts-llm",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Meta",
      "title": "Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM",
      "url": "https://arxiv.org/abs/2403.07816",
      "bullets": [],
      "tags": []
    },
    {
      "id": "DeepLearning.AI-knowledge-graph-for-rag",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "dev",
      "org": "DeepLearning.AI",
      "title": "Knowledge Graph for RAG",
      "url": "https://learn.deeplearning.ai/courses/knowledge-graphs-rag/lesson/1/introduction",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind-a-generalist-ai-agent-for-3d-virtual-environments",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "A generalist AI agent for 3D virtual environments",
      "url": "https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-Research-rethinking-generative-large-language-model-evaluation-for-semantic-comprehension",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "dev",
      "org": "Microsoft Research",
      "title": "Rethinking Generative Large Language Model Evaluation for Semantic Comprehension",
      "url": "https://arxiv.org/abs/2403.07872",
      "bullets": [],
      "tags": []
    },
    {
      "id": "OpenAI-figure-status-update-openai-speech-to-speech-reasoning",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "dev",
      "org": "OpenAI",
      "title": "Figure Status Update - OpenAI Speech-to-Speech Reasoning",
      "url": "https://www.youtube.com/watch?v=Sq1QZB5baNw",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Tancent-large-language-models-are-contrastive-reasoners",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Tancent",
      "title": "Large Language Models are Contrastive Reasoners",
      "url": "https://arxiv.org/abs/2403.08211",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Logits-of-API-Protected-LLMs-Leak-Proprietary-Information-logits-of-api-protected-llms-leak-proprietary-information",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Logits of API-Protected LLMs Leak Proprietary Information",
      "title": "Logits of API-Protected LLMs Leak Proprietary Information",
      "url": "https://arxiv.org/abs/2403.09539",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Apple-mm1-methods-analysis-insights-from-multimodal-llm-pre-training",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Apple",
      "title": "MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training",
      "url": "https://arxiv.org/abs/2403.09611",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Ex-Activision-CEO-Bobby-Kotick-pitched-buying-TikTok-to-potential-partners,-including-Sam-Altman:-report-ex-activision-ceo-bobby-kotick-pitched-buying-tiktok-to-potential-partners-including-sam-altman-report",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "news",
      "org": "Ex-Activision CEO Bobby Kotick pitched buying TikTok to potential partners, including Sam Altman: report",
      "title": "Ex-Activision CEO Bobby Kotick pitched buying TikTok to potential partners, including Sam Altman: report",
      "url": "https://www.businessinsider.in/tech/news/ex-activision-ceo-bobby-kotick-pitched-buying-tiktok-to-potential-partners-including-sam-altman-report/articleshow/108409188.cms",
      "bullets": [],
      "tags": []
    },
    {
      "id": "xAI-open-release-of-grok-1",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "dev",
      "org": "xAI",
      "title": "Open Release of Grok-1",
      "url": "https://x.ai/blog/grok-os",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Cohere-c4ai-command-r-huggingface",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "dev",
      "org": "Cohere",
      "title": "C4AI Command-R (HuggingFace)",
      "url": "https://huggingface.co/CohereForAI/c4ai-command-r-v01",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Stanford-University-quiet-star-language-models-can-teach-themselves-to-think-before-speaking",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Stanford University",
      "title": "Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking",
      "url": "https://arxiv.org/abs/2403.09629",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Peking-University-rat-retrieval-augmented-thoughts-elicit-context-aware-reasoning-in-long-horizon-generation",
      "date": "2024-03-W03",
      "year": "2024",
      "month": "3",
      "week": "3",
      "type": "paper",
      "org": "Peking University",
      "title": "RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation",
      "url": "https://arxiv.org/abs/2403.05313",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Nvidia-nvidia-reveals-blackwell-b200-gpu-the-worlds-most-powerful-chip-for-ai",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "news",
      "org": "Nvidia",
      "title": "Nvidia reveals Blackwell B200 GPU, the ‘world’s most powerful chip’ for AI",
      "url": "https://www.theverge.com/2024/3/18/24105157/nvidia-blackwell-gpu-b200-ai",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Open-Sora-open-sora",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "Open-Sora",
      "title": "Open-Sora",
      "url": "https://github.com/hpcaitech/Open-Sora",
      "bullets": [],
      "tags": []
    },
    {
      "id": "CMU-LTI-enhancing-llm-factual-accuracy-with-rag-to-counter-hallucinations-a-case-study-on-domain-specific-queries-in-private-knowledge-bases",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "CMU-LTI",
      "title": "Enhancing LLM Factual Accuracy with RAG to Counter Hallucinations: A Case Study on Domain-Specific Queries in Private Knowledge-Bases",
      "url": "https://arxiv.org/abs/2403.10446",
      "bullets": [],
      "tags": []
    },
    {
      "id": "UC-Berkeley-raft-adapting-language-model-to-domain-specific-rag",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "UC Berkeley",
      "title": "RAFT: Adapting Language Model to Domain Specific RAG",
      "url": "https://arxiv.org/abs/2403.10131",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-Research-perl-parameter-efficient-reinforcement-learning-from-human-feedback",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Google Research",
      "title": "PERL: Parameter Efficient Reinforcement Learning from Human Feedback",
      "url": "https://arxiv.org/abs/2403.10704",
      "bullets": [],
      "tags": []
    },
    {
      "id": "EACL-2024-aligning-large-and-small-language-models-via-chain-of-thought-reasoning",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "EACL 2024",
      "title": "Aligning Large and Small Language Models via Chain-of-Thought Reasoning",
      "url": "https://aclanthology.org/2024.eacl-long.109/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "RankPrompt:-Step-by-Step-Comparisons-Make-Language-Models-Better-Reasoners-rankprompt-step-by-step-comparisons-make-language-models-better-reasoners",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "RankPrompt: Step-by-Step Comparisons Make Language Models Better Reasoners",
      "title": "RankPrompt: Step-by-Step Comparisons Make Language Models Better Reasoners",
      "url": "https://arxiv.org/abs/2403.12373",
      "bullets": [],
      "tags": []
    },
    {
      "id": "KAIST-sure-summarizing-retrievals-using-answer-candidates-for-open-domain-qa-of-llms",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "KAIST",
      "title": "SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs",
      "url": "https://openreview.net/pdf?id=w4DW6qkRmt",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-Corporation-llmlingua-2-data-distillation-for-efficient-and-faithful-task-agnostic-prompt-compression",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Microsoft Corporation",
      "title": "LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression",
      "url": "https://arxiv.org/abs/2403.12968",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind-tacticai-an-ai-assistant-for-football-tactics",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "TacticAI: an AI assistant for football tactics",
      "url": "https://deepmind.google/discover/blog/tacticai-ai-assistant-for-football-tactics/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind-take-a-step-back-evoking-reasoning-via-abstraction-in-large-language-models",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models",
      "url": "https://arxiv.org/abs/2310.06117",
      "bullets": [],
      "tags": []
    },
    {
      "id": "AI2-rewardbench-evaluating-reward-models-for-language-modeling",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "AI2",
      "title": "RewardBench: Evaluating Reward Models for Language Modeling",
      "url": "https://arxiv.org/abs/2403.13787",
      "bullets": [],
      "tags": []
    },
    {
      "id": "LlamaFactory:-Unified-Efficient-Fine-Tuning-of-100+-Language-Models-llamafactory-unified-efficient-fine-tuning-of-100-language-models",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models",
      "title": "LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models",
      "url": "https://arxiv.org/abs/2403.13372",
      "bullets": [],
      "tags": []
    },
    {
      "id": "MathVerse:-Does-Your-Multi-modal-LLM-Truly-See-the-Diagrams-in-Visual-Math-Problems?-mathverse-does-your-multi-modal-llm-truly-see-the-diagrams-in-visual-math-problems",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?",
      "title": "MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?",
      "url": "https://arxiv.org/abs/2403.14624",
      "bullets": [],
      "tags": []
    },
    {
      "id": "KAIST-adaptive-rag-learning-to-adapt-retrieval-augmented-large-language-models-through-question-complexity",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "KAIST",
      "title": "Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity",
      "url": "https://arxiv.org/abs/2403.14403",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Sakana-AI-evolutionary-optimization-of-model-merging-recipes",
      "date": "2024-03-W04",
      "year": "2024",
      "month": "3",
      "week": "4",
      "type": "paper",
      "org": "Sakana AI",
      "title": "Evolutionary Optimization of Model Merging Recipes",
      "url": "https://arxiv.org/abs/2403.13187",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Instructing-Large-Language-Models-to-Identify-and-Ignore-Irrelevant-Conditions-instructing-large-language-models-to-identify-and-ignore-irrelevant-conditions",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "paper",
      "org": "Instructing Large Language Models to Identify and Ignore Irrelevant Conditions",
      "title": "Instructing Large Language Models to Identify and Ignore Irrelevant Conditions",
      "url": "https://arxiv.org/abs/2403.12744",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-Research,-CMU-can-large-language-models-explore-in-context",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "paper",
      "org": "Microsoft Research, CMU",
      "title": "Can large language models explore in-context?",
      "url": "https://arxiv.org/abs/2403.15371",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Lightning-AI-lightning-thunder",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "dev",
      "org": "Lightning AI",
      "title": "lightning-thunder",
      "url": "https://github.com/Lightning-AI/lightning-thunder?tab=readme-ov-file",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Johns-Hopkins,-Yale,-AI2-followir-evaluating-and-teaching-information-retrieval-models-to-follow-instructions",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "paper",
      "org": "Johns Hopkins, Yale, AI2",
      "title": "FOLLOWIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions",
      "url": "https://arxiv.org/abs/2403.15246",
      "bullets": [],
      "tags": []
    },
    {
      "id": "UC-Berkeley-llm2llm-boosting-llms-with-novel-iterative-data-enhancement",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "paper",
      "org": "UC Berkeley",
      "title": "LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement",
      "url": "https://arxiv.org/abs/2403.15042",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Rutgers-University-aios-llm-agent-operating-system",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "paper",
      "org": "Rutgers University",
      "title": "AIOS: LLM Agent Operating System",
      "url": "https://arxiv.org/abs/2403.16971",
      "bullets": [],
      "tags": []
    },
    {
      "id": "MIT,-Berkeley,-Chicago,-Texas-decoding-compressed-trust-scrutinizing-the-trustworthiness-of-efficient-llms-under-compression",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "paper",
      "org": "MIT, Berkeley, Chicago, Texas",
      "title": "Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression",
      "url": "https://arxiv.org/abs/2403.15447",
      "bullets": [],
      "tags": []
    },
    {
      "id": "OpenAI-sora-first-impressions",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "dev",
      "org": "OpenAI",
      "title": "Sora: first impressions",
      "url": "https://openai.com/blog/sora-first-impressions",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Databricks-introducing-dbrx-a-new-state-of-the-art-open-llm",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "dev",
      "org": "Databricks",
      "title": "Introducing DBRX: A New State-of-the-Art Open LLM",
      "url": "https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm",
      "bullets": [
        {
          "text": "MoE를 활용하여 132B/32B 전체/활성 파라미터 사이즈를 가짐. 32K context length 지원",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Anthropic-claude-3-opus-vs-gpt-4",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "dev",
      "org": "Anthropic",
      "title": "Claude-3-Opus vs GPT-4",
      "url": "https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta,-MIT-the-unreasonable-ineffectiveness-of-the-deeper-layers",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "paper",
      "org": "Meta, MIT",
      "title": "The Unreasonable Ineffectiveness of the Deeper Layers",
      "url": "https://arxiv.org/abs/2403.17887",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Univ.-of-Hong-Kong-mini-gemini-mining-the-potential-of-multi-modality-vision-language-models",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "paper",
      "org": "Univ. of Hong Kong",
      "title": "Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models",
      "url": "https://arxiv.org/abs/2403.18814",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta,-Mila,-McGil,-Montreal-improving-text-to-image-consistency-via-automatic-prompt-optimization",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "paper",
      "org": "Meta, Mila, McGil, Montreal",
      "title": "Improving Text-to-Image Consistency via Automatic Prompt Optimization",
      "url": "https://arxiv.org/abs/2403.17804",
      "bullets": [],
      "tags": []
    },
    {
      "id": "MIT,-Microsoft-supervisory-prompt-training",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "paper",
      "org": "MIT, Microsoft",
      "title": "Supervisory Prompt Training",
      "url": "https://arxiv.org/abs/2403.18051",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Upstage-sdpo-dont-use-your-data-all-at-once",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "paper",
      "org": "Upstage",
      "title": "sDPO: Don't Use Your Data All at Once",
      "url": "https://arxiv.org/abs/2403.19270",
      "bullets": [],
      "tags": []
    },
    {
      "id": "HuggingFace-a-little-guide-to-building-large-language-models-in-2024",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "dev",
      "org": "HuggingFace",
      "title": "A little guide to building Large Language Models in 2024",
      "url": "https://www.youtube.com/watch?v=2-SPH9hIKT8",
      "bullets": [],
      "tags": []
    },
    {
      "id": "AI21labs-introducing-jamba-ai21s-groundbreaking-ssm-transformer-model",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "dev",
      "org": "AI21labs",
      "title": "Introducing Jamba: AI21's Groundbreaking SSM-Transformer Model",
      "url": "https://www.ai21.com/blog/announcing-jamba",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Can-multiple-choice-questions-really-be-useful-in-detecting-the-abilities-of-LLMs?-can-multiple-choice-questions-really-be-useful-in-detecting-the-abilities-of-llms",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "paper",
      "org": "Can multiple-choice questions really be useful in detecting the abilities of LLMs?",
      "title": "Can multiple-choice questions really be useful in detecting the abilities of LLMs?",
      "url": "https://arxiv.org/abs/2403.17752",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Understanding-Emergent-Abilities-of-Language-Models-from-the-Loss-Perspective-understanding-emergent-abilities-of-language-models-from-the-loss-perspective",
      "date": "2024-03-W05",
      "year": "2024",
      "month": "3",
      "week": "5",
      "type": "paper",
      "org": "Understanding Emergent Abilities of Language Models from the Loss Perspective",
      "title": "Understanding Emergent Abilities of Language Models from the Loss Perspective",
      "url": "https://arxiv.org/abs/2403.15796",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Cohere-aya-model-an-instruction-finetuned-open-access-multilingual-language-model",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "Cohere",
      "title": "Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model",
      "url": "https://arxiv.org/abs/2402.07827",
      "bullets": [],
      "tags": []
    },
    {
      "id": "OS-Copilot:-Towards-Generalist-Computer-Agents-with-Self-Improvement-os-copilot-towards-generalist-computer-agents-with-self-improvement",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "OS-Copilot: Towards Generalist Computer Agents with Self-Improvement",
      "title": "OS-Copilot: Towards Generalist Computer Agents with Self-Improvement",
      "url": "https://arxiv.org/abs/2402.07456",
      "bullets": [],
      "tags": []
    },
    {
      "id": "OpenAI-memory-and-new-controls-for-chatgpt",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "dev",
      "org": "OpenAI",
      "title": "Memory and new controls for ChatGPT",
      "url": "https://openai.com/blog/memory-and-new-controls-for-chatgpt",
      "bullets": [],
      "tags": []
    },
    {
      "id": "NVIDIA-say-what-chat-with-rtx-brings-custom-chatbot-to-nvidia-rtx-ai-pcs",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "dev",
      "org": "NVIDIA",
      "title": "Say What? Chat With RTX Brings Custom Chatbot to NVIDIA RTX AI PCs",
      "url": "https://blogs.nvidia.com/blog/chat-with-rtx-available-now/",
      "bullets": [
        {
          "text": "NVIDIA의 성장세 기사",
          "level": 0
        }
      ],
      "tags": []
    },
    {
      "id": "DeepLearning.AI-serverless-llm-apps-with-amazon-bedrock",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "dev",
      "org": "DeepLearning.AI",
      "title": "Serverless LLM apps with Amazon Bedrock",
      "url": "https://www.deeplearning.ai/short-courses/serverless-llm-apps-amazon-bedrock/",
      "bullets": [
        {
          "text": "LLM의 sefl-verification 한계점",
          "level": 0
        }
      ],
      "tags": [
        "AI/ML"
      ]
    },
    {
      "id": "Google-DeepMind-transformers-can-achieve-length-generalization-but-not-robustly",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Transformers Can Achieve Length Generalization But Not Robustly",
      "url": "https://arxiv.org/abs/2402.09371",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind-chain-of-thought-reasoning-without-prompting",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "Google DeepMind",
      "title": "Chain-of-Thought Reasoning Without Prompting",
      "url": "https://arxiv.org/abs/2402.10200",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-our-next-generation-model-gemini-15",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "dev",
      "org": "Google",
      "title": "Our next-generation model: Gemini 1.5",
      "url": "https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "OpenAI-sora-creating-video-from-text",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "dev",
      "org": "OpenAI",
      "title": "Sora: Creating video from text",
      "url": "https://openai.com/sora",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Apple-guiding-instruction-based-image-editing-via-multimodal-large-language-models",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "Apple",
      "title": "Guiding Instruction-based Image Editing via Multimodal Large Language Models",
      "url": "https://arxiv.org/abs/2309.17102",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Using-Counterfactual-Tasks-to-Evaluate-the-Generality-of-Analogical-Reasoning-in-Large-Language-Models-using-counterfactual-tasks-to-evaluate-the-generality-of-analogical-reasoning-in-large-language-models",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "Using Counterfactual Tasks to Evaluate the Generality of Analogical Reasoning in Large Language Models",
      "title": "Using Counterfactual Tasks to Evaluate the Generality of Analogical Reasoning in Large Language Models",
      "url": "https://arxiv.org/abs/2402.08955",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Slack-slack-ai-is-here-letting-you-catch-up-on-lengthy-threads-and-unread-messages",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "news",
      "org": "Slack",
      "title": "Slack AI is here, letting you catch up on lengthy threads and unread messages",
      "url": "https://www.theverge.com/2024/2/14/24070590/slack-ai-launch-thread-summaries-search-recap",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind-&-Research-a-human-inspired-reading-agent-with-gist-memory-of-very-long-contexts",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "Google DeepMind & Research",
      "title": "A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts",
      "url": "https://arxiv.org/abs/2402.09727",
      "bullets": [],
      "tags": []
    },
    {
      "id": "DoRA:-Weight-Decomposed-Low-Rank-Adaptation-dora-weight-decomposed-low-rank-adaptation",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "DoRA: Weight-Decomposed Low-Rank Adaptation",
      "title": "DoRA: Weight-Decomposed Low-Rank Adaptation",
      "url": "https://arxiv.org/abs/2402.09353",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Can-We-Verify-Step-by-Step-for-Incorrect-Answer-Detection?-can-we-verify-step-by-step-for-incorrect-answer-detection",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "Can We Verify Step by Step for Incorrect Answer Detection?",
      "title": "Can We Verify Step by Step for Incorrect Answer Detection?",
      "url": "https://arxiv.org/abs/2402.10528",
      "bullets": [],
      "tags": []
    },
    {
      "id": "minbpe-minbpe",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "dev",
      "org": "minbpe",
      "title": "minbpe",
      "url": "https://github.com/karpathy/minbpe",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Meta-v-jepa",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "dev",
      "org": "Meta",
      "title": "V-JEPA",
      "url": "https://ai.meta.com/research/publications/revisiting-feature-prediction-for-learning-visual-representations-from-video/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Linear-Transformers-with-Learnable-Kernel-Functions-are-Better-In-Context-Models-linear-transformers-with-learnable-kernel-functions-are-better-in-context-models",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "Linear Transformers with Learnable Kernel Functions are Better In-Context Models",
      "title": "Linear Transformers with Learnable Kernel Functions are Better In-Context Models",
      "url": "https://arxiv.org/abs/2402.10644",
      "bullets": [],
      "tags": []
    },
    {
      "id": "DataDreamer:-A-Tool-for-Synthetic-Data-Generation-and-Reproducible-LLM-Workflows-datadreamer-a-tool-for-synthetic-data-generation-and-reproducible-llm-workflows",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows",
      "title": "DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows",
      "url": "https://arxiv.org/abs/2402.10379",
      "bullets": [],
      "tags": []
    },
    {
      "id": "AnyGPT:-Unified-Multimodal-LLM-with-Discrete-Sequence-Modeling-anygpt-unified-multimodal-llm-with-discrete-sequence-modeling",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling",
      "title": "AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling",
      "url": "https://arxiv.org/abs/2402.12226",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Direct-Evaluation-of-Chain-of-Thought-in-Multi-hop-Reasoning-with-Knowledge-Graphs-direct-evaluation-of-chain-of-thought-in-multi-hop-reasoning-with-knowledge-graphs",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "Direct Evaluation of Chain-of-Thought in Multi-hop Reasoning with Knowledge Graphs",
      "title": "Direct Evaluation of Chain-of-Thought in Multi-hop Reasoning with Knowledge Graphs",
      "url": "https://arxiv.org/abs/2402.11199",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Boosting-of-Thoughts:-Trial-and-Error-Problem-Solving-with-Large-Language-Models-boosting-of-thoughts-trial-and-error-problem-solving-with-large-language-models",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models",
      "title": "Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models",
      "url": "https://arxiv.org/abs/2402.11140",
      "bullets": [],
      "tags": []
    },
    {
      "id": "SoftBank’s-Masayoshi-Son-is-reportedly-seeking-$100B-to-build-a-new-AI-chip-venture-softbanks-masayoshi-son-is-reportedly-seeking-100b-to-build-a-new-ai-chip-venture",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "news",
      "org": "SoftBank’s Masayoshi Son is reportedly seeking $100B to build a new AI chip venture",
      "title": "SoftBank’s Masayoshi Son is reportedly seeking $100B to build a new AI chip venture",
      "url": "https://techcrunch.com/2024/02/19/softbanks-masayoshi-son-is-reportedly-seeking-100b-to-build-a-new-ai-chip-venture/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "The-FinBen:-An-Holistic-Financial-Benchmark-for-Large-Language-Models-the-finben-an-holistic-financial-benchmark-for-large-language-models",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "The FinBen: An Holistic Financial Benchmark for Large Language Models",
      "title": "The FinBen: An Holistic Financial Benchmark for Large Language Models",
      "url": "https://arxiv.org/abs/2402.12659",
      "bullets": [],
      "tags": []
    },
    {
      "id": "cosmopedia-cosmopedia",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "dev",
      "org": "cosmopedia",
      "title": "cosmopedia",
      "url": "https://huggingface.co/datasets/HuggingFaceTB/cosmopedia",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Andrej-Karphathy-lets-build-the-gpt-tokenizer",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "dev",
      "org": "Andrej Karphathy",
      "title": "Let’s build the GPT Tokenizer",
      "url": "https://www.youtube.com/watch?v=zduSFxRajkE",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-synthetic-data-almost-from-scratch-generalized-instruction-tuning-for-language-models",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "Microsoft",
      "title": "Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for Language Models",
      "url": "https://arxiv.org/abs/2402.13064",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind-gemma-introducing-new-state-of-the-art-open-models",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "Gemma: Introducing new state-of-the-art open models",
      "url": "https://blog.google/technology/developers/gemma-open-models/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Kaggle-google-ai-assistants-for-data-tasks-with-gemma",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "dev",
      "org": "Kaggle",
      "title": "Google – AI Assistants for Data Tasks with Gemma",
      "url": "https://www.kaggle.com/competitions/data-assistants-with-gemma/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "ARL2:-Aligning-Retrievers-for-Black-box-Large-Language-Models-via-Self-guided-Adaptive-Relevance-Labeling-arl2-aligning-retrievers-for-black-box-large-language-models-via-self-guided-adaptive-relevance-labeling",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "ARL2: Aligning Retrievers for Black-box Large Language Models via Self-guided Adaptive Relevance Labeling",
      "title": "ARL2: Aligning Retrievers for Black-box Large Language Models via Self-guided Adaptive Relevance Labeling",
      "url": "https://arxiv.org/abs/2402.13542",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Making-Reasoning-Matter:-Measuring-and-Improving-Faithfulness-of-Chain-of-Thought-Reasoning-making-reasoning-matter-measuring-and-improving-faithfulness-of-chain-of-thought-reasoning",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning",
      "title": "Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning",
      "url": "https://arxiv.org/abs/2402.13950",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Aria-Everyday-Activities-Dataset-aria-everyday-activities-dataset",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "dev",
      "org": "Aria Everyday Activities Dataset",
      "title": "Aria Everyday Activities Dataset",
      "url": "https://huggingface.co/papers/2402.13349",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-Research-longrope-extending-llm-context-window-beyond-2-million-tokens",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "Microsoft Research",
      "title": "LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens",
      "url": "https://arxiv.org/abs/2402.13753",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Yonsei-University-kmmlu-measuring-massive-multitask-language-understanding-in-korean",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "Yonsei University",
      "title": "KMMLU: Measuring Massive Multitask Language Understanding in Korean",
      "url": "https://arxiv.org/abs/2402.11548",
      "bullets": [],
      "tags": []
    },
    {
      "id": "OpenCodeInterpreter:-Integrating-Code-Generation-with-Execution-and-Refinement-opencodeinterpreter-integrating-code-generation-with-execution-and-refinement",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement",
      "title": "OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement",
      "url": "https://arxiv.org/abs/2402.14658",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Adobe-Acrobat-adds-generative-AI-to-‘easily-chat-with-documents’-adobe-acrobat-adds-generative-ai-to-easily-chat-with-documents",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "news",
      "org": "Adobe Acrobat adds generative AI to ‘easily chat with documents’",
      "title": "Adobe Acrobat adds generative AI to ‘easily chat with documents’",
      "url": "https://www.theverge.com/2024/2/20/24077217/adobe-acrobat-generative-ai-assistant-chatbot-pdf-document",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Hint-before-Solving-Prompting:-Guiding-LLMs-to-Effectively-Utilize-Encoded-Knowledge-hint-before-solving-prompting-guiding-llms-to-effectively-utilize-encoded-knowledge",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge",
      "title": "Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge",
      "url": "https://arxiv.org/abs/2402.14310",
      "bullets": [],
      "tags": []
    },
    {
      "id": "CriticBench:-Benchmarking-LLMs-for-Critique-Correct-Reasoning-criticbench-benchmarking-llms-for-critique-correct-reasoning",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "CriticBench: Benchmarking LLMs for Critique-Correct Reasoning",
      "title": "CriticBench: Benchmarking LLMs for Critique-Correct Reasoning",
      "url": "https://arxiv.org/abs/2402.14809",
      "bullets": [],
      "tags": []
    },
    {
      "id": "YOLOv9:-Learning-What-You-Want-to-Learn-Using-Programmable-Gradient-Information-yolov9-learning-what-you-want-to-learn-using-programmable-gradient-information",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "paper",
      "org": "YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information",
      "title": "YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information",
      "url": "https://arxiv.org/abs/2402.13616",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Stability.ai-stable-diffusion-3",
      "date": "2024-02-W04",
      "year": "2024",
      "month": "2",
      "week": "4",
      "type": "dev",
      "org": "Stability.ai",
      "title": "Stable Diffusion 3",
      "url": "https://stability.ai/news/stable-diffusion-3?utm_source=www.theaivalley.com",
      "bullets": [],
      "tags": []
    },
    {
      "id": "UC-Berkely-lora-efficient-low-rank-adaptation-of-large-models",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "UC Berkely",
      "title": "LoRA+: Efficient Low Rank Adaptation of Large Models",
      "url": "https://arxiv.org/abs/2402.12354",
      "bullets": [
        {
          "text": "기존의 LoRA에서 사용하는 adapater 행렬 A와 B는 고정된 learning rate로 업데이트된다는 점이 문제임 → 두 행렬의 learning rate를 조절함으로써 퍼포먼스와 학습 속도를 향상시킬 수 있는 알고리즘 LoRA+ 를 제시",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "OlympiadBench:-A-Challenging-Benchmark-for-Promoting-AGI-with-Olympiad-Level-Bilingual-Multimodal-Scientific-Problems-olympiadbench-a-challenging-benchmark-for-promoting-agi-with-olympiad-level-bilingual-multimodal-scientific-problems",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "OlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems",
      "title": "OlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems",
      "url": "https://arxiv.org/abs/2402.14008",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Large-Language-Models-for-Data-Annotation:-A-Survey-large-language-models-for-data-annotation-a-survey",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "Large Language Models for Data Annotation: A Survey",
      "title": "Large Language Models for Data Annotation: A Survey",
      "url": "https://arxiv.org/abs/2402.13446",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Purifying-Large-Language-Models-by-Ensembling-a-Small-Language-Model-purifying-large-language-models-by-ensembling-a-small-language-model",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "Purifying Large Language Models by Ensembling a Small Language Model",
      "title": "Purifying Large Language Models by Ensembling a Small Language Model",
      "url": "https://arxiv.org/abs/2402.14845",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Distillation-Contrastive-Decoding:-Improving-LLMs-Reasoning-with-Contrastive-Decoding-and-Distillation-distillation-contrastive-decoding-improving-llms-reasoning-with-contrastive-decoding-and-distillation",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "Distillation Contrastive Decoding: Improving LLMs Reasoning with Contrastive Decoding and Distillation",
      "title": "Distillation Contrastive Decoding: Improving LLMs Reasoning with Contrastive Decoding and Distillation",
      "url": "https://arxiv.org/abs/2402.14874",
      "bullets": [],
      "tags": []
    },
    {
      "id": "tinyBenchmarks:-evaluating-LLMs-with-fewer-examples-tinybenchmarks-evaluating-llms-with-fewer-examples",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "tinyBenchmarks: evaluating LLMs with fewer examples",
      "title": "tinyBenchmarks: evaluating LLMs with fewer examples",
      "url": "https://arxiv.org/abs/2402.14992",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Google-DeepMind-genie-generative-interactive-environmentshttpssitesgooglecomviewgenie-2024",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "dev",
      "org": "Google DeepMind",
      "title": "🧞 [Genie: Generative Interactive Environments](https://sites.google.com/view/genie-2024)",
      "url": "",
      "bullets": [
        {
          "text": "single image prompt로 게임 만들기..",
          "level": 1
        }
      ],
      "tags": [
        "multimodal"
      ]
    },
    {
      "id": "Mistral-AI-le-chat-mistral",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "dev",
      "org": "Mistral AI",
      "title": "Le Chat Mistral",
      "url": "https://chat.mistral.ai/chat",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Mitral-AI-au-large",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "dev",
      "org": "Mitral AI",
      "title": "Au Large",
      "url": "https://mistral.ai/news/mistral-large/",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Microsoft-Research-orca-math-unlocking-the-potential-of-slms-in-grade-school-mathhttpsarxivorgabs240214830",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "Microsoft Research",
      "title": "🐳 [Orca-Math: Unlocking the potential of SLMs in Grade School Math](https://arxiv.org/abs/2402.14830)",
      "url": "",
      "bullets": [
        {
          "text": "Mistral-7B 모델을 베이스로 학습한 7B 모델 Orca-Math. 200K 개의 고품질 합성 데이터, feedback을 통합시키는 학습 방식 등이 활용됨. Llama-2-70B, ChatGPT-3.5 등을 능가하는 퍼포먼스",
          "level": 1
        }
      ],
      "tags": []
    },
    {
      "id": "Argilla-openhermespreferences-a-dataset-of-1m-ai-preferences-for-rlaif-and-dpo",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "dev",
      "org": "Argilla",
      "title": "OpenHermesPreferences - a dataset of 1M AI preferences for RLAIF and DPO",
      "url": "https://huggingface.co/datasets/argilla/OpenHermesPreferences",
      "bullets": [],
      "tags": []
    },
    {
      "id": "LLMs-with-Chain-of-Thought-Are-Non-Causal-Reasoners-llms-with-chain-of-thought-are-non-causal-reasoners",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "LLMs with Chain-of-Thought Are Non-Causal Reasoners",
      "title": "LLMs with Chain-of-Thought Are Non-Causal Reasoners",
      "url": "https://arxiv.org/abs/2402.16048",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Look-Before-You-Leap:-Problem-Elaboration-Prompting-Improves-Mathematical-Reasoning-in-Large-Language-Models-look-before-you-leap-problem-elaboration-prompting-improves-mathematical-reasoning-in-large-language-models",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "Look Before You Leap: Problem Elaboration Prompting Improves Mathematical Reasoning in Large Language Models",
      "title": "Look Before You Leap: Problem Elaboration Prompting Improves Mathematical Reasoning in Large Language Models",
      "url": "https://arxiv.org/abs/2402.15764",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Apple-cancels-work-on-electric-car,-shifts-team-to-generative-AI-apple-cancels-work-on-electric-car-shifts-team-to-generative-ai",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "news",
      "org": "Apple cancels work on electric car, shifts team to generative AI",
      "title": "Apple cancels work on electric car, shifts team to generative AI",
      "url": "https://economictimes.indiatimes.com/tech/technology/apple-cancels-work-on-electric-car-shifts-team-to-generative-ai/articleshow/108052606.cms",
      "bullets": [],
      "tags": []
    },
    {
      "id": "Reasoning-in-Conversation:-Solving-Subjective-Tasks-through-Dialogue-Simulation-for-Large-Language-Models-reasoning-in-conversation-solving-subjective-tasks-through-dialogue-simulation-for-large-language-models",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "paper",
      "org": "Reasoning in Conversation: Solving Subjective Tasks through Dialogue Simulation for Large Language Models",
      "title": "Reasoning in Conversation: Solving Subjective Tasks through Dialogue Simulation for Large Language Models",
      "url": "https://arxiv.org/abs/2402.17226",
      "bullets": [],
      "tags": []
    },
    {
      "id": "DeepLearning.AI-prompt-engineering-with-llama-2",
      "date": "2024-02-W05",
      "year": "2024",
      "month": "2",
      "week": "5",
      "type": "dev",
      "org": "DeepLearning.AI",
      "title": "Prompt Engineering with Llama 2",
      "url": "https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/",
      "bullets": [],
      "tags": []
    }
  ]
}