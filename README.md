ğŸ“œ: Paper link
ğŸ§‘ğŸ»â€ğŸ’»: Developer blog & Github link
ğŸ—ï¸: News

---
# 2024
## â˜ƒ February
<details>
  <summary>1st ~ 3rd week</summary>

- ğŸ“œÂ [Cohere] [Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model](https://arxiv.org/abs/2402.07827)
    - 119ê°œêµ­, 3,000ì—¬ ëª…ì˜ ì—°êµ¬ìê°€ ì°¸ì—¬í•œ ë‹¤êµ­ì–´ ëª¨ë¸ ì—°êµ¬ í”„ë¡œì íŠ¸ì˜ ê²°ê³¼ë¬¼. ë°ì´í„°ì…‹ë„ ì˜¤í”ˆì†ŒìŠ¤ë¡œ ì œê³µ (513M ê°œ instruction fine-tuning ë°ì´í„°ì…‹)
- ğŸ“œÂ [OS-Copilot: Towards Generalist Computer Agents with Self-Improvement](https://arxiv.org/abs/2402.07456)
- ğŸ§‘ğŸ»â€ğŸ’»Â [OpenAI] [Memory and new controls for ChatGPT](https://openai.com/blog/memory-and-new-controls-for-chatgpt)
    - ChatGPTë¥¼ ì´ìš©í•  ë•Œ ê³¼ê±°ì˜ ì±„íŒ… ë‚´ì—­ì„ í˜„ì¬ ì±„íŒ…ì—ì„œì˜ memoryë¡œ í™œìš©í•˜ì—¬ ê°œì¸ ë§ì¶¤ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆë‹¤. ì•„ì§ ì¼ë¶€ ìœ ì € ëŒ€ìƒìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì¤‘ì¸ ê¸°ëŠ¥.
- ğŸ§‘ğŸ»â€ğŸ’»Â [NVIDIA] [Say What? Chat With RTX Brings Custom Chatbot to NVIDIA RTX AI PCs](https://blogs.nvidia.com/blog/chat-with-rtx-available-now/)
- ğŸ—ï¸Â [Nvidia briefly beats Amazon and nears Alphabetâ€™s market cap amid AI hype](https://aibeat.co/nvidia-briefly-beats-amazon-in-market-value/)
- ğŸ§‘ğŸ»â€ğŸ’»Â [DeepLearning.AI] [Serverless LLM apps with Amazon Bedrock](https://www.deeplearning.ai/short-courses/serverless-llm-apps-amazon-bedrock/)
- ğŸ“œÂ [On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks](https://arxiv.org/abs/2402.08115)
- ğŸ“œÂ [Google DeepMind] [Transformers Can Achieve Length Generalization But Not Robustly](https://arxiv.org/abs/2402.09371)
    - íŠ¸ëœìŠ¤í¬ë¨¸ë„ ì œí•œì ìœ¼ë¡œ ì…ë ¥ ê¸¸ì´ë¥¼ ëŠ˜ë¦´(extrapolate) ìˆ˜ ìˆë‹¤. (ì•½ 2.5ë°°). í•˜ì§€ë§Œ ì¼ë°˜í™” ê°€ëŠ¥í•œ ì„¸íŒ…ì€ ì•„ë‹˜.
- ğŸ“œÂ [Google DeepMind] [Chain-of-Thought Reasoning Without Prompting](https://arxiv.org/abs/2402.10200)
    - ë§ ê·¸ëŒ€ë¡œ í”„ë¡¬í”„íŠ¸ ì—†ì´ CoT Reasoningì„ ìœ ë„í•  ìˆ˜ ìˆë‹¤. Decoding processë¥¼ ì¡°ì •í•¨
- ğŸ§‘ğŸ»â€ğŸ’»Â [Google] [Our next-generation model: Gemini 1.5](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/)
    - ë¬´ë ¤ ì…ë ¥ì„ 1M í† í°ìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆë‹¤ê³  ì£¼ì¥í•˜ëŠ” Gemini 1.5 ë²„ì „ì´ ë“±ì¥. ë°°í¬ ì¤€ë¹„ëŠ” ë˜ì—ˆìœ¼ë‚˜ ì•„ì§ ë°°í¬í•˜ì§€ ì•Šì€ ê²ƒìœ¼ë¡œ ì•Œë ¤ì§.
- ğŸ§‘ğŸ»â€ğŸ’»Â [OpenAI] [Sora: Creating video from text](https://openai.com/sora)
    - OpenAIì—ì„œ ë§Œë“  ìµœì´ˆì˜ Text-to-Video ëª¨ë¸. ì…ì´ ë–¡ ë²Œì–´ì§ˆ ì •ë„ì˜ ì„±ëŠ¥ìœ¼ë¡œ ì—¬ëŸ¬ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ í™”ì œë¥¼ ë¶ˆëŸ¬ì¼ìœ¼í‚¤ëŠ” ì¤‘.
- ğŸ“œÂ [Apple] [Guiding Instruction-based Image Editing via Multimodal Large Language Models](https://arxiv.org/abs/2309.17102)
    - ì´ë¯¸ì§€ í¸ì§‘ì— ìˆì–´ì„œ ì „ë¬¸ì ì¸ ì§€ì‹ ì—†ì´ í…ìŠ¤íŠ¸ë§Œì„ ì´ìš©í•˜ëŠ”ë° ê·¸ ê²°ê³¼ë¬¼ì´ ì•„ì£¼ ë›°ì–´ë‚¨. ICLRâ€™24 Spotlight ë…¼ë¬¸.
- ğŸ“œÂ [Using Counterfactual Tasks to Evaluate the Generality of Analogical Reasoning in Large Language Models](https://arxiv.org/abs/2402.08955)
- ğŸ—ï¸Â [Slack AI is here, letting you catch up on lengthy threads and unread messages](https://www.theverge.com/2024/2/14/24070590/slack-ai-launch-thread-summaries-search-recap)
    - ì½ì§€ ì•Šì€ ìŠ¤ë ˆë“œ ìš”ì•½ ê¸°ëŠ¥. ì•„ì§ UK & USì—ì„œë§Œ ì´ìš© ê°€ëŠ¥
- ğŸ“œÂ [Google DeepMind & Research] [A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts](https://arxiv.org/abs/2402.09727)
    - [gist memories]ì— ì—í”¼ì†Œë“œë¥¼ ì €ì¥í•˜ì—¬ ReadAgentê°€ taskì™€ ê´€ë ¨ ìˆëŠ” ì •ë³´ë¥¼ ë¹ ë¥´ê²Œ ê°€ì ¸ì˜¤ë„ë¡ í•˜ëŠ” ë°©ì‹. ì‚¬ëŒì´ ê¸´ ê¸€ì„ ì½ëŠ” ë°©ì‹ì—ì„œ ì°©ì•ˆ.
- ğŸ“œÂ [DoRA: Weight-Decomposed Low-Rank Adaptation](https://arxiv.org/abs/2402.09353)
    - LoRAì™€ FT ì‚¬ì´ì˜ gapì„ ì¤„ì´ê¸° ìœ„í•´ pre-trained weightë¥¼ magnitudeì™€ directionìœ¼ë¡œ ë¶„í•´í•˜ëŠ” ë°©ë²•ì„ ë„ì…
- ğŸ“œÂ [Can We Verify Step by Step for Incorrect Answer Detection?](https://arxiv.org/abs/2402.10528)
    - CoTì˜ ê° stepì— ëŒ€í•´ process discernibility score (PDS)ë¥¼ êµ¬í•˜ì—¬ answer-checking baselineì„ ì œê³µ
- ğŸ§‘ğŸ»â€ğŸ’»Â [minbpe](https://github.com/karpathy/minbpe)
    - Karpathyê°€ OpenAIë¥¼ í‡´ì‚¬í•˜ë©° ê³µê°œí•œ BPE ì½”ë“œ. ë‚˜ë§Œì˜ í† í¬ë‚˜ì´ì €ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤.
- ğŸ§‘ğŸ»â€ğŸ’»Â [Meta] [V-JEPA](https://ai.meta.com/research/publications/revisiting-feature-prediction-for-learning-visual-representations-from-video/)
    - ì•„ì£¼ ì ì€ ì–‘ì˜ labeled dataë¡œ self-superviseí•œ ëª¨ë¸ë¡œ, ìƒì„±í˜•ì´ ì•„ë‹˜. ìƒˆë¡œìš´ ì»¨ì…‰ Joint Embedding Predictive Architectureë¥¼ ì œì•ˆ.
</details>

<details>
  <summary>4th week</summary>
  
- ğŸ“œÂ [Linear Transformers with Learnable Kernel Functions are Better In-Context Models](https://arxiv.org/abs/2402.10644)
  - Transformer ê¸°ë°˜ì˜ ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ì„ ëŠ¥ê°€í•œë‹¤ê³  ì œì•ˆë˜ì—ˆë˜ State Space Modelsì—ê²Œ ë¶€ì¡±í•œ In-Context Learning ëŠ¥ë ¥ì„ ì±„ì›Œì£¼ê¸° ìœ„í•œ ë°©ë²•ì„ ë„ì…. Taylor Expansionì„ í™œìš©.
- ğŸ“œÂ [DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows](https://arxiv.org/abs/2402.10379)
    - LLM í•™ìŠµì— í™œìš©ë˜ëŠ” ë°ì´í„°ì…‹ ê´€ë ¨ ì›Œí¬ í”Œë¡œìš°ë¥¼ ì¬í˜„ ê°€ëŠ¥í•˜ë„ë¡ ë„ì™€ì£¼ëŠ” í”„ë ˆì„ì›Œí¬. íŠ¹íˆ í•©ì„± ë°ì´í„° ìƒì„±ì´ í¬í•¨ëœ ê²ƒì´ íŠ¹ì§•.
- ğŸ“œÂ [AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://arxiv.org/abs/2402.12226)
    - ìŒì„±, í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ìŒì•…ì„ discrete tokenìœ¼ë¡œ ì…ë ¥ ë°›ì•„ autoregressiveí•˜ê²Œ ì²˜ë¦¬í•˜ëŠ” ë©€í‹°ëª¨ë‹¬ ëª¨ë¸. ë°ì´í„° ìˆ˜ì¤€ì˜ ì „ì²˜ë¦¬ë§Œ í•„ìš”.
- ğŸ“œÂ [Direct Evaluation of Chain-of-Thought in Multi-hop Reasoning with Knowledge Graphs](https://arxiv.org/abs/2402.11199)
    - Knowledge Graphë¥¼ í™œìš©í•˜ì—¬ ì˜¬ë°”ë¥¸ ì¶”ë¡  ê³¼ì •ì„ í†µí•´ ìµœì¢… ì •ë‹µì´ ë„ì¶œë˜ì—ˆëŠ”ì§€ ê²€ì¦
- ğŸ“œÂ [Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models](https://arxiv.org/abs/2402.11140)
    - Tree of Thoughtsë¥¼ ë°˜ë³µì ìœ¼ë¡œ trial-and-error ê³¼ì •ì— í¬í•¨ì‹œì¼œ ìµœì¢… ê²°ê³¼ë¥¼ ë„ì¶œí•´ë‚´ëŠ” ë°©ì‹
- ğŸ—ï¸Â [SoftBankâ€™s Masayoshi Son is reportedly seeking $100B to build a new AI chip venture](https://techcrunch.com/2024/02/19/softbanks-masayoshi-son-is-reportedly-seeking-100b-to-build-a-new-ai-chip-venture/)
    - ì†Œí”„íŠ¸ë±…í¬ ì†ì •ì˜ íšŒì¥ì´ ìƒˆë¡œìš´ AI ì¹© ê°œë°œì„ ìœ„í•´ 133ì¡° ê·œëª¨ì˜ ìê¸ˆì„ ëª¨ì§‘
- ğŸ“œÂ [The FinBen: An Holistic Financial Benchmark for Large Language Models](https://arxiv.org/abs/2402.12659)
    - ê¸ˆìœµ ë„ë©”ì¸ ì˜¤í”ˆ ì†ŒìŠ¤ ë²¤ì¹˜ë§ˆí¬
- ğŸ§‘ğŸ»â€ğŸ’»Â [cosmopedia](https://huggingface.co/datasets/HuggingFaceTB/cosmopedia)
    - Mistral-8x7B-Instruct-v0.1ì— ì˜í•´ ìƒì„±ëœ textbooks, blogposts, stories, post, WikiHow articles í•©ì„± ë°ì´í„°ì…‹. 30M files, 25B tokens
- ğŸ§‘ğŸ»â€ğŸ’»Â [Andrej Karphathy] [Letâ€™s build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE)
    - ìµœê·¼ ê³µê°œí•œ GPT Tokenizerì™€ ê´€ë ¨í•´ì„œ ì¹´íŒŒì‹œê°€ ì§ì ‘ ì´¬ì˜í•œ 2ì‹œê°„ ë¶„ëŸ‰ì˜ ê°•ì˜ ì˜ìƒ
- ğŸ“œÂ [Microsoft] [Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for Language Models](https://arxiv.org/abs/2402.13064)
    - human knowledgeì™€ capabilityì— ê´€í•œ taxonomyë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê³  ì´ë¥¼ decomposition â†’ recombineí•˜ì—¬ ë‹¤ì•™í–” instruction dataë¥¼ ìƒì„±
- ğŸ§‘ğŸ»â€ğŸ’» [Google DeepMind] [Gemma: Introducing new state-of-the-art open models](https://blog.google/technology/developers/gemma-open-models/)
    - 6T í† í°ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ì˜¤í”ˆ ì†ŒìŠ¤ë¡œ ê³µê°œí•œ 2B, 7B ëª¨ë¸. instruction versionë„ ìˆìŒ.
</details>
